#!/bin/bash
#
#SBATCH --job-name="Test-UniXCoder"
#SBATCH --partition=gpu
#SBATCH --time=08:00:00
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=24
#SBATCH --gpus-per-task=2
#SBATCH --mem-per-cpu=1G
#SBATCH --account=education-eemcs-courses-in4334

module load 2022r2
module load openmpi
module load py-torch
module load py-numpy
module load py-scikit-learn
module load py-pip

echo "-> Starting python download" >> "meta-test-result.txt"

python -m pip install --user transformers >> "meta-test-result.txt"

echo "---Starting script:  $(date '+%X')" >> "meta-test-result.txt"
srun python run.py --output_dir=./saved_models --model_type=roberta --tokenizer_name=microsoft/unixcoder-base-nine --model_name_or_path=microsoft/unixcoder-base-nine --do_eval --do_test --train_data_file=../dataset/train.jsonl --eval_data_file=../dataset/valid.jsonl --test_data_file=../dataset/test.jsonl --epoch 5 --block_size 400 --train_batch_size 32 --eval_batch_size 64 --learning_rate 2e-5 --max_grad_norm 1.0 --evaluate_during_training --seed 123456 > test.log 2>&1
echo "done ($(date '+%X'))... \n--------------------"