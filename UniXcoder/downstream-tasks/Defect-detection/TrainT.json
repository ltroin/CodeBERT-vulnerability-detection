{"func": "int _gnutls_ciphertext2compressed(gnutls_session_t session,\n\t\t\t\t  opaque * compress_data,\n\t\t\t\t  int compress_size,\n\t\t\t\t  gnutls_datum_t ciphertext, uint8 type)\n{\n    uint8 MAC[MAX_HASH_SIZE];\n    uint16 c_length;\n    uint8 pad;\n    int length;\n    mac_hd_t td;\n    uint16 blocksize;\n    int ret, i, pad_failed = 0;\n    uint8 major, minor;\n    gnutls_protocol_t ver;\n    int hash_size =\n\t_gnutls_hash_get_algo_len(session->security_parameters.\n\t\t\t\t  read_mac_algorithm);\n\n    ver = gnutls_protocol_get_version(session);\n    minor = _gnutls_version_get_minor(ver);\n    major = _gnutls_version_get_major(ver);\n\n    blocksize = _gnutls_cipher_get_block_size(session->security_parameters.\n\t\t\t\t\t      read_bulk_cipher_algorithm);\n\n    /* initialize MAC \n     */\n    td = mac_init(session->security_parameters.read_mac_algorithm,\n\t\t  session->connection_state.read_mac_secret.data,\n\t\t  session->connection_state.read_mac_secret.size, ver);\n\n    if (td == GNUTLS_MAC_FAILED\n\t&& session->security_parameters.read_mac_algorithm !=\n\tGNUTLS_MAC_NULL) {\n\tgnutls_assert();\n\treturn GNUTLS_E_INTERNAL_ERROR;\n    }\n\n\n    /* actual decryption (inplace)\n     */\n    switch (_gnutls_cipher_is_block\n\t    (session->security_parameters.read_bulk_cipher_algorithm)) {\n    case CIPHER_STREAM:\n\tif ((ret = _gnutls_cipher_decrypt(session->connection_state.\n\t\t\t\t\t  read_cipher_state,\n\t\t\t\t\t  ciphertext.data,\n\t\t\t\t\t  ciphertext.size)) < 0) {\n\t    gnutls_assert();\n\t    return ret;\n\t}\n\n\tlength = ciphertext.size - hash_size;\n\n\tbreak;\n    case CIPHER_BLOCK:\n\tif ((ciphertext.size < blocksize)\n\t    || (ciphertext.size % blocksize != 0)) {\n\t    gnutls_assert();\n\t    return GNUTLS_E_DECRYPTION_FAILED;\n\t}\n\n\tif ((ret = _gnutls_cipher_decrypt(session->connection_state.\n\t\t\t\t\t  read_cipher_state,\n\t\t\t\t\t  ciphertext.data,\n\t\t\t\t\t  ciphertext.size)) < 0) {\n\t    gnutls_assert();\n\t    return ret;\n\t}\n\n\t/* ignore the IV in TLS 1.1.\n\t */\n\tif (session->security_parameters.version >= GNUTLS_TLS1_1) {\n\t    ciphertext.size -= blocksize;\n\t    ciphertext.data += blocksize;\n\n\t    if (ciphertext.size == 0) {\n\t\tgnutls_assert();\n\t\treturn GNUTLS_E_DECRYPTION_FAILED;\n\t    }\n\t}\n\n\tpad = ciphertext.data[ciphertext.size - 1] + 1;\t/* pad */\n\n\tlength = ciphertext.size - hash_size - pad;\n\n\tif (pad > ciphertext.size - hash_size) {\n\t    gnutls_assert();\n\t    /* We do not fail here. We check below for the\n\t     * the pad_failed. If zero means success.\n\t     */\n\t    pad_failed = GNUTLS_E_DECRYPTION_FAILED;\n\t}\n\n\t/* Check the pading bytes (TLS 1.x)\n\t */\n\tif (ver >= GNUTLS_TLS1)\n\t    for (i = 2; i < pad; i++) {\n\t\tif (ciphertext.data[ciphertext.size - i] !=\n\t\t    ciphertext.data[ciphertext.size - 1])\n\t\t    pad_failed = GNUTLS_E_DECRYPTION_FAILED;\n\t    }\n\n\tbreak;\n    default:\n\tgnutls_assert();\n\treturn GNUTLS_E_INTERNAL_ERROR;\n    }\n\n    if (length < 0)\n\tlength = 0;\n    c_length = _gnutls_conv_uint16((uint16) length);\n\n    /* Pass the type, version, length and compressed through\n     * MAC.\n     */\n    if (td != GNUTLS_MAC_FAILED) {\n\t_gnutls_hmac(td,\n\t\t     UINT64DATA(session->connection_state.\n\t\t\t\tread_sequence_number), 8);\n\n\t_gnutls_hmac(td, &type, 1);\n\tif (ver >= GNUTLS_TLS1) {\t/* TLS 1.x */\n\t    _gnutls_hmac(td, &major, 1);\n\t    _gnutls_hmac(td, &minor, 1);\n\t}\n\t_gnutls_hmac(td, &c_length, 2);\n\n\tif (length > 0)\n\t    _gnutls_hmac(td, ciphertext.data, length);\n\n\tmac_deinit(td, MAC, ver);\n    }\n\n    /* This one was introduced to avoid a timing attack against the TLS\n     * 1.0 protocol.\n     */\n    if (pad_failed != 0)\n\treturn pad_failed;\n\n    /* HMAC was not the same. \n     */\n    if (memcmp(MAC, &ciphertext.data[length], hash_size) != 0) {\n\tgnutls_assert();\n\treturn GNUTLS_E_DECRYPTION_FAILED;\n    }\n\n    /* copy the decrypted stuff to compress_data.\n     */\n    if (compress_size < length) {\n\tgnutls_assert();\n\treturn GNUTLS_E_INTERNAL_ERROR;\n    }\n    memcpy(compress_data, ciphertext.data, length);\n\n    return length;\n}", "target": 1, "cwe": [], "project": "gnutls", "commit_id": "7ad6162573ba79a4392c63b453ad0220ca6c5ace", "hash": 73008646937836648589283922871188272089, "size": 157, "message": "added an extra check while checking the padding."}
{"func": "static char *make_filename_safe(const char *filename TSRMLS_DC)\n{\n\tif (*filename && strncmp(filename, \":memory:\", sizeof(\":memory:\")-1)) {\n\t\tchar *fullpath = expand_filepath(filename, NULL TSRMLS_CC);\n\n\t\tif (!fullpath) {\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (PG(safe_mode) && (!php_checkuid(fullpath, NULL, CHECKUID_CHECK_FILE_AND_DIR))) {\n\t\t\tefree(fullpath);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (php_check_open_basedir(fullpath TSRMLS_CC)) {\n\t\t\tefree(fullpath);\n\t\t\treturn NULL;\n\t\t}\n\t\treturn fullpath;\n\t}\n\treturn estrdup(filename);\n}", "target": 1, "cwe": ["CWE-264"], "project": "php-src", "commit_id": "055ecbc62878e86287d742c7246c21606cee8183", "hash": 211824207069112513181516095447837228041, "size": 22, "message": "Improve check for :memory: pseudo-filename in SQlite"}
{"func": "unpack_Z_stream(int fd_in, int fd_out)\n{\n\tIF_DESKTOP(long long total_written = 0;)\n\tIF_DESKTOP(long long) int retval = -1;\n\tunsigned char *stackp;\n\tlong code;\n\tint finchar;\n\tlong oldcode;\n\tlong incode;\n\tint inbits;\n\tint posbits;\n\tint outpos;\n\tint insize;\n\tint bitmask;\n\tlong free_ent;\n\tlong maxcode;\n\tlong maxmaxcode;\n\tint n_bits;\n\tint rsize = 0;\n\tunsigned char *inbuf; /* were eating insane amounts of stack - */\n\tunsigned char *outbuf; /* bad for some embedded targets */\n\tunsigned char *htab;\n\tunsigned short *codetab;\n\n\t/* Hmm, these were statics - why?! */\n\t/* user settable max # bits/code */\n\tint maxbits; /* = BITS; */\n\t/* block compress mode -C compatible with 2.0 */\n\tint block_mode; /* = BLOCK_MODE; */\n\n\tinbuf = xzalloc(IBUFSIZ + 64);\n\toutbuf = xzalloc(OBUFSIZ + 2048);\n\thtab = xzalloc(HSIZE);  /* wsn't zeroed out before, maybe can xmalloc? */\n\tcodetab = xzalloc(HSIZE * sizeof(codetab[0]));\n\n\tinsize = 0;\n\n\t/* xread isn't good here, we have to return - caller may want\n\t * to do some cleanup (e.g. delete incomplete unpacked file etc) */\n\tif (full_read(fd_in, inbuf, 1) != 1) {\n\t\tbb_error_msg(\"short read\");\n\t\tgoto err;\n\t}\n\n\tmaxbits = inbuf[0] & BIT_MASK;\n\tblock_mode = inbuf[0] & BLOCK_MODE;\n\tmaxmaxcode = MAXCODE(maxbits);\n\n\tif (maxbits > BITS) {\n\t\tbb_error_msg(\"compressed with %d bits, can only handle \"\n\t\t\t\tBITS_STR\" bits\", maxbits);\n\t\tgoto err;\n\t}\n\n\tn_bits = INIT_BITS;\n\tmaxcode = MAXCODE(INIT_BITS) - 1;\n\tbitmask = (1 << INIT_BITS) - 1;\n\toldcode = -1;\n\tfinchar = 0;\n\toutpos = 0;\n\tposbits = 0 << 3;\n\n\tfree_ent = ((block_mode) ? FIRST : 256);\n\n\t/* As above, initialize the first 256 entries in the table. */\n\t/*clear_tab_prefixof(); - done by xzalloc */\n\n\tfor (code = 255; code >= 0; --code) {\n\t\ttab_suffixof(code) = (unsigned char) code;\n\t}\n\n\tdo {\n resetbuf:\n\t\t{\n\t\t\tint i;\n\t\t\tint e;\n\t\t\tint o;\n\n\t\t\to = posbits >> 3;\n\t\t\te = insize - o;\n\n\t\t\tfor (i = 0; i < e; ++i)\n\t\t\t\tinbuf[i] = inbuf[i + o];\n\n\t\t\tinsize = e;\n\t\t\tposbits = 0;\n\t\t}\n\n\t\tif (insize < (int) (IBUFSIZ + 64) - IBUFSIZ) {\n\t\t\trsize = safe_read(fd_in, inbuf + insize, IBUFSIZ);\n//error check??\n\t\t\tinsize += rsize;\n\t\t}\n\n\t\tinbits = ((rsize > 0) ? (insize - insize % n_bits) << 3 :\n\t\t\t\t  (insize << 3) - (n_bits - 1));\n\n\t\twhile (inbits > posbits) {\n\t\t\tif (free_ent > maxcode) {\n\t\t\t\tposbits =\n\t\t\t\t\t((posbits - 1) +\n\t\t\t\t\t ((n_bits << 3) -\n\t\t\t\t\t  (posbits - 1 + (n_bits << 3)) % (n_bits << 3)));\n\t\t\t\t++n_bits;\n\t\t\t\tif (n_bits == maxbits) {\n\t\t\t\t\tmaxcode = maxmaxcode;\n\t\t\t\t} else {\n\t\t\t\t\tmaxcode = MAXCODE(n_bits) - 1;\n\t\t\t\t}\n\t\t\t\tbitmask = (1 << n_bits) - 1;\n\t\t\t\tgoto resetbuf;\n\t\t\t}\n\t\t\t{\n\t\t\t\tunsigned char *p = &inbuf[posbits >> 3];\n\n\t\t\t\tcode = ((((long) (p[0])) | ((long) (p[1]) << 8) |\n\t\t\t\t         ((long) (p[2]) << 16)) >> (posbits & 0x7)) & bitmask;\n\t\t\t}\n\t\t\tposbits += n_bits;\n\n\n\t\t\tif (oldcode == -1) {\n\t\t\t\toldcode = code;\n\t\t\t\tfinchar = (int) oldcode;\n\t\t\t\toutbuf[outpos++] = (unsigned char) finchar;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (code == CLEAR && block_mode) {\n\t\t\t\tclear_tab_prefixof();\n\t\t\t\tfree_ent = FIRST - 1;\n\t\t\t\tposbits =\n\t\t\t\t\t((posbits - 1) +\n\t\t\t\t\t ((n_bits << 3) -\n\t\t\t\t\t  (posbits - 1 + (n_bits << 3)) % (n_bits << 3)));\n\t\t\t\tn_bits = INIT_BITS;\n\t\t\t\tmaxcode = MAXCODE(INIT_BITS) - 1;\n\t\t\t\tbitmask = (1 << INIT_BITS) - 1;\n\t\t\t\tgoto resetbuf;\n\t\t\t}\n\n\t\t\tincode = code;\n\t\t\tstackp = de_stack;\n\n\t\t\t/* Special case for KwKwK string. */\n\t\t\tif (code >= free_ent) {\n\t\t\t\tif (code > free_ent) {\n\t\t\t\t\tunsigned char *p;\n\n\t\t\t\t\tposbits -= n_bits;\n\t\t\t\t\tp = &inbuf[posbits >> 3];\n\n\t\t\t\t\tbb_error_msg\n\t\t\t\t\t\t(\"insize:%d posbits:%d inbuf:%02X %02X %02X %02X %02X (%d)\",\n\t\t\t\t\t\t insize, posbits, p[-1], p[0], p[1], p[2], p[3],\n\t\t\t\t\t\t (posbits & 07));\n\t\t\t\t\tbb_error_msg(\"corrupted data\");\n\t\t\t\t\tgoto err;\n\t\t\t\t}\n\n\t\t\t\t*--stackp = (unsigned char) finchar;\n\t\t\t\tcode = oldcode;\n\t\t\t}\n\n\t\t\t/* Generate output characters in reverse order */\n\t\t\twhile ((long) code >= (long) 256) {\n\t\t\t\t*--stackp = tab_suffixof(code);\n\t\t\t\tcode = tab_prefixof(code);\n\t\t\t}\n\n\t\t\tfinchar = tab_suffixof(code);\n\t\t\t*--stackp = (unsigned char) finchar;\n\n\t\t\t/* And put them out in forward order */\n\t\t\t{\n\t\t\t\tint i;\n\n\t\t\t\ti = de_stack - stackp;\n\t\t\t\tif (outpos + i >= OBUFSIZ) {\n\t\t\t\t\tdo {\n\t\t\t\t\t\tif (i > OBUFSIZ - outpos) {\n\t\t\t\t\t\t\ti = OBUFSIZ - outpos;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif (i > 0) {\n\t\t\t\t\t\t\tmemcpy(outbuf + outpos, stackp, i);\n\t\t\t\t\t\t\toutpos += i;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif (outpos >= OBUFSIZ) {\n\t\t\t\t\t\t\tfull_write(fd_out, outbuf, outpos);\n//error check??\n\t\t\t\t\t\t\tIF_DESKTOP(total_written += outpos;)\n\t\t\t\t\t\t\toutpos = 0;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tstackp += i;\n\t\t\t\t\t\ti = de_stack - stackp;\n\t\t\t\t\t} while (i > 0);\n\t\t\t\t} else {\n\t\t\t\t\tmemcpy(outbuf + outpos, stackp, i);\n\t\t\t\t\toutpos += i;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t/* Generate the new entry. */\n\t\t\tcode = free_ent;\n\t\t\tif (code < maxmaxcode) {\n\t\t\t\ttab_prefixof(code) = (unsigned short) oldcode;\n\t\t\t\ttab_suffixof(code) = (unsigned char) finchar;\n\t\t\t\tfree_ent = code + 1;\n\t\t\t}\n\n\t\t\t/* Remember previous code.  */\n\t\t\toldcode = incode;\n\t\t}\n\n\t} while (rsize > 0);\n\n\tif (outpos > 0) {\n\t\tfull_write(fd_out, outbuf, outpos);\n//error check??\n\t\tIF_DESKTOP(total_written += outpos;)\n\t}\n\n\tretval = IF_DESKTOP(total_written) + 0;\n err:\n\tfree(inbuf);\n\tfree(outbuf);\n\tfree(htab);\n\tfree(codetab);\n\treturn retval;\n}", "target": 1, "cwe": [], "project": "busybox", "commit_id": "251fc70e9722f931eec23a34030d05ba5f747b0e", "hash": 21401706257394042943815500829552774160, "size": 232, "message": "uncompress: fix buffer underrun by corrupted input\n\nSigned-off-by: Denys Vlasenko <vda.linux@googlemail.com>"}
{"func": "static void cirrus_do_copy(CirrusVGAState *s, int dst, int src, int w, int h)\n{\n    int sx, sy;\n    int dx, dy;\n    int width, height;\n    int depth;\n    int notify = 0;\n\n    depth = s->get_bpp((VGAState *)s) / 8;\n    s->get_resolution((VGAState *)s, &width, &height);\n\n    /* extra x, y */\n    sx = (src % (width * depth)) / depth;\n    sy = (src / (width * depth));\n    dx = (dst % (width *depth)) / depth;\n    dy = (dst / (width * depth));\n\n    /* normalize width */\n    w /= depth;\n\n    /* if we're doing a backward copy, we have to adjust\n       our x/y to be the upper left corner (instead of the lower\n       right corner) */\n    if (s->cirrus_blt_dstpitch < 0) {\n\tsx -= (s->cirrus_blt_width / depth) - 1;\n\tdx -= (s->cirrus_blt_width / depth) - 1;\n\tsy -= s->cirrus_blt_height - 1;\n\tdy -= s->cirrus_blt_height - 1;\n    }\n\n    /* are we in the visible portion of memory? */\n    if (sx >= 0 && sy >= 0 && dx >= 0 && dy >= 0 &&\n\t(sx + w) <= width && (sy + h) <= height &&\n\t(dx + w) <= width && (dy + h) <= height) {\n\tnotify = 1;\n    }\n\n    /* make to sure only copy if it's a plain copy ROP */\n    if (*s->cirrus_rop != cirrus_bitblt_rop_fwd_src &&\n\t*s->cirrus_rop != cirrus_bitblt_rop_bkwd_src)\n\tnotify = 0;\n\n    /* we have to flush all pending changes so that the copy\n       is generated at the appropriate moment in time */\n    if (notify)\n\tvga_hw_update();\n\n    (*s->cirrus_rop) (s, s->vram_ptr + s->cirrus_blt_dstaddr,\n\t\t      s->vram_ptr + s->cirrus_blt_srcaddr,\n\t\t      s->cirrus_blt_dstpitch, s->cirrus_blt_srcpitch,\n\t\t      s->cirrus_blt_width, s->cirrus_blt_height);\n\n    if (notify)\n\ts->ds->dpy_copy(s->ds,\n\t\t\tsx, sy, dx, dy,\n\t\t\ts->cirrus_blt_width / depth,\n\t\t\ts->cirrus_blt_height);\n\n    /* we don't have to notify the display that this portion has\n       changed since dpy_copy implies this */\n\n    if (!notify)\n\tcirrus_invalidate_region(s, s->cirrus_blt_dstaddr,\n\t\t\t\t s->cirrus_blt_dstpitch, s->cirrus_blt_width,\n\t\t\t\t s->cirrus_blt_height);\n}", "target": 1, "cwe": ["CWE-787"], "project": "qemu", "commit_id": "b2eb849d4b1fdb6f35d5c46958c7f703cf64cfef", "hash": 135590882627853658533498335902319684573, "size": 66, "message": "CVE-2007-1320 - Cirrus LGD-54XX \"bitblt\" heap overflow\n\nI have just noticed that patch for CVE-2007-1320 has never been applied\nto the QEMU CVS. Please find it below.\n\n| Multiple heap-based buffer overflows in the cirrus_invalidate_region\n| function in the Cirrus VGA extension in QEMU 0.8.2, as used in Xen and\n| possibly other products, might allow local users to execute arbitrary\n| code via unspecified vectors related to \"attempting to mark\n| non-existent regions as dirty,\" aka the \"bitblt\" heap overflow.\n\n\ngit-svn-id: svn://svn.savannah.nongnu.org/qemu/trunk@4340 c046a42c-6fe2-441c-8c8c-71466251a162"}
{"func": "glue(cirrus_bitblt_rop_fwd_, ROP_NAME)(CirrusVGAState *s,\n                             uint8_t *dst,const uint8_t *src,\n                             int dstpitch,int srcpitch,\n                             int bltwidth,int bltheight)\n{\n    int x,y;\n    dstpitch -= bltwidth;\n    srcpitch -= bltwidth;\n    for (y = 0; y < bltheight; y++) {\n        for (x = 0; x < bltwidth; x++) {\n            ROP_OP(*dst, *src);\n            dst++;\n            src++;\n        }\n        dst += dstpitch;\n        src += srcpitch;\n    }\n}", "target": 1, "cwe": ["CWE-787"], "project": "qemu", "commit_id": "b2eb849d4b1fdb6f35d5c46958c7f703cf64cfef", "hash": 27696392987383562433164405181263025184, "size": 18, "message": "CVE-2007-1320 - Cirrus LGD-54XX \"bitblt\" heap overflow\n\nI have just noticed that patch for CVE-2007-1320 has never been applied\nto the QEMU CVS. Please find it below.\n\n| Multiple heap-based buffer overflows in the cirrus_invalidate_region\n| function in the Cirrus VGA extension in QEMU 0.8.2, as used in Xen and\n| possibly other products, might allow local users to execute arbitrary\n| code via unspecified vectors related to \"attempting to mark\n| non-existent regions as dirty,\" aka the \"bitblt\" heap overflow.\n\n\ngit-svn-id: svn://svn.savannah.nongnu.org/qemu/trunk@4340 c046a42c-6fe2-441c-8c8c-71466251a162"}
{"func": "static int cirrus_bitblt_videotovideo_copy(CirrusVGAState * s)\n{\n    if (s->ds->dpy_copy) {\n\tcirrus_do_copy(s, s->cirrus_blt_dstaddr - s->start_addr,\n\t\t       s->cirrus_blt_srcaddr - s->start_addr,\n\t\t       s->cirrus_blt_width, s->cirrus_blt_height);\n    } else {\n\t(*s->cirrus_rop) (s, s->vram_ptr + s->cirrus_blt_dstaddr,\n\t\t\t  s->vram_ptr + s->cirrus_blt_srcaddr,\n\t\t\t  s->cirrus_blt_dstpitch, s->cirrus_blt_srcpitch,\n\t\t\t  s->cirrus_blt_width, s->cirrus_blt_height);\n\n\tcirrus_invalidate_region(s, s->cirrus_blt_dstaddr,\n\t\t\t\t s->cirrus_blt_dstpitch, s->cirrus_blt_width,\n\t\t\t\t s->cirrus_blt_height);\n    }\n\n    return 1;\n}", "target": 1, "cwe": ["CWE-787"], "project": "qemu", "commit_id": "b2eb849d4b1fdb6f35d5c46958c7f703cf64cfef", "hash": 331046290845234389374470092408344022350, "size": 19, "message": "CVE-2007-1320 - Cirrus LGD-54XX \"bitblt\" heap overflow\n\nI have just noticed that patch for CVE-2007-1320 has never been applied\nto the QEMU CVS. Please find it below.\n\n| Multiple heap-based buffer overflows in the cirrus_invalidate_region\n| function in the Cirrus VGA extension in QEMU 0.8.2, as used in Xen and\n| possibly other products, might allow local users to execute arbitrary\n| code via unspecified vectors related to \"attempting to mark\n| non-existent regions as dirty,\" aka the \"bitblt\" heap overflow.\n\n\ngit-svn-id: svn://svn.savannah.nongnu.org/qemu/trunk@4340 c046a42c-6fe2-441c-8c8c-71466251a162"}
{"func": "static void cirrus_mem_writeb_mode4and5_8bpp(CirrusVGAState * s,\n\t\t\t\t\t     unsigned mode,\n\t\t\t\t\t     unsigned offset,\n\t\t\t\t\t     uint32_t mem_value)\n{\n    int x;\n    unsigned val = mem_value;\n    uint8_t *dst;\n\n    dst = s->vram_ptr + offset;\n    for (x = 0; x < 8; x++) {\n\tif (val & 0x80) {\n\t    *dst = s->cirrus_shadow_gr1;\n\t} else if (mode == 5) {\n\t    *dst = s->cirrus_shadow_gr0;\n\t}\n\tval <<= 1;\n\tdst++;\n    }\n    cpu_physical_memory_set_dirty(s->vram_offset + offset);\n    cpu_physical_memory_set_dirty(s->vram_offset + offset + 7);\n}", "target": 1, "cwe": ["CWE-787"], "project": "qemu", "commit_id": "b2eb849d4b1fdb6f35d5c46958c7f703cf64cfef", "hash": 50418188797463436407734640880675508745, "size": 22, "message": "CVE-2007-1320 - Cirrus LGD-54XX \"bitblt\" heap overflow\n\nI have just noticed that patch for CVE-2007-1320 has never been applied\nto the QEMU CVS. Please find it below.\n\n| Multiple heap-based buffer overflows in the cirrus_invalidate_region\n| function in the Cirrus VGA extension in QEMU 0.8.2, as used in Xen and\n| possibly other products, might allow local users to execute arbitrary\n| code via unspecified vectors related to \"attempting to mark\n| non-existent regions as dirty,\" aka the \"bitblt\" heap overflow.\n\n\ngit-svn-id: svn://svn.savannah.nongnu.org/qemu/trunk@4340 c046a42c-6fe2-441c-8c8c-71466251a162"}
{"func": "static int cirrus_bitblt_common_patterncopy(CirrusVGAState * s,\n\t\t\t\t\t    const uint8_t * src)\n{\n    uint8_t *dst;\n\n    dst = s->vram_ptr + s->cirrus_blt_dstaddr;\n    (*s->cirrus_rop) (s, dst, src,\n                      s->cirrus_blt_dstpitch, 0,\n                      s->cirrus_blt_width, s->cirrus_blt_height);\n    cirrus_invalidate_region(s, s->cirrus_blt_dstaddr,\n                             s->cirrus_blt_dstpitch, s->cirrus_blt_width,\n                             s->cirrus_blt_height);\n    return 1;\n}", "target": 1, "cwe": ["CWE-787"], "project": "qemu", "commit_id": "b2eb849d4b1fdb6f35d5c46958c7f703cf64cfef", "hash": 176630228639235556421341667256894067184, "size": 14, "message": "CVE-2007-1320 - Cirrus LGD-54XX \"bitblt\" heap overflow\n\nI have just noticed that patch for CVE-2007-1320 has never been applied\nto the QEMU CVS. Please find it below.\n\n| Multiple heap-based buffer overflows in the cirrus_invalidate_region\n| function in the Cirrus VGA extension in QEMU 0.8.2, as used in Xen and\n| possibly other products, might allow local users to execute arbitrary\n| code via unspecified vectors related to \"attempting to mark\n| non-existent regions as dirty,\" aka the \"bitblt\" heap overflow.\n\n\ngit-svn-id: svn://svn.savannah.nongnu.org/qemu/trunk@4340 c046a42c-6fe2-441c-8c8c-71466251a162"}
{"func": "static void cirrus_invalidate_region(CirrusVGAState * s, int off_begin,\n\t\t\t\t     int off_pitch, int bytesperline,\n\t\t\t\t     int lines)\n{\n    int y;\n    int off_cur;\n    int off_cur_end;\n\n    for (y = 0; y < lines; y++) {\n\toff_cur = off_begin;\n\toff_cur_end = off_cur + bytesperline;\n\toff_cur &= TARGET_PAGE_MASK;\n\twhile (off_cur < off_cur_end) {\n\t    cpu_physical_memory_set_dirty(s->vram_offset + off_cur);\n\t    off_cur += TARGET_PAGE_SIZE;\n\t}\n\toff_begin += off_pitch;\n    }\n}", "target": 1, "cwe": ["CWE-787"], "project": "qemu", "commit_id": "b2eb849d4b1fdb6f35d5c46958c7f703cf64cfef", "hash": 335738960224286063332470333845363880021, "size": 19, "message": "CVE-2007-1320 - Cirrus LGD-54XX \"bitblt\" heap overflow\n\nI have just noticed that patch for CVE-2007-1320 has never been applied\nto the QEMU CVS. Please find it below.\n\n| Multiple heap-based buffer overflows in the cirrus_invalidate_region\n| function in the Cirrus VGA extension in QEMU 0.8.2, as used in Xen and\n| possibly other products, might allow local users to execute arbitrary\n| code via unspecified vectors related to \"attempting to mark\n| non-existent regions as dirty,\" aka the \"bitblt\" heap overflow.\n\n\ngit-svn-id: svn://svn.savannah.nongnu.org/qemu/trunk@4340 c046a42c-6fe2-441c-8c8c-71466251a162"}
{"func": "static int cirrus_bitblt_videotovideo_patterncopy(CirrusVGAState * s)\n{\n    return cirrus_bitblt_common_patterncopy(s,\n\t\t\t\t\t    s->vram_ptr +\n                                            (s->cirrus_blt_srcaddr & ~7));\n}", "target": 1, "cwe": ["CWE-787"], "project": "qemu", "commit_id": "b2eb849d4b1fdb6f35d5c46958c7f703cf64cfef", "hash": 58384268221957848687614989550830035306, "size": 6, "message": "CVE-2007-1320 - Cirrus LGD-54XX \"bitblt\" heap overflow\n\nI have just noticed that patch for CVE-2007-1320 has never been applied\nto the QEMU CVS. Please find it below.\n\n| Multiple heap-based buffer overflows in the cirrus_invalidate_region\n| function in the Cirrus VGA extension in QEMU 0.8.2, as used in Xen and\n| possibly other products, might allow local users to execute arbitrary\n| code via unspecified vectors related to \"attempting to mark\n| non-existent regions as dirty,\" aka the \"bitblt\" heap overflow.\n\n\ngit-svn-id: svn://svn.savannah.nongnu.org/qemu/trunk@4340 c046a42c-6fe2-441c-8c8c-71466251a162"}
{"func": "static int cirrus_bitblt_solidfill(CirrusVGAState *s, int blt_rop)\n{\n    cirrus_fill_t rop_func;\n\n    rop_func = cirrus_fill[rop_to_index[blt_rop]][s->cirrus_blt_pixelwidth - 1];\n    rop_func(s, s->vram_ptr + s->cirrus_blt_dstaddr,\n             s->cirrus_blt_dstpitch,\n             s->cirrus_blt_width, s->cirrus_blt_height);\n    cirrus_invalidate_region(s, s->cirrus_blt_dstaddr,\n\t\t\t     s->cirrus_blt_dstpitch, s->cirrus_blt_width,\n\t\t\t     s->cirrus_blt_height);\n    cirrus_bitblt_reset(s);\n    return 1;\n}", "target": 1, "cwe": ["CWE-787"], "project": "qemu", "commit_id": "b2eb849d4b1fdb6f35d5c46958c7f703cf64cfef", "hash": 149842811940934737817714037905575936616, "size": 14, "message": "CVE-2007-1320 - Cirrus LGD-54XX \"bitblt\" heap overflow\n\nI have just noticed that patch for CVE-2007-1320 has never been applied\nto the QEMU CVS. Please find it below.\n\n| Multiple heap-based buffer overflows in the cirrus_invalidate_region\n| function in the Cirrus VGA extension in QEMU 0.8.2, as used in Xen and\n| possibly other products, might allow local users to execute arbitrary\n| code via unspecified vectors related to \"attempting to mark\n| non-existent regions as dirty,\" aka the \"bitblt\" heap overflow.\n\n\ngit-svn-id: svn://svn.savannah.nongnu.org/qemu/trunk@4340 c046a42c-6fe2-441c-8c8c-71466251a162"}
{"func": "static void cirrus_bitblt_cputovideo_next(CirrusVGAState * s)\n{\n    int copy_count;\n    uint8_t *end_ptr;\n\n    if (s->cirrus_srccounter > 0) {\n        if (s->cirrus_blt_mode & CIRRUS_BLTMODE_PATTERNCOPY) {\n            cirrus_bitblt_common_patterncopy(s, s->cirrus_bltbuf);\n        the_end:\n            s->cirrus_srccounter = 0;\n            cirrus_bitblt_reset(s);\n        } else {\n            /* at least one scan line */\n            do {\n                (*s->cirrus_rop)(s, s->vram_ptr + s->cirrus_blt_dstaddr,\n                                 s->cirrus_bltbuf, 0, 0, s->cirrus_blt_width, 1);\n                cirrus_invalidate_region(s, s->cirrus_blt_dstaddr, 0,\n                                         s->cirrus_blt_width, 1);\n                s->cirrus_blt_dstaddr += s->cirrus_blt_dstpitch;\n                s->cirrus_srccounter -= s->cirrus_blt_srcpitch;\n                if (s->cirrus_srccounter <= 0)\n                    goto the_end;\n                /* more bytes than needed can be transfered because of\n                   word alignment, so we keep them for the next line */\n                /* XXX: keep alignment to speed up transfer */\n                end_ptr = s->cirrus_bltbuf + s->cirrus_blt_srcpitch;\n                copy_count = s->cirrus_srcptr_end - end_ptr;\n                memmove(s->cirrus_bltbuf, end_ptr, copy_count);\n                s->cirrus_srcptr = s->cirrus_bltbuf + copy_count;\n                s->cirrus_srcptr_end = s->cirrus_bltbuf + s->cirrus_blt_srcpitch;\n            } while (s->cirrus_srcptr >= s->cirrus_srcptr_end);\n        }\n    }\n}", "target": 1, "cwe": ["CWE-787"], "project": "qemu", "commit_id": "b2eb849d4b1fdb6f35d5c46958c7f703cf64cfef", "hash": 246597330759913647803692062244246778621, "size": 34, "message": "CVE-2007-1320 - Cirrus LGD-54XX \"bitblt\" heap overflow\n\nI have just noticed that patch for CVE-2007-1320 has never been applied\nto the QEMU CVS. Please find it below.\n\n| Multiple heap-based buffer overflows in the cirrus_invalidate_region\n| function in the Cirrus VGA extension in QEMU 0.8.2, as used in Xen and\n| possibly other products, might allow local users to execute arbitrary\n| code via unspecified vectors related to \"attempting to mark\n| non-existent regions as dirty,\" aka the \"bitblt\" heap overflow.\n\n\ngit-svn-id: svn://svn.savannah.nongnu.org/qemu/trunk@4340 c046a42c-6fe2-441c-8c8c-71466251a162"}
{"func": "static void cirrus_mem_writeb_mode4and5_16bpp(CirrusVGAState * s,\n\t\t\t\t\t      unsigned mode,\n\t\t\t\t\t      unsigned offset,\n\t\t\t\t\t      uint32_t mem_value)\n{\n    int x;\n    unsigned val = mem_value;\n    uint8_t *dst;\n\n    dst = s->vram_ptr + offset;\n    for (x = 0; x < 8; x++) {\n\tif (val & 0x80) {\n\t    *dst = s->cirrus_shadow_gr1;\n\t    *(dst + 1) = s->gr[0x11];\n\t} else if (mode == 5) {\n\t    *dst = s->cirrus_shadow_gr0;\n\t    *(dst + 1) = s->gr[0x10];\n\t}\n\tval <<= 1;\n\tdst += 2;\n    }\n    cpu_physical_memory_set_dirty(s->vram_offset + offset);\n    cpu_physical_memory_set_dirty(s->vram_offset + offset + 15);\n}", "target": 1, "cwe": ["CWE-787"], "project": "qemu", "commit_id": "b2eb849d4b1fdb6f35d5c46958c7f703cf64cfef", "hash": 241662835431977252361369897799666577695, "size": 24, "message": "CVE-2007-1320 - Cirrus LGD-54XX \"bitblt\" heap overflow\n\nI have just noticed that patch for CVE-2007-1320 has never been applied\nto the QEMU CVS. Please find it below.\n\n| Multiple heap-based buffer overflows in the cirrus_invalidate_region\n| function in the Cirrus VGA extension in QEMU 0.8.2, as used in Xen and\n| possibly other products, might allow local users to execute arbitrary\n| code via unspecified vectors related to \"attempting to mark\n| non-existent regions as dirty,\" aka the \"bitblt\" heap overflow.\n\n\ngit-svn-id: svn://svn.savannah.nongnu.org/qemu/trunk@4340 c046a42c-6fe2-441c-8c8c-71466251a162"}
{"func": "static int cirrus_bitblt_videotovideo_copy(CirrusVGAState * s)\n{\n    if (s->ds->dpy_copy) {\n\tcirrus_do_copy(s, s->cirrus_blt_dstaddr - s->start_addr,\n\t\t       s->cirrus_blt_srcaddr - s->start_addr,\n\t\t       s->cirrus_blt_width, s->cirrus_blt_height);\n    } else {\n\n    if (BLTUNSAFE(s))\n        return 0;\n\n\t(*s->cirrus_rop) (s, s->vram_ptr +\n                (s->cirrus_blt_dstaddr & s->cirrus_addr_mask),\n\t\t\t  s->vram_ptr +\n                (s->cirrus_blt_srcaddr & s->cirrus_addr_mask),\n\t\t\t  s->cirrus_blt_dstpitch, s->cirrus_blt_srcpitch,\n\t\t\t  s->cirrus_blt_width, s->cirrus_blt_height);\n\n\tcirrus_invalidate_region(s, s->cirrus_blt_dstaddr,\n\t\t\t\t s->cirrus_blt_dstpitch, s->cirrus_blt_width,\n\t\t\t\t s->cirrus_blt_height);\n    }\n\n    return 1;\n}", "target": 1, "cwe": ["CWE-787"], "project": "qemu", "commit_id": "65d35a09979e63541afc5bfc595b9f1b1b4ae069", "hash": 128516004862549772575527502984330639841, "size": 25, "message": "CVE-2008-4539: fix a heap overflow in Cirrus emulation\n\nThe code in hw/cirrus_vga.c has changed a lot between CVE-2007-1320 has\nbeen announced and the patch has been applied. As a consequence it has\nwrongly applied and QEMU is still vulnerable to this bug if using VNC.\n\n(noticed by Jan Niehusmann)\n\nSigned-off-by: Aurelien Jarno <aurelien@aurel32.net>\n\ngit-svn-id: svn://svn.savannah.nongnu.org/qemu/trunk@5587 c046a42c-6fe2-441c-8c8c-71466251a162"}
{"func": "asmlinkage long compat_sys_mount(char __user * dev_name, char __user * dir_name,\n\t\t\t\t char __user * type, unsigned long flags,\n\t\t\t\t void __user * data)\n{\n\tunsigned long type_page;\n\tunsigned long data_page;\n\tunsigned long dev_page;\n\tchar *dir_page;\n\tint retval;\n\n\tretval = copy_mount_options (type, &type_page);\n\tif (retval < 0)\n\t\tgoto out;\n\n\tdir_page = getname(dir_name);\n\tretval = PTR_ERR(dir_page);\n\tif (IS_ERR(dir_page))\n\t\tgoto out1;\n\n\tretval = copy_mount_options (dev_name, &dev_page);\n\tif (retval < 0)\n\t\tgoto out2;\n\n\tretval = copy_mount_options (data, &data_page);\n\tif (retval < 0)\n\t\tgoto out3;\n\n\tretval = -EINVAL;\n\n\tif (type_page) {\n\t\tif (!strcmp((char *)type_page, SMBFS_NAME)) {\n\t\t\tdo_smb_super_data_conv((void *)data_page);\n\t\t} else if (!strcmp((char *)type_page, NCPFS_NAME)) {\n\t\t\tdo_ncp_super_data_conv((void *)data_page);\n\t\t} else if (!strcmp((char *)type_page, NFS4_NAME)) {\n\t\t\tif (do_nfs4_super_data_conv((void *) data_page))\n\t\t\t\tgoto out4;\n\t\t}\n\t}\n\n\tlock_kernel();\n\tretval = do_mount((char*)dev_page, dir_page, (char*)type_page,\n\t\t\tflags, (void*)data_page);\n\tunlock_kernel();\n\n out4:\n\tfree_page(data_page);\n out3:\n\tfree_page(dev_page);\n out2:\n\tputname(dir_page);\n out1:\n\tfree_page(type_page);\n out:\n\treturn retval;\n}", "target": 1, "cwe": [], "project": "linux-2.6", "commit_id": "822191a2fa1584a29c3224ab328507adcaeac1ab", "hash": 269348981982883739425210455454652432542, "size": 56, "message": "[PATCH] skip data conversion in compat_sys_mount when data_page is NULL\n\nOpenVZ Linux kernel team has found a problem with mounting in compat mode.\n\nSimple command \"mount -t smbfs ...\" on Fedora Core 5 distro in 32-bit mode\nleads to oops:\n\n  Unable to handle kernel NULL pointer dereference at 0000000000000000 RIP: compat_sys_mount+0xd6/0x290\n  Process mount (pid: 14656, veid=300, threadinfo ffff810034d30000, task ffff810034c86bc0)\n  Call Trace: ia32_sysret+0x0/0xa\n\nThe problem is that data_page pointer can be NULL, so we should skip data\nconversion in this case.\n\nSigned-off-by: Andrey Mirkin <amirkin@openvz.org>\nCc: <stable@kernel.org>\nSigned-off-by: Andrew Morton <akpm@osdl.org>\nSigned-off-by: Linus Torvalds <torvalds@osdl.org>"}
{"func": "unsigned short atalk_checksum(struct ddpehdr *ddp, int len)\n{\n\tunsigned long sum = 0;\t/* Assume unsigned long is >16 bits */\n\tunsigned char *data = (unsigned char *)ddp;\n\n\tlen  -= 4;\t\t/* skip header 4 bytes */\n\tdata += 4;\n\n\t/* This ought to be unwrapped neatly. I'll trust gcc for now */\n\twhile (len--) {\n\t\tsum += *data;\n\t\tsum <<= 1;\n\t\tif (sum & 0x10000) {\n\t\t\tsum++;\n\t\t\tsum &= 0xFFFF;\n\t\t}\n\t\tdata++;\n\t}\n\t/* Use 0xFFFF for 0. 0 itself means none */\n\treturn sum ? htons((unsigned short)sum) : 0xFFFF;\n}", "target": 1, "cwe": [], "project": "history", "commit_id": "7ab442d7e0a76402c12553ee256f756097cae2d2", "hash": 21680921567039844396111342843486104161, "size": 21, "message": "[DDP]: Convert to new protocol interface.\n\nConvert ddp to the new protocol interface which means it has to\nhandle fragmented skb's.  The only big change is in the checksum\nroutine which has to do more work (like skb_checksum).\n\nMinor speedup is folding the carry to avoid a branch.\n\nTested against a 2.4 system and by running both code over\na range of packets."}
{"func": "static int ltalk_rcv(struct sk_buff *skb, struct net_device *dev,\n\t\t\tstruct packet_type *pt)\n{\n\t/* Expand any short form frames */\n\tif (skb->mac.raw[2] == 1) {\n\t\tstruct ddpehdr *ddp;\n\t\t/* Find our address */\n\t\tstruct atalk_addr *ap = atalk_find_dev_addr(dev);\n\n\t\tif (!ap || skb->len < sizeof(struct ddpshdr))\n\t\t\tgoto freeit;\n\t\t/*\n\t\t * The push leaves us with a ddephdr not an shdr, and\n\t\t * handily the port bytes in the right place preset.\n\t\t */\n\n\t\tskb_push(skb, sizeof(*ddp) - 4);\n\t\t/* FIXME: use skb->cb to be able to use shared skbs */\n\t\tddp = (struct ddpehdr *)skb->data;\n\n\t\t/* Now fill in the long header */\n\n\t \t/*\n\t \t * These two first. The mac overlays the new source/dest\n\t \t * network information so we MUST copy these before\n\t \t * we write the network numbers !\n\t \t */\n\n\t\tddp->deh_dnode = skb->mac.raw[0];     /* From physical header */\n\t\tddp->deh_snode = skb->mac.raw[1];     /* From physical header */\n\n\t\tddp->deh_dnet  = ap->s_net;\t/* Network number */\n\t\tddp->deh_snet  = ap->s_net;\n\t\tddp->deh_sum   = 0;\t\t/* No checksum */\n\t\t/*\n\t\t * Not sure about this bit...\n\t\t */\n\t\tddp->deh_len   = skb->len;\n\t\tddp->deh_hops  = DDP_MAXHOPS;\t/* Non routable, so force a drop\n\t\t\t\t\t\t   if we slip up later */\n\t\t/* Mend the byte order */\n\t\t*((__u16 *)ddp) = htons(*((__u16 *)ddp));\n\t}\n\tskb->h.raw = skb->data;\n\n\treturn atalk_rcv(skb, dev, pt);\nfreeit:\n\tkfree_skb(skb);\n\treturn 0;\n}", "target": 1, "cwe": [], "project": "history", "commit_id": "7ab442d7e0a76402c12553ee256f756097cae2d2", "hash": 19552567024474732272704415128707431614, "size": 50, "message": "[DDP]: Convert to new protocol interface.\n\nConvert ddp to the new protocol interface which means it has to\nhandle fragmented skb's.  The only big change is in the checksum\nroutine which has to do more work (like skb_checksum).\n\nMinor speedup is folding the carry to avoid a branch.\n\nTested against a 2.4 system and by running both code over\na range of packets."}
{"func": "static int atalk_rcv(struct sk_buff *skb, struct net_device *dev,\n\t\t     struct packet_type *pt)\n{\n\tstruct ddpehdr *ddp = ddp_hdr(skb);\n\tstruct sock *sock;\n\tstruct atalk_iface *atif;\n\tstruct sockaddr_at tosat;\n        int origlen;\n        struct ddpebits ddphv;\n\n\t/* Size check */\n\tif (skb->len < sizeof(*ddp))\n\t\tgoto freeit;\n\n\t/*\n\t *\tFix up the length field\t[Ok this is horrible but otherwise\n\t *\tI end up with unions of bit fields and messy bit field order\n\t *\tcompiler/endian dependencies..]\n\t *\n\t *\tFIXME: This is a write to a shared object. Granted it\n\t *\thappens to be safe BUT.. (Its safe as user space will not\n\t *\trun until we put it back)\n\t */\n\t*((__u16 *)&ddphv) = ntohs(*((__u16 *)ddp));\n\n\t/* Trim buffer in case of stray trailing data */\n\toriglen = skb->len;\n\tskb_trim(skb, min_t(unsigned int, skb->len, ddphv.deh_len));\n\n\t/*\n\t * Size check to see if ddp->deh_len was crap\n\t * (Otherwise we'll detonate most spectacularly\n\t * in the middle of recvmsg()).\n\t */\n\tif (skb->len < sizeof(*ddp))\n\t\tgoto freeit;\n\n\t/*\n\t * Any checksums. Note we don't do htons() on this == is assumed to be\n\t * valid for net byte orders all over the networking code...\n\t */\n\tif (ddp->deh_sum &&\n\t    atalk_checksum(ddp, ddphv.deh_len) != ddp->deh_sum)\n\t\t/* Not a valid AppleTalk frame - dustbin time */\n\t\tgoto freeit;\n\n\t/* Check the packet is aimed at us */\n\tif (!ddp->deh_dnet)\t/* Net 0 is 'this network' */\n\t\tatif = atalk_find_anynet(ddp->deh_dnode, dev);\n\telse\n\t\tatif = atalk_find_interface(ddp->deh_dnet, ddp->deh_dnode);\n\n\t/* Not ours, so we route the packet via the correct AppleTalk iface */\n\tif (!atif) {\n\t\tatalk_route_packet(skb, dev, ddp, &ddphv, origlen);\n\t\tgoto out;\n\t}\n\n\t/* if IP over DDP is not selected this code will be optimized out */\n\tif (is_ip_over_ddp(skb))\n\t\treturn handle_ip_over_ddp(skb);\n\t/*\n\t * Which socket - atalk_search_socket() looks for a *full match*\n\t * of the <net, node, port> tuple.\n\t */\n\ttosat.sat_addr.s_net  = ddp->deh_dnet;\n\ttosat.sat_addr.s_node = ddp->deh_dnode;\n\ttosat.sat_port\t      = ddp->deh_dport;\n\n\tsock = atalk_search_socket(&tosat, atif);\n\tif (!sock) /* But not one of our sockets */\n\t\tgoto freeit;\n\n\t/* Queue packet (standard) */\n\tskb->sk = sock;\n\n\tif (sock_queue_rcv_skb(sock, skb) < 0)\n\t\tgoto freeit;\nout:\n\treturn 0;\nfreeit:\n\tkfree_skb(skb);\n\tgoto out;\n}", "target": 1, "cwe": [], "project": "history", "commit_id": "7ab442d7e0a76402c12553ee256f756097cae2d2", "hash": 72319509895917336671439817546429948838, "size": 84, "message": "[DDP]: Convert to new protocol interface.\n\nConvert ddp to the new protocol interface which means it has to\nhandle fragmented skb's.  The only big change is in the checksum\nroutine which has to do more work (like skb_checksum).\n\nMinor speedup is folding the carry to avoid a branch.\n\nTested against a 2.4 system and by running both code over\na range of packets."}
{"func": "static int atalk_sendmsg(struct kiocb *iocb, struct socket *sock, struct msghdr *msg,\n\t\t\t int len)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct atalk_sock *at = at_sk(sk);\n\tstruct sockaddr_at *usat = (struct sockaddr_at *)msg->msg_name;\n\tint flags = msg->msg_flags;\n\tint loopback = 0;\n\tstruct sockaddr_at local_satalk, gsat;\n\tstruct sk_buff *skb;\n\tstruct net_device *dev;\n\tstruct ddpehdr *ddp;\n\tint size;\n\tstruct atalk_route *rt;\n\tint err;\n\n\tif (flags & ~MSG_DONTWAIT)\n\t\treturn -EINVAL;\n\n\tif (len > DDP_MAXSZ)\n\t\treturn -EMSGSIZE;\n\n\tif (usat) {\n\t\tif (sk->sk_zapped)\n\t\t\tif (atalk_autobind(sk) < 0)\n\t\t\t\treturn -EBUSY;\n\n\t\tif (msg->msg_namelen < sizeof(*usat) ||\n\t\t    usat->sat_family != AF_APPLETALK)\n\t\t\treturn -EINVAL;\n\n\t\t/* netatalk doesn't implement this check */\n\t\tif (usat->sat_addr.s_node == ATADDR_BCAST &&\n\t\t    !sock_flag(sk, SOCK_BROADCAST)) {\n\t\t\tprintk(KERN_INFO \"SO_BROADCAST: Fix your netatalk as \"\n\t\t\t\t\t \"it will break before 2.2\\n\");\n#if 0\n\t\t\treturn -EPERM;\n#endif\n\t\t}\n\t} else {\n\t\tif (sk->sk_state != TCP_ESTABLISHED)\n\t\t\treturn -ENOTCONN;\n\t\tusat = &local_satalk;\n\t\tusat->sat_family      = AF_APPLETALK;\n\t\tusat->sat_port\t      = at->dest_port;\n\t\tusat->sat_addr.s_node = at->dest_node;\n\t\tusat->sat_addr.s_net  = at->dest_net;\n\t}\n\n\t/* Build a packet */\n\tSOCK_DEBUG(sk, \"SK %p: Got address.\\n\", sk);\n\n\t/* For headers */\n\tsize = sizeof(struct ddpehdr) + len + ddp_dl->header_length;\n\n\tif (usat->sat_addr.s_net || usat->sat_addr.s_node == ATADDR_ANYNODE) {\n\t\trt = atrtr_find(&usat->sat_addr);\n\t\tif (!rt)\n\t\t\treturn -ENETUNREACH;\n\n\t\tdev = rt->dev;\n\t} else {\n\t\tstruct atalk_addr at_hint;\n\n\t\tat_hint.s_node = 0;\n\t\tat_hint.s_net  = at->src_net;\n\n\t\trt = atrtr_find(&at_hint);\n\t\tif (!rt)\n\t\t\treturn -ENETUNREACH;\n\n\t\tdev = rt->dev;\n\t}\n\n\tSOCK_DEBUG(sk, \"SK %p: Size needed %d, device %s\\n\",\n\t\t\tsk, size, dev->name);\n\n\tsize += dev->hard_header_len;\n\tskb = sock_alloc_send_skb(sk, size, (flags & MSG_DONTWAIT), &err);\n\tif (!skb)\n\t\treturn err;\n\t\n\tskb->sk = sk;\n\tskb_reserve(skb, ddp_dl->header_length);\n\tskb_reserve(skb, dev->hard_header_len);\n\tskb->dev = dev;\n\n\tSOCK_DEBUG(sk, \"SK %p: Begin build.\\n\", sk);\n\n\tddp = (struct ddpehdr *)skb_put(skb, sizeof(struct ddpehdr));\n\tddp->deh_pad  = 0;\n\tddp->deh_hops = 0;\n\tddp->deh_len  = len + sizeof(*ddp);\n\t/*\n\t * Fix up the length field [Ok this is horrible but otherwise\n\t * I end up with unions of bit fields and messy bit field order\n\t * compiler/endian dependencies..\n\t */\n\t*((__u16 *)ddp) = ntohs(*((__u16 *)ddp));\n\n\tddp->deh_dnet  = usat->sat_addr.s_net;\n\tddp->deh_snet  = at->src_net;\n\tddp->deh_dnode = usat->sat_addr.s_node;\n\tddp->deh_snode = at->src_node;\n\tddp->deh_dport = usat->sat_port;\n\tddp->deh_sport = at->src_port;\n\n\tSOCK_DEBUG(sk, \"SK %p: Copy user data (%d bytes).\\n\", sk, len);\n\n\terr = memcpy_fromiovec(skb_put(skb, len), msg->msg_iov, len);\n\tif (err) {\n\t\tkfree_skb(skb);\n\t\treturn -EFAULT;\n\t}\n\n\tif (sk->sk_no_check == 1)\n\t\tddp->deh_sum = 0;\n\telse\n\t\tddp->deh_sum = atalk_checksum(ddp, len + sizeof(*ddp));\n\n\t/*\n\t * Loopback broadcast packets to non gateway targets (ie routes\n\t * to group we are in)\n\t */\n\tif (ddp->deh_dnode == ATADDR_BCAST &&\n\t    !(rt->flags & RTF_GATEWAY) && !(dev->flags & IFF_LOOPBACK)) {\n\t\tstruct sk_buff *skb2 = skb_copy(skb, GFP_KERNEL);\n\n\t\tif (skb2) {\n\t\t\tloopback = 1;\n\t\t\tSOCK_DEBUG(sk, \"SK %p: send out(copy).\\n\", sk);\n\t\t\tif (aarp_send_ddp(dev, skb2,\n\t\t\t\t\t  &usat->sat_addr, NULL) == -1)\n\t\t\t\tkfree_skb(skb2);\n\t\t\t\t/* else queued/sent above in the aarp queue */\n\t\t}\n\t}\n\n\tif (dev->flags & IFF_LOOPBACK || loopback) {\n\t\tSOCK_DEBUG(sk, \"SK %p: Loop back.\\n\", sk);\n\t\t/* loop back */\n\t\tskb_orphan(skb);\n\t\tddp_dl->request(ddp_dl, skb, dev->dev_addr);\n\t} else {\n\t\tSOCK_DEBUG(sk, \"SK %p: send out.\\n\", sk);\n\t\tif (rt->flags & RTF_GATEWAY) {\n\t\t    gsat.sat_addr = rt->gateway;\n\t\t    usat = &gsat;\n\t\t}\n\n\t\tif (aarp_send_ddp(dev, skb, &usat->sat_addr, NULL) == -1)\n\t\t\tkfree_skb(skb);\n\t\t/* else queued/sent above in the aarp queue */\n\t}\n\tSOCK_DEBUG(sk, \"SK %p: Done write (%d).\\n\", sk, len);\n\n\treturn len;\n}", "target": 1, "cwe": [], "project": "history", "commit_id": "7ab442d7e0a76402c12553ee256f756097cae2d2", "hash": 153761947041868070552175845906838763499, "size": 159, "message": "[DDP]: Convert to new protocol interface.\n\nConvert ddp to the new protocol interface which means it has to\nhandle fragmented skb's.  The only big change is in the checksum\nroutine which has to do more work (like skb_checksum).\n\nMinor speedup is folding the carry to avoid a branch.\n\nTested against a 2.4 system and by running both code over\na range of packets."}
{"func": "static int fat_ioctl_filldir(void *__buf, const char *name, int name_len,\n\t\t\t     loff_t offset, u64 ino, unsigned int d_type)\n{\n\tstruct fat_ioctl_filldir_callback *buf = __buf;\n\tstruct dirent __user *d1 = buf->dirent;\n\tstruct dirent __user *d2 = d1 + 1;\n\n\tif (buf->result)\n\t\treturn -EINVAL;\n\tbuf->result++;\n\n\tif (name != NULL) {\n\t\t/* dirent has only short name */\n\t\tif (name_len >= sizeof(d1->d_name))\n\t\t\tname_len = sizeof(d1->d_name) - 1;\n\n\t\tif (put_user(0, d2->d_name)\t\t\t||\n\t\t    put_user(0, &d2->d_reclen)\t\t\t||\n\t\t    copy_to_user(d1->d_name, name, name_len)\t||\n\t\t    put_user(0, d1->d_name + name_len)\t\t||\n\t\t    put_user(name_len, &d1->d_reclen))\n\t\t\tgoto efault;\n\t} else {\n\t\t/* dirent has short and long name */\n\t\tconst char *longname = buf->longname;\n\t\tint long_len = buf->long_len;\n\t\tconst char *shortname = buf->shortname;\n\t\tint short_len = buf->short_len;\n\n\t\tif (long_len >= sizeof(d1->d_name))\n\t\t\tlong_len = sizeof(d1->d_name) - 1;\n\t\tif (short_len >= sizeof(d1->d_name))\n\t\t\tshort_len = sizeof(d1->d_name) - 1;\n\n\t\tif (copy_to_user(d2->d_name, longname, long_len)\t||\n\t\t    put_user(0, d2->d_name + long_len)\t\t\t||\n\t\t    put_user(long_len, &d2->d_reclen)\t\t\t||\n\t\t    put_user(ino, &d2->d_ino)\t\t\t\t||\n\t\t    put_user(offset, &d2->d_off)\t\t\t||\n\t\t    copy_to_user(d1->d_name, shortname, short_len)\t||\n\t\t    put_user(0, d1->d_name + short_len)\t\t\t||\n\t\t    put_user(short_len, &d1->d_reclen))\n\t\t\tgoto efault;\n\t}\n\treturn 0;\nefault:\n\tbuf->result = -EFAULT;\n\treturn -EFAULT;\n}", "target": 1, "cwe": [], "project": "linux-2.6", "commit_id": "c483bab099cb89e92b7cad94a52fcdaf37e56657", "hash": 187708325882921454075693237509471435333, "size": 49, "message": "fat: fix VFAT compat ioctls on 64-bit systems\n\nIf you compile and run the below test case in an msdos or vfat directory on\nan x86-64 system with -m32 you'll get garbage in the kernel_dirent struct\nfollowed by a SIGSEGV.\n\nThe patch fixes this.\n\nReported and initial fix by Bart Oldeman\n\n#include <sys/types.h>\n#include <sys/ioctl.h>\n#include <dirent.h>\n#include <stdio.h>\n#include <unistd.h>\n#include <fcntl.h>\nstruct kernel_dirent {\n         long            d_ino;\n         long\t\td_off;\n         unsigned short  d_reclen;\n         char            d_name[256]; /* We must not include limits.h! */\n};\n#define VFAT_IOCTL_READDIR_BOTH  _IOR('r', 1, struct kernel_dirent [2])\n#define VFAT_IOCTL_READDIR_SHORT  _IOR('r', 2, struct kernel_dirent [2])\n\nint main(void)\n{\n         int fd = open(\".\", O_RDONLY);\n         struct kernel_dirent de[2];\n\n         while (1) {\n                 int i = ioctl(fd, VFAT_IOCTL_READDIR_BOTH, (long)de);\n                 if (i == -1) break;\n                 if (de[0].d_reclen == 0) break;\n                 printf(\"SFN: reclen=%2d off=%d ino=%d, %-12s\",\n \t\t       de[0].d_reclen, de[0].d_off, de[0].d_ino, de[0].d_name);\n \t\tif (de[1].d_reclen)\n \t\t  printf(\"\\tLFN: reclen=%2d off=%d ino=%d, %s\",\n \t\t    de[1].d_reclen, de[1].d_off, de[1].d_ino, de[1].d_name);\n \t\tprintf(\"\\n\");\n         }\n         return 0;\n}\n\nSigned-off-by: Bart Oldeman <bartoldeman@users.sourceforge.net>\nSigned-off-by: OGAWA Hirofumi <hirofumi@mail.parknet.co.jp>\nCc: <stable@kernel.org>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "static int fat_dir_ioctl(struct inode * inode, struct file * filp,\n\t\t  unsigned int cmd, unsigned long arg)\n{\n\tstruct fat_ioctl_filldir_callback buf;\n\tstruct dirent __user *d1;\n\tint ret, short_only, both;\n\n\tswitch (cmd) {\n\tcase VFAT_IOCTL_READDIR_SHORT:\n\t\tshort_only = 1;\n\t\tboth = 0;\n\t\tbreak;\n\tcase VFAT_IOCTL_READDIR_BOTH:\n\t\tshort_only = 0;\n\t\tboth = 1;\n\t\tbreak;\n\tdefault:\n\t\treturn fat_generic_ioctl(inode, filp, cmd, arg);\n\t}\n\n\td1 = (struct dirent __user *)arg;\n\tif (!access_ok(VERIFY_WRITE, d1, sizeof(struct dirent[2])))\n\t\treturn -EFAULT;\n\t/*\n\t * Yes, we don't need this put_user() absolutely. However old\n\t * code didn't return the right value. So, app use this value,\n\t * in order to check whether it is EOF.\n\t */\n\tif (put_user(0, &d1->d_reclen))\n\t\treturn -EFAULT;\n\n\tbuf.dirent = d1;\n\tbuf.result = 0;\n\tmutex_lock(&inode->i_mutex);\n\tret = -ENOENT;\n\tif (!IS_DEADDIR(inode)) {\n\t\tret = __fat_readdir(inode, filp, &buf, fat_ioctl_filldir,\n\t\t\t\t    short_only, both);\n\t}\n\tmutex_unlock(&inode->i_mutex);\n\tif (ret >= 0)\n\t\tret = buf.result;\n\treturn ret;\n}", "target": 1, "cwe": [], "project": "linux-2.6", "commit_id": "c483bab099cb89e92b7cad94a52fcdaf37e56657", "hash": 113627596617655061806217101411583896910, "size": 44, "message": "fat: fix VFAT compat ioctls on 64-bit systems\n\nIf you compile and run the below test case in an msdos or vfat directory on\nan x86-64 system with -m32 you'll get garbage in the kernel_dirent struct\nfollowed by a SIGSEGV.\n\nThe patch fixes this.\n\nReported and initial fix by Bart Oldeman\n\n#include <sys/types.h>\n#include <sys/ioctl.h>\n#include <dirent.h>\n#include <stdio.h>\n#include <unistd.h>\n#include <fcntl.h>\nstruct kernel_dirent {\n         long            d_ino;\n         long\t\td_off;\n         unsigned short  d_reclen;\n         char            d_name[256]; /* We must not include limits.h! */\n};\n#define VFAT_IOCTL_READDIR_BOTH  _IOR('r', 1, struct kernel_dirent [2])\n#define VFAT_IOCTL_READDIR_SHORT  _IOR('r', 2, struct kernel_dirent [2])\n\nint main(void)\n{\n         int fd = open(\".\", O_RDONLY);\n         struct kernel_dirent de[2];\n\n         while (1) {\n                 int i = ioctl(fd, VFAT_IOCTL_READDIR_BOTH, (long)de);\n                 if (i == -1) break;\n                 if (de[0].d_reclen == 0) break;\n                 printf(\"SFN: reclen=%2d off=%d ino=%d, %-12s\",\n \t\t       de[0].d_reclen, de[0].d_off, de[0].d_ino, de[0].d_name);\n \t\tif (de[1].d_reclen)\n \t\t  printf(\"\\tLFN: reclen=%2d off=%d ino=%d, %s\",\n \t\t    de[1].d_reclen, de[1].d_off, de[1].d_ino, de[1].d_name);\n \t\tprintf(\"\\n\");\n         }\n         return 0;\n}\n\nSigned-off-by: Bart Oldeman <bartoldeman@users.sourceforge.net>\nSigned-off-by: OGAWA Hirofumi <hirofumi@mail.parknet.co.jp>\nCc: <stable@kernel.org>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "static long fat_compat_dir_ioctl(struct file *file, unsigned cmd,\n\t\t\t\t unsigned long arg)\n{\n\tstruct compat_dirent __user *p = compat_ptr(arg);\n\tint ret;\n\tmm_segment_t oldfs = get_fs();\n\tstruct dirent d[2];\n\n\tswitch (cmd) {\n\tcase VFAT_IOCTL_READDIR_BOTH32:\n\t\tcmd = VFAT_IOCTL_READDIR_BOTH;\n\t\tbreak;\n\tcase VFAT_IOCTL_READDIR_SHORT32:\n\t\tcmd = VFAT_IOCTL_READDIR_SHORT;\n\t\tbreak;\n\tdefault:\n\t\treturn -ENOIOCTLCMD;\n\t}\n\n\tset_fs(KERNEL_DS);\n\tlock_kernel();\n\tret = fat_dir_ioctl(file->f_path.dentry->d_inode, file,\n\t\t\t    cmd, (unsigned long) &d);\n\tunlock_kernel();\n\tset_fs(oldfs);\n\tif (ret >= 0) {\n\t\tret |= fat_compat_put_dirent32(&d[0], p);\n\t\tret |= fat_compat_put_dirent32(&d[1], p + 1);\n\t}\n\treturn ret;\n}", "target": 1, "cwe": [], "project": "linux-2.6", "commit_id": "c483bab099cb89e92b7cad94a52fcdaf37e56657", "hash": 291589362780422191634012586934810692426, "size": 31, "message": "fat: fix VFAT compat ioctls on 64-bit systems\n\nIf you compile and run the below test case in an msdos or vfat directory on\nan x86-64 system with -m32 you'll get garbage in the kernel_dirent struct\nfollowed by a SIGSEGV.\n\nThe patch fixes this.\n\nReported and initial fix by Bart Oldeman\n\n#include <sys/types.h>\n#include <sys/ioctl.h>\n#include <dirent.h>\n#include <stdio.h>\n#include <unistd.h>\n#include <fcntl.h>\nstruct kernel_dirent {\n         long            d_ino;\n         long\t\td_off;\n         unsigned short  d_reclen;\n         char            d_name[256]; /* We must not include limits.h! */\n};\n#define VFAT_IOCTL_READDIR_BOTH  _IOR('r', 1, struct kernel_dirent [2])\n#define VFAT_IOCTL_READDIR_SHORT  _IOR('r', 2, struct kernel_dirent [2])\n\nint main(void)\n{\n         int fd = open(\".\", O_RDONLY);\n         struct kernel_dirent de[2];\n\n         while (1) {\n                 int i = ioctl(fd, VFAT_IOCTL_READDIR_BOTH, (long)de);\n                 if (i == -1) break;\n                 if (de[0].d_reclen == 0) break;\n                 printf(\"SFN: reclen=%2d off=%d ino=%d, %-12s\",\n \t\t       de[0].d_reclen, de[0].d_off, de[0].d_ino, de[0].d_name);\n \t\tif (de[1].d_reclen)\n \t\t  printf(\"\\tLFN: reclen=%2d off=%d ino=%d, %s\",\n \t\t    de[1].d_reclen, de[1].d_off, de[1].d_ino, de[1].d_name);\n \t\tprintf(\"\\n\");\n         }\n         return 0;\n}\n\nSigned-off-by: Bart Oldeman <bartoldeman@users.sourceforge.net>\nSigned-off-by: OGAWA Hirofumi <hirofumi@mail.parknet.co.jp>\nCc: <stable@kernel.org>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "static long fat_compat_put_dirent32(struct dirent *d,\n\t\t\t\t    struct compat_dirent __user *d32)\n{\n        if (!access_ok(VERIFY_WRITE, d32, sizeof(struct compat_dirent)))\n                return -EFAULT;\n\n        __put_user(d->d_ino, &d32->d_ino);\n        __put_user(d->d_off, &d32->d_off);\n        __put_user(d->d_reclen, &d32->d_reclen);\n        if (__copy_to_user(d32->d_name, d->d_name, d->d_reclen))\n\t\treturn -EFAULT;\n\n        return 0;\n}", "target": 1, "cwe": [], "project": "linux-2.6", "commit_id": "c483bab099cb89e92b7cad94a52fcdaf37e56657", "hash": 106659780049225785767525003746183196183, "size": 14, "message": "fat: fix VFAT compat ioctls on 64-bit systems\n\nIf you compile and run the below test case in an msdos or vfat directory on\nan x86-64 system with -m32 you'll get garbage in the kernel_dirent struct\nfollowed by a SIGSEGV.\n\nThe patch fixes this.\n\nReported and initial fix by Bart Oldeman\n\n#include <sys/types.h>\n#include <sys/ioctl.h>\n#include <dirent.h>\n#include <stdio.h>\n#include <unistd.h>\n#include <fcntl.h>\nstruct kernel_dirent {\n         long            d_ino;\n         long\t\td_off;\n         unsigned short  d_reclen;\n         char            d_name[256]; /* We must not include limits.h! */\n};\n#define VFAT_IOCTL_READDIR_BOTH  _IOR('r', 1, struct kernel_dirent [2])\n#define VFAT_IOCTL_READDIR_SHORT  _IOR('r', 2, struct kernel_dirent [2])\n\nint main(void)\n{\n         int fd = open(\".\", O_RDONLY);\n         struct kernel_dirent de[2];\n\n         while (1) {\n                 int i = ioctl(fd, VFAT_IOCTL_READDIR_BOTH, (long)de);\n                 if (i == -1) break;\n                 if (de[0].d_reclen == 0) break;\n                 printf(\"SFN: reclen=%2d off=%d ino=%d, %-12s\",\n \t\t       de[0].d_reclen, de[0].d_off, de[0].d_ino, de[0].d_name);\n \t\tif (de[1].d_reclen)\n \t\t  printf(\"\\tLFN: reclen=%2d off=%d ino=%d, %s\",\n \t\t    de[1].d_reclen, de[1].d_off, de[1].d_ino, de[1].d_name);\n \t\tprintf(\"\\n\");\n         }\n         return 0;\n}\n\nSigned-off-by: Bart Oldeman <bartoldeman@users.sourceforge.net>\nSigned-off-by: OGAWA Hirofumi <hirofumi@mail.parknet.co.jp>\nCc: <stable@kernel.org>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "static int vfat_ioctl32(unsigned fd, unsigned cmd, unsigned long arg)\n{\n\tstruct compat_dirent __user *p = compat_ptr(arg);\n\tint ret;\n\tmm_segment_t oldfs = get_fs();\n\tstruct dirent d[2];\n\n\tswitch(cmd)\n\t{\n        \tcase VFAT_IOCTL_READDIR_BOTH32:\n                \tcmd = VFAT_IOCTL_READDIR_BOTH;\n                \tbreak;\n        \tcase VFAT_IOCTL_READDIR_SHORT32:\n                \tcmd = VFAT_IOCTL_READDIR_SHORT;\n                \tbreak;\n\t}\n\n\tset_fs(KERNEL_DS);\n\tret = sys_ioctl(fd,cmd,(unsigned long)&d);\n\tset_fs(oldfs);\n\tif (ret >= 0) {\n\t\tret |= put_dirent32(&d[0], p);\n\t\tret |= put_dirent32(&d[1], p + 1);\n\t}\n\treturn ret;\n}", "target": 1, "cwe": [], "project": "linux-2.6", "commit_id": "188f83dfe0eeecd1427d0d255cc97dbf7ef6b4b7", "hash": 111898724151179411964972445082613411107, "size": 26, "message": "[PATCH] BLOCK: Move the msdos device ioctl compat stuff to the msdos driver [try #6]\n\nMove the msdos device ioctl compat stuff from fs/compat_ioctl.c to the msdos\ndriver so that the msdos header file doesn't need to be included.\n\nSigned-Off-By: David Howells <dhowells@redhat.com>\nSigned-off-by: Jens Axboe <axboe@kernel.dk>"}
{"func": "put_dirent32 (struct dirent *d, struct compat_dirent __user *d32)\n{\n        if (!access_ok(VERIFY_WRITE, d32, sizeof(struct compat_dirent)))\n                return -EFAULT;\n\n        __put_user(d->d_ino, &d32->d_ino);\n        __put_user(d->d_off, &d32->d_off);\n        __put_user(d->d_reclen, &d32->d_reclen);\n        if (__copy_to_user(d32->d_name, d->d_name, d->d_reclen))\n\t\treturn -EFAULT;\n\n        return 0;\n}", "target": 1, "cwe": [], "project": "linux-2.6", "commit_id": "188f83dfe0eeecd1427d0d255cc97dbf7ef6b4b7", "hash": 270045642335722159449853839682351083428, "size": 13, "message": "[PATCH] BLOCK: Move the msdos device ioctl compat stuff to the msdos driver [try #6]\n\nMove the msdos device ioctl compat stuff from fs/compat_ioctl.c to the msdos\ndriver so that the msdos header file doesn't need to be included.\n\nSigned-Off-By: David Howells <dhowells@redhat.com>\nSigned-off-by: Jens Axboe <axboe@kernel.dk>"}
{"func": "unsigned long convert_rip_to_linear(struct task_struct *child, struct pt_regs *regs)\n{\n\tunsigned long addr, seg;\n\n\taddr = regs->rip;\n\tseg = regs->cs & 0xffff;\n\n\t/*\n\t * We'll assume that the code segments in the GDT\n\t * are all zero-based. That is largely true: the\n\t * TLS segments are used for data, and the PNPBIOS\n\t * and APM bios ones we just ignore here.\n\t */\n\tif (seg & LDT_SEGMENT) {\n\t\tu32 *desc;\n\t\tunsigned long base;\n\n\t\tdown(&child->mm->context.sem);\n\t\tdesc = child->mm->context.ldt + (seg & ~7);\n\t\tbase = (desc[0] >> 16) | ((desc[1] & 0xff) << 16) | (desc[1] & 0xff000000);\n\n\t\t/* 16-bit code segment? */\n\t\tif (!((desc[1] >> 22) & 1))\n\t\t\taddr &= 0xffff;\n\t\taddr += base;\n\t\tup(&child->mm->context.sem);\n\t}\n\treturn addr;\n}", "target": 1, "cwe": ["CWE-20"], "project": "linux-2.6", "commit_id": "29eb51101c02df517ca64ec472d7501127ad1da8", "hash": 1508545436095858671693183645763265341, "size": 29, "message": "Handle bogus %cs selector in single-step instruction decoding\n\nThe code for LDT segment selectors was not robust in the face of a bogus\nselector set in %cs via ptrace before the single-step was done.\n\nSigned-off-by: Roland McGrath <roland@redhat.com>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "static unsigned long convert_eip_to_linear(struct task_struct *child, struct pt_regs *regs)\n{\n\tunsigned long addr, seg;\n\n\taddr = regs->eip;\n\tseg = regs->xcs & 0xffff;\n\tif (regs->eflags & VM_MASK) {\n\t\taddr = (addr & 0xffff) + (seg << 4);\n\t\treturn addr;\n\t}\n\n\t/*\n\t * We'll assume that the code segments in the GDT\n\t * are all zero-based. That is largely true: the\n\t * TLS segments are used for data, and the PNPBIOS\n\t * and APM bios ones we just ignore here.\n\t */\n\tif (seg & LDT_SEGMENT) {\n\t\tu32 *desc;\n\t\tunsigned long base;\n\n\t\tdown(&child->mm->context.sem);\n\t\tdesc = child->mm->context.ldt + (seg & ~7);\n\t\tbase = (desc[0] >> 16) | ((desc[1] & 0xff) << 16) | (desc[1] & 0xff000000);\n\n\t\t/* 16-bit code segment? */\n\t\tif (!((desc[1] >> 22) & 1))\n\t\t\taddr &= 0xffff;\n\t\taddr += base;\n\t\tup(&child->mm->context.sem);\n\t}\n\treturn addr;\n}", "target": 1, "cwe": ["CWE-20"], "project": "linux-2.6", "commit_id": "29eb51101c02df517ca64ec472d7501127ad1da8", "hash": 106350190623619753707189764532983232553, "size": 33, "message": "Handle bogus %cs selector in single-step instruction decoding\n\nThe code for LDT segment selectors was not robust in the face of a bogus\nselector set in %cs via ptrace before the single-step was done.\n\nSigned-off-by: Roland McGrath <roland@redhat.com>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "pfm_smpl_buffer_alloc(struct task_struct *task, pfm_context_t *ctx, unsigned long rsize, void **user_vaddr)\n{\n\tstruct mm_struct *mm = task->mm;\n\tstruct vm_area_struct *vma = NULL;\n\tunsigned long size;\n\tvoid *smpl_buf;\n\n\n\t/*\n\t * the fixed header + requested size and align to page boundary\n\t */\n\tsize = PAGE_ALIGN(rsize);\n\n\tDPRINT((\"sampling buffer rsize=%lu size=%lu bytes\\n\", rsize, size));\n\n\t/*\n\t * check requested size to avoid Denial-of-service attacks\n\t * XXX: may have to refine this test\n\t * Check against address space limit.\n\t *\n\t * if ((mm->total_vm << PAGE_SHIFT) + len> task->rlim[RLIMIT_AS].rlim_cur)\n\t * \treturn -ENOMEM;\n\t */\n\tif (size > task->signal->rlim[RLIMIT_MEMLOCK].rlim_cur)\n\t\treturn -ENOMEM;\n\n\t/*\n\t * We do the easy to undo allocations first.\n \t *\n\t * pfm_rvmalloc(), clears the buffer, so there is no leak\n\t */\n\tsmpl_buf = pfm_rvmalloc(size);\n\tif (smpl_buf == NULL) {\n\t\tDPRINT((\"Can't allocate sampling buffer\\n\"));\n\t\treturn -ENOMEM;\n\t}\n\n\tDPRINT((\"smpl_buf @%p\\n\", smpl_buf));\n\n\t/* allocate vma */\n\tvma = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL);\n\tif (!vma) {\n\t\tDPRINT((\"Cannot allocate vma\\n\"));\n\t\tgoto error_kmem;\n\t}\n\n\t/*\n\t * partially initialize the vma for the sampling buffer\n\t */\n\tvma->vm_mm\t     = mm;\n\tvma->vm_flags\t     = VM_READ| VM_MAYREAD |VM_RESERVED;\n\tvma->vm_page_prot    = PAGE_READONLY; /* XXX may need to change */\n\n\t/*\n\t * Now we have everything we need and we can initialize\n\t * and connect all the data structures\n\t */\n\n\tctx->ctx_smpl_hdr   = smpl_buf;\n\tctx->ctx_smpl_size  = size; /* aligned size */\n\n\t/*\n\t * Let's do the difficult operations next.\n\t *\n\t * now we atomically find some area in the address space and\n\t * remap the buffer in it.\n\t */\n\tdown_write(&task->mm->mmap_sem);\n\n\t/* find some free area in address space, must have mmap sem held */\n\tvma->vm_start = pfm_get_unmapped_area(NULL, 0, size, 0, MAP_PRIVATE|MAP_ANONYMOUS, 0);\n\tif (vma->vm_start == 0UL) {\n\t\tDPRINT((\"Cannot find unmapped area for size %ld\\n\", size));\n\t\tup_write(&task->mm->mmap_sem);\n\t\tgoto error;\n\t}\n\tvma->vm_end = vma->vm_start + size;\n\tvma->vm_pgoff = vma->vm_start >> PAGE_SHIFT;\n\n\tDPRINT((\"aligned size=%ld, hdr=%p mapped @0x%lx\\n\", size, ctx->ctx_smpl_hdr, vma->vm_start));\n\n\t/* can only be applied to current task, need to have the mm semaphore held when called */\n\tif (pfm_remap_buffer(vma, (unsigned long)smpl_buf, vma->vm_start, size)) {\n\t\tDPRINT((\"Can't remap buffer\\n\"));\n\t\tup_write(&task->mm->mmap_sem);\n\t\tgoto error;\n\t}\n\n\t/*\n\t * now insert the vma in the vm list for the process, must be\n\t * done with mmap lock held\n\t */\n\tinsert_vm_struct(mm, vma);\n\n\tmm->total_vm  += size >> PAGE_SHIFT;\n\tvm_stat_account(vma->vm_mm, vma->vm_flags, vma->vm_file,\n\t\t\t\t\t\t\tvma_pages(vma));\n\tup_write(&task->mm->mmap_sem);\n\n\t/*\n\t * keep track of user level virtual address\n\t */\n\tctx->ctx_smpl_vaddr = (void *)vma->vm_start;\n\t*(unsigned long *)user_vaddr = vma->vm_start;\n\n\treturn 0;\n\nerror:\n\tkmem_cache_free(vm_area_cachep, vma);\nerror_kmem:\n\tpfm_rvfree(smpl_buf, size);\n\n\treturn -ENOMEM;\n}", "target": 1, "cwe": [], "project": "linux-2.6", "commit_id": "41d5e5d73ecef4ef56b7b4cde962929a712689b4", "hash": 87803820803317589966380178034337365249, "size": 114, "message": "[IA64] permon use-after-free fix\n\nPerfmon associates vmalloc()ed memory with a file descriptor, and installs\na vma mapping that memory.  Unfortunately, the vm_file field is not filled\nin, so processes with mappings to that memory do not prevent the file from\nbeing closed and the memory freed.  This results in use-after-free bugs and\nmultiple freeing of pages, etc.\n\nI saw this bug on an Altix on SLES9.  Haven't reproduced upstream but it\nlooks like the same issue is there.\n\nSigned-off-by: Nick Piggin <npiggin@suse.de>\nCc: Stephane Eranian <eranian@hpl.hp.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Tony Luck <tony.luck@intel.com>"}
{"func": "pfm_context_create(pfm_context_t *ctx, void *arg, int count, struct pt_regs *regs)\n{\n\tpfarg_context_t *req = (pfarg_context_t *)arg;\n\tstruct file *filp;\n\tint ctx_flags;\n\tint ret;\n\n\t/* let's check the arguments first */\n\tret = pfarg_is_sane(current, req);\n\tif (ret < 0) return ret;\n\n\tctx_flags = req->ctx_flags;\n\n\tret = -ENOMEM;\n\n\tctx = pfm_context_alloc();\n\tif (!ctx) goto error;\n\n\tret = pfm_alloc_fd(&filp);\n\tif (ret < 0) goto error_file;\n\n\treq->ctx_fd = ctx->ctx_fd = ret;\n\n\t/*\n\t * attach context to file\n\t */\n\tfilp->private_data = ctx;\n\n\t/*\n\t * does the user want to sample?\n\t */\n\tif (pfm_uuid_cmp(req->ctx_smpl_buf_id, pfm_null_uuid)) {\n\t\tret = pfm_setup_buffer_fmt(current, ctx, ctx_flags, 0, req);\n\t\tif (ret) goto buffer_error;\n\t}\n\n\t/*\n\t * init context protection lock\n\t */\n\tspin_lock_init(&ctx->ctx_lock);\n\n\t/*\n\t * context is unloaded\n\t */\n\tctx->ctx_state = PFM_CTX_UNLOADED;\n\n\t/*\n\t * initialization of context's flags\n\t */\n\tctx->ctx_fl_block       = (ctx_flags & PFM_FL_NOTIFY_BLOCK) ? 1 : 0;\n\tctx->ctx_fl_system      = (ctx_flags & PFM_FL_SYSTEM_WIDE) ? 1: 0;\n\tctx->ctx_fl_is_sampling = ctx->ctx_buf_fmt ? 1 : 0; /* assume record() is defined */\n\tctx->ctx_fl_no_msg      = (ctx_flags & PFM_FL_OVFL_NO_MSG) ? 1: 0;\n\t/*\n\t * will move to set properties\n\t * ctx->ctx_fl_excl_idle   = (ctx_flags & PFM_FL_EXCL_IDLE) ? 1: 0;\n\t */\n\n\t/*\n\t * init restart semaphore to locked\n\t */\n\tinit_completion(&ctx->ctx_restart_done);\n\n\t/*\n\t * activation is used in SMP only\n\t */\n\tctx->ctx_last_activation = PFM_INVALID_ACTIVATION;\n\tSET_LAST_CPU(ctx, -1);\n\n\t/*\n\t * initialize notification message queue\n\t */\n\tctx->ctx_msgq_head = ctx->ctx_msgq_tail = 0;\n\tinit_waitqueue_head(&ctx->ctx_msgq_wait);\n\tinit_waitqueue_head(&ctx->ctx_zombieq);\n\n\tDPRINT((\"ctx=%p flags=0x%x system=%d notify_block=%d excl_idle=%d no_msg=%d ctx_fd=%d \\n\",\n\t\tctx,\n\t\tctx_flags,\n\t\tctx->ctx_fl_system,\n\t\tctx->ctx_fl_block,\n\t\tctx->ctx_fl_excl_idle,\n\t\tctx->ctx_fl_no_msg,\n\t\tctx->ctx_fd));\n\n\t/*\n\t * initialize soft PMU state\n\t */\n\tpfm_reset_pmu_state(ctx);\n\n\treturn 0;\n\nbuffer_error:\n\tpfm_free_fd(ctx->ctx_fd, filp);\n\n\tif (ctx->ctx_buf_fmt) {\n\t\tpfm_buf_fmt_exit(ctx->ctx_buf_fmt, current, NULL, regs);\n\t}\nerror_file:\n\tpfm_context_free(ctx);\n\nerror:\n\treturn ret;\n}", "target": 1, "cwe": [], "project": "linux-2.6", "commit_id": "41d5e5d73ecef4ef56b7b4cde962929a712689b4", "hash": 13520750174224364535947939006635351369, "size": 104, "message": "[IA64] permon use-after-free fix\n\nPerfmon associates vmalloc()ed memory with a file descriptor, and installs\na vma mapping that memory.  Unfortunately, the vm_file field is not filled\nin, so processes with mappings to that memory do not prevent the file from\nbeing closed and the memory freed.  This results in use-after-free bugs and\nmultiple freeing of pages, etc.\n\nI saw this bug on an Altix on SLES9.  Haven't reproduced upstream but it\nlooks like the same issue is there.\n\nSigned-off-by: Nick Piggin <npiggin@suse.de>\nCc: Stephane Eranian <eranian@hpl.hp.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Tony Luck <tony.luck@intel.com>"}
{"func": "pfm_setup_buffer_fmt(struct task_struct *task, pfm_context_t *ctx, unsigned int ctx_flags,\n\t\t     unsigned int cpu, pfarg_context_t *arg)\n{\n\tpfm_buffer_fmt_t *fmt = NULL;\n\tunsigned long size = 0UL;\n\tvoid *uaddr = NULL;\n\tvoid *fmt_arg = NULL;\n\tint ret = 0;\n#define PFM_CTXARG_BUF_ARG(a)\t(pfm_buffer_fmt_t *)(a+1)\n\n\t/* invoke and lock buffer format, if found */\n\tfmt = pfm_find_buffer_fmt(arg->ctx_smpl_buf_id);\n\tif (fmt == NULL) {\n\t\tDPRINT((\"[%d] cannot find buffer format\\n\", task->pid));\n\t\treturn -EINVAL;\n\t}\n\n\t/*\n\t * buffer argument MUST be contiguous to pfarg_context_t\n\t */\n\tif (fmt->fmt_arg_size) fmt_arg = PFM_CTXARG_BUF_ARG(arg);\n\n\tret = pfm_buf_fmt_validate(fmt, task, ctx_flags, cpu, fmt_arg);\n\n\tDPRINT((\"[%d] after validate(0x%x,%d,%p)=%d\\n\", task->pid, ctx_flags, cpu, fmt_arg, ret));\n\n\tif (ret) goto error;\n\n\t/* link buffer format and context */\n\tctx->ctx_buf_fmt = fmt;\n\n\t/*\n\t * check if buffer format wants to use perfmon buffer allocation/mapping service\n\t */\n\tret = pfm_buf_fmt_getsize(fmt, task, ctx_flags, cpu, fmt_arg, &size);\n\tif (ret) goto error;\n\n\tif (size) {\n\t\t/*\n\t\t * buffer is always remapped into the caller's address space\n\t\t */\n\t\tret = pfm_smpl_buffer_alloc(current, ctx, size, &uaddr);\n\t\tif (ret) goto error;\n\n\t\t/* keep track of user address of buffer */\n\t\targ->ctx_smpl_vaddr = uaddr;\n\t}\n\tret = pfm_buf_fmt_init(fmt, task, ctx->ctx_smpl_hdr, ctx_flags, cpu, fmt_arg);\n\nerror:\n\treturn ret;\n}", "target": 1, "cwe": [], "project": "linux-2.6", "commit_id": "41d5e5d73ecef4ef56b7b4cde962929a712689b4", "hash": 46202394531124018831417285404810810597, "size": 52, "message": "[IA64] permon use-after-free fix\n\nPerfmon associates vmalloc()ed memory with a file descriptor, and installs\na vma mapping that memory.  Unfortunately, the vm_file field is not filled\nin, so processes with mappings to that memory do not prevent the file from\nbeing closed and the memory freed.  This results in use-after-free bugs and\nmultiple freeing of pages, etc.\n\nI saw this bug on an Altix on SLES9.  Haven't reproduced upstream but it\nlooks like the same issue is there.\n\nSigned-off-by: Nick Piggin <npiggin@suse.de>\nCc: Stephane Eranian <eranian@hpl.hp.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Tony Luck <tony.luck@intel.com>"}
{"func": "static int __init snd_mem_init(void)\n{\n#ifdef CONFIG_PROC_FS\n\tsnd_mem_proc = create_proc_entry(SND_MEM_PROC_FILE, 0644, NULL);\n\tif (snd_mem_proc) {\n\t\tsnd_mem_proc->read_proc = snd_mem_proc_read;\n#ifdef CONFIG_PCI\n\t\tsnd_mem_proc->write_proc = snd_mem_proc_write;\n#endif\n\t}\n#endif\n\treturn 0;\n}", "target": 1, "cwe": [], "project": "linux-2.6", "commit_id": "ccec6e2c4a74adf76ed4e2478091a311b1806212", "hash": 6222875397067194352861204548094447265, "size": 13, "message": "Convert snd-page-alloc proc file to use seq_file\n\nUse seq_file for the proc file read/write of snd-page-alloc module.\nThis automatically fixes bugs in the old proc code.\n\nSigned-off-by: Takashi Iwai <tiwai@suse.de>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "static int snd_mem_proc_read(char *page, char **start, off_t off,\n\t\t\t     int count, int *eof, void *data)\n{\n\tint len = 0;\n\tlong pages = snd_allocated_pages >> (PAGE_SHIFT-12);\n\tstruct snd_mem_list *mem;\n\tint devno;\n\tstatic char *types[] = { \"UNKNOWN\", \"CONT\", \"DEV\", \"DEV-SG\", \"SBUS\" };\n\n\tmutex_lock(&list_mutex);\n\tlen += snprintf(page + len, count - len,\n\t\t\t\"pages  : %li bytes (%li pages per %likB)\\n\",\n\t\t\tpages * PAGE_SIZE, pages, PAGE_SIZE / 1024);\n\tdevno = 0;\n\tlist_for_each_entry(mem, &mem_list_head, list) {\n\t\tdevno++;\n\t\tlen += snprintf(page + len, count - len,\n\t\t\t\t\"buffer %d : ID %08x : type %s\\n\",\n\t\t\t\tdevno, mem->id, types[mem->buffer.dev.type]);\n\t\tlen += snprintf(page + len, count - len,\n\t\t\t\t\"  addr = 0x%lx, size = %d bytes\\n\",\n\t\t\t\t(unsigned long)mem->buffer.addr, (int)mem->buffer.bytes);\n\t}\n\tmutex_unlock(&list_mutex);\n\treturn len;\n}", "target": 1, "cwe": [], "project": "linux-2.6", "commit_id": "ccec6e2c4a74adf76ed4e2478091a311b1806212", "hash": 177539223428479219345960137138678283235, "size": 26, "message": "Convert snd-page-alloc proc file to use seq_file\n\nUse seq_file for the proc file read/write of snd-page-alloc module.\nThis automatically fixes bugs in the old proc code.\n\nSigned-off-by: Takashi Iwai <tiwai@suse.de>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "static int snd_mem_proc_write(struct file *file, const char __user *buffer,\n\t\t\t      unsigned long count, void *data)\n{\n\tchar buf[128];\n\tchar *token, *p;\n\n\tif (count > ARRAY_SIZE(buf) - 1)\n\t\tcount = ARRAY_SIZE(buf) - 1;\n\tif (copy_from_user(buf, buffer, count))\n\t\treturn -EFAULT;\n\tbuf[ARRAY_SIZE(buf) - 1] = '\\0';\n\n\tp = buf;\n\ttoken = gettoken(&p);\n\tif (! token || *token == '#')\n\t\treturn (int)count;\n\tif (strcmp(token, \"add\") == 0) {\n\t\tchar *endp;\n\t\tint vendor, device, size, buffers;\n\t\tlong mask;\n\t\tint i, alloced;\n\t\tstruct pci_dev *pci;\n\n\t\tif ((token = gettoken(&p)) == NULL ||\n\t\t    (vendor = simple_strtol(token, NULL, 0)) <= 0 ||\n\t\t    (token = gettoken(&p)) == NULL ||\n\t\t    (device = simple_strtol(token, NULL, 0)) <= 0 ||\n\t\t    (token = gettoken(&p)) == NULL ||\n\t\t    (mask = simple_strtol(token, NULL, 0)) < 0 ||\n\t\t    (token = gettoken(&p)) == NULL ||\n\t\t    (size = memparse(token, &endp)) < 64*1024 ||\n\t\t    size > 16*1024*1024 /* too big */ ||\n\t\t    (token = gettoken(&p)) == NULL ||\n\t\t    (buffers = simple_strtol(token, NULL, 0)) <= 0 ||\n\t\t    buffers > 4) {\n\t\t\tprintk(KERN_ERR \"snd-page-alloc: invalid proc write format\\n\");\n\t\t\treturn (int)count;\n\t\t}\n\t\tvendor &= 0xffff;\n\t\tdevice &= 0xffff;\n\n\t\talloced = 0;\n\t\tpci = NULL;\n\t\twhile ((pci = pci_get_device(vendor, device, pci)) != NULL) {\n\t\t\tif (mask > 0 && mask < 0xffffffff) {\n\t\t\t\tif (pci_set_dma_mask(pci, mask) < 0 ||\n\t\t\t\t    pci_set_consistent_dma_mask(pci, mask) < 0) {\n\t\t\t\t\tprintk(KERN_ERR \"snd-page-alloc: cannot set DMA mask %lx for pci %04x:%04x\\n\", mask, vendor, device);\n\t\t\t\t\treturn (int)count;\n\t\t\t\t}\n\t\t\t}\n\t\t\tfor (i = 0; i < buffers; i++) {\n\t\t\t\tstruct snd_dma_buffer dmab;\n\t\t\t\tmemset(&dmab, 0, sizeof(dmab));\n\t\t\t\tif (snd_dma_alloc_pages(SNDRV_DMA_TYPE_DEV, snd_dma_pci_data(pci),\n\t\t\t\t\t\t\tsize, &dmab) < 0) {\n\t\t\t\t\tprintk(KERN_ERR \"snd-page-alloc: cannot allocate buffer pages (size = %d)\\n\", size);\n\t\t\t\t\tpci_dev_put(pci);\n\t\t\t\t\treturn (int)count;\n\t\t\t\t}\n\t\t\t\tsnd_dma_reserve_buf(&dmab, snd_dma_pci_buf_id(pci));\n\t\t\t}\n\t\t\talloced++;\n\t\t}\n\t\tif (! alloced) {\n\t\t\tfor (i = 0; i < buffers; i++) {\n\t\t\t\tstruct snd_dma_buffer dmab;\n\t\t\t\tmemset(&dmab, 0, sizeof(dmab));\n\t\t\t\t/* FIXME: We can allocate only in ZONE_DMA\n\t\t\t\t * without a device pointer!\n\t\t\t\t */\n\t\t\t\tif (snd_dma_alloc_pages(SNDRV_DMA_TYPE_DEV, NULL,\n\t\t\t\t\t\t\tsize, &dmab) < 0) {\n\t\t\t\t\tprintk(KERN_ERR \"snd-page-alloc: cannot allocate buffer pages (size = %d)\\n\", size);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tsnd_dma_reserve_buf(&dmab, (unsigned int)((vendor << 16) | device));\n\t\t\t}\n\t\t}\n\t} else if (strcmp(token, \"erase\") == 0)\n\t\t/* FIXME: need for releasing each buffer chunk? */\n\t\tfree_all_reserved_pages();\n\telse\n\t\tprintk(KERN_ERR \"snd-page-alloc: invalid proc cmd\\n\");\n\treturn (int)count;\n}", "target": 1, "cwe": [], "project": "linux-2.6", "commit_id": "ccec6e2c4a74adf76ed4e2478091a311b1806212", "hash": 309883721051093126401462833357401098731, "size": 86, "message": "Convert snd-page-alloc proc file to use seq_file\n\nUse seq_file for the proc file read/write of snd-page-alloc module.\nThis automatically fixes bugs in the old proc code.\n\nSigned-off-by: Takashi Iwai <tiwai@suse.de>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "static int putreg(struct task_struct *child,\n\tunsigned long regno, unsigned long value)\n{\n\tunsigned long tmp; \n\t\n\t/* Some code in the 64bit emulation may not be 64bit clean.\n\t   Don't take any chances. */\n\tif (test_tsk_thread_flag(child, TIF_IA32))\n\t\tvalue &= 0xffffffff;\n\tswitch (regno) {\n\t\tcase offsetof(struct user_regs_struct,fs):\n\t\t\tif (value && (value & 3) != 3)\n\t\t\t\treturn -EIO;\n\t\t\tchild->thread.fsindex = value & 0xffff; \n\t\t\treturn 0;\n\t\tcase offsetof(struct user_regs_struct,gs):\n\t\t\tif (value && (value & 3) != 3)\n\t\t\t\treturn -EIO;\n\t\t\tchild->thread.gsindex = value & 0xffff;\n\t\t\treturn 0;\n\t\tcase offsetof(struct user_regs_struct,ds):\n\t\t\tif (value && (value & 3) != 3)\n\t\t\t\treturn -EIO;\n\t\t\tchild->thread.ds = value & 0xffff;\n\t\t\treturn 0;\n\t\tcase offsetof(struct user_regs_struct,es): \n\t\t\tif (value && (value & 3) != 3)\n\t\t\t\treturn -EIO;\n\t\t\tchild->thread.es = value & 0xffff;\n\t\t\treturn 0;\n\t\tcase offsetof(struct user_regs_struct,ss):\n\t\t\tif ((value & 3) != 3)\n\t\t\t\treturn -EIO;\n\t\t\tvalue &= 0xffff;\n\t\t\treturn 0;\n\t\tcase offsetof(struct user_regs_struct,fs_base):\n\t\t\tif (value >= TASK_SIZE_OF(child))\n\t\t\t\treturn -EIO;\n\t\t\tchild->thread.fs = value;\n\t\t\treturn 0;\n\t\tcase offsetof(struct user_regs_struct,gs_base):\n\t\t\tif (value >= TASK_SIZE_OF(child))\n\t\t\t\treturn -EIO;\n\t\t\tchild->thread.gs = value;\n\t\t\treturn 0;\n\t\tcase offsetof(struct user_regs_struct, eflags):\n\t\t\tvalue &= FLAG_MASK;\n\t\t\ttmp = get_stack_long(child, EFL_OFFSET); \n\t\t\ttmp &= ~FLAG_MASK; \n\t\t\tvalue |= tmp;\n\t\t\tbreak;\n\t\tcase offsetof(struct user_regs_struct,cs): \n\t\t\tif ((value & 3) != 3)\n\t\t\t\treturn -EIO;\n\t\t\tvalue &= 0xffff;\n\t\t\tbreak;\n\t}\n\tput_stack_long(child, regno - sizeof(struct pt_regs), value);\n\treturn 0;\n}", "target": 1, "cwe": ["CWE-264"], "project": "linux-2.6", "commit_id": "176df2457ef6207156ca1a40991c54ca01fef567", "hash": 118245962164453333133896654852307172628, "size": 60, "message": "x86_64: Zero extend all registers after ptrace in 32bit entry path.\n\nStrictly it's only needed for eax.\n\nIt actually does a little more than strictly needed -- the other registers\nare already zero extended.\n\nAlso remove the now unnecessary and non functional compat task check\nin ptrace.\n\nThis is CVE-2007-4573\n\nFound by Wojciech Purczynski\n\nSigned-off-by: Andi Kleen <ak@suse.de>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "static int pwc_video_close(struct inode *inode, struct file *file)\n{\n\tstruct video_device *vdev = file->private_data;\n\tstruct pwc_device *pdev;\n\tint i;\n\n\tPWC_DEBUG_OPEN(\">> video_close called(vdev = 0x%p).\\n\", vdev);\n\n\tpdev = (struct pwc_device *)vdev->priv;\n\tif (pdev->vopen == 0)\n\t\tPWC_DEBUG_MODULE(\"video_close() called on closed device?\\n\");\n\n\t/* Dump statistics, but only if a reasonable amount of frames were\n\t   processed (to prevent endless log-entries in case of snap-shot\n\t   programs)\n\t */\n\tif (pdev->vframe_count > 20)\n\t\tPWC_DEBUG_MODULE(\"Closing video device: %d frames received, dumped %d frames, %d frames with errors.\\n\", pdev->vframe_count, pdev->vframes_dumped, pdev->vframes_error);\n\n\tif (DEVICE_USE_CODEC1(pdev->type))\n\t    pwc_dec1_exit();\n\telse\n\t    pwc_dec23_exit();\n\n\tpwc_isoc_cleanup(pdev);\n\tpwc_free_buffers(pdev);\n\n\t/* Turn off LEDS and power down camera, but only when not unplugged */\n\tif (pdev->error_status != EPIPE) {\n\t\t/* Turn LEDs off */\n\t\tif (pwc_set_leds(pdev, 0, 0) < 0)\n\t\t\tPWC_DEBUG_MODULE(\"Failed to set LED on/off time.\\n\");\n\t\tif (power_save) {\n\t\t\ti = pwc_camera_power(pdev, 0);\n\t\t\tif (i < 0)\n\t\t\t\tPWC_ERROR(\"Failed to power down camera (%d)\\n\", i);\n\t\t}\n\t}\n\tpdev->vopen--;\n\tPWC_DEBUG_OPEN(\"<< video_close() vopen=%d\\n\", pdev->vopen);\n\treturn 0;\n}", "target": 1, "cwe": ["CWE-399"], "project": "linux-2.6", "commit_id": "85237f202d46d55c1bffe0c5b1aa3ddc0f1dce4d", "hash": 124682724723247590310182780943974549817, "size": 42, "message": "USB: fix DoS in pwc USB video driver\n\nthe pwc driver has a disconnect method that waits for user space to\nclose the device. This opens up an opportunity for a DoS attack,\nblocking the USB subsystem and making khubd's task busy wait in\nkernel space. This patch shifts freeing resources to close if an opened\ndevice is disconnected.\n\nSigned-off-by: Oliver Neukum <oneukum@suse.de>\nCC: stable <stable@kernel.org>\nSigned-off-by: Greg Kroah-Hartman <gregkh@suse.de>"}
{"func": "static void usb_pwc_disconnect(struct usb_interface *intf)\n{\n\tstruct pwc_device *pdev;\n\tint hint;\n\n\tlock_kernel();\n\tpdev = usb_get_intfdata (intf);\n\tusb_set_intfdata (intf, NULL);\n\tif (pdev == NULL) {\n\t\tPWC_ERROR(\"pwc_disconnect() Called without private pointer.\\n\");\n\t\tgoto disconnect_out;\n\t}\n\tif (pdev->udev == NULL) {\n\t\tPWC_ERROR(\"pwc_disconnect() already called for %p\\n\", pdev);\n\t\tgoto disconnect_out;\n\t}\n\tif (pdev->udev != interface_to_usbdev(intf)) {\n\t\tPWC_ERROR(\"pwc_disconnect() Woops: pointer mismatch udev/pdev.\\n\");\n\t\tgoto disconnect_out;\n\t}\n\n\t/* We got unplugged; this is signalled by an EPIPE error code */\n\tif (pdev->vopen) {\n\t\tPWC_INFO(\"Disconnected while webcam is in use!\\n\");\n\t\tpdev->error_status = EPIPE;\n\t}\n\n\t/* Alert waiting processes */\n\twake_up_interruptible(&pdev->frameq);\n\t/* Wait until device is closed */\n\twhile (pdev->vopen)\n\t\tschedule();\n\t/* Device is now closed, so we can safely unregister it */\n\tPWC_DEBUG_PROBE(\"Unregistering video device in disconnect().\\n\");\n\tpwc_remove_sysfs_files(pdev->vdev);\n\tvideo_unregister_device(pdev->vdev);\n\n\t/* Free memory (don't set pdev to 0 just yet) */\n\tkfree(pdev);\n\ndisconnect_out:\n\t/* search device_hint[] table if we occupy a slot, by any chance */\n\tfor (hint = 0; hint < MAX_DEV_HINTS; hint++)\n\t\tif (device_hint[hint].pdev == pdev)\n\t\t\tdevice_hint[hint].pdev = NULL;\n\n\tunlock_kernel();\n}", "target": 1, "cwe": ["CWE-399"], "project": "linux-2.6", "commit_id": "85237f202d46d55c1bffe0c5b1aa3ddc0f1dce4d", "hash": 73412740084702268395071715055708958170, "size": 48, "message": "USB: fix DoS in pwc USB video driver\n\nthe pwc driver has a disconnect method that waits for user space to\nclose the device. This opens up an opportunity for a DoS attack,\nblocking the USB subsystem and making khubd's task busy wait in\nkernel space. This patch shifts freeing resources to close if an opened\ndevice is disconnected.\n\nSigned-off-by: Oliver Neukum <oneukum@suse.de>\nCC: stable <stable@kernel.org>\nSigned-off-by: Greg Kroah-Hartman <gregkh@suse.de>"}
{"func": "static int return_EIO(void)\n{\n\treturn -EIO;\n}", "target": 1, "cwe": [], "project": "linux-2.6", "commit_id": "be6aab0e9fa6d3c6d75aa1e38ac972d8b4ee82b8", "hash": 96018639668712651740578198950715256807, "size": 4, "message": "[PATCH] fix memory corruption from misinterpreted bad_inode_ops return values\n\nCVE-2006-5753 is for a case where an inode can be marked bad, switching\nthe ops to bad_inode_ops, which are all connected as:\n\nstatic int return_EIO(void)\n{\n        return -EIO;\n}\n\n#define EIO_ERROR ((void *) (return_EIO))\n\nstatic struct inode_operations bad_inode_ops =\n{\n        .create         = bad_inode_create\n...etc...\n\nThe problem here is that the void cast causes return types to not be\npromoted, and for ops such as listxattr which expect more than 32 bits of\nreturn value, the 32-bit -EIO is interpreted as a large positive 64-bit\nnumber, i.e. 0x00000000fffffffa instead of 0xfffffffa.\n\nThis goes particularly badly when the return value is taken as a number of\nbytes to copy into, say, a user's buffer for example...\n\nI originally had coded up the fix by creating a return_EIO_<TYPE> macro\nfor each return type, like this:\n\nstatic int return_EIO_int(void)\n{\n\treturn -EIO;\n}\n#define EIO_ERROR_INT ((void *) (return_EIO_int))\n\nstatic struct inode_operations bad_inode_ops =\n{\n\t.create\t\t= EIO_ERROR_INT,\n...etc...\n\nbut Al felt that it was probably better to create an EIO-returner for each\nactual op signature.  Since so few ops share a signature, I just went ahead\n& created an EIO function for each individual file & inode op that returns\na value.\n\nSigned-off-by: Eric Sandeen <sandeen@redhat.com>\nCc: Al Viro <viro@zeniv.linux.org.uk>\nSigned-off-by: Andrew Morton <akpm@osdl.org>\nSigned-off-by: Linus Torvalds <torvalds@osdl.org>"}
{"func": "void make_bad_inode(struct inode * inode) \n{\n\tremove_inode_hash(inode);\n\n\tinode->i_mode = S_IFREG;\n\tinode->i_atime = inode->i_mtime = inode->i_ctime =\n\t\tcurrent_fs_time(inode->i_sb);\n\tinode->i_op = &bad_inode_ops;\t\n\tinode->i_fop = &bad_file_ops;\t\n}", "target": 1, "cwe": [], "project": "linux-2.6", "commit_id": "be6aab0e9fa6d3c6d75aa1e38ac972d8b4ee82b8", "hash": 324712412023376655821555259142241889315, "size": 10, "message": "[PATCH] fix memory corruption from misinterpreted bad_inode_ops return values\n\nCVE-2006-5753 is for a case where an inode can be marked bad, switching\nthe ops to bad_inode_ops, which are all connected as:\n\nstatic int return_EIO(void)\n{\n        return -EIO;\n}\n\n#define EIO_ERROR ((void *) (return_EIO))\n\nstatic struct inode_operations bad_inode_ops =\n{\n        .create         = bad_inode_create\n...etc...\n\nThe problem here is that the void cast causes return types to not be\npromoted, and for ops such as listxattr which expect more than 32 bits of\nreturn value, the 32-bit -EIO is interpreted as a large positive 64-bit\nnumber, i.e. 0x00000000fffffffa instead of 0xfffffffa.\n\nThis goes particularly badly when the return value is taken as a number of\nbytes to copy into, say, a user's buffer for example...\n\nI originally had coded up the fix by creating a return_EIO_<TYPE> macro\nfor each return type, like this:\n\nstatic int return_EIO_int(void)\n{\n\treturn -EIO;\n}\n#define EIO_ERROR_INT ((void *) (return_EIO_int))\n\nstatic struct inode_operations bad_inode_ops =\n{\n\t.create\t\t= EIO_ERROR_INT,\n...etc...\n\nbut Al felt that it was probably better to create an EIO-returner for each\nactual op signature.  Since so few ops share a signature, I just went ahead\n& created an EIO function for each individual file & inode op that returns\na value.\n\nSigned-off-by: Eric Sandeen <sandeen@redhat.com>\nCc: Al Viro <viro@zeniv.linux.org.uk>\nSigned-off-by: Andrew Morton <akpm@osdl.org>\nSigned-off-by: Linus Torvalds <torvalds@osdl.org>"}
{"func": "int is_bad_inode(struct inode * inode) \n{\n\treturn (inode->i_op == &bad_inode_ops);\t\n}", "target": 1, "cwe": [], "project": "linux-2.6", "commit_id": "be6aab0e9fa6d3c6d75aa1e38ac972d8b4ee82b8", "hash": 274069347086903071473148868064705582935, "size": 4, "message": "[PATCH] fix memory corruption from misinterpreted bad_inode_ops return values\n\nCVE-2006-5753 is for a case where an inode can be marked bad, switching\nthe ops to bad_inode_ops, which are all connected as:\n\nstatic int return_EIO(void)\n{\n        return -EIO;\n}\n\n#define EIO_ERROR ((void *) (return_EIO))\n\nstatic struct inode_operations bad_inode_ops =\n{\n        .create         = bad_inode_create\n...etc...\n\nThe problem here is that the void cast causes return types to not be\npromoted, and for ops such as listxattr which expect more than 32 bits of\nreturn value, the 32-bit -EIO is interpreted as a large positive 64-bit\nnumber, i.e. 0x00000000fffffffa instead of 0xfffffffa.\n\nThis goes particularly badly when the return value is taken as a number of\nbytes to copy into, say, a user's buffer for example...\n\nI originally had coded up the fix by creating a return_EIO_<TYPE> macro\nfor each return type, like this:\n\nstatic int return_EIO_int(void)\n{\n\treturn -EIO;\n}\n#define EIO_ERROR_INT ((void *) (return_EIO_int))\n\nstatic struct inode_operations bad_inode_ops =\n{\n\t.create\t\t= EIO_ERROR_INT,\n...etc...\n\nbut Al felt that it was probably better to create an EIO-returner for each\nactual op signature.  Since so few ops share a signature, I just went ahead\n& created an EIO function for each individual file & inode op that returns\na value.\n\nSigned-off-by: Eric Sandeen <sandeen@redhat.com>\nCc: Al Viro <viro@zeniv.linux.org.uk>\nSigned-off-by: Andrew Morton <akpm@osdl.org>\nSigned-off-by: Linus Torvalds <torvalds@osdl.org>"}
{"func": "void hash_preload(struct mm_struct *mm, unsigned long ea,\n\t\t  unsigned long access, unsigned long trap)\n{\n\tunsigned long vsid;\n\tvoid *pgdir;\n\tpte_t *ptep;\n\tcpumask_t mask;\n\tunsigned long flags;\n\tint local = 0;\n\n\t/* We don't want huge pages prefaulted for now\n\t */\n\tif (unlikely(in_hugepage_area(mm->context, ea)))\n\t\treturn;\n\n\tDBG_LOW(\"hash_preload(mm=%p, mm->pgdir=%p, ea=%016lx, access=%lx,\"\n\t\t\" trap=%lx\\n\", mm, mm->pgd, ea, access, trap);\n\n\t/* Get PTE, VSID, access mask */\n\tpgdir = mm->pgd;\n\tif (pgdir == NULL)\n\t\treturn;\n\tptep = find_linux_pte(pgdir, ea);\n\tif (!ptep)\n\t\treturn;\n\tvsid = get_vsid(mm->context.id, ea);\n\n\t/* Hash it in */\n\tlocal_irq_save(flags);\n\tmask = cpumask_of_cpu(smp_processor_id());\n\tif (cpus_equal(mm->cpu_vm_mask, mask))\n\t\tlocal = 1;\n#ifndef CONFIG_PPC_64K_PAGES\n\t__hash_page_4K(ea, access, vsid, ptep, trap, local);\n#else\n\tif (mmu_ci_restrictions) {\n\t\t/* If this PTE is non-cacheable, switch to 4k */\n\t\tif (mm->context.user_psize == MMU_PAGE_64K &&\n\t\t    (pte_val(*ptep) & _PAGE_NO_CACHE)) {\n\t\t\tmm->context.user_psize = MMU_PAGE_4K;\n\t\t\tmm->context.sllp = SLB_VSID_USER |\n\t\t\t\tmmu_psize_defs[MMU_PAGE_4K].sllp;\n\t\t\tget_paca()->context = mm->context;\n\t\t\tslb_flush_and_rebolt();\n#ifdef CONFIG_SPE_BASE\n\t\t\tspu_flush_all_slbs(mm);\n#endif\n\t\t}\n\t}\n\tif (mm->context.user_psize == MMU_PAGE_64K)\n\t\t__hash_page_64K(ea, access, vsid, ptep, trap, local);\n\telse\n\t\t__hash_page_4K(ea, access, vsid, ptep, trap, local);\n#endif /* CONFIG_PPC_64K_PAGES */\n\tlocal_irq_restore(flags);\n}", "target": 1, "cwe": ["CWE-200"], "project": "linux-2.6", "commit_id": "721151d004dcf01a71b12bb6b893f9160284cf6e", "hash": 283712393711387453956188968218825085417, "size": 56, "message": "[POWERPC] Allow drivers to map individual 4k pages to userspace\n\nSome drivers have resources that they want to be able to map into\nuserspace that are 4k in size.  On a kernel configured with 64k pages\nwe currently end up mapping the 4k we want plus another 60k of\nphysical address space, which could contain anything.  This can\nintroduce security problems, for example in the case of an infiniband\nadaptor where the other 60k could contain registers that some other\nprogram is using for its communications.\n\nThis patch adds a new function, remap_4k_pfn, which drivers can use to\nmap a single 4k page to userspace regardless of whether the kernel is\nusing a 4k or a 64k page size.  Like remap_pfn_range, it would\ntypically be called in a driver's mmap function.  It only maps a\nsingle 4k page, which on a 64k page kernel appears replicated 16 times\nthroughout a 64k page.  On a 4k page kernel it reduces to a call to\nremap_pfn_range.\n\nThe way this works on a 64k kernel is that a new bit, _PAGE_4K_PFN,\ngets set on the linux PTE.  This alters the way that __hash_page_4K\ncomputes the real address to put in the HPTE.  The RPN field of the\nlinux PTE becomes the 4k RPN directly rather than being interpreted as\na 64k RPN.  Since the RPN field is 32 bits, this means that physical\naddresses being mapped with remap_4k_pfn have to be below 2^44,\ni.e. 0x100000000000.\n\nThe patch also factors out the code in arch/powerpc/mm/hash_utils_64.c\nthat deals with demoting a process to use 4k pages into one function\nthat gets called in the various different places where we need to do\nthat.  There were some discrepancies between exactly what was done in\nthe various places, such as a call to spu_flush_all_slbs in one case\nbut not in others.\n\nSigned-off-by: Paul Mackerras <paulus@samba.org>"}
{"func": "int hash_page(unsigned long ea, unsigned long access, unsigned long trap)\n{\n\tvoid *pgdir;\n\tunsigned long vsid;\n\tstruct mm_struct *mm;\n\tpte_t *ptep;\n\tcpumask_t tmp;\n\tint rc, user_region = 0, local = 0;\n\tint psize;\n\n\tDBG_LOW(\"hash_page(ea=%016lx, access=%lx, trap=%lx\\n\",\n\t\tea, access, trap);\n\n\tif ((ea & ~REGION_MASK) >= PGTABLE_RANGE) {\n\t\tDBG_LOW(\" out of pgtable range !\\n\");\n \t\treturn 1;\n\t}\n\n\t/* Get region & vsid */\n \tswitch (REGION_ID(ea)) {\n\tcase USER_REGION_ID:\n\t\tuser_region = 1;\n\t\tmm = current->mm;\n\t\tif (! mm) {\n\t\t\tDBG_LOW(\" user region with no mm !\\n\");\n\t\t\treturn 1;\n\t\t}\n\t\tvsid = get_vsid(mm->context.id, ea);\n\t\tpsize = mm->context.user_psize;\n\t\tbreak;\n\tcase VMALLOC_REGION_ID:\n\t\tmm = &init_mm;\n\t\tvsid = get_kernel_vsid(ea);\n\t\tif (ea < VMALLOC_END)\n\t\t\tpsize = mmu_vmalloc_psize;\n\t\telse\n\t\t\tpsize = mmu_io_psize;\n\t\tbreak;\n\tdefault:\n\t\t/* Not a valid range\n\t\t * Send the problem up to do_page_fault \n\t\t */\n\t\treturn 1;\n\t}\n\tDBG_LOW(\" mm=%p, mm->pgdir=%p, vsid=%016lx\\n\", mm, mm->pgd, vsid);\n\n\t/* Get pgdir */\n\tpgdir = mm->pgd;\n\tif (pgdir == NULL)\n\t\treturn 1;\n\n\t/* Check CPU locality */\n\ttmp = cpumask_of_cpu(smp_processor_id());\n\tif (user_region && cpus_equal(mm->cpu_vm_mask, tmp))\n\t\tlocal = 1;\n\n\t/* Handle hugepage regions */\n\tif (unlikely(in_hugepage_area(mm->context, ea))) {\n\t\tDBG_LOW(\" -> huge page !\\n\");\n\t\treturn hash_huge_page(mm, access, ea, vsid, local, trap);\n\t}\n\n\t/* Get PTE and page size from page tables */\n\tptep = find_linux_pte(pgdir, ea);\n\tif (ptep == NULL || !pte_present(*ptep)) {\n\t\tDBG_LOW(\" no PTE !\\n\");\n\t\treturn 1;\n\t}\n\n#ifndef CONFIG_PPC_64K_PAGES\n\tDBG_LOW(\" i-pte: %016lx\\n\", pte_val(*ptep));\n#else\n\tDBG_LOW(\" i-pte: %016lx %016lx\\n\", pte_val(*ptep),\n\t\tpte_val(*(ptep + PTRS_PER_PTE)));\n#endif\n\t/* Pre-check access permissions (will be re-checked atomically\n\t * in __hash_page_XX but this pre-check is a fast path\n\t */\n\tif (access & ~pte_val(*ptep)) {\n\t\tDBG_LOW(\" no access !\\n\");\n\t\treturn 1;\n\t}\n\n\t/* Do actual hashing */\n#ifndef CONFIG_PPC_64K_PAGES\n\trc = __hash_page_4K(ea, access, vsid, ptep, trap, local);\n#else\n\tif (mmu_ci_restrictions) {\n\t\t/* If this PTE is non-cacheable, switch to 4k */\n\t\tif (psize == MMU_PAGE_64K &&\n\t\t    (pte_val(*ptep) & _PAGE_NO_CACHE)) {\n\t\t\tif (user_region) {\n\t\t\t\tpsize = MMU_PAGE_4K;\n\t\t\t\tmm->context.user_psize = MMU_PAGE_4K;\n\t\t\t\tmm->context.sllp = SLB_VSID_USER |\n\t\t\t\t\tmmu_psize_defs[MMU_PAGE_4K].sllp;\n\t\t\t} else if (ea < VMALLOC_END) {\n\t\t\t\t/*\n\t\t\t\t * some driver did a non-cacheable mapping\n\t\t\t\t * in vmalloc space, so switch vmalloc\n\t\t\t\t * to 4k pages\n\t\t\t\t */\n\t\t\t\tprintk(KERN_ALERT \"Reducing vmalloc segment \"\n\t\t\t\t       \"to 4kB pages because of \"\n\t\t\t\t       \"non-cacheable mapping\\n\");\n\t\t\t\tpsize = mmu_vmalloc_psize = MMU_PAGE_4K;\n\t\t\t}\n#ifdef CONFIG_SPE_BASE\n\t\t\tspu_flush_all_slbs(mm);\n#endif\n\t\t}\n\t\tif (user_region) {\n\t\t\tif (psize != get_paca()->context.user_psize) {\n\t\t\t\tget_paca()->context = mm->context;\n\t\t\t\tslb_flush_and_rebolt();\n\t\t\t}\n\t\t} else if (get_paca()->vmalloc_sllp !=\n\t\t\t   mmu_psize_defs[mmu_vmalloc_psize].sllp) {\n\t\t\tget_paca()->vmalloc_sllp =\n\t\t\t\tmmu_psize_defs[mmu_vmalloc_psize].sllp;\n\t\t\tslb_flush_and_rebolt();\n\t\t}\n\t}\n\tif (psize == MMU_PAGE_64K)\n\t\trc = __hash_page_64K(ea, access, vsid, ptep, trap, local);\n\telse\n\t\trc = __hash_page_4K(ea, access, vsid, ptep, trap, local);\n#endif /* CONFIG_PPC_64K_PAGES */\n\n#ifndef CONFIG_PPC_64K_PAGES\n\tDBG_LOW(\" o-pte: %016lx\\n\", pte_val(*ptep));\n#else\n\tDBG_LOW(\" o-pte: %016lx %016lx\\n\", pte_val(*ptep),\n\t\tpte_val(*(ptep + PTRS_PER_PTE)));\n#endif\n\tDBG_LOW(\" -> rc=%d\\n\", rc);\n\treturn rc;\n}", "target": 1, "cwe": ["CWE-200"], "project": "linux-2.6", "commit_id": "721151d004dcf01a71b12bb6b893f9160284cf6e", "hash": 9811447350898023489441854944582708716, "size": 138, "message": "[POWERPC] Allow drivers to map individual 4k pages to userspace\n\nSome drivers have resources that they want to be able to map into\nuserspace that are 4k in size.  On a kernel configured with 64k pages\nwe currently end up mapping the 4k we want plus another 60k of\nphysical address space, which could contain anything.  This can\nintroduce security problems, for example in the case of an infiniband\nadaptor where the other 60k could contain registers that some other\nprogram is using for its communications.\n\nThis patch adds a new function, remap_4k_pfn, which drivers can use to\nmap a single 4k page to userspace regardless of whether the kernel is\nusing a 4k or a 64k page size.  Like remap_pfn_range, it would\ntypically be called in a driver's mmap function.  It only maps a\nsingle 4k page, which on a 64k page kernel appears replicated 16 times\nthroughout a 64k page.  On a 4k page kernel it reduces to a call to\nremap_pfn_range.\n\nThe way this works on a 64k kernel is that a new bit, _PAGE_4K_PFN,\ngets set on the linux PTE.  This alters the way that __hash_page_4K\ncomputes the real address to put in the HPTE.  The RPN field of the\nlinux PTE becomes the 4k RPN directly rather than being interpreted as\na 64k RPN.  Since the RPN field is 32 bits, this means that physical\naddresses being mapped with remap_4k_pfn have to be below 2^44,\ni.e. 0x100000000000.\n\nThe patch also factors out the code in arch/powerpc/mm/hash_utils_64.c\nthat deals with demoting a process to use 4k pages into one function\nthat gets called in the various different places where we need to do\nthat.  There were some discrepancies between exactly what was done in\nthe various places, such as a call to spu_flush_all_slbs in one case\nbut not in others.\n\nSigned-off-by: Paul Mackerras <paulus@samba.org>"}
{"func": "int ieee80211_rx(struct ieee80211_device *ieee, struct sk_buff *skb,\n\t\t struct ieee80211_rx_stats *rx_stats)\n{\n\tstruct net_device *dev = ieee->dev;\n\tstruct ieee80211_hdr_4addr *hdr;\n\tsize_t hdrlen;\n\tu16 fc, type, stype, sc;\n\tstruct net_device_stats *stats;\n\tunsigned int frag;\n\tu8 *payload;\n\tu16 ethertype;\n#ifdef NOT_YET\n\tstruct net_device *wds = NULL;\n\tstruct sk_buff *skb2 = NULL;\n\tstruct net_device *wds = NULL;\n\tint frame_authorized = 0;\n\tint from_assoc_ap = 0;\n\tvoid *sta = NULL;\n#endif\n\tu8 dst[ETH_ALEN];\n\tu8 src[ETH_ALEN];\n\tstruct ieee80211_crypt_data *crypt = NULL;\n\tint keyidx = 0;\n\tint can_be_decrypted = 0;\n\n\thdr = (struct ieee80211_hdr_4addr *)skb->data;\n\tstats = &ieee->stats;\n\n\tif (skb->len < 10) {\n\t\tprintk(KERN_INFO \"%s: SKB length < 10\\n\", dev->name);\n\t\tgoto rx_dropped;\n\t}\n\n\tfc = le16_to_cpu(hdr->frame_ctl);\n\ttype = WLAN_FC_GET_TYPE(fc);\n\tstype = WLAN_FC_GET_STYPE(fc);\n\tsc = le16_to_cpu(hdr->seq_ctl);\n\tfrag = WLAN_GET_SEQ_FRAG(sc);\n\thdrlen = ieee80211_get_hdrlen(fc);\n\n\t/* Put this code here so that we avoid duplicating it in all\n\t * Rx paths. - Jean II */\n#ifdef CONFIG_WIRELESS_EXT\n#ifdef IW_WIRELESS_SPY\t\t/* defined in iw_handler.h */\n\t/* If spy monitoring on */\n\tif (ieee->spy_data.spy_number > 0) {\n\t\tstruct iw_quality wstats;\n\n\t\twstats.updated = 0;\n\t\tif (rx_stats->mask & IEEE80211_STATMASK_RSSI) {\n\t\t\twstats.level = rx_stats->rssi;\n\t\t\twstats.updated |= IW_QUAL_LEVEL_UPDATED;\n\t\t} else\n\t\t\twstats.updated |= IW_QUAL_LEVEL_INVALID;\n\n\t\tif (rx_stats->mask & IEEE80211_STATMASK_NOISE) {\n\t\t\twstats.noise = rx_stats->noise;\n\t\t\twstats.updated |= IW_QUAL_NOISE_UPDATED;\n\t\t} else\n\t\t\twstats.updated |= IW_QUAL_NOISE_INVALID;\n\n\t\tif (rx_stats->mask & IEEE80211_STATMASK_SIGNAL) {\n\t\t\twstats.qual = rx_stats->signal;\n\t\t\twstats.updated |= IW_QUAL_QUAL_UPDATED;\n\t\t} else\n\t\t\twstats.updated |= IW_QUAL_QUAL_INVALID;\n\n\t\t/* Update spy records */\n\t\twireless_spy_update(ieee->dev, hdr->addr2, &wstats);\n\t}\n#endif\t\t\t\t/* IW_WIRELESS_SPY */\n#endif\t\t\t\t/* CONFIG_WIRELESS_EXT */\n\n#ifdef NOT_YET\n\thostap_update_rx_stats(local->ap, hdr, rx_stats);\n#endif\n\n\tif (ieee->iw_mode == IW_MODE_MONITOR) {\n\t\tstats->rx_packets++;\n\t\tstats->rx_bytes += skb->len;\n\t\tieee80211_monitor_rx(ieee, skb, rx_stats);\n\t\treturn 1;\n\t}\n\n\tcan_be_decrypted = (is_multicast_ether_addr(hdr->addr1) ||\n\t\t\t    is_broadcast_ether_addr(hdr->addr2)) ?\n\t    ieee->host_mc_decrypt : ieee->host_decrypt;\n\n\tif (can_be_decrypted) {\n\t\tif (skb->len >= hdrlen + 3) {\n\t\t\t/* Top two-bits of byte 3 are the key index */\n\t\t\tkeyidx = skb->data[hdrlen + 3] >> 6;\n\t\t}\n\n\t\t/* ieee->crypt[] is WEP_KEY (4) in length.  Given that keyidx\n\t\t * is only allowed 2-bits of storage, no value of keyidx can\n\t\t * be provided via above code that would result in keyidx\n\t\t * being out of range */\n\t\tcrypt = ieee->crypt[keyidx];\n\n#ifdef NOT_YET\n\t\tsta = NULL;\n\n\t\t/* Use station specific key to override default keys if the\n\t\t * receiver address is a unicast address (\"individual RA\"). If\n\t\t * bcrx_sta_key parameter is set, station specific key is used\n\t\t * even with broad/multicast targets (this is against IEEE\n\t\t * 802.11, but makes it easier to use different keys with\n\t\t * stations that do not support WEP key mapping). */\n\n\t\tif (!(hdr->addr1[0] & 0x01) || local->bcrx_sta_key)\n\t\t\t(void)hostap_handle_sta_crypto(local, hdr, &crypt,\n\t\t\t\t\t\t       &sta);\n#endif\n\n\t\t/* allow NULL decrypt to indicate an station specific override\n\t\t * for default encryption */\n\t\tif (crypt && (crypt->ops == NULL ||\n\t\t\t      crypt->ops->decrypt_mpdu == NULL))\n\t\t\tcrypt = NULL;\n\n\t\tif (!crypt && (fc & IEEE80211_FCTL_PROTECTED)) {\n\t\t\t/* This seems to be triggered by some (multicast?)\n\t\t\t * frames from other than current BSS, so just drop the\n\t\t\t * frames silently instead of filling system log with\n\t\t\t * these reports. */\n\t\t\tIEEE80211_DEBUG_DROP(\"Decryption failed (not set)\"\n\t\t\t\t\t     \" (SA=\" MAC_FMT \")\\n\",\n\t\t\t\t\t     MAC_ARG(hdr->addr2));\n\t\t\tieee->ieee_stats.rx_discards_undecryptable++;\n\t\t\tgoto rx_dropped;\n\t\t}\n\t}\n#ifdef NOT_YET\n\tif (type != WLAN_FC_TYPE_DATA) {\n\t\tif (type == WLAN_FC_TYPE_MGMT && stype == WLAN_FC_STYPE_AUTH &&\n\t\t    fc & IEEE80211_FCTL_PROTECTED && ieee->host_decrypt &&\n\t\t    (keyidx = hostap_rx_frame_decrypt(ieee, skb, crypt)) < 0) {\n\t\t\tprintk(KERN_DEBUG \"%s: failed to decrypt mgmt::auth \"\n\t\t\t       \"from \" MAC_FMT \"\\n\", dev->name,\n\t\t\t       MAC_ARG(hdr->addr2));\n\t\t\t/* TODO: could inform hostapd about this so that it\n\t\t\t * could send auth failure report */\n\t\t\tgoto rx_dropped;\n\t\t}\n\n\t\tif (ieee80211_rx_frame_mgmt(ieee, skb, rx_stats, type, stype))\n\t\t\tgoto rx_dropped;\n\t\telse\n\t\t\tgoto rx_exit;\n\t}\n#endif\n\t/* drop duplicate 802.11 retransmissions (IEEE 802.11 Chap. 9.29) */\n\tif (sc == ieee->prev_seq_ctl)\n\t\tgoto rx_dropped;\n\telse\n\t\tieee->prev_seq_ctl = sc;\n\n\t/* Data frame - extract src/dst addresses */\n\tif (skb->len < IEEE80211_3ADDR_LEN)\n\t\tgoto rx_dropped;\n\n\tswitch (fc & (IEEE80211_FCTL_FROMDS | IEEE80211_FCTL_TODS)) {\n\tcase IEEE80211_FCTL_FROMDS:\n\t\tmemcpy(dst, hdr->addr1, ETH_ALEN);\n\t\tmemcpy(src, hdr->addr3, ETH_ALEN);\n\t\tbreak;\n\tcase IEEE80211_FCTL_TODS:\n\t\tmemcpy(dst, hdr->addr3, ETH_ALEN);\n\t\tmemcpy(src, hdr->addr2, ETH_ALEN);\n\t\tbreak;\n\tcase IEEE80211_FCTL_FROMDS | IEEE80211_FCTL_TODS:\n\t\tif (skb->len < IEEE80211_4ADDR_LEN)\n\t\t\tgoto rx_dropped;\n\t\tmemcpy(dst, hdr->addr3, ETH_ALEN);\n\t\tmemcpy(src, hdr->addr4, ETH_ALEN);\n\t\tbreak;\n\tcase 0:\n\t\tmemcpy(dst, hdr->addr1, ETH_ALEN);\n\t\tmemcpy(src, hdr->addr2, ETH_ALEN);\n\t\tbreak;\n\t}\n\n#ifdef NOT_YET\n\tif (hostap_rx_frame_wds(ieee, hdr, fc, &wds))\n\t\tgoto rx_dropped;\n\tif (wds) {\n\t\tskb->dev = dev = wds;\n\t\tstats = hostap_get_stats(dev);\n\t}\n\n\tif (ieee->iw_mode == IW_MODE_MASTER && !wds &&\n\t    (fc & (IEEE80211_FCTL_TODS | IEEE80211_FCTL_FROMDS)) ==\n\t    IEEE80211_FCTL_FROMDS && ieee->stadev\n\t    && !compare_ether_addr(hdr->addr2, ieee->assoc_ap_addr)) {\n\t\t/* Frame from BSSID of the AP for which we are a client */\n\t\tskb->dev = dev = ieee->stadev;\n\t\tstats = hostap_get_stats(dev);\n\t\tfrom_assoc_ap = 1;\n\t}\n#endif\n\n\tdev->last_rx = jiffies;\n\n#ifdef NOT_YET\n\tif ((ieee->iw_mode == IW_MODE_MASTER ||\n\t     ieee->iw_mode == IW_MODE_REPEAT) && !from_assoc_ap) {\n\t\tswitch (hostap_handle_sta_rx(ieee, dev, skb, rx_stats,\n\t\t\t\t\t     wds != NULL)) {\n\t\tcase AP_RX_CONTINUE_NOT_AUTHORIZED:\n\t\t\tframe_authorized = 0;\n\t\t\tbreak;\n\t\tcase AP_RX_CONTINUE:\n\t\t\tframe_authorized = 1;\n\t\t\tbreak;\n\t\tcase AP_RX_DROP:\n\t\t\tgoto rx_dropped;\n\t\tcase AP_RX_EXIT:\n\t\t\tgoto rx_exit;\n\t\t}\n\t}\n#endif\n\n\t/* Nullfunc frames may have PS-bit set, so they must be passed to\n\t * hostap_handle_sta_rx() before being dropped here. */\n\n\tstype &= ~IEEE80211_STYPE_QOS_DATA;\n\n\tif (stype != IEEE80211_STYPE_DATA &&\n\t    stype != IEEE80211_STYPE_DATA_CFACK &&\n\t    stype != IEEE80211_STYPE_DATA_CFPOLL &&\n\t    stype != IEEE80211_STYPE_DATA_CFACKPOLL) {\n\t\tif (stype != IEEE80211_STYPE_NULLFUNC)\n\t\t\tIEEE80211_DEBUG_DROP(\"RX: dropped data frame \"\n\t\t\t\t\t     \"with no data (type=0x%02x, \"\n\t\t\t\t\t     \"subtype=0x%02x, len=%d)\\n\",\n\t\t\t\t\t     type, stype, skb->len);\n\t\tgoto rx_dropped;\n\t}\n\n\t/* skb: hdr + (possibly fragmented, possibly encrypted) payload */\n\n\tif ((fc & IEEE80211_FCTL_PROTECTED) && can_be_decrypted &&\n\t    (keyidx = ieee80211_rx_frame_decrypt(ieee, skb, crypt)) < 0)\n\t\tgoto rx_dropped;\n\n\thdr = (struct ieee80211_hdr_4addr *)skb->data;\n\n\t/* skb: hdr + (possibly fragmented) plaintext payload */\n\t// PR: FIXME: hostap has additional conditions in the \"if\" below:\n\t// ieee->host_decrypt && (fc & IEEE80211_FCTL_PROTECTED) &&\n\tif ((frag != 0) || (fc & IEEE80211_FCTL_MOREFRAGS)) {\n\t\tint flen;\n\t\tstruct sk_buff *frag_skb = ieee80211_frag_cache_get(ieee, hdr);\n\t\tIEEE80211_DEBUG_FRAG(\"Rx Fragment received (%u)\\n\", frag);\n\n\t\tif (!frag_skb) {\n\t\t\tIEEE80211_DEBUG(IEEE80211_DL_RX | IEEE80211_DL_FRAG,\n\t\t\t\t\t\"Rx cannot get skb from fragment \"\n\t\t\t\t\t\"cache (morefrag=%d seq=%u frag=%u)\\n\",\n\t\t\t\t\t(fc & IEEE80211_FCTL_MOREFRAGS) != 0,\n\t\t\t\t\tWLAN_GET_SEQ_SEQ(sc), frag);\n\t\t\tgoto rx_dropped;\n\t\t}\n\n\t\tflen = skb->len;\n\t\tif (frag != 0)\n\t\t\tflen -= hdrlen;\n\n\t\tif (frag_skb->tail + flen > frag_skb->end) {\n\t\t\tprintk(KERN_WARNING \"%s: host decrypted and \"\n\t\t\t       \"reassembled frame did not fit skb\\n\",\n\t\t\t       dev->name);\n\t\t\tieee80211_frag_cache_invalidate(ieee, hdr);\n\t\t\tgoto rx_dropped;\n\t\t}\n\n\t\tif (frag == 0) {\n\t\t\t/* copy first fragment (including full headers) into\n\t\t\t * beginning of the fragment cache skb */\n\t\t\tskb_copy_from_linear_data(skb, skb_put(frag_skb, flen), flen);\n\t\t} else {\n\t\t\t/* append frame payload to the end of the fragment\n\t\t\t * cache skb */\n\t\t\tskb_copy_from_linear_data_offset(skb, hdrlen,\n\t\t\t\t      skb_put(frag_skb, flen), flen);\n\t\t}\n\t\tdev_kfree_skb_any(skb);\n\t\tskb = NULL;\n\n\t\tif (fc & IEEE80211_FCTL_MOREFRAGS) {\n\t\t\t/* more fragments expected - leave the skb in fragment\n\t\t\t * cache for now; it will be delivered to upper layers\n\t\t\t * after all fragments have been received */\n\t\t\tgoto rx_exit;\n\t\t}\n\n\t\t/* this was the last fragment and the frame will be\n\t\t * delivered, so remove skb from fragment cache */\n\t\tskb = frag_skb;\n\t\thdr = (struct ieee80211_hdr_4addr *)skb->data;\n\t\tieee80211_frag_cache_invalidate(ieee, hdr);\n\t}\n\n\t/* skb: hdr + (possible reassembled) full MSDU payload; possibly still\n\t * encrypted/authenticated */\n\tif ((fc & IEEE80211_FCTL_PROTECTED) && can_be_decrypted &&\n\t    ieee80211_rx_frame_decrypt_msdu(ieee, skb, keyidx, crypt))\n\t\tgoto rx_dropped;\n\n\thdr = (struct ieee80211_hdr_4addr *)skb->data;\n\tif (crypt && !(fc & IEEE80211_FCTL_PROTECTED) && !ieee->open_wep) {\n\t\tif (\t\t/*ieee->ieee802_1x && */\n\t\t\t   ieee80211_is_eapol_frame(ieee, skb)) {\n\t\t\t/* pass unencrypted EAPOL frames even if encryption is\n\t\t\t * configured */\n\t\t} else {\n\t\t\tIEEE80211_DEBUG_DROP(\"encryption configured, but RX \"\n\t\t\t\t\t     \"frame not encrypted (SA=\" MAC_FMT\n\t\t\t\t\t     \")\\n\", MAC_ARG(hdr->addr2));\n\t\t\tgoto rx_dropped;\n\t\t}\n\t}\n\n\tif (crypt && !(fc & IEEE80211_FCTL_PROTECTED) && !ieee->open_wep &&\n\t    !ieee80211_is_eapol_frame(ieee, skb)) {\n\t\tIEEE80211_DEBUG_DROP(\"dropped unencrypted RX data \"\n\t\t\t\t     \"frame from \" MAC_FMT\n\t\t\t\t     \" (drop_unencrypted=1)\\n\",\n\t\t\t\t     MAC_ARG(hdr->addr2));\n\t\tgoto rx_dropped;\n\t}\n\n\t/* If the frame was decrypted in hardware, we may need to strip off\n\t * any security data (IV, ICV, etc) that was left behind */\n\tif (!can_be_decrypted && (fc & IEEE80211_FCTL_PROTECTED) &&\n\t    ieee->host_strip_iv_icv) {\n\t\tint trimlen = 0;\n\n\t\t/* Top two-bits of byte 3 are the key index */\n\t\tif (skb->len >= hdrlen + 3)\n\t\t\tkeyidx = skb->data[hdrlen + 3] >> 6;\n\n\t\t/* To strip off any security data which appears before the\n\t\t * payload, we simply increase hdrlen (as the header gets\n\t\t * chopped off immediately below). For the security data which\n\t\t * appears after the payload, we use skb_trim. */\n\n\t\tswitch (ieee->sec.encode_alg[keyidx]) {\n\t\tcase SEC_ALG_WEP:\n\t\t\t/* 4 byte IV */\n\t\t\thdrlen += 4;\n\t\t\t/* 4 byte ICV */\n\t\t\ttrimlen = 4;\n\t\t\tbreak;\n\t\tcase SEC_ALG_TKIP:\n\t\t\t/* 4 byte IV, 4 byte ExtIV */\n\t\t\thdrlen += 8;\n\t\t\t/* 8 byte MIC, 4 byte ICV */\n\t\t\ttrimlen = 12;\n\t\t\tbreak;\n\t\tcase SEC_ALG_CCMP:\n\t\t\t/* 8 byte CCMP header */\n\t\t\thdrlen += 8;\n\t\t\t/* 8 byte MIC */\n\t\t\ttrimlen = 8;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (skb->len < trimlen)\n\t\t\tgoto rx_dropped;\n\n\t\t__skb_trim(skb, skb->len - trimlen);\n\n\t\tif (skb->len < hdrlen)\n\t\t\tgoto rx_dropped;\n\t}\n\n\t/* skb: hdr + (possible reassembled) full plaintext payload */\n\n\tpayload = skb->data + hdrlen;\n\tethertype = (payload[6] << 8) | payload[7];\n\n#ifdef NOT_YET\n\t/* If IEEE 802.1X is used, check whether the port is authorized to send\n\t * the received frame. */\n\tif (ieee->ieee802_1x && ieee->iw_mode == IW_MODE_MASTER) {\n\t\tif (ethertype == ETH_P_PAE) {\n\t\t\tprintk(KERN_DEBUG \"%s: RX: IEEE 802.1X frame\\n\",\n\t\t\t       dev->name);\n\t\t\tif (ieee->hostapd && ieee->apdev) {\n\t\t\t\t/* Send IEEE 802.1X frames to the user\n\t\t\t\t * space daemon for processing */\n\t\t\t\tprism2_rx_80211(ieee->apdev, skb, rx_stats,\n\t\t\t\t\t\tPRISM2_RX_MGMT);\n\t\t\t\tieee->apdevstats.rx_packets++;\n\t\t\t\tieee->apdevstats.rx_bytes += skb->len;\n\t\t\t\tgoto rx_exit;\n\t\t\t}\n\t\t} else if (!frame_authorized) {\n\t\t\tprintk(KERN_DEBUG \"%s: dropped frame from \"\n\t\t\t       \"unauthorized port (IEEE 802.1X): \"\n\t\t\t       \"ethertype=0x%04x\\n\", dev->name, ethertype);\n\t\t\tgoto rx_dropped;\n\t\t}\n\t}\n#endif\n\n\t/* convert hdr + possible LLC headers into Ethernet header */\n\tif (skb->len - hdrlen >= 8 &&\n\t    ((memcmp(payload, rfc1042_header, SNAP_SIZE) == 0 &&\n\t      ethertype != ETH_P_AARP && ethertype != ETH_P_IPX) ||\n\t     memcmp(payload, bridge_tunnel_header, SNAP_SIZE) == 0)) {\n\t\t/* remove RFC1042 or Bridge-Tunnel encapsulation and\n\t\t * replace EtherType */\n\t\tskb_pull(skb, hdrlen + SNAP_SIZE);\n\t\tmemcpy(skb_push(skb, ETH_ALEN), src, ETH_ALEN);\n\t\tmemcpy(skb_push(skb, ETH_ALEN), dst, ETH_ALEN);\n\t} else {\n\t\tu16 len;\n\t\t/* Leave Ethernet header part of hdr and full payload */\n\t\tskb_pull(skb, hdrlen);\n\t\tlen = htons(skb->len);\n\t\tmemcpy(skb_push(skb, 2), &len, 2);\n\t\tmemcpy(skb_push(skb, ETH_ALEN), src, ETH_ALEN);\n\t\tmemcpy(skb_push(skb, ETH_ALEN), dst, ETH_ALEN);\n\t}\n\n#ifdef NOT_YET\n\tif (wds && ((fc & (IEEE80211_FCTL_TODS | IEEE80211_FCTL_FROMDS)) ==\n\t\t    IEEE80211_FCTL_TODS) && skb->len >= ETH_HLEN + ETH_ALEN) {\n\t\t/* Non-standard frame: get addr4 from its bogus location after\n\t\t * the payload */\n\t\tskb_copy_to_linear_data_offset(skb, ETH_ALEN,\n\t\t\t\t\t       skb->data + skb->len - ETH_ALEN,\n\t\t\t\t\t       ETH_ALEN);\n\t\tskb_trim(skb, skb->len - ETH_ALEN);\n\t}\n#endif\n\n\tstats->rx_packets++;\n\tstats->rx_bytes += skb->len;\n\n#ifdef NOT_YET\n\tif (ieee->iw_mode == IW_MODE_MASTER && !wds && ieee->ap->bridge_packets) {\n\t\tif (dst[0] & 0x01) {\n\t\t\t/* copy multicast frame both to the higher layers and\n\t\t\t * to the wireless media */\n\t\t\tieee->ap->bridged_multicast++;\n\t\t\tskb2 = skb_clone(skb, GFP_ATOMIC);\n\t\t\tif (skb2 == NULL)\n\t\t\t\tprintk(KERN_DEBUG \"%s: skb_clone failed for \"\n\t\t\t\t       \"multicast frame\\n\", dev->name);\n\t\t} else if (hostap_is_sta_assoc(ieee->ap, dst)) {\n\t\t\t/* send frame directly to the associated STA using\n\t\t\t * wireless media and not passing to higher layers */\n\t\t\tieee->ap->bridged_unicast++;\n\t\t\tskb2 = skb;\n\t\t\tskb = NULL;\n\t\t}\n\t}\n\n\tif (skb2 != NULL) {\n\t\t/* send to wireless media */\n\t\tskb2->dev = dev;\n\t\tskb2->protocol = __constant_htons(ETH_P_802_3);\n\t\tskb_reset_mac_header(skb2);\n\t\tskb_reset_network_header(skb2);\n\t\t/* skb2->network_header += ETH_HLEN; */\n\t\tdev_queue_xmit(skb2);\n\t}\n#endif\n\n\tif (skb) {\n\t\tskb->protocol = eth_type_trans(skb, dev);\n\t\tmemset(skb->cb, 0, sizeof(skb->cb));\n\t\tskb->ip_summed = CHECKSUM_NONE;\t/* 802.11 crc not sufficient */\n\t\tif (netif_rx(skb) == NET_RX_DROP) {\n\t\t\t/* netif_rx always succeeds, but it might drop\n\t\t\t * the packet.  If it drops the packet, we log that\n\t\t\t * in our stats. */\n\t\t\tIEEE80211_DEBUG_DROP\n\t\t\t    (\"RX: netif_rx dropped the packet\\n\");\n\t\t\tstats->rx_dropped++;\n\t\t}\n\t}\n\n      rx_exit:\n#ifdef NOT_YET\n\tif (sta)\n\t\thostap_handle_sta_release(sta);\n#endif\n\treturn 1;\n\n      rx_dropped:\n\tstats->rx_dropped++;\n\n\t/* Returning 0 indicates to caller that we have not handled the SKB--\n\t * so it is still allocated and can be used again by underlying\n\t * hardware as a DMA target */\n\treturn 0;\n}", "target": 1, "cwe": ["CWE-189"], "project": "linux-2.6", "commit_id": "04045f98e0457aba7d4e6736f37eed189c48a5f7", "hash": 308579844544821127492397604808934650173, "size": 502, "message": "[IEEE80211]: avoid integer underflow for runt rx frames\n\nReported by Chris Evans <scarybeasts@gmail.com>:\n\n> The summary is that an evil 80211 frame can crash out a victim's\n> machine. It only applies to drivers using the 80211 wireless code, and\n> only then to certain drivers (and even then depends on a card's\n> firmware not dropping a dubious packet). I must confess I'm not\n> keeping track of Linux wireless support, and the different protocol\n> stacks etc.\n>\n> Details are as follows:\n>\n> ieee80211_rx() does not explicitly check that \"skb->len >= hdrlen\".\n> There are other skb->len checks, but not enough to prevent a subtle\n> off-by-two error if the frame has the IEEE80211_STYPE_QOS_DATA flag\n> set.\n>\n> This leads to integer underflow and crash here:\n>\n> if (frag != 0)\n>    flen -= hdrlen;\n>\n> (flen is subsequently used as a memcpy length parameter).\n\nHow about this?\n\nSigned-off-by: John W. Linville <linville@tuxdriver.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>"}
{"func": "static int do_dccp_getsockopt(struct sock *sk, int level, int optname,\n\t\t    char __user *optval, int __user *optlen)\n{\n\tstruct dccp_sock *dp;\n\tint val, len;\n\n\tif (get_user(len, optlen))\n\t\treturn -EFAULT;\n\n\tif (len < sizeof(int))\n\t\treturn -EINVAL;\n\n\tdp = dccp_sk(sk);\n\n\tswitch (optname) {\n\tcase DCCP_SOCKOPT_PACKET_SIZE:\n\t\tDCCP_WARN(\"sockopt(PACKET_SIZE) is deprecated: fix your app\\n\");\n\t\treturn 0;\n\tcase DCCP_SOCKOPT_SERVICE:\n\t\treturn dccp_getsockopt_service(sk, len,\n\t\t\t\t\t       (__be32 __user *)optval, optlen);\n\tcase DCCP_SOCKOPT_SEND_CSCOV:\n\t\tval = dp->dccps_pcslen;\n\t\tbreak;\n\tcase DCCP_SOCKOPT_RECV_CSCOV:\n\t\tval = dp->dccps_pcrlen;\n\t\tbreak;\n\tcase 128 ... 191:\n\t\treturn ccid_hc_rx_getsockopt(dp->dccps_hc_rx_ccid, sk, optname,\n\t\t\t\t\t     len, (u32 __user *)optval, optlen);\n\tcase 192 ... 255:\n\t\treturn ccid_hc_tx_getsockopt(dp->dccps_hc_tx_ccid, sk, optname,\n\t\t\t\t\t     len, (u32 __user *)optval, optlen);\n\tdefault:\n\t\treturn -ENOPROTOOPT;\n\t}\n\n\tif (put_user(len, optlen) || copy_to_user(optval, &val, len))\n\t\treturn -EFAULT;\n\n\treturn 0;\n}", "target": 1, "cwe": [], "project": "linux-2.6", "commit_id": "39ebc0276bada8bb70e067cb6d0eb71839c0fb08", "hash": 329364480182313507598951454775228741886, "size": 42, "message": "[DCCP] getsockopt: Fix DCCP_SOCKOPT_[SEND,RECV]_CSCOV\n\nWe were only checking if there was enough space to put the int, but\nleft len as specified by the (malicious) user, sigh, fix it by setting\nlen to sizeof(val) and transfering just one int worth of data, the one\nasked for.\n\nAlso check for negative len values.\n\nSigned-off-by: Arnaldo Carvalho de Melo <acme@ghostprotocols.net>\nSigned-off-by: David S. Miller <davem@davemloft.net>"}
{"func": "static int jpc_qcx_getcompparms(jpc_qcxcp_t *compparms, jpc_cstate_t *cstate,\n  jas_stream_t *in, uint_fast16_t len)\n{\n\tuint_fast8_t tmp;\n\tint n;\n\tint i;\n\n\t/* Eliminate compiler warning about unused variables. */\n\tcstate = 0;\n\n\tn = 0;\n\tif (jpc_getuint8(in, &tmp)) {\n\t\treturn -1;\n\t}\n\t++n;\n\tcompparms->qntsty = tmp & 0x1f;\n\tcompparms->numguard = (tmp >> 5) & 7;\n\tswitch (compparms->qntsty) {\n\tcase JPC_QCX_SIQNT:\n\t\tcompparms->numstepsizes = 1;\n\t\tbreak;\n\tcase JPC_QCX_NOQNT:\n\t\tcompparms->numstepsizes = (len - n);\n\t\tbreak;\n\tcase JPC_QCX_SEQNT:\n\t\t/* XXX - this is a hack */\n\t\tcompparms->numstepsizes = (len - n) / 2;\n\t\tbreak;\n\t}\n\tif (compparms->numstepsizes > 0) {\n\t\tcompparms->stepsizes = jas_alloc2(compparms->numstepsizes,\n\t\t  sizeof(uint_fast16_t));\n\t\tassert(compparms->stepsizes);\n\t\tfor (i = 0; i < compparms->numstepsizes; ++i) {\n\t\t\tif (compparms->qntsty == JPC_QCX_NOQNT) {\n\t\t\t\tif (jpc_getuint8(in, &tmp)) {\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t\tcompparms->stepsizes[i] = JPC_QCX_EXPN(tmp >> 3);\n\t\t\t} else {\n\t\t\t\tif (jpc_getuint16(in, &compparms->stepsizes[i])) {\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else {\n\t\tcompparms->stepsizes = 0;\n\t}\n\tif (jas_stream_error(in) || jas_stream_eof(in)) {\n\t\tjpc_qcx_destroycompparms(compparms);\n\t\treturn -1;\n\t}\n\treturn 0;\n}", "target": 1, "cwe": [], "project": "jasper", "commit_id": "4031ca321d8cb5798c316ab39c7a5dc88a61fdd7", "hash": 254403990052538507929301018495167224098, "size": 54, "message": "Incorporated changes from patch\njasper-1.900.3-libjasper-stepsizes-overflow.patch"}
{"func": "isdn_net_setcfg(isdn_net_ioctl_cfg * cfg)\n{\n\tisdn_net_dev *p = isdn_net_findif(cfg->name);\n\tulong features;\n\tint i;\n\tint drvidx;\n\tint chidx;\n\tchar drvid[25];\n\n\tif (p) {\n\t\tisdn_net_local *lp = p->local;\n\n\t\t/* See if any registered driver supports the features we want */\n\t\tfeatures = ((1 << cfg->l2_proto) << ISDN_FEATURE_L2_SHIFT) |\n\t\t\t((1 << cfg->l3_proto) << ISDN_FEATURE_L3_SHIFT);\n\t\tfor (i = 0; i < ISDN_MAX_DRIVERS; i++)\n\t\t\tif (dev->drv[i])\n\t\t\t\tif ((dev->drv[i]->interface->features & features) == features)\n\t\t\t\t\tbreak;\n\t\tif (i == ISDN_MAX_DRIVERS) {\n\t\t\tprintk(KERN_WARNING \"isdn_net: No driver with selected features\\n\");\n\t\t\treturn -ENODEV;\n\t\t}\n\t\tif (lp->p_encap != cfg->p_encap){\n#ifdef CONFIG_ISDN_X25\n\t\t\tstruct concap_proto * cprot = p -> cprot;\n#endif\n\t\t\tif (isdn_net_device_started(p)) {\n\t\t\t\tprintk(KERN_WARNING \"%s: cannot change encap when if is up\\n\",\n\t\t\t\t       p->dev->name);\n\t\t\t\treturn -EBUSY;\n\t\t\t}\n#ifdef CONFIG_ISDN_X25\n\t\t\tif( cprot && cprot -> pops )\n\t\t\t\tcprot -> pops -> proto_del ( cprot );\n\t\t\tp -> cprot = NULL;\n\t\t\tlp -> dops = NULL;\n\t\t\t/* ... ,  prepare for configuration of new one ... */\n\t\t\tswitch ( cfg -> p_encap ){\n\t\t\tcase ISDN_NET_ENCAP_X25IFACE:\n\t\t\t\tlp -> dops = &isdn_concap_reliable_dl_dops;\n\t\t\t}\n\t\t\t/* ... and allocate new one ... */\n\t\t\tp -> cprot = isdn_concap_new( cfg -> p_encap );\n\t\t\t/* p -> cprot == NULL now if p_encap is not supported\n\t\t\t   by means of the concap_proto mechanism */\n\t\t\t/* the protocol is not configured yet; this will\n\t\t\t   happen later when isdn_net_reset() is called */\n#endif\n\t\t}\n\t\tswitch ( cfg->p_encap ) {\n\t\tcase ISDN_NET_ENCAP_SYNCPPP:\n#ifndef CONFIG_ISDN_PPP\n\t\t\tprintk(KERN_WARNING \"%s: SyncPPP support not configured\\n\",\n\t\t\t       p->dev->name);\n\t\t\treturn -EINVAL;\n#else\n\t\t\tp->dev->type = ARPHRD_PPP;\t/* change ARP type */\n\t\t\tp->dev->addr_len = 0;\n\t\t\tp->dev->do_ioctl = isdn_ppp_dev_ioctl;\n#endif\n\t\t\tbreak;\n\t\tcase ISDN_NET_ENCAP_X25IFACE:\n#ifndef CONFIG_ISDN_X25\n\t\t\tprintk(KERN_WARNING \"%s: isdn-x25 support not configured\\n\",\n\t\t\t       p->dev->name);\n\t\t\treturn -EINVAL;\n#else\n\t\t\tp->dev->type = ARPHRD_X25;\t/* change ARP type */\n\t\t\tp->dev->addr_len = 0;\n#endif\n\t\t\tbreak;\n\t\tcase ISDN_NET_ENCAP_CISCOHDLCK:\n\t\t\tp->dev->do_ioctl = isdn_ciscohdlck_dev_ioctl;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif( cfg->p_encap >= 0 &&\n\t\t\t    cfg->p_encap <= ISDN_NET_ENCAP_MAX_ENCAP )\n\t\t\t\tbreak;\n\t\t\tprintk(KERN_WARNING\n\t\t\t       \"%s: encapsulation protocol %d not supported\\n\",\n\t\t\t       p->dev->name, cfg->p_encap);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (strlen(cfg->drvid)) {\n\t\t\t/* A bind has been requested ... */\n\t\t\tchar *c,\n\t\t\t*e;\n\n\t\t\tdrvidx = -1;\n\t\t\tchidx = -1;\n\t\t\tstrcpy(drvid, cfg->drvid);\n\t\t\tif ((c = strchr(drvid, ','))) {\n\t\t\t\t/* The channel-number is appended to the driver-Id with a comma */\n\t\t\t\tchidx = (int) simple_strtoul(c + 1, &e, 10);\n\t\t\t\tif (e == c)\n\t\t\t\t\tchidx = -1;\n\t\t\t\t*c = '\\0';\n\t\t\t}\n\t\t\tfor (i = 0; i < ISDN_MAX_DRIVERS; i++)\n\t\t\t\t/* Lookup driver-Id in array */\n\t\t\t\tif (!(strcmp(dev->drvid[i], drvid))) {\n\t\t\t\t\tdrvidx = i;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\tif ((drvidx == -1) || (chidx == -1))\n\t\t\t\t/* Either driver-Id or channel-number invalid */\n\t\t\t\treturn -ENODEV;\n\t\t} else {\n\t\t\t/* Parameters are valid, so get them */\n\t\t\tdrvidx = lp->pre_device;\n\t\t\tchidx = lp->pre_channel;\n\t\t}\n\t\tif (cfg->exclusive > 0) {\n\t\t\tunsigned long flags;\n\n\t\t\t/* If binding is exclusive, try to grab the channel */\n\t\t\tspin_lock_irqsave(&dev->lock, flags);\n\t\t\tif ((i = isdn_get_free_channel(ISDN_USAGE_NET,\n\t\t\t\tlp->l2_proto, lp->l3_proto, drvidx,\n\t\t\t\tchidx, lp->msn)) < 0) {\n\t\t\t\t/* Grab failed, because desired channel is in use */\n\t\t\t\tlp->exclusive = -1;\n\t\t\t\tspin_unlock_irqrestore(&dev->lock, flags);\n\t\t\t\treturn -EBUSY;\n\t\t\t}\n\t\t\t/* All went ok, so update isdninfo */\n\t\t\tdev->usage[i] = ISDN_USAGE_EXCLUSIVE;\n\t\t\tisdn_info_update();\n\t\t\tspin_unlock_irqrestore(&dev->lock, flags);\n\t\t\tlp->exclusive = i;\n\t\t} else {\n\t\t\t/* Non-exclusive binding or unbind. */\n\t\t\tlp->exclusive = -1;\n\t\t\tif ((lp->pre_device != -1) && (cfg->exclusive == -1)) {\n\t\t\t\tisdn_unexclusive_channel(lp->pre_device, lp->pre_channel);\n\t\t\t\tisdn_free_channel(lp->pre_device, lp->pre_channel, ISDN_USAGE_NET);\n\t\t\t\tdrvidx = -1;\n\t\t\t\tchidx = -1;\n\t\t\t}\n\t\t}\n\t\tstrcpy(lp->msn, cfg->eaz);\n\t\tlp->pre_device = drvidx;\n\t\tlp->pre_channel = chidx;\n\t\tlp->onhtime = cfg->onhtime;\n\t\tlp->charge = cfg->charge;\n\t\tlp->l2_proto = cfg->l2_proto;\n\t\tlp->l3_proto = cfg->l3_proto;\n\t\tlp->cbdelay = cfg->cbdelay;\n\t\tlp->dialmax = cfg->dialmax;\n\t\tlp->triggercps = cfg->triggercps;\n\t\tlp->slavedelay = cfg->slavedelay * HZ;\n\t\tlp->pppbind = cfg->pppbind;\n\t\tlp->dialtimeout = cfg->dialtimeout >= 0 ? cfg->dialtimeout * HZ : -1;\n\t\tlp->dialwait = cfg->dialwait * HZ;\n\t\tif (cfg->secure)\n\t\t\tlp->flags |= ISDN_NET_SECURE;\n\t\telse\n\t\t\tlp->flags &= ~ISDN_NET_SECURE;\n\t\tif (cfg->cbhup)\n\t\t\tlp->flags |= ISDN_NET_CBHUP;\n\t\telse\n\t\t\tlp->flags &= ~ISDN_NET_CBHUP;\n\t\tswitch (cfg->callback) {\n\t\t\tcase 0:\n\t\t\t\tlp->flags &= ~(ISDN_NET_CALLBACK | ISDN_NET_CBOUT);\n\t\t\t\tbreak;\n\t\t\tcase 1:\n\t\t\t\tlp->flags |= ISDN_NET_CALLBACK;\n\t\t\t\tlp->flags &= ~ISDN_NET_CBOUT;\n\t\t\t\tbreak;\n\t\t\tcase 2:\n\t\t\t\tlp->flags |= ISDN_NET_CBOUT;\n\t\t\t\tlp->flags &= ~ISDN_NET_CALLBACK;\n\t\t\t\tbreak;\n\t\t}\n\t\tlp->flags &= ~ISDN_NET_DIALMODE_MASK;\t/* first all bits off */\n\t\tif (cfg->dialmode && !(cfg->dialmode & ISDN_NET_DIALMODE_MASK)) {\n\t\t\t/* old isdnctrl version, where only 0 or 1 is given */\n\t\t\tprintk(KERN_WARNING\n\t\t\t     \"Old isdnctrl version detected! Please update.\\n\");\n\t\t\tlp->flags |= ISDN_NET_DM_OFF; /* turn on `off' bit */\n\t\t}\n\t\telse {\n\t\t\tlp->flags |= cfg->dialmode;  /* turn on selected bits */\n\t\t}\n\t\tif (cfg->chargehup)\n\t\t\tlp->hupflags |= ISDN_CHARGEHUP;\n\t\telse\n\t\t\tlp->hupflags &= ~ISDN_CHARGEHUP;\n\t\tif (cfg->ihup)\n\t\t\tlp->hupflags |= ISDN_INHUP;\n\t\telse\n\t\t\tlp->hupflags &= ~ISDN_INHUP;\n\t\tif (cfg->chargeint > 10) {\n\t\t\tlp->hupflags |= ISDN_CHARGEHUP | ISDN_HAVECHARGE | ISDN_MANCHARGE;\n\t\t\tlp->chargeint = cfg->chargeint * HZ;\n\t\t}\n\t\tif (cfg->p_encap != lp->p_encap) {\n\t\t\tif (cfg->p_encap == ISDN_NET_ENCAP_RAWIP) {\n\t\t\t\tp->dev->header_ops = NULL;\n\t\t\t\tp->dev->flags = IFF_NOARP|IFF_POINTOPOINT;\n\t\t\t} else {\n\t\t\t\tp->dev->header_ops = &isdn_header_ops;\n\t\t\t\tif (cfg->p_encap == ISDN_NET_ENCAP_ETHER)\n\t\t\t\t\tp->dev->flags = IFF_BROADCAST | IFF_MULTICAST;\n\t\t\t\telse\n\t\t\t\t\tp->dev->flags = IFF_NOARP|IFF_POINTOPOINT;\n\t\t\t}\n\t\t}\n\t\tlp->p_encap = cfg->p_encap;\n\t\treturn 0;\n\t}\n\treturn -ENODEV;\n}", "target": 1, "cwe": ["CWE-119"], "project": "linux-2.6", "commit_id": "0f13864e5b24d9cbe18d125d41bfa4b726a82e40", "hash": 80796293720356790057810511838637183896, "size": 215, "message": "isdn: avoid copying overly-long strings\n\nAddresses http://bugzilla.kernel.org/show_bug.cgi?id=9416\n\nSigned-off-by: Karsten Keil <kkeil@suse.de>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "isdn_net_addphone(isdn_net_ioctl_phone * phone)\n{\n\tisdn_net_dev *p = isdn_net_findif(phone->name);\n\tisdn_net_phone *n;\n\n\tif (p) {\n\t\tif (!(n = kmalloc(sizeof(isdn_net_phone), GFP_KERNEL)))\n\t\t\treturn -ENOMEM;\n\t\tstrcpy(n->num, phone->phone);\n\t\tn->next = p->local->phone[phone->outgoing & 1];\n\t\tp->local->phone[phone->outgoing & 1] = n;\n\t\treturn 0;\n\t}\n\treturn -ENODEV;\n}", "target": 1, "cwe": ["CWE-119"], "project": "linux-2.6", "commit_id": "0f13864e5b24d9cbe18d125d41bfa4b726a82e40", "hash": 242762251649869568016628227707027738238, "size": 15, "message": "isdn: avoid copying overly-long strings\n\nAddresses http://bugzilla.kernel.org/show_bug.cgi?id=9416\n\nSigned-off-by: Karsten Keil <kkeil@suse.de>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "isdn_net_find_icall(int di, int ch, int idx, setup_parm *setup)\n{\n\tchar *eaz;\n\tint si1;\n\tint si2;\n\tint ematch;\n\tint wret;\n\tint swapped;\n\tint sidx = 0;\n\tu_long flags;\n\tisdn_net_dev *p;\n\tisdn_net_phone *n;\n\tchar nr[32];\n\tchar *my_eaz;\n\n\t/* Search name in netdev-chain */\n\tif (!setup->phone[0]) {\n\t\tnr[0] = '0';\n\t\tnr[1] = '\\0';\n\t\tprintk(KERN_INFO \"isdn_net: Incoming call without OAD, assuming '0'\\n\");\n\t} else\n\t\tstrcpy(nr, setup->phone);\n\tsi1 = (int) setup->si1;\n\tsi2 = (int) setup->si2;\n\tif (!setup->eazmsn[0]) {\n\t\tprintk(KERN_WARNING \"isdn_net: Incoming call without CPN, assuming '0'\\n\");\n\t\teaz = \"0\";\n\t} else\n\t\teaz = setup->eazmsn;\n\tif (dev->net_verbose > 1)\n\t\tprintk(KERN_INFO \"isdn_net: call from %s,%d,%d -> %s\\n\", nr, si1, si2, eaz);\n\t/* Accept DATA and VOICE calls at this stage\n\t * local eaz is checked later for allowed call types\n\t */\n\tif ((si1 != 7) && (si1 != 1)) {\n\t\tif (dev->net_verbose > 1)\n\t\t\tprintk(KERN_INFO \"isdn_net: Service-Indicator not 1 or 7, ignored\\n\");\n\t\treturn 0;\n\t}\n\tn = (isdn_net_phone *) 0;\n\tp = dev->netdev;\n\tematch = wret = swapped = 0;\n#ifdef ISDN_DEBUG_NET_ICALL\n\tprintk(KERN_DEBUG \"n_fi: di=%d ch=%d idx=%d usg=%d\\n\", di, ch, idx,\n\t\tdev->usage[idx]);\n#endif\n\twhile (p) {\n\t\tint matchret;\n\t\tisdn_net_local *lp = p->local;\n\n\t\t/* If last check has triggered as binding-swap, revert it */\n\t\tswitch (swapped) {\n\t\t\tcase 2:\n\t\t\t\tisdn_net_swap_usage(idx, sidx);\n\t\t\t\t/* fall through */\n\t\t\tcase 1:\n\t\t\t\tisdn_net_swapbind(di);\n\t\t\t\tbreak;\n\t\t}\n\t\tswapped = 0;\n                /* check acceptable call types for DOV */\n                my_eaz = isdn_map_eaz2msn(lp->msn, di);\n                if (si1 == 1) { /* it's a DOV call, check if we allow it */\n                        if (*my_eaz == 'v' || *my_eaz == 'V' ||\n\t\t\t    *my_eaz == 'b' || *my_eaz == 'B')\n                                my_eaz++; /* skip to allow a match */\n                        else\n                                my_eaz = NULL; /* force non match */\n                } else { /* it's a DATA call, check if we allow it */\n                        if (*my_eaz == 'b' || *my_eaz == 'B')\n                                my_eaz++; /* skip to allow a match */\n                }\n                if (my_eaz)\n                        matchret = isdn_msncmp(eaz, my_eaz);\n                else\n                        matchret = 1;\n                if (!matchret)\n                        ematch = 1;\n\n\t\t/* Remember if more numbers eventually can match */\n\t\tif (matchret > wret)\n\t\t\twret = matchret;\n#ifdef ISDN_DEBUG_NET_ICALL\n\t\tprintk(KERN_DEBUG \"n_fi: if='%s', l.msn=%s, l.flags=%d, l.dstate=%d\\n\",\n\t\t       p->dev->name, lp->msn, lp->flags, lp->dialstate);\n#endif\n\t\tif ((!matchret) &&                                        /* EAZ is matching   */\n\t\t    (((!(lp->flags & ISDN_NET_CONNECTED)) &&              /* but not connected */\n\t\t      (USG_NONE(dev->usage[idx]))) ||                     /* and ch. unused or */\n\t\t     ((((lp->dialstate == 4) || (lp->dialstate == 12)) && /* if dialing        */\n\t\t       (!(lp->flags & ISDN_NET_CALLBACK)))                /* but no callback   */\n\t\t     )))\n\t\t\t {\n#ifdef ISDN_DEBUG_NET_ICALL\n\t\t\tprintk(KERN_DEBUG \"n_fi: match1, pdev=%d pch=%d\\n\",\n\t\t\t       lp->pre_device, lp->pre_channel);\n#endif\n\t\t\tif (dev->usage[idx] & ISDN_USAGE_EXCLUSIVE) {\n\t\t\t\tif ((lp->pre_channel != ch) ||\n\t\t\t\t    (lp->pre_device != di)) {\n\t\t\t\t\t/* Here we got a problem:\n\t\t\t\t\t * If using an ICN-Card, an incoming call is always signaled on\n\t\t\t\t\t * on the first channel of the card, if both channels are\n\t\t\t\t\t * down. However this channel may be bound exclusive. If the\n\t\t\t\t\t * second channel is free, this call should be accepted.\n\t\t\t\t\t * The solution is horribly but it runs, so what:\n\t\t\t\t\t * We exchange the exclusive bindings of the two channels, the\n\t\t\t\t\t * corresponding variables in the interface-structs.\n\t\t\t\t\t */\n\t\t\t\t\tif (ch == 0) {\n\t\t\t\t\t\tsidx = isdn_dc2minor(di, 1);\n#ifdef ISDN_DEBUG_NET_ICALL\n\t\t\t\t\t\tprintk(KERN_DEBUG \"n_fi: ch is 0\\n\");\n#endif\n\t\t\t\t\t\tif (USG_NONE(dev->usage[sidx])) {\n\t\t\t\t\t\t\t/* Second Channel is free, now see if it is bound\n\t\t\t\t\t\t\t * exclusive too. */\n\t\t\t\t\t\t\tif (dev->usage[sidx] & ISDN_USAGE_EXCLUSIVE) {\n#ifdef ISDN_DEBUG_NET_ICALL\n\t\t\t\t\t\t\t\tprintk(KERN_DEBUG \"n_fi: 2nd channel is down and bound\\n\");\n#endif\n\t\t\t\t\t\t\t\t/* Yes, swap bindings only, if the original\n\t\t\t\t\t\t\t\t * binding is bound to channel 1 of this driver */\n\t\t\t\t\t\t\t\tif ((lp->pre_device == di) &&\n\t\t\t\t\t\t\t\t    (lp->pre_channel == 1)) {\n\t\t\t\t\t\t\t\t\tisdn_net_swapbind(di);\n\t\t\t\t\t\t\t\t\tswapped = 1;\n\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\t/* ... else iterate next device */\n\t\t\t\t\t\t\t\t\tp = (isdn_net_dev *) p->next;\n\t\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t} else {\n#ifdef ISDN_DEBUG_NET_ICALL\n\t\t\t\t\t\t\t\tprintk(KERN_DEBUG \"n_fi: 2nd channel is down and unbound\\n\");\n#endif\n\t\t\t\t\t\t\t\t/* No, swap always and swap excl-usage also */\n\t\t\t\t\t\t\t\tisdn_net_swap_usage(idx, sidx);\n\t\t\t\t\t\t\t\tisdn_net_swapbind(di);\n\t\t\t\t\t\t\t\tswapped = 2;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t/* Now check for exclusive binding again */\n#ifdef ISDN_DEBUG_NET_ICALL\n\t\t\t\t\t\t\tprintk(KERN_DEBUG \"n_fi: final check\\n\");\n#endif\n\t\t\t\t\t\t\tif ((dev->usage[idx] & ISDN_USAGE_EXCLUSIVE) &&\n\t\t\t\t\t\t\t    ((lp->pre_channel != ch) ||\n\t\t\t\t\t\t\t     (lp->pre_device != di))) {\n#ifdef ISDN_DEBUG_NET_ICALL\n\t\t\t\t\t\t\t\tprintk(KERN_DEBUG \"n_fi: final check failed\\n\");\n#endif\n\t\t\t\t\t\t\t\tp = (isdn_net_dev *) p->next;\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\t/* We are already on the second channel, so nothing to do */\n#ifdef ISDN_DEBUG_NET_ICALL\n\t\t\t\t\t\tprintk(KERN_DEBUG \"n_fi: already on 2nd channel\\n\");\n#endif\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n#ifdef ISDN_DEBUG_NET_ICALL\n\t\t\tprintk(KERN_DEBUG \"n_fi: match2\\n\");\n#endif\n\t\t\tn = lp->phone[0];\n\t\t\tif (lp->flags & ISDN_NET_SECURE) {\n\t\t\t\twhile (n) {\n\t\t\t\t\tif (!isdn_msncmp(nr, n->num))\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tn = (isdn_net_phone *) n->next;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (n || (!(lp->flags & ISDN_NET_SECURE))) {\n#ifdef ISDN_DEBUG_NET_ICALL\n\t\t\t\tprintk(KERN_DEBUG \"n_fi: match3\\n\");\n#endif\n\t\t\t\t/* matching interface found */\n\n\t\t\t\t/*\n\t\t\t\t * Is the state STOPPED?\n\t\t\t\t * If so, no dialin is allowed,\n\t\t\t\t * so reject actively.\n\t\t\t\t * */\n\t\t\t\tif (ISDN_NET_DIALMODE(*lp) == ISDN_NET_DM_OFF) {\n\t\t\t\t\tprintk(KERN_INFO \"incoming call, interface %s `stopped' -> rejected\\n\",\n\t\t\t\t\t       p->dev->name);\n\t\t\t\t\treturn 3;\n\t\t\t\t}\n\t\t\t\t/*\n\t\t\t\t * Is the interface up?\n\t\t\t\t * If not, reject the call actively.\n\t\t\t\t */\n\t\t\t\tif (!isdn_net_device_started(p)) {\n\t\t\t\t\tprintk(KERN_INFO \"%s: incoming call, interface down -> rejected\\n\",\n\t\t\t\t\t       p->dev->name);\n\t\t\t\t\treturn 3;\n\t\t\t\t}\n\t\t\t\t/* Interface is up, now see if it's a slave. If so, see if\n\t\t\t\t * it's master and parent slave is online. If not, reject the call.\n\t\t\t\t */\n\t\t\t\tif (lp->master) {\n\t\t\t\t\tisdn_net_local *mlp = (isdn_net_local *) lp->master->priv;\n\t\t\t\t\tprintk(KERN_DEBUG \"ICALLslv: %s\\n\", p->dev->name);\n\t\t\t\t\tprintk(KERN_DEBUG \"master=%s\\n\", lp->master->name);\n\t\t\t\t\tif (mlp->flags & ISDN_NET_CONNECTED) {\n\t\t\t\t\t\tprintk(KERN_DEBUG \"master online\\n\");\n\t\t\t\t\t\t/* Master is online, find parent-slave (master if first slave) */\n\t\t\t\t\t\twhile (mlp->slave) {\n\t\t\t\t\t\t\tif ((isdn_net_local *) mlp->slave->priv == lp)\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\tmlp = (isdn_net_local *) mlp->slave->priv;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else\n\t\t\t\t\t\tprintk(KERN_DEBUG \"master offline\\n\");\n\t\t\t\t\t/* Found parent, if it's offline iterate next device */\n\t\t\t\t\tprintk(KERN_DEBUG \"mlpf: %d\\n\", mlp->flags & ISDN_NET_CONNECTED);\n\t\t\t\t\tif (!(mlp->flags & ISDN_NET_CONNECTED)) {\n\t\t\t\t\t\tp = (isdn_net_dev *) p->next;\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t} \n\t\t\t\tif (lp->flags & ISDN_NET_CALLBACK) {\n\t\t\t\t\tint chi;\n\t\t\t\t\t/*\n\t\t\t\t\t * Is the state MANUAL?\n\t\t\t\t\t * If so, no callback can be made,\n\t\t\t\t\t * so reject actively.\n\t\t\t\t\t * */\n\t\t\t\t\tif (ISDN_NET_DIALMODE(*lp) == ISDN_NET_DM_OFF) {\n\t\t\t\t\t\tprintk(KERN_INFO \"incoming call for callback, interface %s `off' -> rejected\\n\",\n\t\t\t\t\t\t       p->dev->name);\n\t\t\t\t\t\treturn 3;\n\t\t\t\t\t}\n\t\t\t\t\tprintk(KERN_DEBUG \"%s: call from %s -> %s, start callback\\n\",\n\t\t\t\t\t       p->dev->name, nr, eaz);\n\t\t\t\t\tif (lp->phone[1]) {\n\t\t\t\t\t\t/* Grab a free ISDN-Channel */\n\t\t\t\t\t\tspin_lock_irqsave(&dev->lock, flags);\n\t\t\t\t\t\tif ((chi = \n\t\t\t\t\t\t\tisdn_get_free_channel(\n\t\t\t\t\t\t\t\tISDN_USAGE_NET,\n\t\t\t\t\t\t\t\tlp->l2_proto,\n\t\t\t\t\t\t\t\tlp->l3_proto,\n\t\t\t\t\t\t\t  \tlp->pre_device,\n\t\t\t\t\t\t \t\tlp->pre_channel,\n\t\t\t\t\t\t \t\tlp->msn)\n\t\t\t\t\t\t\t\t) < 0) {\n\n\t\t\t\t\t\t\tprintk(KERN_WARNING \"isdn_net_find_icall: No channel for %s\\n\",\n\t\t\t\t\t\t\t\tp->dev->name);\n\t\t\t\t\t\t\tspin_unlock_irqrestore(&dev->lock, flags);\n\t\t\t\t\t\t\treturn 0;\n\t\t\t\t\t\t}\n\t\t\t\t\t\t/* Setup dialstate. */\n\t\t\t\t\t\tlp->dtimer = 0;\n\t\t\t\t\t\tlp->dialstate = 11;\n\t\t\t\t\t\t/* Connect interface with channel */\n\t\t\t\t\t\tisdn_net_bind_channel(lp, chi);\n#ifdef CONFIG_ISDN_PPP\n\t\t\t\t\t\tif (lp->p_encap == ISDN_NET_ENCAP_SYNCPPP)\n\t\t\t\t\t\t\tif (isdn_ppp_bind(lp) < 0) {\n\t\t\t\t\t\t\t\tspin_unlock_irqrestore(&dev->lock, flags);\n\t\t\t\t\t\t\t\tisdn_net_unbind_channel(lp);\n\t\t\t\t\t\t\t\treturn 0;\n\t\t\t\t\t\t\t}\n#endif\n\t\t\t\t\t\tspin_unlock_irqrestore(&dev->lock, flags);\n\t\t\t\t\t\t/* Initiate dialing by returning 2 or 4 */\n\t\t\t\t\t\treturn (lp->flags & ISDN_NET_CBHUP) ? 2 : 4;\n\t\t\t\t\t} else\n\t\t\t\t\t\tprintk(KERN_WARNING \"isdn_net: %s: No phone number\\n\",\n\t\t\t\t\t\t\tp->dev->name);\n\t\t\t\t\treturn 0;\n\t\t\t\t} else {\n\t\t\t\t\tprintk(KERN_DEBUG \"%s: call from %s -> %s accepted\\n\",\n\t\t\t\t\t\tp->dev->name, nr, eaz);\n\t\t\t\t\t/* if this interface is dialing, it does it probably on a different\n\t\t\t\t\t   device, so free this device */\n\t\t\t\t\tif ((lp->dialstate == 4) || (lp->dialstate == 12)) {\n#ifdef CONFIG_ISDN_PPP\n\t\t\t\t\t\tif (lp->p_encap == ISDN_NET_ENCAP_SYNCPPP)\n\t\t\t\t\t\t\tisdn_ppp_free(lp);\n#endif\n\t\t\t\t\t\tisdn_net_lp_disconnected(lp);\n\t\t\t\t\t\tisdn_free_channel(lp->isdn_device, lp->isdn_channel,\n\t\t\t\t\t\t\t ISDN_USAGE_NET);\n\t\t\t\t\t}\n\t\t\t\t\tspin_lock_irqsave(&dev->lock, flags);\n\t\t\t\t\tdev->usage[idx] &= ISDN_USAGE_EXCLUSIVE;\n\t\t\t\t\tdev->usage[idx] |= ISDN_USAGE_NET;\n\t\t\t\t\tstrcpy(dev->num[idx], nr);\n\t\t\t\t\tisdn_info_update();\n\t\t\t\t\tdev->st_netdev[idx] = lp->netdev;\n\t\t\t\t\tlp->isdn_device = di;\n\t\t\t\t\tlp->isdn_channel = ch;\n\t\t\t\t\tlp->ppp_slot = -1;\n\t\t\t\t\tlp->flags |= ISDN_NET_CONNECTED;\n\t\t\t\t\tlp->dialstate = 7;\n\t\t\t\t\tlp->dtimer = 0;\n\t\t\t\t\tlp->outgoing = 0;\n\t\t\t\t\tlp->huptimer = 0;\n\t\t\t\t\tlp->hupflags |= ISDN_WAITCHARGE;\n\t\t\t\t\tlp->hupflags &= ~ISDN_HAVECHARGE;\n#ifdef CONFIG_ISDN_PPP\n\t\t\t\t\tif (lp->p_encap == ISDN_NET_ENCAP_SYNCPPP) {\n\t\t\t\t\t\tif (isdn_ppp_bind(lp) < 0) {\n\t\t\t\t\t\t\tisdn_net_unbind_channel(lp);\n\t\t\t\t\t\t\tspin_unlock_irqrestore(&dev->lock, flags);\n\t\t\t\t\t\t\treturn 0;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n#endif\n\t\t\t\t\tspin_unlock_irqrestore(&dev->lock, flags);\n\t\t\t\t\treturn 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tp = (isdn_net_dev *) p->next;\n\t}\n\t/* If none of configured EAZ/MSN matched and not verbose, be silent */\n\tif (!ematch || dev->net_verbose)\n\t\tprintk(KERN_INFO \"isdn_net: call from %s -> %d %s ignored\\n\", nr, di, eaz);\n\treturn (wret == 2)?5:0;\n}", "target": 1, "cwe": ["CWE-119"], "project": "linux-2.6", "commit_id": "0f13864e5b24d9cbe18d125d41bfa4b726a82e40", "hash": 322344461636009915251514953321701663520, "size": 326, "message": "isdn: avoid copying overly-long strings\n\nAddresses http://bugzilla.kernel.org/show_bug.cgi?id=9416\n\nSigned-off-by: Karsten Keil <kkeil@suse.de>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "static int esp6_input(struct xfrm_state *x, struct sk_buff *skb)\n{\n\tstruct ip_esp_hdr *esph;\n\tstruct esp_data *esp = x->data;\n\tstruct crypto_aead *aead = esp->aead;\n\tstruct aead_request *req;\n\tstruct sk_buff *trailer;\n\tint elen = skb->len - sizeof(*esph) - crypto_aead_ivsize(aead);\n\tint nfrags;\n\tint ret = 0;\n\tvoid *tmp;\n\tu8 *iv;\n\tstruct scatterlist *sg;\n\tstruct scatterlist *asg;\n\n\tif (!pskb_may_pull(skb, sizeof(*esph))) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif (elen <= 0) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif ((nfrags = skb_cow_data(skb, 0, &trailer)) < 0) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tret = -ENOMEM;\n\ttmp = esp_alloc_tmp(aead, nfrags + 1);\n\tif (!tmp)\n\t\tgoto out;\n\n\tESP_SKB_CB(skb)->tmp = tmp;\n\tiv = esp_tmp_iv(aead, tmp);\n\treq = esp_tmp_req(aead, iv);\n\tasg = esp_req_sg(aead, req);\n\tsg = asg + 1;\n\n\tskb->ip_summed = CHECKSUM_NONE;\n\n\tesph = (struct ip_esp_hdr *)skb->data;\n\n\t/* Get ivec. This can be wrong, check against another impls. */\n\tiv = esph->enc_data;\n\n\tsg_init_table(sg, nfrags);\n\tskb_to_sgvec(skb, sg, sizeof(*esph) + crypto_aead_ivsize(aead), elen);\n\tsg_init_one(asg, esph, sizeof(*esph));\n\n\taead_request_set_callback(req, 0, esp_input_done, skb);\n\taead_request_set_crypt(req, sg, sg, elen, iv);\n\taead_request_set_assoc(req, asg, sizeof(*esph));\n\n\tret = crypto_aead_decrypt(req);\n\tif (ret == -EINPROGRESS)\n\t\tgoto out;\n\n\tret = esp_input_done2(skb, ret);\n\nout:\n\treturn ret;\n}", "target": 1, "cwe": ["CWE-16"], "project": "linux-2.6", "commit_id": "920fc941a9617f95ccb283037fe6f8a38d95bb69", "hash": 104942264381159022017048355767372737702, "size": 65, "message": "[ESP]: Ensure IV is in linear part of the skb to avoid BUG() due to OOB access\n\nESP does not account for the IV size when calling pskb_may_pull() to\nensure everything it accesses directly is within the linear part of a\npotential fragment. This results in a BUG() being triggered when the\nboth the IPv4 and IPv6 ESP stack is fed with an skb where the first\nfragment ends between the end of the esp header and the end of the IV.\n\nThis bug was found by Dirk Nehring <dnehring@gmx.net> .\n\nSigned-off-by: Thomas Graf <tgraf@suug.ch>\nSigned-off-by: David S. Miller <davem@davemloft.net>"}
{"func": "static int esp_input(struct xfrm_state *x, struct sk_buff *skb)\n{\n\tstruct ip_esp_hdr *esph;\n\tstruct esp_data *esp = x->data;\n\tstruct crypto_aead *aead = esp->aead;\n\tstruct aead_request *req;\n\tstruct sk_buff *trailer;\n\tint elen = skb->len - sizeof(*esph) - crypto_aead_ivsize(aead);\n\tint nfrags;\n\tvoid *tmp;\n\tu8 *iv;\n\tstruct scatterlist *sg;\n\tstruct scatterlist *asg;\n\tint err = -EINVAL;\n\n\tif (!pskb_may_pull(skb, sizeof(*esph)))\n\t\tgoto out;\n\n\tif (elen <= 0)\n\t\tgoto out;\n\n\tif ((err = skb_cow_data(skb, 0, &trailer)) < 0)\n\t\tgoto out;\n\tnfrags = err;\n\n\terr = -ENOMEM;\n\ttmp = esp_alloc_tmp(aead, nfrags + 1);\n\tif (!tmp)\n\t\tgoto out;\n\n\tESP_SKB_CB(skb)->tmp = tmp;\n\tiv = esp_tmp_iv(aead, tmp);\n\treq = esp_tmp_req(aead, iv);\n\tasg = esp_req_sg(aead, req);\n\tsg = asg + 1;\n\n\tskb->ip_summed = CHECKSUM_NONE;\n\n\tesph = (struct ip_esp_hdr *)skb->data;\n\n\t/* Get ivec. This can be wrong, check against another impls. */\n\tiv = esph->enc_data;\n\n\tsg_init_table(sg, nfrags);\n\tskb_to_sgvec(skb, sg, sizeof(*esph) + crypto_aead_ivsize(aead), elen);\n\tsg_init_one(asg, esph, sizeof(*esph));\n\n\taead_request_set_callback(req, 0, esp_input_done, skb);\n\taead_request_set_crypt(req, sg, sg, elen, iv);\n\taead_request_set_assoc(req, asg, sizeof(*esph));\n\n\terr = crypto_aead_decrypt(req);\n\tif (err == -EINPROGRESS)\n\t\tgoto out;\n\n\terr = esp_input_done2(skb, err);\n\nout:\n\treturn err;\n}", "target": 1, "cwe": ["CWE-16"], "project": "linux-2.6", "commit_id": "920fc941a9617f95ccb283037fe6f8a38d95bb69", "hash": 261859902457785342652484608745523864123, "size": 60, "message": "[ESP]: Ensure IV is in linear part of the skb to avoid BUG() due to OOB access\n\nESP does not account for the IV size when calling pskb_may_pull() to\nensure everything it accesses directly is within the linear part of a\npotential fragment. This results in a BUG() being triggered when the\nboth the IPv4 and IPv6 ESP stack is fed with an skb where the first\nfragment ends between the end of the esp header and the end of the IV.\n\nThis bug was found by Dirk Nehring <dnehring@gmx.net> .\n\nSigned-off-by: Thomas Graf <tgraf@suug.ch>\nSigned-off-by: David S. Miller <davem@davemloft.net>"}
{"func": "isdn_ioctl(struct inode *inode, struct file *file, uint cmd, ulong arg)\n{\n\tuint minor = iminor(inode);\n\tisdn_ctrl c;\n\tint drvidx;\n\tint chidx;\n\tint ret;\n\tint i;\n\tchar __user *p;\n\tchar *s;\n\tunion iocpar {\n\t\tchar name[10];\n\t\tchar bname[22];\n\t\tisdn_ioctl_struct iocts;\n\t\tisdn_net_ioctl_phone phone;\n\t\tisdn_net_ioctl_cfg cfg;\n\t} iocpar;\n\tvoid __user *argp = (void __user *)arg;\n\n#define name  iocpar.name\n#define bname iocpar.bname\n#define iocts iocpar.iocts\n#define phone iocpar.phone\n#define cfg   iocpar.cfg\n\n\tif (minor == ISDN_MINOR_STATUS) {\n\t\tswitch (cmd) {\n\t\t\tcase IIOCGETDVR:\n\t\t\t\treturn (TTY_DV +\n\t\t\t\t\t(NET_DV << 8) +\n\t\t\t\t\t(INF_DV << 16));\n\t\t\tcase IIOCGETCPS:\n\t\t\t\tif (arg) {\n\t\t\t\t\tulong __user *p = argp;\n\t\t\t\t\tint i;\n\t\t\t\t\tif (!access_ok(VERIFY_WRITE, p,\n\t\t\t\t\t\t\tsizeof(ulong) * ISDN_MAX_CHANNELS * 2))\n\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\tfor (i = 0; i < ISDN_MAX_CHANNELS; i++) {\n\t\t\t\t\t\tput_user(dev->ibytes[i], p++);\n\t\t\t\t\t\tput_user(dev->obytes[i], p++);\n\t\t\t\t\t}\n\t\t\t\t\treturn 0;\n\t\t\t\t} else\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\tbreak;\n#ifdef CONFIG_NETDEVICES\n\t\t\tcase IIOCNETGPN:\n\t\t\t\t/* Get peer phone number of a connected \n\t\t\t\t * isdn network interface */\n\t\t\t\tif (arg) {\n\t\t\t\t\tif (copy_from_user(&phone, argp, sizeof(phone)))\n\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\treturn isdn_net_getpeer(&phone, argp);\n\t\t\t\t} else\n\t\t\t\t\treturn -EINVAL;\n#endif\n\t\t\tdefault:\n\t\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\tif (!dev->drivers)\n\t\treturn -ENODEV;\n\tif (minor <= ISDN_MINOR_BMAX) {\n\t\tdrvidx = isdn_minor2drv(minor);\n\t\tif (drvidx < 0)\n\t\t\treturn -ENODEV;\n\t\tchidx = isdn_minor2chan(minor);\n\t\tif (!(dev->drv[drvidx]->flags & DRV_FLAG_RUNNING))\n\t\t\treturn -ENODEV;\n\t\treturn 0;\n\t}\n\tif (minor <= ISDN_MINOR_CTRLMAX) {\n/*\n * isdn net devices manage lots of configuration variables as linked lists.\n * Those lists must only be manipulated from user space. Some of the ioctl's\n * service routines access user space and are not atomic. Therefor, ioctl's\n * manipulating the lists and ioctl's sleeping while accessing the lists\n * are serialized by means of a semaphore.\n */\n\t\tswitch (cmd) {\n\t\t\tcase IIOCNETDWRSET:\n\t\t\t\tprintk(KERN_INFO \"INFO: ISDN_DW_ABC_EXTENSION not enabled\\n\");\n\t\t\t\treturn(-EINVAL);\n\t\t\tcase IIOCNETLCR:\n\t\t\t\tprintk(KERN_INFO \"INFO: ISDN_ABC_LCR_SUPPORT not enabled\\n\");\n\t\t\t\treturn -ENODEV;\n#ifdef CONFIG_NETDEVICES\n\t\t\tcase IIOCNETAIF:\n\t\t\t\t/* Add a network-interface */\n\t\t\t\tif (arg) {\n\t\t\t\t\tif (copy_from_user(name, argp, sizeof(name)))\n\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\ts = name;\n\t\t\t\t} else {\n\t\t\t\t\ts = NULL;\n\t\t\t\t}\n\t\t\t\tret = mutex_lock_interruptible(&dev->mtx);\n\t\t\t\tif( ret ) return ret;\n\t\t\t\tif ((s = isdn_net_new(s, NULL))) {\n\t\t\t\t\tif (copy_to_user(argp, s, strlen(s) + 1)){\n\t\t\t\t\t\tret = -EFAULT;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tret = 0;\n\t\t\t\t\t}\n\t\t\t\t} else\n\t\t\t\t\tret = -ENODEV;\n\t\t\t\tmutex_unlock(&dev->mtx);\n\t\t\t\treturn ret;\n\t\t\tcase IIOCNETASL:\n\t\t\t\t/* Add a slave to a network-interface */\n\t\t\t\tif (arg) {\n\t\t\t\t\tif (copy_from_user(bname, argp, sizeof(bname) - 1))\n\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t} else\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\tret = mutex_lock_interruptible(&dev->mtx);\n\t\t\t\tif( ret ) return ret;\n\t\t\t\tif ((s = isdn_net_newslave(bname))) {\n\t\t\t\t\tif (copy_to_user(argp, s, strlen(s) + 1)){\n\t\t\t\t\t\tret = -EFAULT;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tret = 0;\n\t\t\t\t\t}\n\t\t\t\t} else\n\t\t\t\t\tret = -ENODEV;\n\t\t\t\tmutex_unlock(&dev->mtx);\n\t\t\t\treturn ret;\n\t\t\tcase IIOCNETDIF:\n\t\t\t\t/* Delete a network-interface */\n\t\t\t\tif (arg) {\n\t\t\t\t\tif (copy_from_user(name, argp, sizeof(name)))\n\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\tret = mutex_lock_interruptible(&dev->mtx);\n\t\t\t\t\tif( ret ) return ret;\n\t\t\t\t\tret = isdn_net_rm(name);\n\t\t\t\t\tmutex_unlock(&dev->mtx);\n\t\t\t\t\treturn ret;\n\t\t\t\t} else\n\t\t\t\t\treturn -EINVAL;\n\t\t\tcase IIOCNETSCF:\n\t\t\t\t/* Set configurable parameters of a network-interface */\n\t\t\t\tif (arg) {\n\t\t\t\t\tif (copy_from_user(&cfg, argp, sizeof(cfg)))\n\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\treturn isdn_net_setcfg(&cfg);\n\t\t\t\t} else\n\t\t\t\t\treturn -EINVAL;\n\t\t\tcase IIOCNETGCF:\n\t\t\t\t/* Get configurable parameters of a network-interface */\n\t\t\t\tif (arg) {\n\t\t\t\t\tif (copy_from_user(&cfg, argp, sizeof(cfg)))\n\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\tif (!(ret = isdn_net_getcfg(&cfg))) {\n\t\t\t\t\t\tif (copy_to_user(argp, &cfg, sizeof(cfg)))\n\t\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\t}\n\t\t\t\t\treturn ret;\n\t\t\t\t} else\n\t\t\t\t\treturn -EINVAL;\n\t\t\tcase IIOCNETANM:\n\t\t\t\t/* Add a phone-number to a network-interface */\n\t\t\t\tif (arg) {\n\t\t\t\t\tif (copy_from_user(&phone, argp, sizeof(phone)))\n\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\tret = mutex_lock_interruptible(&dev->mtx);\n\t\t\t\t\tif( ret ) return ret;\n\t\t\t\t\tret = isdn_net_addphone(&phone);\n\t\t\t\t\tmutex_unlock(&dev->mtx);\n\t\t\t\t\treturn ret;\n\t\t\t\t} else\n\t\t\t\t\treturn -EINVAL;\n\t\t\tcase IIOCNETGNM:\n\t\t\t\t/* Get list of phone-numbers of a network-interface */\n\t\t\t\tif (arg) {\n\t\t\t\t\tif (copy_from_user(&phone, argp, sizeof(phone)))\n\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\tret = mutex_lock_interruptible(&dev->mtx);\n\t\t\t\t\tif( ret ) return ret;\n\t\t\t\t\tret = isdn_net_getphones(&phone, argp);\n\t\t\t\t\tmutex_unlock(&dev->mtx);\n\t\t\t\t\treturn ret;\n\t\t\t\t} else\n\t\t\t\t\treturn -EINVAL;\n\t\t\tcase IIOCNETDNM:\n\t\t\t\t/* Delete a phone-number of a network-interface */\n\t\t\t\tif (arg) {\n\t\t\t\t\tif (copy_from_user(&phone, argp, sizeof(phone)))\n\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\tret = mutex_lock_interruptible(&dev->mtx);\n\t\t\t\t\tif( ret ) return ret;\n\t\t\t\t\tret = isdn_net_delphone(&phone);\n\t\t\t\t\tmutex_unlock(&dev->mtx);\n\t\t\t\t\treturn ret;\n\t\t\t\t} else\n\t\t\t\t\treturn -EINVAL;\n\t\t\tcase IIOCNETDIL:\n\t\t\t\t/* Force dialing of a network-interface */\n\t\t\t\tif (arg) {\n\t\t\t\t\tif (copy_from_user(name, argp, sizeof(name)))\n\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\treturn isdn_net_force_dial(name);\n\t\t\t\t} else\n\t\t\t\t\treturn -EINVAL;\n#ifdef CONFIG_ISDN_PPP\n\t\t\tcase IIOCNETALN:\n\t\t\t\tif (!arg)\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\tif (copy_from_user(name, argp, sizeof(name)))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\treturn isdn_ppp_dial_slave(name);\n\t\t\tcase IIOCNETDLN:\n\t\t\t\tif (!arg)\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\tif (copy_from_user(name, argp, sizeof(name)))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\treturn isdn_ppp_hangup_slave(name);\n#endif\n\t\t\tcase IIOCNETHUP:\n\t\t\t\t/* Force hangup of a network-interface */\n\t\t\t\tif (!arg)\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\tif (copy_from_user(name, argp, sizeof(name)))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\treturn isdn_net_force_hangup(name);\n\t\t\t\tbreak;\n#endif                          /* CONFIG_NETDEVICES */\n\t\t\tcase IIOCSETVER:\n\t\t\t\tdev->net_verbose = arg;\n\t\t\t\tprintk(KERN_INFO \"isdn: Verbose-Level is %d\\n\", dev->net_verbose);\n\t\t\t\treturn 0;\n\t\t\tcase IIOCSETGST:\n\t\t\t\tif (arg)\n\t\t\t\t\tdev->global_flags |= ISDN_GLOBAL_STOPPED;\n\t\t\t\telse\n\t\t\t\t\tdev->global_flags &= ~ISDN_GLOBAL_STOPPED;\n\t\t\t\tprintk(KERN_INFO \"isdn: Global Mode %s\\n\",\n\t\t\t\t       (dev->global_flags & ISDN_GLOBAL_STOPPED) ? \"stopped\" : \"running\");\n\t\t\t\treturn 0;\n\t\t\tcase IIOCSETBRJ:\n\t\t\t\tdrvidx = -1;\n\t\t\t\tif (arg) {\n\t\t\t\t\tint i;\n\t\t\t\t\tchar *p;\n\t\t\t\t\tif (copy_from_user(&iocts, argp,\n\t\t\t\t\t     sizeof(isdn_ioctl_struct)))\n\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\tif (strlen(iocts.drvid)) {\n\t\t\t\t\t\tif ((p = strchr(iocts.drvid, ',')))\n\t\t\t\t\t\t\t*p = 0;\n\t\t\t\t\t\tdrvidx = -1;\n\t\t\t\t\t\tfor (i = 0; i < ISDN_MAX_DRIVERS; i++)\n\t\t\t\t\t\t\tif (!(strcmp(dev->drvid[i], iocts.drvid))) {\n\t\t\t\t\t\t\t\tdrvidx = i;\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (drvidx == -1)\n\t\t\t\t\treturn -ENODEV;\n\t\t\t\tif (iocts.arg)\n\t\t\t\t\tdev->drv[drvidx]->flags |= DRV_FLAG_REJBUS;\n\t\t\t\telse\n\t\t\t\t\tdev->drv[drvidx]->flags &= ~DRV_FLAG_REJBUS;\n\t\t\t\treturn 0;\n\t\t\tcase IIOCSIGPRF:\n\t\t\t\tdev->profd = current;\n\t\t\t\treturn 0;\n\t\t\t\tbreak;\n\t\t\tcase IIOCGETPRF:\n\t\t\t\t/* Get all Modem-Profiles */\n\t\t\t\tif (arg) {\n\t\t\t\t\tchar __user *p = argp;\n\t\t\t\t\tint i;\n\n\t\t\t\t\tif (!access_ok(VERIFY_WRITE, argp,\n\t\t\t\t\t(ISDN_MODEM_NUMREG + ISDN_MSNLEN + ISDN_LMSNLEN)\n\t\t\t\t\t\t   * ISDN_MAX_CHANNELS))\n\t\t\t\t\t\treturn -EFAULT;\n\n\t\t\t\t\tfor (i = 0; i < ISDN_MAX_CHANNELS; i++) {\n\t\t\t\t\t\tif (copy_to_user(p, dev->mdm.info[i].emu.profile,\n\t\t\t\t\t\t      ISDN_MODEM_NUMREG))\n\t\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\t\tp += ISDN_MODEM_NUMREG;\n\t\t\t\t\t\tif (copy_to_user(p, dev->mdm.info[i].emu.pmsn, ISDN_MSNLEN))\n\t\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\t\tp += ISDN_MSNLEN;\n\t\t\t\t\t\tif (copy_to_user(p, dev->mdm.info[i].emu.plmsn, ISDN_LMSNLEN))\n\t\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\t\tp += ISDN_LMSNLEN;\n\t\t\t\t\t}\n\t\t\t\t\treturn (ISDN_MODEM_NUMREG + ISDN_MSNLEN + ISDN_LMSNLEN) * ISDN_MAX_CHANNELS;\n\t\t\t\t} else\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\tbreak;\n\t\t\tcase IIOCSETPRF:\n\t\t\t\t/* Set all Modem-Profiles */\n\t\t\t\tif (arg) {\n\t\t\t\t\tchar __user *p = argp;\n\t\t\t\t\tint i;\n\n\t\t\t\t\tif (!access_ok(VERIFY_READ, argp,\n\t\t\t\t\t(ISDN_MODEM_NUMREG + ISDN_MSNLEN + ISDN_LMSNLEN)\n\t\t\t\t\t\t   * ISDN_MAX_CHANNELS))\n\t\t\t\t\t\treturn -EFAULT;\n\n\t\t\t\t\tfor (i = 0; i < ISDN_MAX_CHANNELS; i++) {\n\t\t\t\t\t\tif (copy_from_user(dev->mdm.info[i].emu.profile, p,\n\t\t\t\t\t\t     ISDN_MODEM_NUMREG))\n\t\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\t\tp += ISDN_MODEM_NUMREG;\n\t\t\t\t\t\tif (copy_from_user(dev->mdm.info[i].emu.plmsn, p, ISDN_LMSNLEN))\n\t\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\t\tp += ISDN_LMSNLEN;\n\t\t\t\t\t\tif (copy_from_user(dev->mdm.info[i].emu.pmsn, p, ISDN_MSNLEN))\n\t\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\t\tp += ISDN_MSNLEN;\n\t\t\t\t\t}\n\t\t\t\t\treturn 0;\n\t\t\t\t} else\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\tbreak;\n\t\t\tcase IIOCSETMAP:\n\t\t\tcase IIOCGETMAP:\n\t\t\t\t/* Set/Get MSN->EAZ-Mapping for a driver */\n\t\t\t\tif (arg) {\n\n\t\t\t\t\tif (copy_from_user(&iocts, argp,\n\t\t\t\t\t     sizeof(isdn_ioctl_struct)))\n\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\tif (strlen(iocts.drvid)) {\n\t\t\t\t\t\tdrvidx = -1;\n\t\t\t\t\t\tfor (i = 0; i < ISDN_MAX_DRIVERS; i++)\n\t\t\t\t\t\t\tif (!(strcmp(dev->drvid[i], iocts.drvid))) {\n\t\t\t\t\t\t\t\tdrvidx = i;\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t} else\n\t\t\t\t\t\tdrvidx = 0;\n\t\t\t\t\tif (drvidx == -1)\n\t\t\t\t\t\treturn -ENODEV;\n\t\t\t\t\tif (cmd == IIOCSETMAP) {\n\t\t\t\t\t\tint loop = 1;\n\n\t\t\t\t\t\tp = (char __user *) iocts.arg;\n\t\t\t\t\t\ti = 0;\n\t\t\t\t\t\twhile (loop) {\n\t\t\t\t\t\t\tint j = 0;\n\n\t\t\t\t\t\t\twhile (1) {\n\t\t\t\t\t\t\t\tif (!access_ok(VERIFY_READ, p, 1))\n\t\t\t\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\t\t\t\tget_user(bname[j], p++);\n\t\t\t\t\t\t\t\tswitch (bname[j]) {\n\t\t\t\t\t\t\t\t\tcase '\\0':\n\t\t\t\t\t\t\t\t\t\tloop = 0;\n\t\t\t\t\t\t\t\t\t\t/* Fall through */\n\t\t\t\t\t\t\t\t\tcase ',':\n\t\t\t\t\t\t\t\t\t\tbname[j] = '\\0';\n\t\t\t\t\t\t\t\t\t\tstrcpy(dev->drv[drvidx]->msn2eaz[i], bname);\n\t\t\t\t\t\t\t\t\t\tj = ISDN_MSNLEN;\n\t\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t\t\t\t\tj++;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tif (j >= ISDN_MSNLEN)\n\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif (++i > 9)\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tp = (char __user *) iocts.arg;\n\t\t\t\t\t\tfor (i = 0; i < 10; i++) {\n\t\t\t\t\t\t\tsprintf(bname, \"%s%s\",\n\t\t\t\t\t\t\t\tstrlen(dev->drv[drvidx]->msn2eaz[i]) ?\n\t\t\t\t\t\t\t\tdev->drv[drvidx]->msn2eaz[i] : \"_\",\n\t\t\t\t\t\t\t\t(i < 9) ? \",\" : \"\\0\");\n\t\t\t\t\t\t\tif (copy_to_user(p, bname, strlen(bname) + 1))\n\t\t\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\t\t\tp += strlen(bname);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\treturn 0;\n\t\t\t\t} else\n\t\t\t\t\treturn -EINVAL;\n\t\t\tcase IIOCDBGVAR:\n\t\t\t\tif (arg) {\n\t\t\t\t\tif (copy_to_user(argp, &dev, sizeof(ulong)))\n\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\treturn 0;\n\t\t\t\t} else\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tif ((cmd & IIOCDRVCTL) == IIOCDRVCTL)\n\t\t\t\t\tcmd = ((cmd >> _IOC_NRSHIFT) & _IOC_NRMASK) & ISDN_DRVIOCTL_MASK;\n\t\t\t\telse\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\tif (arg) {\n\t\t\t\t\tint i;\n\t\t\t\t\tchar *p;\n\t\t\t\t\tif (copy_from_user(&iocts, argp, sizeof(isdn_ioctl_struct)))\n\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\tif (strlen(iocts.drvid)) {\n\t\t\t\t\t\tif ((p = strchr(iocts.drvid, ',')))\n\t\t\t\t\t\t\t*p = 0;\n\t\t\t\t\t\tdrvidx = -1;\n\t\t\t\t\t\tfor (i = 0; i < ISDN_MAX_DRIVERS; i++)\n\t\t\t\t\t\t\tif (!(strcmp(dev->drvid[i], iocts.drvid))) {\n\t\t\t\t\t\t\t\tdrvidx = i;\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t} else\n\t\t\t\t\t\tdrvidx = 0;\n\t\t\t\t\tif (drvidx == -1)\n\t\t\t\t\t\treturn -ENODEV;\n\t\t\t\t\tif (!access_ok(VERIFY_WRITE, argp,\n\t\t\t\t\t     sizeof(isdn_ioctl_struct)))\n\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\tc.driver = drvidx;\n\t\t\t\t\tc.command = ISDN_CMD_IOCTL;\n\t\t\t\t\tc.arg = cmd;\n\t\t\t\t\tmemcpy(c.parm.num, &iocts.arg, sizeof(ulong));\n\t\t\t\t\tret = isdn_command(&c);\n\t\t\t\t\tmemcpy(&iocts.arg, c.parm.num, sizeof(ulong));\n\t\t\t\t\tif (copy_to_user(argp, &iocts, sizeof(isdn_ioctl_struct)))\n\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\treturn ret;\n\t\t\t\t} else\n\t\t\t\t\treturn -EINVAL;\n\t\t}\n\t}\n#ifdef CONFIG_ISDN_PPP\n\tif (minor <= ISDN_MINOR_PPPMAX)\n\t\treturn (isdn_ppp_ioctl(minor - ISDN_MINOR_PPP, file, cmd, arg));\n#endif\n\treturn -ENODEV;\n\n#undef name\n#undef bname\n#undef iocts\n#undef phone\n#undef cfg\n}", "target": 1, "cwe": ["CWE-119"], "project": "linux-2.6", "commit_id": "eafe1aa37e6ec2d56f14732b5240c4dd09f0613a", "hash": 328221509131099860922910070027499343329, "size": 446, "message": "I4L: fix isdn_ioctl memory overrun vulnerability\n\nFix possible memory overrun issue in the isdn ioctl code.\n\nFound by ADLAB <adlab@venustech.com.cn>\n\nSigned-off-by: Karsten Keil <kkeil@suse.de>\nCc: ADLAB <adlab@venustech.com.cn>\nCc: <stable@kernel.org>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "shmem_alloc_page(gfp_t gfp,struct shmem_inode_info *info, unsigned long idx)\n{\n\treturn alloc_page(gfp | __GFP_ZERO);\n}", "target": 1, "cwe": ["CWE-200"], "project": "linux-2.6", "commit_id": "e84e2e132c9c66d8498e7710d4ea532d1feaaac5", "hash": 40898721436560148466228075046362201453, "size": 4, "message": "tmpfs: restore missing clear_highpage\n\ntmpfs was misconverted to __GFP_ZERO in 2.6.11.  There's an unusual case in\nwhich shmem_getpage receives the page from its caller instead of allocating.\nWe must cover this case by clear_highpage before SetPageUptodate, as before.\n\nSigned-off-by: Hugh Dickins <hugh@veritas.com>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "static int shmem_getpage(struct inode *inode, unsigned long idx,\n\t\t\tstruct page **pagep, enum sgp_type sgp, int *type)\n{\n\tstruct address_space *mapping = inode->i_mapping;\n\tstruct shmem_inode_info *info = SHMEM_I(inode);\n\tstruct shmem_sb_info *sbinfo;\n\tstruct page *filepage = *pagep;\n\tstruct page *swappage;\n\tswp_entry_t *entry;\n\tswp_entry_t swap;\n\tint error;\n\n\tif (idx >= SHMEM_MAX_INDEX)\n\t\treturn -EFBIG;\n\n\tif (type)\n\t\t*type = 0;\n\n\t/*\n\t * Normally, filepage is NULL on entry, and either found\n\t * uptodate immediately, or allocated and zeroed, or read\n\t * in under swappage, which is then assigned to filepage.\n\t * But shmem_readpage and shmem_write_begin pass in a locked\n\t * filepage, which may be found not uptodate by other callers\n\t * too, and may need to be copied from the swappage read in.\n\t */\nrepeat:\n\tif (!filepage)\n\t\tfilepage = find_lock_page(mapping, idx);\n\tif (filepage && PageUptodate(filepage))\n\t\tgoto done;\n\terror = 0;\n\tif (sgp == SGP_QUICK)\n\t\tgoto failed;\n\n\tspin_lock(&info->lock);\n\tshmem_recalc_inode(inode);\n\tentry = shmem_swp_alloc(info, idx, sgp);\n\tif (IS_ERR(entry)) {\n\t\tspin_unlock(&info->lock);\n\t\terror = PTR_ERR(entry);\n\t\tgoto failed;\n\t}\n\tswap = *entry;\n\n\tif (swap.val) {\n\t\t/* Look it up and read it in.. */\n\t\tswappage = lookup_swap_cache(swap);\n\t\tif (!swappage) {\n\t\t\tshmem_swp_unmap(entry);\n\t\t\t/* here we actually do the io */\n\t\t\tif (type && !(*type & VM_FAULT_MAJOR)) {\n\t\t\t\t__count_vm_event(PGMAJFAULT);\n\t\t\t\t*type |= VM_FAULT_MAJOR;\n\t\t\t}\n\t\t\tspin_unlock(&info->lock);\n\t\t\tswappage = shmem_swapin(info, swap, idx);\n\t\t\tif (!swappage) {\n\t\t\t\tspin_lock(&info->lock);\n\t\t\t\tentry = shmem_swp_alloc(info, idx, sgp);\n\t\t\t\tif (IS_ERR(entry))\n\t\t\t\t\terror = PTR_ERR(entry);\n\t\t\t\telse {\n\t\t\t\t\tif (entry->val == swap.val)\n\t\t\t\t\t\terror = -ENOMEM;\n\t\t\t\t\tshmem_swp_unmap(entry);\n\t\t\t\t}\n\t\t\t\tspin_unlock(&info->lock);\n\t\t\t\tif (error)\n\t\t\t\t\tgoto failed;\n\t\t\t\tgoto repeat;\n\t\t\t}\n\t\t\twait_on_page_locked(swappage);\n\t\t\tpage_cache_release(swappage);\n\t\t\tgoto repeat;\n\t\t}\n\n\t\t/* We have to do this with page locked to prevent races */\n\t\tif (TestSetPageLocked(swappage)) {\n\t\t\tshmem_swp_unmap(entry);\n\t\t\tspin_unlock(&info->lock);\n\t\t\twait_on_page_locked(swappage);\n\t\t\tpage_cache_release(swappage);\n\t\t\tgoto repeat;\n\t\t}\n\t\tif (PageWriteback(swappage)) {\n\t\t\tshmem_swp_unmap(entry);\n\t\t\tspin_unlock(&info->lock);\n\t\t\twait_on_page_writeback(swappage);\n\t\t\tunlock_page(swappage);\n\t\t\tpage_cache_release(swappage);\n\t\t\tgoto repeat;\n\t\t}\n\t\tif (!PageUptodate(swappage)) {\n\t\t\tshmem_swp_unmap(entry);\n\t\t\tspin_unlock(&info->lock);\n\t\t\tunlock_page(swappage);\n\t\t\tpage_cache_release(swappage);\n\t\t\terror = -EIO;\n\t\t\tgoto failed;\n\t\t}\n\n\t\tif (filepage) {\n\t\t\tshmem_swp_set(info, entry, 0);\n\t\t\tshmem_swp_unmap(entry);\n\t\t\tdelete_from_swap_cache(swappage);\n\t\t\tspin_unlock(&info->lock);\n\t\t\tcopy_highpage(filepage, swappage);\n\t\t\tunlock_page(swappage);\n\t\t\tpage_cache_release(swappage);\n\t\t\tflush_dcache_page(filepage);\n\t\t\tSetPageUptodate(filepage);\n\t\t\tset_page_dirty(filepage);\n\t\t\tswap_free(swap);\n\t\t} else if (!(error = move_from_swap_cache(\n\t\t\t\tswappage, idx, mapping))) {\n\t\t\tinfo->flags |= SHMEM_PAGEIN;\n\t\t\tshmem_swp_set(info, entry, 0);\n\t\t\tshmem_swp_unmap(entry);\n\t\t\tspin_unlock(&info->lock);\n\t\t\tfilepage = swappage;\n\t\t\tswap_free(swap);\n\t\t} else {\n\t\t\tshmem_swp_unmap(entry);\n\t\t\tspin_unlock(&info->lock);\n\t\t\tunlock_page(swappage);\n\t\t\tpage_cache_release(swappage);\n\t\t\tif (error == -ENOMEM) {\n\t\t\t\t/* let kswapd refresh zone for GFP_ATOMICs */\n\t\t\t\tcongestion_wait(WRITE, HZ/50);\n\t\t\t}\n\t\t\tgoto repeat;\n\t\t}\n\t} else if (sgp == SGP_READ && !filepage) {\n\t\tshmem_swp_unmap(entry);\n\t\tfilepage = find_get_page(mapping, idx);\n\t\tif (filepage &&\n\t\t    (!PageUptodate(filepage) || TestSetPageLocked(filepage))) {\n\t\t\tspin_unlock(&info->lock);\n\t\t\twait_on_page_locked(filepage);\n\t\t\tpage_cache_release(filepage);\n\t\t\tfilepage = NULL;\n\t\t\tgoto repeat;\n\t\t}\n\t\tspin_unlock(&info->lock);\n\t} else {\n\t\tshmem_swp_unmap(entry);\n\t\tsbinfo = SHMEM_SB(inode->i_sb);\n\t\tif (sbinfo->max_blocks) {\n\t\t\tspin_lock(&sbinfo->stat_lock);\n\t\t\tif (sbinfo->free_blocks == 0 ||\n\t\t\t    shmem_acct_block(info->flags)) {\n\t\t\t\tspin_unlock(&sbinfo->stat_lock);\n\t\t\t\tspin_unlock(&info->lock);\n\t\t\t\terror = -ENOSPC;\n\t\t\t\tgoto failed;\n\t\t\t}\n\t\t\tsbinfo->free_blocks--;\n\t\t\tinode->i_blocks += BLOCKS_PER_PAGE;\n\t\t\tspin_unlock(&sbinfo->stat_lock);\n\t\t} else if (shmem_acct_block(info->flags)) {\n\t\t\tspin_unlock(&info->lock);\n\t\t\terror = -ENOSPC;\n\t\t\tgoto failed;\n\t\t}\n\n\t\tif (!filepage) {\n\t\t\tspin_unlock(&info->lock);\n\t\t\tfilepage = shmem_alloc_page(mapping_gfp_mask(mapping),\n\t\t\t\t\t\t    info,\n\t\t\t\t\t\t    idx);\n\t\t\tif (!filepage) {\n\t\t\t\tshmem_unacct_blocks(info->flags, 1);\n\t\t\t\tshmem_free_blocks(inode, 1);\n\t\t\t\terror = -ENOMEM;\n\t\t\t\tgoto failed;\n\t\t\t}\n\n\t\t\tspin_lock(&info->lock);\n\t\t\tentry = shmem_swp_alloc(info, idx, sgp);\n\t\t\tif (IS_ERR(entry))\n\t\t\t\terror = PTR_ERR(entry);\n\t\t\telse {\n\t\t\t\tswap = *entry;\n\t\t\t\tshmem_swp_unmap(entry);\n\t\t\t}\n\t\t\tif (error || swap.val || 0 != add_to_page_cache_lru(\n\t\t\t\t\tfilepage, mapping, idx, GFP_ATOMIC)) {\n\t\t\t\tspin_unlock(&info->lock);\n\t\t\t\tpage_cache_release(filepage);\n\t\t\t\tshmem_unacct_blocks(info->flags, 1);\n\t\t\t\tshmem_free_blocks(inode, 1);\n\t\t\t\tfilepage = NULL;\n\t\t\t\tif (error)\n\t\t\t\t\tgoto failed;\n\t\t\t\tgoto repeat;\n\t\t\t}\n\t\t\tinfo->flags |= SHMEM_PAGEIN;\n\t\t}\n\n\t\tinfo->alloced++;\n\t\tspin_unlock(&info->lock);\n\t\tflush_dcache_page(filepage);\n\t\tSetPageUptodate(filepage);\n\t}\ndone:\n\tif (*pagep != filepage) {\n\t\t*pagep = filepage;\n\t\tif (sgp != SGP_FAULT)\n\t\t\tunlock_page(filepage);\n\n\t}\n\treturn 0;\n\nfailed:\n\tif (*pagep != filepage) {\n\t\tunlock_page(filepage);\n\t\tpage_cache_release(filepage);\n\t}\n\treturn error;\n}", "target": 1, "cwe": ["CWE-200"], "project": "linux-2.6", "commit_id": "e84e2e132c9c66d8498e7710d4ea532d1feaaac5", "hash": 337224798820921138280301426323775912767, "size": 221, "message": "tmpfs: restore missing clear_highpage\n\ntmpfs was misconverted to __GFP_ZERO in 2.6.11.  There's an unusual case in\nwhich shmem_getpage receives the page from its caller instead of allocating.\nWe must cover this case by clear_highpage before SetPageUptodate, as before.\n\nSigned-off-by: Hugh Dickins <hugh@veritas.com>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "shmem_alloc_page(gfp_t gfp, struct shmem_inode_info *info,\n\t\t unsigned long idx)\n{\n\tstruct vm_area_struct pvma;\n\tstruct page *page;\n\n\tmemset(&pvma, 0, sizeof(struct vm_area_struct));\n\tpvma.vm_policy = mpol_shared_policy_lookup(&info->policy, idx);\n\tpvma.vm_pgoff = idx;\n\tpvma.vm_end = PAGE_SIZE;\n\tpage = alloc_page_vma(gfp | __GFP_ZERO, &pvma, 0);\n\tmpol_free(pvma.vm_policy);\n\treturn page;\n}", "target": 1, "cwe": ["CWE-200"], "project": "linux-2.6", "commit_id": "e84e2e132c9c66d8498e7710d4ea532d1feaaac5", "hash": 209078005530362263064364667908690042525, "size": 14, "message": "tmpfs: restore missing clear_highpage\n\ntmpfs was misconverted to __GFP_ZERO in 2.6.11.  There's an unusual case in\nwhich shmem_getpage receives the page from its caller instead of allocating.\nWe must cover this case by clear_highpage before SetPageUptodate, as before.\n\nSigned-off-by: Hugh Dickins <hugh@veritas.com>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "ProcShmCreatePixmap(client)\n    register ClientPtr client;\n{\n    PixmapPtr pMap;\n    DrawablePtr pDraw;\n    DepthPtr pDepth;\n    register int i, rc;\n    ShmDescPtr shmdesc;\n    REQUEST(xShmCreatePixmapReq);\n    unsigned int width, height, depth;\n    unsigned long size;\n\n    REQUEST_SIZE_MATCH(xShmCreatePixmapReq);\n    client->errorValue = stuff->pid;\n    if (!sharedPixmaps)\n\treturn BadImplementation;\n    LEGAL_NEW_RESOURCE(stuff->pid, client);\n    rc = dixLookupDrawable(&pDraw, stuff->drawable, client, M_ANY,\n\t\t\t   DixGetAttrAccess);\n    if (rc != Success)\n\treturn rc;\n\n    VERIFY_SHMPTR(stuff->shmseg, stuff->offset, TRUE, shmdesc, client);\n    \n    width = stuff->width;\n    height = stuff->height;\n    depth = stuff->depth;\n    if (!width || !height || !depth)\n    {\n\tclient->errorValue = 0;\n        return BadValue;\n    }\n    if (width > 32767 || height > 32767)\n\treturn BadAlloc;\n\n    if (stuff->depth != 1)\n    {\n        pDepth = pDraw->pScreen->allowedDepths;\n        for (i=0; i<pDraw->pScreen->numDepths; i++, pDepth++)\n\t   if (pDepth->depth == stuff->depth)\n               goto CreatePmap;\n\tclient->errorValue = stuff->depth;\n        return BadValue;\n    }\n\nCreatePmap:\n    size = PixmapBytePad(width, depth) * height;\n    if (sizeof(size) == 4 && BitsPerPixel(depth) > 8) {\n\tif (size < width * height)\n\t    return BadAlloc;\n\t/* thankfully, offset is unsigned */\n\tif (stuff->offset + size < size)\n\t    return BadAlloc;\n    }\n\n    VERIFY_SHMSIZE(shmdesc, stuff->offset, size, client);\n    pMap = (*shmFuncs[pDraw->pScreen->myNum]->CreatePixmap)(\n\t\t\t    pDraw->pScreen, stuff->width,\n\t\t\t    stuff->height, stuff->depth,\n\t\t\t    shmdesc->addr + stuff->offset);\n    if (pMap)\n    {\n\trc = XaceHook(XACE_RESOURCE_ACCESS, client, stuff->pid, RT_PIXMAP,\n\t\t      pMap, RT_NONE, NULL, DixCreateAccess);\n\tif (rc != Success) {\n\t    pDraw->pScreen->DestroyPixmap(pMap);\n\t    return rc;\n\t}\n\tdixSetPrivate(&pMap->devPrivates, shmPixmapPrivate, shmdesc);\n\tshmdesc->refcnt++;\n\tpMap->drawable.serialNumber = NEXT_SERIAL_NUMBER;\n\tpMap->drawable.id = stuff->pid;\n\tif (AddResource(stuff->pid, RT_PIXMAP, (pointer)pMap))\n\t{\n\t    return(client->noClientException);\n\t}\n\tpDraw->pScreen->DestroyPixmap(pMap);\n    }\n    return (BadAlloc);\n}", "target": 1, "cwe": ["CWE-189"], "project": "xserver", "commit_id": "be6c17fcf9efebc0bbcc3d9a25f8c5a2450c2161", "hash": 129275241199461482775430751894790125185, "size": 80, "message": "CVE-2007-6429: Always test for size+offset wrapping."}
{"func": "ProcPanoramiXShmCreatePixmap(\n    register ClientPtr client)\n{\n    ScreenPtr pScreen = NULL;\n    PixmapPtr pMap = NULL;\n    DrawablePtr pDraw;\n    DepthPtr pDepth;\n    int i, j, result, rc;\n    ShmDescPtr shmdesc;\n    REQUEST(xShmCreatePixmapReq);\n    unsigned int width, height, depth;\n    unsigned long size;\n    PanoramiXRes *newPix;\n\n    REQUEST_SIZE_MATCH(xShmCreatePixmapReq);\n    client->errorValue = stuff->pid;\n    if (!sharedPixmaps)\n\treturn BadImplementation;\n    LEGAL_NEW_RESOURCE(stuff->pid, client);\n    rc = dixLookupDrawable(&pDraw, stuff->drawable, client, M_ANY,\n\t\t\t   DixUnknownAccess);\n    if (rc != Success)\n\treturn rc;\n\n    VERIFY_SHMPTR(stuff->shmseg, stuff->offset, TRUE, shmdesc, client);\n\n    width = stuff->width;\n    height = stuff->height;\n    depth = stuff->depth;\n    if (!width || !height || !depth)\n    {\n\tclient->errorValue = 0;\n        return BadValue;\n    }\n    if (width > 32767 || height > 32767)\n        return BadAlloc;\n\n    if (stuff->depth != 1)\n    {\n        pDepth = pDraw->pScreen->allowedDepths;\n        for (i=0; i<pDraw->pScreen->numDepths; i++, pDepth++)\n\t   if (pDepth->depth == stuff->depth)\n               goto CreatePmap;\n\tclient->errorValue = stuff->depth;\n        return BadValue;\n    }\n\nCreatePmap:\n    size = PixmapBytePad(width, depth) * height;\n    if (sizeof(size) == 4 && BitsPerPixel(depth) > 8) {\n        if (size < width * height)\n            return BadAlloc;\n        /* thankfully, offset is unsigned */\n        if (stuff->offset + size < size)\n            return BadAlloc;\n    }\n\n    VERIFY_SHMSIZE(shmdesc, stuff->offset, size, client);\n\n    if(!(newPix = (PanoramiXRes *) xalloc(sizeof(PanoramiXRes))))\n\treturn BadAlloc;\n\n    newPix->type = XRT_PIXMAP;\n    newPix->u.pix.shared = TRUE;\n    newPix->info[0].id = stuff->pid;\n    for(j = 1; j < PanoramiXNumScreens; j++)\n\tnewPix->info[j].id = FakeClientID(client->index);\n\n    result = (client->noClientException);\n\n    FOR_NSCREENS(j) {\n\tpScreen = screenInfo.screens[j];\n\n\tpMap = (*shmFuncs[j]->CreatePixmap)(pScreen, \n\t\t\t\tstuff->width, stuff->height, stuff->depth,\n\t\t\t\tshmdesc->addr + stuff->offset);\n\n\tif (pMap) {\n\t    dixSetPrivate(&pMap->devPrivates, shmPixmapPrivate, shmdesc);\n            shmdesc->refcnt++;\n\t    pMap->drawable.serialNumber = NEXT_SERIAL_NUMBER;\n\t    pMap->drawable.id = newPix->info[j].id;\n\t    if (!AddResource(newPix->info[j].id, RT_PIXMAP, (pointer)pMap)) {\n\t\t(*pScreen->DestroyPixmap)(pMap);\n\t\tresult = BadAlloc;\n\t\tbreak;\n\t    }\n\t} else {\n\t   result = BadAlloc;\n\t   break;\n\t}\n    }\n\n    if(result == BadAlloc) {\n\twhile(j--) {\n\t    (*pScreen->DestroyPixmap)(pMap);\n\t    FreeResource(newPix->info[j].id, RT_NONE);\n\t}\n\txfree(newPix);\n    } else \n\tAddResource(stuff->pid, XRT_PIXMAP, newPix);\n\n    return result;\n}", "target": 1, "cwe": ["CWE-189"], "project": "xserver", "commit_id": "be6c17fcf9efebc0bbcc3d9a25f8c5a2450c2161", "hash": 17219291516037378365261386718006722853, "size": 104, "message": "CVE-2007-6429: Always test for size+offset wrapping."}
{"func": "static int copy_from_user_mmap_sem(void *dst, const void __user *src, size_t n)\n{\n\tint partial;\n\n\tpagefault_disable();\n\tpartial = __copy_from_user_inatomic(dst, src, n);\n\tpagefault_enable();\n\n\t/*\n\t * Didn't copy everything, drop the mmap_sem and do a faulting copy\n\t */\n\tif (unlikely(partial)) {\n\t\tup_read(&current->mm->mmap_sem);\n\t\tpartial = copy_from_user(dst, src, n);\n\t\tdown_read(&current->mm->mmap_sem);\n\t}\n\n\treturn partial;\n}", "target": 1, "cwe": ["CWE-94"], "project": "linux-2.6", "commit_id": "8811930dc74a503415b35c4a79d14fb0b408a361", "hash": 235093879813159381271611100311257866404, "size": 19, "message": "splice: missing user pointer access verification\n\nvmsplice_to_user() must always check the user pointer and length\nwith access_ok() before copying. Likewise, for the slow path of\ncopy_from_user_mmap_sem() we need to check that we may read from\nthe user region.\n\nSigned-off-by: Jens Axboe <jens.axboe@oracle.com>\nCc: Wojciech Purczynski <cliph@research.coseinc.com>\nSigned-off-by: Greg Kroah-Hartman <gregkh@suse.de>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "static long vmsplice_to_user(struct file *file, const struct iovec __user *iov,\n\t\t\t     unsigned long nr_segs, unsigned int flags)\n{\n\tstruct pipe_inode_info *pipe;\n\tstruct splice_desc sd;\n\tssize_t size;\n\tint error;\n\tlong ret;\n\n\tpipe = pipe_info(file->f_path.dentry->d_inode);\n\tif (!pipe)\n\t\treturn -EBADF;\n\n\tif (pipe->inode)\n\t\tmutex_lock(&pipe->inode->i_mutex);\n\n\terror = ret = 0;\n\twhile (nr_segs) {\n\t\tvoid __user *base;\n\t\tsize_t len;\n\n\t\t/*\n\t\t * Get user address base and length for this iovec.\n\t\t */\n\t\terror = get_user(base, &iov->iov_base);\n\t\tif (unlikely(error))\n\t\t\tbreak;\n\t\terror = get_user(len, &iov->iov_len);\n\t\tif (unlikely(error))\n\t\t\tbreak;\n\n\t\t/*\n\t\t * Sanity check this iovec. 0 read succeeds.\n\t\t */\n\t\tif (unlikely(!len))\n\t\t\tbreak;\n\t\tif (unlikely(!base)) {\n\t\t\terror = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\n\t\tsd.len = 0;\n\t\tsd.total_len = len;\n\t\tsd.flags = flags;\n\t\tsd.u.userptr = base;\n\t\tsd.pos = 0;\n\n\t\tsize = __splice_from_pipe(pipe, &sd, pipe_to_user);\n\t\tif (size < 0) {\n\t\t\tif (!ret)\n\t\t\t\tret = size;\n\n\t\t\tbreak;\n\t\t}\n\n\t\tret += size;\n\n\t\tif (size < len)\n\t\t\tbreak;\n\n\t\tnr_segs--;\n\t\tiov++;\n\t}\n\n\tif (pipe->inode)\n\t\tmutex_unlock(&pipe->inode->i_mutex);\n\n\tif (!ret)\n\t\tret = error;\n\n\treturn ret;\n}", "target": 1, "cwe": ["CWE-94"], "project": "linux-2.6", "commit_id": "8811930dc74a503415b35c4a79d14fb0b408a361", "hash": 93812929696679570671165480928317227145, "size": 72, "message": "splice: missing user pointer access verification\n\nvmsplice_to_user() must always check the user pointer and length\nwith access_ok() before copying. Likewise, for the slow path of\ncopy_from_user_mmap_sem() we need to check that we may read from\nthe user region.\n\nSigned-off-by: Jens Axboe <jens.axboe@oracle.com>\nCc: Wojciech Purczynski <cliph@research.coseinc.com>\nSigned-off-by: Greg Kroah-Hartman <gregkh@suse.de>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "static int get_iovec_page_array(const struct iovec __user *iov,\n\t\t\t\tunsigned int nr_vecs, struct page **pages,\n\t\t\t\tstruct partial_page *partial, int aligned)\n{\n\tint buffers = 0, error = 0;\n\n\tdown_read(&current->mm->mmap_sem);\n\n\twhile (nr_vecs) {\n\t\tunsigned long off, npages;\n\t\tstruct iovec entry;\n\t\tvoid __user *base;\n\t\tsize_t len;\n\t\tint i;\n\n\t\terror = -EFAULT;\n\t\tif (copy_from_user_mmap_sem(&entry, iov, sizeof(entry)))\n\t\t\tbreak;\n\n\t\tbase = entry.iov_base;\n\t\tlen = entry.iov_len;\n\n\t\t/*\n\t\t * Sanity check this iovec. 0 read succeeds.\n\t\t */\n\t\terror = 0;\n\t\tif (unlikely(!len))\n\t\t\tbreak;\n\t\terror = -EFAULT;\n\t\tif (unlikely(!base))\n\t\t\tbreak;\n\n\t\t/*\n\t\t * Get this base offset and number of pages, then map\n\t\t * in the user pages.\n\t\t */\n\t\toff = (unsigned long) base & ~PAGE_MASK;\n\n\t\t/*\n\t\t * If asked for alignment, the offset must be zero and the\n\t\t * length a multiple of the PAGE_SIZE.\n\t\t */\n\t\terror = -EINVAL;\n\t\tif (aligned && (off || len & ~PAGE_MASK))\n\t\t\tbreak;\n\n\t\tnpages = (off + len + PAGE_SIZE - 1) >> PAGE_SHIFT;\n\t\tif (npages > PIPE_BUFFERS - buffers)\n\t\t\tnpages = PIPE_BUFFERS - buffers;\n\n\t\terror = get_user_pages(current, current->mm,\n\t\t\t\t       (unsigned long) base, npages, 0, 0,\n\t\t\t\t       &pages[buffers], NULL);\n\n\t\tif (unlikely(error <= 0))\n\t\t\tbreak;\n\n\t\t/*\n\t\t * Fill this contiguous range into the partial page map.\n\t\t */\n\t\tfor (i = 0; i < error; i++) {\n\t\t\tconst int plen = min_t(size_t, len, PAGE_SIZE - off);\n\n\t\t\tpartial[buffers].offset = off;\n\t\t\tpartial[buffers].len = plen;\n\n\t\t\toff = 0;\n\t\t\tlen -= plen;\n\t\t\tbuffers++;\n\t\t}\n\n\t\t/*\n\t\t * We didn't complete this iov, stop here since it probably\n\t\t * means we have to move some of this into a pipe to\n\t\t * be able to continue.\n\t\t */\n\t\tif (len)\n\t\t\tbreak;\n\n\t\t/*\n\t\t * Don't continue if we mapped fewer pages than we asked for,\n\t\t * or if we mapped the max number of pages that we have\n\t\t * room for.\n\t\t */\n\t\tif (error < npages || buffers == PIPE_BUFFERS)\n\t\t\tbreak;\n\n\t\tnr_vecs--;\n\t\tiov++;\n\t}\n\n\tup_read(&current->mm->mmap_sem);\n\n\tif (buffers)\n\t\treturn buffers;\n\n\treturn error;\n}", "target": 1, "cwe": ["CWE-94"], "project": "linux-2.6", "commit_id": "712a30e63c8066ed84385b12edbfb804f49cbc44", "hash": 235267654020111867894816915382074891733, "size": 98, "message": "splice: fix user pointer access in get_iovec_page_array()\n\nCommit 8811930dc74a503415b35c4a79d14fb0b408a361 (\"splice: missing user\npointer access verification\") added the proper access_ok() calls to\ncopy_from_user_mmap_sem() which ensures we can copy the struct iovecs\nfrom userspace to the kernel.\n\nBut we also must check whether we can access the actual memory region\npointed to by the struct iovec to fix the access checks properly.\n\nSigned-off-by: Bastian Blank <waldi@debian.org>\nAcked-by: Oliver Pinter <oliver.pntr@gmail.com>\nCc: Jens Axboe <jens.axboe@oracle.com>\nCc: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Pekka Enberg <penberg@cs.helsinki.fi>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "asmlinkage long sys_setrlimit(unsigned int resource, struct rlimit __user *rlim)\n{\n\tstruct rlimit new_rlim, *old_rlim;\n\tunsigned long it_prof_secs;\n\tint retval;\n\n\tif (resource >= RLIM_NLIMITS)\n\t\treturn -EINVAL;\n\tif (copy_from_user(&new_rlim, rlim, sizeof(*rlim)))\n\t\treturn -EFAULT;\n\tif (new_rlim.rlim_cur > new_rlim.rlim_max)\n\t\treturn -EINVAL;\n\told_rlim = current->signal->rlim + resource;\n\tif ((new_rlim.rlim_max > old_rlim->rlim_max) &&\n\t    !capable(CAP_SYS_RESOURCE))\n\t\treturn -EPERM;\n\tif (resource == RLIMIT_NOFILE && new_rlim.rlim_max > NR_OPEN)\n\t\treturn -EPERM;\n\n\tretval = security_task_setrlimit(resource, &new_rlim);\n\tif (retval)\n\t\treturn retval;\n\n\ttask_lock(current->group_leader);\n\t*old_rlim = new_rlim;\n\ttask_unlock(current->group_leader);\n\n\tif (resource != RLIMIT_CPU)\n\t\tgoto out;\n\n\t/*\n\t * RLIMIT_CPU handling.   Note that the kernel fails to return an error\n\t * code if it rejected the user's attempt to set RLIMIT_CPU.  This is a\n\t * very long-standing error, and fixing it now risks breakage of\n\t * applications, so we live with it\n\t */\n\tif (new_rlim.rlim_cur == RLIM_INFINITY)\n\t\tgoto out;\n\n\tit_prof_secs = cputime_to_secs(current->signal->it_prof_expires);\n\tif (it_prof_secs == 0 || new_rlim.rlim_cur <= it_prof_secs) {\n\t\tunsigned long rlim_cur = new_rlim.rlim_cur;\n\t\tcputime_t cputime;\n\n\t\tif (rlim_cur == 0) {\n\t\t\t/*\n\t\t\t * The caller is asking for an immediate RLIMIT_CPU\n\t\t\t * expiry.  But we use the zero value to mean \"it was\n\t\t\t * never set\".  So let's cheat and make it one second\n\t\t\t * instead\n\t\t\t */\n\t\t\trlim_cur = 1;\n\t\t}\n\t\tcputime = secs_to_cputime(rlim_cur);\n\t\tread_lock(&tasklist_lock);\n\t\tspin_lock_irq(&current->sighand->siglock);\n\t\tset_process_cpu_timer(current, CPUCLOCK_PROF, &cputime, NULL);\n\t\tspin_unlock_irq(&current->sighand->siglock);\n\t\tread_unlock(&tasklist_lock);\n\t}\nout:\n\treturn 0;\n}", "target": 1, "cwe": ["CWE-20"], "project": "linux-2.6", "commit_id": "9926e4c74300c4b31dee007298c6475d33369df0", "hash": 53303886230877642634155857946902981974, "size": 63, "message": "CPU time limit patch / setrlimit(RLIMIT_CPU, 0) cheat fix\n\nAs discovered here today, the change in Kernel 2.6.17 intended to inhibit\nusers from setting RLIMIT_CPU to 0 (as that is equivalent to unlimited) by\n\"cheating\" and setting it to 1 in such a case, does not make a difference,\nas the check is done in the wrong place (too late), and only applies to the\nprofiling code.\n\nOn all systems I checked running kernels above 2.6.17, no matter what the\nhard and soft CPU time limits were before, a user could escape them by\nissuing in the shell (sh/bash/zsh) \"ulimit -t 0\", and then the user's\nprocess was not ever killed.\n\nAttached is a trivial patch to fix that.  Simply moving the check to a\nslightly earlier location (specifically, before the line that actually\nassigns the limit - *old_rlim = new_rlim), does the trick.\n\nDo note that at least the zsh (but not ash, dash, or bash) shell has the\nproblem of \"caching\" the limits set by the ulimit command, so when running\nzsh the fix will not immediately be evident - after entering \"ulimit -t 0\",\n\"ulimit -a\" will show \"-t: cpu time (seconds) 0\", even though the actual\nlimit as returned by getrlimit(...) will be 1.  It can be verified by\nopening a subshell (which will not have the values of the parent shell in\ncache) and checking in it, or just by running a CPU intensive command like\n\"echo '65536^1048576' | bc\" and verifying that it dumps core after one\nsecond.\n\nRegardless of whether that is a misfeature in the shell, perhaps it would\nbe better to return -EINVAL from setrlimit in such a case instead of\ncheating and setting to 1, as that does not really reflect the actual state\nof the process anymore.  I do not however know what the ground for that\ndecision was in the original 2.6.17 change, and whether there would be any\n\"backward\" compatibility issues, so I preferred not to touch that right\nnow.\n\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "static int setup_rt_frame(int sig, struct k_sigaction *ka, siginfo_t *info,\n\t\t\t   sigset_t *set, struct pt_regs * regs)\n{\n\tvoid __user *restorer;\n\tstruct rt_sigframe __user *frame;\n\tint err = 0;\n\tint usig;\n\n\tframe = get_sigframe(ka, regs, sizeof(*frame));\n\n\tif (!access_ok(VERIFY_WRITE, frame, sizeof(*frame)))\n\t\tgoto give_sigsegv;\n\n\tusig = current_thread_info()->exec_domain\n\t\t&& current_thread_info()->exec_domain->signal_invmap\n\t\t&& sig < 32\n\t\t? current_thread_info()->exec_domain->signal_invmap[sig]\n\t\t: sig;\n\n\terr |= __put_user(usig, &frame->sig);\n\terr |= __put_user(&frame->info, &frame->pinfo);\n\terr |= __put_user(&frame->uc, &frame->puc);\n\terr |= copy_siginfo_to_user(&frame->info, info);\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\t/* Create the ucontext.  */\n\terr |= __put_user(0, &frame->uc.uc_flags);\n\terr |= __put_user(0, &frame->uc.uc_link);\n\terr |= __put_user(current->sas_ss_sp, &frame->uc.uc_stack.ss_sp);\n\terr |= __put_user(sas_ss_flags(regs->sp),\n\t\t\t  &frame->uc.uc_stack.ss_flags);\n\terr |= __put_user(current->sas_ss_size, &frame->uc.uc_stack.ss_size);\n\terr |= setup_sigcontext(&frame->uc.uc_mcontext, &frame->fpstate,\n\t\t\t        regs, set->sig[0]);\n\terr |= __copy_to_user(&frame->uc.uc_sigmask, set, sizeof(*set));\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\t/* Set up to return from userspace.  */\n\trestorer = VDSO32_SYMBOL(current->mm->context.vdso, rt_sigreturn);\n\tif (ka->sa.sa_flags & SA_RESTORER)\n\t\trestorer = ka->sa.sa_restorer;\n\terr |= __put_user(restorer, &frame->pretcode);\n\t \n\t/*\n\t * This is movl $,%ax ; int $0x80\n\t *\n\t * WE DO NOT USE IT ANY MORE! It's only left here for historical\n\t * reasons and because gdb uses it as a signature to notice\n\t * signal handler stack frames.\n\t */\n\terr |= __put_user(0xb8, (char __user *)(frame->retcode+0));\n\terr |= __put_user(__NR_rt_sigreturn, (int __user *)(frame->retcode+1));\n\terr |= __put_user(0x80cd, (short __user *)(frame->retcode+5));\n\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\t/* Set up registers for signal handler */\n\tregs->sp = (unsigned long) frame;\n\tregs->ip = (unsigned long) ka->sa.sa_handler;\n\tregs->ax = (unsigned long) usig;\n\tregs->dx = (unsigned long) &frame->info;\n\tregs->cx = (unsigned long) &frame->uc;\n\n\tregs->ds = __USER_DS;\n\tregs->es = __USER_DS;\n\tregs->ss = __USER_DS;\n\tregs->cs = __USER_CS;\n\n\t/*\n\t * Clear TF when entering the signal handler, but\n\t * notify any tracer that was single-stepping it.\n\t * The tracer may want to single-step inside the\n\t * handler too.\n\t */\n\tregs->flags &= ~TF_MASK;\n\tif (test_thread_flag(TIF_SINGLESTEP))\n\t\tptrace_notify(SIGTRAP);\n\n#if DEBUG_SIG\n\tprintk(\"SIG deliver (%s:%d): sp=%p pc=%p ra=%p\\n\",\n\t\tcurrent->comm, current->pid, frame, regs->ip, frame->pretcode);\n#endif\n\n\treturn 0;\n\ngive_sigsegv:\n\tforce_sigsegv(sig, current);\n\treturn -EFAULT;\n}", "target": 1, "cwe": ["CWE-399"], "project": "linux-2.6", "commit_id": "e40cd10ccff3d9fbffd57b93780bee4b7b9bff51", "hash": 25210609055917764870719712764967878905, "size": 92, "message": "x86: clear DF before calling signal handler\n\nThe Linux kernel currently does not clear the direction flag before\ncalling a signal handler, whereas the x86/x86-64 ABI requires that.\n\nLinux had this behavior/bug forever, but this becomes a real problem\nwith gcc version 4.3, which assumes that the direction flag is\ncorrectly cleared at the entry of a function.\n\nThis patches changes the setup_frame() functions to clear the\ndirection before entering the signal handler.\n\nSigned-off-by: Aurelien Jarno <aurelien@aurel32.net>\nSigned-off-by: Ingo Molnar <mingo@elte.hu>\nAcked-by: H. Peter Anvin <hpa@zytor.com>"}
{"func": "int ia32_setup_rt_frame(int sig, struct k_sigaction *ka, siginfo_t *info,\n\t\t\tcompat_sigset_t *set, struct pt_regs *regs)\n{\n\tstruct rt_sigframe __user *frame;\n\tstruct exec_domain *ed = current_thread_info()->exec_domain;\n\tvoid __user *restorer;\n\tint err = 0;\n\n\t/* __copy_to_user optimizes that into a single 8 byte store */\n\tstatic const struct {\n\t\tu8 movl;\n\t\tu32 val;\n\t\tu16 int80;\n\t\tu16 pad;\n\t\tu8  pad2;\n\t} __attribute__((packed)) code = {\n\t\t0xb8,\n\t\t__NR_ia32_rt_sigreturn,\n\t\t0x80cd,\n\t\t0,\n\t};\n\n\tframe = get_sigframe(ka, regs, sizeof(*frame));\n\n\tif (!access_ok(VERIFY_WRITE, frame, sizeof(*frame)))\n\t\tgoto give_sigsegv;\n\n\terr |= __put_user((ed && ed->signal_invmap && sig < 32\n\t\t\t   ? ed->signal_invmap[sig] : sig), &frame->sig);\n\terr |= __put_user(ptr_to_compat(&frame->info), &frame->pinfo);\n\terr |= __put_user(ptr_to_compat(&frame->uc), &frame->puc);\n\terr |= copy_siginfo_to_user32(&frame->info, info);\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\t/* Create the ucontext.  */\n\terr |= __put_user(0, &frame->uc.uc_flags);\n\terr |= __put_user(0, &frame->uc.uc_link);\n\terr |= __put_user(current->sas_ss_sp, &frame->uc.uc_stack.ss_sp);\n\terr |= __put_user(sas_ss_flags(regs->sp),\n\t\t\t  &frame->uc.uc_stack.ss_flags);\n\terr |= __put_user(current->sas_ss_size, &frame->uc.uc_stack.ss_size);\n\terr |= ia32_setup_sigcontext(&frame->uc.uc_mcontext, &frame->fpstate,\n\t\t\t\t     regs, set->sig[0]);\n\terr |= __copy_to_user(&frame->uc.uc_sigmask, set, sizeof(*set));\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\tif (ka->sa.sa_flags & SA_RESTORER)\n\t\trestorer = ka->sa.sa_restorer;\n\telse\n\t\trestorer = VDSO32_SYMBOL(current->mm->context.vdso,\n\t\t\t\t\t rt_sigreturn);\n\terr |= __put_user(ptr_to_compat(restorer), &frame->pretcode);\n\n\t/*\n\t * Not actually used anymore, but left because some gdb\n\t * versions need it.\n\t */\n\terr |= __copy_to_user(frame->retcode, &code, 8);\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\t/* Set up registers for signal handler */\n\tregs->sp = (unsigned long) frame;\n\tregs->ip = (unsigned long) ka->sa.sa_handler;\n\n\t/* Make -mregparm=3 work */\n\tregs->ax = sig;\n\tregs->dx = (unsigned long) &frame->info;\n\tregs->cx = (unsigned long) &frame->uc;\n\n\t/* Make -mregparm=3 work */\n\tregs->ax = sig;\n\tregs->dx = (unsigned long) &frame->info;\n\tregs->cx = (unsigned long) &frame->uc;\n\n\tasm volatile(\"movl %0,%%ds\" :: \"r\" (__USER32_DS));\n\tasm volatile(\"movl %0,%%es\" :: \"r\" (__USER32_DS));\n\n\tregs->cs = __USER32_CS;\n\tregs->ss = __USER32_DS;\n\n\tset_fs(USER_DS);\n\tregs->flags &= ~X86_EFLAGS_TF;\n\tif (test_thread_flag(TIF_SINGLESTEP))\n\t\tptrace_notify(SIGTRAP);\n\n#if DEBUG_SIG\n\tprintk(KERN_DEBUG \"SIG deliver (%s:%d): sp=%p pc=%lx ra=%u\\n\",\n\t       current->comm, current->pid, frame, regs->ip, frame->pretcode);\n#endif\n\n\treturn 0;\n\ngive_sigsegv:\n\tforce_sigsegv(sig, current);\n\treturn -EFAULT;\n}", "target": 1, "cwe": ["CWE-399"], "project": "linux-2.6", "commit_id": "e40cd10ccff3d9fbffd57b93780bee4b7b9bff51", "hash": 336026717347518607266497936354610258572, "size": 99, "message": "x86: clear DF before calling signal handler\n\nThe Linux kernel currently does not clear the direction flag before\ncalling a signal handler, whereas the x86/x86-64 ABI requires that.\n\nLinux had this behavior/bug forever, but this becomes a real problem\nwith gcc version 4.3, which assumes that the direction flag is\ncorrectly cleared at the entry of a function.\n\nThis patches changes the setup_frame() functions to clear the\ndirection before entering the signal handler.\n\nSigned-off-by: Aurelien Jarno <aurelien@aurel32.net>\nSigned-off-by: Ingo Molnar <mingo@elte.hu>\nAcked-by: H. Peter Anvin <hpa@zytor.com>"}
{"func": "static int setup_rt_frame(int sig, struct k_sigaction *ka, siginfo_t *info,\n\t\t\t   sigset_t *set, struct pt_regs * regs)\n{\n\tstruct rt_sigframe __user *frame;\n\tstruct _fpstate __user *fp = NULL; \n\tint err = 0;\n\tstruct task_struct *me = current;\n\n\tif (used_math()) {\n\t\tfp = get_stack(ka, regs, sizeof(struct _fpstate)); \n\t\tframe = (void __user *)round_down(\n\t\t\t(unsigned long)fp - sizeof(struct rt_sigframe), 16) - 8;\n\n\t\tif (!access_ok(VERIFY_WRITE, fp, sizeof(struct _fpstate)))\n\t\t\tgoto give_sigsegv;\n\n\t\tif (save_i387(fp) < 0) \n\t\t\terr |= -1; \n\t} else\n\t\tframe = get_stack(ka, regs, sizeof(struct rt_sigframe)) - 8;\n\n\tif (!access_ok(VERIFY_WRITE, frame, sizeof(*frame)))\n\t\tgoto give_sigsegv;\n\n\tif (ka->sa.sa_flags & SA_SIGINFO) { \n\t\terr |= copy_siginfo_to_user(&frame->info, info);\n\t\tif (err)\n\t\t\tgoto give_sigsegv;\n\t}\n\t\t\n\t/* Create the ucontext.  */\n\terr |= __put_user(0, &frame->uc.uc_flags);\n\terr |= __put_user(0, &frame->uc.uc_link);\n\terr |= __put_user(me->sas_ss_sp, &frame->uc.uc_stack.ss_sp);\n\terr |= __put_user(sas_ss_flags(regs->sp),\n\t\t\t  &frame->uc.uc_stack.ss_flags);\n\terr |= __put_user(me->sas_ss_size, &frame->uc.uc_stack.ss_size);\n\terr |= setup_sigcontext(&frame->uc.uc_mcontext, regs, set->sig[0], me);\n\terr |= __put_user(fp, &frame->uc.uc_mcontext.fpstate);\n\tif (sizeof(*set) == 16) { \n\t\t__put_user(set->sig[0], &frame->uc.uc_sigmask.sig[0]);\n\t\t__put_user(set->sig[1], &frame->uc.uc_sigmask.sig[1]); \n\t} else\n\t\terr |= __copy_to_user(&frame->uc.uc_sigmask, set, sizeof(*set));\n\n\t/* Set up to return from userspace.  If provided, use a stub\n\t   already in userspace.  */\n\t/* x86-64 should always use SA_RESTORER. */\n\tif (ka->sa.sa_flags & SA_RESTORER) {\n\t\terr |= __put_user(ka->sa.sa_restorer, &frame->pretcode);\n\t} else {\n\t\t/* could use a vstub here */\n\t\tgoto give_sigsegv; \n\t}\n\n\tif (err)\n\t\tgoto give_sigsegv;\n\n#ifdef DEBUG_SIG\n\tprintk(\"%d old ip %lx old sp %lx old ax %lx\\n\", current->pid,regs->ip,regs->sp,regs->ax);\n#endif\n\n\t/* Set up registers for signal handler */\n\tregs->di = sig;\n\t/* In case the signal handler was declared without prototypes */ \n\tregs->ax = 0;\n\n\t/* This also works for non SA_SIGINFO handlers because they expect the\n\t   next argument after the signal number on the stack. */\n\tregs->si = (unsigned long)&frame->info;\n\tregs->dx = (unsigned long)&frame->uc;\n\tregs->ip = (unsigned long) ka->sa.sa_handler;\n\n\tregs->sp = (unsigned long)frame;\n\n\t/* Set up the CS register to run signal handlers in 64-bit mode,\n\t   even if the handler happens to be interrupting 32-bit code. */\n\tregs->cs = __USER_CS;\n\n\t/* This, by contrast, has nothing to do with segment registers -\n\t   see include/asm-x86_64/uaccess.h for details. */\n\tset_fs(USER_DS);\n\n\tregs->flags &= ~X86_EFLAGS_TF;\n\tif (test_thread_flag(TIF_SINGLESTEP))\n\t\tptrace_notify(SIGTRAP);\n#ifdef DEBUG_SIG\n\tprintk(\"SIG deliver (%s:%d): sp=%p pc=%lx ra=%p\\n\",\n\t\tcurrent->comm, current->pid, frame, regs->ip, frame->pretcode);\n#endif\n\n\treturn 0;\n\ngive_sigsegv:\n\tforce_sigsegv(sig, current);\n\treturn -EFAULT;\n}", "target": 1, "cwe": ["CWE-399"], "project": "linux-2.6", "commit_id": "e40cd10ccff3d9fbffd57b93780bee4b7b9bff51", "hash": 323536889097069150889416252395929520907, "size": 97, "message": "x86: clear DF before calling signal handler\n\nThe Linux kernel currently does not clear the direction flag before\ncalling a signal handler, whereas the x86/x86-64 ABI requires that.\n\nLinux had this behavior/bug forever, but this becomes a real problem\nwith gcc version 4.3, which assumes that the direction flag is\ncorrectly cleared at the entry of a function.\n\nThis patches changes the setup_frame() functions to clear the\ndirection before entering the signal handler.\n\nSigned-off-by: Aurelien Jarno <aurelien@aurel32.net>\nSigned-off-by: Ingo Molnar <mingo@elte.hu>\nAcked-by: H. Peter Anvin <hpa@zytor.com>"}
{"func": "static int setup_frame(int sig, struct k_sigaction *ka,\n\t\t       sigset_t *set, struct pt_regs * regs)\n{\n\tvoid __user *restorer;\n\tstruct sigframe __user *frame;\n\tint err = 0;\n\tint usig;\n\n\tframe = get_sigframe(ka, regs, sizeof(*frame));\n\n\tif (!access_ok(VERIFY_WRITE, frame, sizeof(*frame)))\n\t\tgoto give_sigsegv;\n\n\tusig = current_thread_info()->exec_domain\n\t\t&& current_thread_info()->exec_domain->signal_invmap\n\t\t&& sig < 32\n\t\t? current_thread_info()->exec_domain->signal_invmap[sig]\n\t\t: sig;\n\n\terr = __put_user(usig, &frame->sig);\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\terr = setup_sigcontext(&frame->sc, &frame->fpstate, regs, set->sig[0]);\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\tif (_NSIG_WORDS > 1) {\n\t\terr = __copy_to_user(&frame->extramask, &set->sig[1],\n\t\t\t\t      sizeof(frame->extramask));\n\t\tif (err)\n\t\t\tgoto give_sigsegv;\n\t}\n\n\tif (current->binfmt->hasvdso)\n\t\trestorer = VDSO32_SYMBOL(current->mm->context.vdso, sigreturn);\n\telse\n\t\trestorer = &frame->retcode;\n\tif (ka->sa.sa_flags & SA_RESTORER)\n\t\trestorer = ka->sa.sa_restorer;\n\n\t/* Set up to return from userspace.  */\n\terr |= __put_user(restorer, &frame->pretcode);\n\t \n\t/*\n\t * This is popl %eax ; movl $,%eax ; int $0x80\n\t *\n\t * WE DO NOT USE IT ANY MORE! It's only left here for historical\n\t * reasons and because gdb uses it as a signature to notice\n\t * signal handler stack frames.\n\t */\n\terr |= __put_user(0xb858, (short __user *)(frame->retcode+0));\n\terr |= __put_user(__NR_sigreturn, (int __user *)(frame->retcode+2));\n\terr |= __put_user(0x80cd, (short __user *)(frame->retcode+6));\n\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\t/* Set up registers for signal handler */\n\tregs->sp = (unsigned long) frame;\n\tregs->ip = (unsigned long) ka->sa.sa_handler;\n\tregs->ax = (unsigned long) sig;\n\tregs->dx = (unsigned long) 0;\n\tregs->cx = (unsigned long) 0;\n\n\tregs->ds = __USER_DS;\n\tregs->es = __USER_DS;\n\tregs->ss = __USER_DS;\n\tregs->cs = __USER_CS;\n\n\t/*\n\t * Clear TF when entering the signal handler, but\n\t * notify any tracer that was single-stepping it.\n\t * The tracer may want to single-step inside the\n\t * handler too.\n\t */\n\tregs->flags &= ~TF_MASK;\n\tif (test_thread_flag(TIF_SINGLESTEP))\n\t\tptrace_notify(SIGTRAP);\n\n#if DEBUG_SIG\n\tprintk(\"SIG deliver (%s:%d): sp=%p pc=%p ra=%p\\n\",\n\t\tcurrent->comm, current->pid, frame, regs->ip, frame->pretcode);\n#endif\n\n\treturn 0;\n\ngive_sigsegv:\n\tforce_sigsegv(sig, current);\n\treturn -EFAULT;\n}", "target": 1, "cwe": ["CWE-399"], "project": "linux-2.6", "commit_id": "e40cd10ccff3d9fbffd57b93780bee4b7b9bff51", "hash": 240195482991768344151461321121195113778, "size": 91, "message": "x86: clear DF before calling signal handler\n\nThe Linux kernel currently does not clear the direction flag before\ncalling a signal handler, whereas the x86/x86-64 ABI requires that.\n\nLinux had this behavior/bug forever, but this becomes a real problem\nwith gcc version 4.3, which assumes that the direction flag is\ncorrectly cleared at the entry of a function.\n\nThis patches changes the setup_frame() functions to clear the\ndirection before entering the signal handler.\n\nSigned-off-by: Aurelien Jarno <aurelien@aurel32.net>\nSigned-off-by: Ingo Molnar <mingo@elte.hu>\nAcked-by: H. Peter Anvin <hpa@zytor.com>"}
{"func": "int ia32_setup_frame(int sig, struct k_sigaction *ka,\n\t\t     compat_sigset_t *set, struct pt_regs *regs)\n{\n\tstruct sigframe __user *frame;\n\tvoid __user *restorer;\n\tint err = 0;\n\n\t/* copy_to_user optimizes that into a single 8 byte store */\n\tstatic const struct {\n\t\tu16 poplmovl;\n\t\tu32 val;\n\t\tu16 int80;\n\t\tu16 pad;\n\t} __attribute__((packed)) code = {\n\t\t0xb858,\t\t /* popl %eax ; movl $...,%eax */\n\t\t__NR_ia32_sigreturn,\n\t\t0x80cd,\t\t/* int $0x80 */\n\t\t0,\n\t};\n\n\tframe = get_sigframe(ka, regs, sizeof(*frame));\n\n\tif (!access_ok(VERIFY_WRITE, frame, sizeof(*frame)))\n\t\tgoto give_sigsegv;\n\n\terr |= __put_user(sig, &frame->sig);\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\terr |= ia32_setup_sigcontext(&frame->sc, &frame->fpstate, regs,\n\t\t\t\t\tset->sig[0]);\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\tif (_COMPAT_NSIG_WORDS > 1) {\n\t\terr |= __copy_to_user(frame->extramask, &set->sig[1],\n\t\t\t\t      sizeof(frame->extramask));\n\t\tif (err)\n\t\t\tgoto give_sigsegv;\n\t}\n\n\tif (ka->sa.sa_flags & SA_RESTORER) {\n\t\trestorer = ka->sa.sa_restorer;\n\t} else {\n\t\t/* Return stub is in 32bit vsyscall page */\n\t\tif (current->binfmt->hasvdso)\n\t\t\trestorer = VDSO32_SYMBOL(current->mm->context.vdso,\n\t\t\t\t\t\t sigreturn);\n\t\telse\n\t\t\trestorer = &frame->retcode;\n\t}\n\terr |= __put_user(ptr_to_compat(restorer), &frame->pretcode);\n\n\t/*\n\t * These are actually not used anymore, but left because some\n\t * gdb versions depend on them as a marker.\n\t */\n\terr |= __copy_to_user(frame->retcode, &code, 8);\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\t/* Set up registers for signal handler */\n\tregs->sp = (unsigned long) frame;\n\tregs->ip = (unsigned long) ka->sa.sa_handler;\n\n\t/* Make -mregparm=3 work */\n\tregs->ax = sig;\n\tregs->dx = 0;\n\tregs->cx = 0;\n\n\tasm volatile(\"movl %0,%%ds\" :: \"r\" (__USER32_DS));\n\tasm volatile(\"movl %0,%%es\" :: \"r\" (__USER32_DS));\n\n\tregs->cs = __USER32_CS;\n\tregs->ss = __USER32_DS;\n\n\tset_fs(USER_DS);\n\tregs->flags &= ~X86_EFLAGS_TF;\n\tif (test_thread_flag(TIF_SINGLESTEP))\n\t\tptrace_notify(SIGTRAP);\n\n#if DEBUG_SIG\n\tprintk(KERN_DEBUG \"SIG deliver (%s:%d): sp=%p pc=%lx ra=%u\\n\",\n\t       current->comm, current->pid, frame, regs->ip, frame->pretcode);\n#endif\n\n\treturn 0;\n\ngive_sigsegv:\n\tforce_sigsegv(sig, current);\n\treturn -EFAULT;\n}", "target": 1, "cwe": ["CWE-399"], "project": "linux-2.6", "commit_id": "e40cd10ccff3d9fbffd57b93780bee4b7b9bff51", "hash": 242893451020799354943598531577743834358, "size": 92, "message": "x86: clear DF before calling signal handler\n\nThe Linux kernel currently does not clear the direction flag before\ncalling a signal handler, whereas the x86/x86-64 ABI requires that.\n\nLinux had this behavior/bug forever, but this becomes a real problem\nwith gcc version 4.3, which assumes that the direction flag is\ncorrectly cleared at the entry of a function.\n\nThis patches changes the setup_frame() functions to clear the\ndirection before entering the signal handler.\n\nSigned-off-by: Aurelien Jarno <aurelien@aurel32.net>\nSigned-off-by: Ingo Molnar <mingo@elte.hu>\nAcked-by: H. Peter Anvin <hpa@zytor.com>"}
{"func": "static unsigned long __peek_user(struct task_struct *child, addr_t addr)\n{\n\tstruct user *dummy = NULL;\n\taddr_t offset, tmp;\n\n\tif (addr < (addr_t) &dummy->regs.acrs) {\n\t\t/*\n\t\t * psw and gprs are stored on the stack\n\t\t */\n\t\ttmp = *(addr_t *)((addr_t) &task_pt_regs(child)->psw + addr);\n\t\tif (addr == (addr_t) &dummy->regs.psw.mask)\n\t\t\t/* Remove per bit from user psw. */\n\t\t\ttmp &= ~PSW_MASK_PER;\n\n\t} else if (addr < (addr_t) &dummy->regs.orig_gpr2) {\n\t\t/*\n\t\t * access registers are stored in the thread structure\n\t\t */\n\t\toffset = addr - (addr_t) &dummy->regs.acrs;\n#ifdef CONFIG_64BIT\n\t\t/*\n\t\t * Very special case: old & broken 64 bit gdb reading\n\t\t * from acrs[15]. Result is a 64 bit value. Read the\n\t\t * 32 bit acrs[15] value and shift it by 32. Sick...\n\t\t */\n\t\tif (addr == (addr_t) &dummy->regs.acrs[15])\n\t\t\ttmp = ((unsigned long) child->thread.acrs[15]) << 32;\n\t\telse\n#endif\n\t\ttmp = *(addr_t *)((addr_t) &child->thread.acrs + offset);\n\n\t} else if (addr == (addr_t) &dummy->regs.orig_gpr2) {\n\t\t/*\n\t\t * orig_gpr2 is stored on the kernel stack\n\t\t */\n\t\ttmp = (addr_t) task_pt_regs(child)->orig_gpr2;\n\n\t} else if (addr < (addr_t) (&dummy->regs.fp_regs + 1)) {\n\t\t/* \n\t\t * floating point regs. are stored in the thread structure\n\t\t */\n\t\toffset = addr - (addr_t) &dummy->regs.fp_regs;\n\t\ttmp = *(addr_t *)((addr_t) &child->thread.fp_regs + offset);\n\t\tif (addr == (addr_t) &dummy->regs.fp_regs.fpc)\n\t\t\ttmp &= (unsigned long) FPC_VALID_MASK\n\t\t\t\t<< (BITS_PER_LONG - 32);\n\n\t} else if (addr < (addr_t) (&dummy->regs.per_info + 1)) {\n\t\t/*\n\t\t * per_info is found in the thread structure\n\t\t */\n\t\toffset = addr - (addr_t) &dummy->regs.per_info;\n\t\ttmp = *(addr_t *)((addr_t) &child->thread.per_info + offset);\n\n\t} else\n\t\ttmp = 0;\n\n\treturn tmp;\n}", "target": 1, "cwe": ["CWE-399"], "project": "linux-2.6", "commit_id": "3d6e48f43340343d97839eadb1ab7b6a3ea98797", "hash": 228545314486915469738309849042034394364, "size": 59, "message": "[S390] CVE-2008-1514: prevent ptrace padding area read/write in 31-bit mode\n\nWhen running a 31-bit ptrace, on either an s390 or s390x kernel,\nreads and writes into a padding area in struct user_regs_struct32\nwill result in a kernel panic.\n\nThis is also known as CVE-2008-1514.\n\nTest case available here:\nhttp://sources.redhat.com/cgi-bin/cvsweb.cgi/~checkout~/tests/ptrace-tests/tests/user-area-padding.c?cvsroot=systemtap\n\nSteps to reproduce:\n1) wget the above\n2) gcc -o user-area-padding-31bit user-area-padding.c -Wall -ggdb2 -D_GNU_SOURCE -m31\n3) ./user-area-padding-31bit\n<panic>\n\nTest status\n-----------\nWithout patch, both s390 and s390x kernels panic. With patch, the test case,\nas well as the gdb testsuite, pass without incident, padding area reads\nreturning zero, writes ignored.\n\nNb: original version returned -EINVAL on write attempts, which broke the\ngdb test and made the test case slightly unhappy, Jan Kratochvil suggested\nthe change to return 0 on write attempts.\n\nSigned-off-by: Jarod Wilson <jarod@redhat.com>\nTested-by: Jan Kratochvil <jan.kratochvil@redhat.com>\nSigned-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>"}
{"func": "static int __poke_user_compat(struct task_struct *child,\n\t\t\t      addr_t addr, addr_t data)\n{\n\tstruct user32 *dummy32 = NULL;\n\tper_struct32 *dummy_per32 = NULL;\n\t__u32 tmp = (__u32) data;\n\taddr_t offset;\n\n\tif (addr < (addr_t) &dummy32->regs.acrs) {\n\t\t/*\n\t\t * psw, gprs, acrs and orig_gpr2 are stored on the stack\n\t\t */\n\t\tif (addr == (addr_t) &dummy32->regs.psw.mask) {\n\t\t\t/* Build a 64 bit psw mask from 31 bit mask. */\n\t\t\tif (tmp != PSW32_MASK_MERGE(psw32_user_bits, tmp))\n\t\t\t\t/* Invalid psw mask. */\n\t\t\t\treturn -EINVAL;\n\t\t\ttask_pt_regs(child)->psw.mask =\n\t\t\t\tPSW_MASK_MERGE(psw_user32_bits, (__u64) tmp << 32);\n\t\t} else if (addr == (addr_t) &dummy32->regs.psw.addr) {\n\t\t\t/* Build a 64 bit psw address from 31 bit address. */\n\t\t\ttask_pt_regs(child)->psw.addr =\n\t\t\t\t(__u64) tmp & PSW32_ADDR_INSN;\n\t\t} else {\n\t\t\t/* gpr 0-15 */\n\t\t\t*(__u32*)((addr_t) &task_pt_regs(child)->psw\n\t\t\t\t  + addr*2 + 4) = tmp;\n\t\t}\n\t} else if (addr < (addr_t) (&dummy32->regs.orig_gpr2)) {\n\t\t/*\n\t\t * access registers are stored in the thread structure\n\t\t */\n\t\toffset = addr - (addr_t) &dummy32->regs.acrs;\n\t\t*(__u32*)((addr_t) &child->thread.acrs + offset) = tmp;\n\n\t} else if (addr == (addr_t) (&dummy32->regs.orig_gpr2)) {\n\t\t/*\n\t\t * orig_gpr2 is stored on the kernel stack\n\t\t */\n\t\t*(__u32*)((addr_t) &task_pt_regs(child)->orig_gpr2 + 4) = tmp;\n\n\t} else if (addr < (addr_t) (&dummy32->regs.fp_regs + 1)) {\n\t\t/*\n\t\t * floating point regs. are stored in the thread structure \n\t\t */\n\t\tif (addr == (addr_t) &dummy32->regs.fp_regs.fpc &&\n\t\t    (tmp & ~FPC_VALID_MASK) != 0)\n\t\t\t/* Invalid floating point control. */\n\t\t\treturn -EINVAL;\n\t        offset = addr - (addr_t) &dummy32->regs.fp_regs;\n\t\t*(__u32 *)((addr_t) &child->thread.fp_regs + offset) = tmp;\n\n\t} else if (addr < (addr_t) (&dummy32->regs.per_info + 1)) {\n\t\t/*\n\t\t * per_info is found in the thread structure.\n\t\t */\n\t\toffset = addr - (addr_t) &dummy32->regs.per_info;\n\t\t/*\n\t\t * This is magic. See per_struct and per_struct32.\n\t\t * By incident the offsets in per_struct are exactly\n\t\t * twice the offsets in per_struct32 for all fields.\n\t\t * The 8 byte fields need special handling though,\n\t\t * because the second half (bytes 4-7) is needed and\n\t\t * not the first half.\n\t\t */\n\t\tif ((offset >= (addr_t) &dummy_per32->control_regs &&\n\t\t     offset < (addr_t) (&dummy_per32->control_regs + 1)) ||\n\t\t    (offset >= (addr_t) &dummy_per32->starting_addr &&\n\t\t     offset <= (addr_t) &dummy_per32->ending_addr) ||\n\t\t    offset == (addr_t) &dummy_per32->lowcore.words.address)\n\t\t\toffset = offset*2 + 4;\n\t\telse\n\t\t\toffset = offset*2;\n\t\t*(__u32 *)((addr_t) &child->thread.per_info + offset) = tmp;\n\n\t}\n\n\tFixPerRegisters(child);\n\treturn 0;\n}", "target": 1, "cwe": ["CWE-399"], "project": "linux-2.6", "commit_id": "3d6e48f43340343d97839eadb1ab7b6a3ea98797", "hash": 336645180341076785138852510297161990377, "size": 80, "message": "[S390] CVE-2008-1514: prevent ptrace padding area read/write in 31-bit mode\n\nWhen running a 31-bit ptrace, on either an s390 or s390x kernel,\nreads and writes into a padding area in struct user_regs_struct32\nwill result in a kernel panic.\n\nThis is also known as CVE-2008-1514.\n\nTest case available here:\nhttp://sources.redhat.com/cgi-bin/cvsweb.cgi/~checkout~/tests/ptrace-tests/tests/user-area-padding.c?cvsroot=systemtap\n\nSteps to reproduce:\n1) wget the above\n2) gcc -o user-area-padding-31bit user-area-padding.c -Wall -ggdb2 -D_GNU_SOURCE -m31\n3) ./user-area-padding-31bit\n<panic>\n\nTest status\n-----------\nWithout patch, both s390 and s390x kernels panic. With patch, the test case,\nas well as the gdb testsuite, pass without incident, padding area reads\nreturning zero, writes ignored.\n\nNb: original version returned -EINVAL on write attempts, which broke the\ngdb test and made the test case slightly unhappy, Jan Kratochvil suggested\nthe change to return 0 on write attempts.\n\nSigned-off-by: Jarod Wilson <jarod@redhat.com>\nTested-by: Jan Kratochvil <jan.kratochvil@redhat.com>\nSigned-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>"}
{"func": "static int __poke_user(struct task_struct *child, addr_t addr, addr_t data)\n{\n\tstruct user *dummy = NULL;\n\taddr_t offset;\n\n\tif (addr < (addr_t) &dummy->regs.acrs) {\n\t\t/*\n\t\t * psw and gprs are stored on the stack\n\t\t */\n\t\tif (addr == (addr_t) &dummy->regs.psw.mask &&\n#ifdef CONFIG_COMPAT\n\t\t    data != PSW_MASK_MERGE(psw_user32_bits, data) &&\n#endif\n\t\t    data != PSW_MASK_MERGE(psw_user_bits, data))\n\t\t\t/* Invalid psw mask. */\n\t\t\treturn -EINVAL;\n#ifndef CONFIG_64BIT\n\t\tif (addr == (addr_t) &dummy->regs.psw.addr)\n\t\t\t/* I'd like to reject addresses without the\n\t\t\t   high order bit but older gdb's rely on it */\n\t\t\tdata |= PSW_ADDR_AMODE;\n#endif\n\t\t*(addr_t *)((addr_t) &task_pt_regs(child)->psw + addr) = data;\n\n\t} else if (addr < (addr_t) (&dummy->regs.orig_gpr2)) {\n\t\t/*\n\t\t * access registers are stored in the thread structure\n\t\t */\n\t\toffset = addr - (addr_t) &dummy->regs.acrs;\n#ifdef CONFIG_64BIT\n\t\t/*\n\t\t * Very special case: old & broken 64 bit gdb writing\n\t\t * to acrs[15] with a 64 bit value. Ignore the lower\n\t\t * half of the value and write the upper 32 bit to\n\t\t * acrs[15]. Sick...\n\t\t */\n\t\tif (addr == (addr_t) &dummy->regs.acrs[15])\n\t\t\tchild->thread.acrs[15] = (unsigned int) (data >> 32);\n\t\telse\n#endif\n\t\t*(addr_t *)((addr_t) &child->thread.acrs + offset) = data;\n\n\t} else if (addr == (addr_t) &dummy->regs.orig_gpr2) {\n\t\t/*\n\t\t * orig_gpr2 is stored on the kernel stack\n\t\t */\n\t\ttask_pt_regs(child)->orig_gpr2 = data;\n\n\t} else if (addr < (addr_t) (&dummy->regs.fp_regs + 1)) {\n\t\t/*\n\t\t * floating point regs. are stored in the thread structure\n\t\t */\n\t\tif (addr == (addr_t) &dummy->regs.fp_regs.fpc &&\n\t\t    (data & ~((unsigned long) FPC_VALID_MASK\n\t\t\t      << (BITS_PER_LONG - 32))) != 0)\n\t\t\treturn -EINVAL;\n\t\toffset = addr - (addr_t) &dummy->regs.fp_regs;\n\t\t*(addr_t *)((addr_t) &child->thread.fp_regs + offset) = data;\n\n\t} else if (addr < (addr_t) (&dummy->regs.per_info + 1)) {\n\t\t/*\n\t\t * per_info is found in the thread structure \n\t\t */\n\t\toffset = addr - (addr_t) &dummy->regs.per_info;\n\t\t*(addr_t *)((addr_t) &child->thread.per_info + offset) = data;\n\n\t}\n\n\tFixPerRegisters(child);\n\treturn 0;\n}", "target": 1, "cwe": ["CWE-399"], "project": "linux-2.6", "commit_id": "3d6e48f43340343d97839eadb1ab7b6a3ea98797", "hash": 315587780023225026373961097981804672550, "size": 71, "message": "[S390] CVE-2008-1514: prevent ptrace padding area read/write in 31-bit mode\n\nWhen running a 31-bit ptrace, on either an s390 or s390x kernel,\nreads and writes into a padding area in struct user_regs_struct32\nwill result in a kernel panic.\n\nThis is also known as CVE-2008-1514.\n\nTest case available here:\nhttp://sources.redhat.com/cgi-bin/cvsweb.cgi/~checkout~/tests/ptrace-tests/tests/user-area-padding.c?cvsroot=systemtap\n\nSteps to reproduce:\n1) wget the above\n2) gcc -o user-area-padding-31bit user-area-padding.c -Wall -ggdb2 -D_GNU_SOURCE -m31\n3) ./user-area-padding-31bit\n<panic>\n\nTest status\n-----------\nWithout patch, both s390 and s390x kernels panic. With patch, the test case,\nas well as the gdb testsuite, pass without incident, padding area reads\nreturning zero, writes ignored.\n\nNb: original version returned -EINVAL on write attempts, which broke the\ngdb test and made the test case slightly unhappy, Jan Kratochvil suggested\nthe change to return 0 on write attempts.\n\nSigned-off-by: Jarod Wilson <jarod@redhat.com>\nTested-by: Jan Kratochvil <jan.kratochvil@redhat.com>\nSigned-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>"}
{"func": "static u32 __peek_user_compat(struct task_struct *child, addr_t addr)\n{\n\tstruct user32 *dummy32 = NULL;\n\tper_struct32 *dummy_per32 = NULL;\n\taddr_t offset;\n\t__u32 tmp;\n\n\tif (addr < (addr_t) &dummy32->regs.acrs) {\n\t\t/*\n\t\t * psw and gprs are stored on the stack\n\t\t */\n\t\tif (addr == (addr_t) &dummy32->regs.psw.mask) {\n\t\t\t/* Fake a 31 bit psw mask. */\n\t\t\ttmp = (__u32)(task_pt_regs(child)->psw.mask >> 32);\n\t\t\ttmp = PSW32_MASK_MERGE(psw32_user_bits, tmp);\n\t\t} else if (addr == (addr_t) &dummy32->regs.psw.addr) {\n\t\t\t/* Fake a 31 bit psw address. */\n\t\t\ttmp = (__u32) task_pt_regs(child)->psw.addr |\n\t\t\t\tPSW32_ADDR_AMODE31;\n\t\t} else {\n\t\t\t/* gpr 0-15 */\n\t\t\ttmp = *(__u32 *)((addr_t) &task_pt_regs(child)->psw +\n\t\t\t\t\t addr*2 + 4);\n\t\t}\n\t} else if (addr < (addr_t) (&dummy32->regs.orig_gpr2)) {\n\t\t/*\n\t\t * access registers are stored in the thread structure\n\t\t */\n\t\toffset = addr - (addr_t) &dummy32->regs.acrs;\n\t\ttmp = *(__u32*)((addr_t) &child->thread.acrs + offset);\n\n\t} else if (addr == (addr_t) (&dummy32->regs.orig_gpr2)) {\n\t\t/*\n\t\t * orig_gpr2 is stored on the kernel stack\n\t\t */\n\t\ttmp = *(__u32*)((addr_t) &task_pt_regs(child)->orig_gpr2 + 4);\n\n\t} else if (addr < (addr_t) (&dummy32->regs.fp_regs + 1)) {\n\t\t/*\n\t\t * floating point regs. are stored in the thread structure \n\t\t */\n\t        offset = addr - (addr_t) &dummy32->regs.fp_regs;\n\t\ttmp = *(__u32 *)((addr_t) &child->thread.fp_regs + offset);\n\n\t} else if (addr < (addr_t) (&dummy32->regs.per_info + 1)) {\n\t\t/*\n\t\t * per_info is found in the thread structure\n\t\t */\n\t\toffset = addr - (addr_t) &dummy32->regs.per_info;\n\t\t/* This is magic. See per_struct and per_struct32. */\n\t\tif ((offset >= (addr_t) &dummy_per32->control_regs &&\n\t\t     offset < (addr_t) (&dummy_per32->control_regs + 1)) ||\n\t\t    (offset >= (addr_t) &dummy_per32->starting_addr &&\n\t\t     offset <= (addr_t) &dummy_per32->ending_addr) ||\n\t\t    offset == (addr_t) &dummy_per32->lowcore.words.address)\n\t\t\toffset = offset*2 + 4;\n\t\telse\n\t\t\toffset = offset*2;\n\t\ttmp = *(__u32 *)((addr_t) &child->thread.per_info + offset);\n\n\t} else\n\t\ttmp = 0;\n\n\treturn tmp;\n}", "target": 1, "cwe": ["CWE-399"], "project": "linux-2.6", "commit_id": "3d6e48f43340343d97839eadb1ab7b6a3ea98797", "hash": 35699932838905238073673094450593528770, "size": 65, "message": "[S390] CVE-2008-1514: prevent ptrace padding area read/write in 31-bit mode\n\nWhen running a 31-bit ptrace, on either an s390 or s390x kernel,\nreads and writes into a padding area in struct user_regs_struct32\nwill result in a kernel panic.\n\nThis is also known as CVE-2008-1514.\n\nTest case available here:\nhttp://sources.redhat.com/cgi-bin/cvsweb.cgi/~checkout~/tests/ptrace-tests/tests/user-area-padding.c?cvsroot=systemtap\n\nSteps to reproduce:\n1) wget the above\n2) gcc -o user-area-padding-31bit user-area-padding.c -Wall -ggdb2 -D_GNU_SOURCE -m31\n3) ./user-area-padding-31bit\n<panic>\n\nTest status\n-----------\nWithout patch, both s390 and s390x kernels panic. With patch, the test case,\nas well as the gdb testsuite, pass without incident, padding area reads\nreturning zero, writes ignored.\n\nNb: original version returned -EINVAL on write attempts, which broke the\ngdb test and made the test case slightly unhappy, Jan Kratochvil suggested\nthe change to return 0 on write attempts.\n\nSigned-off-by: Jarod Wilson <jarod@redhat.com>\nTested-by: Jan Kratochvil <jan.kratochvil@redhat.com>\nSigned-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>"}
{"func": "int fcntl_dirnotify(int fd, struct file *filp, unsigned long arg)\n{\n\tstruct dnotify_struct *dn;\n\tstruct dnotify_struct *odn;\n\tstruct dnotify_struct **prev;\n\tstruct inode *inode;\n\tfl_owner_t id = current->files;\n\tint error = 0;\n\n\tif ((arg & ~DN_MULTISHOT) == 0) {\n\t\tdnotify_flush(filp, id);\n\t\treturn 0;\n\t}\n\tif (!dir_notify_enable)\n\t\treturn -EINVAL;\n\tinode = filp->f_path.dentry->d_inode;\n\tif (!S_ISDIR(inode->i_mode))\n\t\treturn -ENOTDIR;\n\tdn = kmem_cache_alloc(dn_cache, GFP_KERNEL);\n\tif (dn == NULL)\n\t\treturn -ENOMEM;\n\tspin_lock(&inode->i_lock);\n\tprev = &inode->i_dnotify;\n\twhile ((odn = *prev) != NULL) {\n\t\tif ((odn->dn_owner == id) && (odn->dn_filp == filp)) {\n\t\t\todn->dn_fd = fd;\n\t\t\todn->dn_mask |= arg;\n\t\t\tinode->i_dnotify_mask |= arg & ~DN_MULTISHOT;\n\t\t\tgoto out_free;\n\t\t}\n\t\tprev = &odn->dn_next;\n\t}\n\n\terror = __f_setown(filp, task_pid(current), PIDTYPE_PID, 0);\n\tif (error)\n\t\tgoto out_free;\n\n\tdn->dn_mask = arg;\n\tdn->dn_fd = fd;\n\tdn->dn_filp = filp;\n\tdn->dn_owner = id;\n\tinode->i_dnotify_mask |= arg & ~DN_MULTISHOT;\n\tdn->dn_next = inode->i_dnotify;\n\tinode->i_dnotify = dn;\n\tspin_unlock(&inode->i_lock);\n\n\tif (filp->f_op && filp->f_op->dir_notify)\n\t\treturn filp->f_op->dir_notify(filp, arg);\n\treturn 0;\n\nout_free:\n\tspin_unlock(&inode->i_lock);\n\tkmem_cache_free(dn_cache, dn);\n\treturn error;\n}", "target": 1, "cwe": ["CWE-362"], "project": "linux-2.6", "commit_id": "214b7049a7929f03bbd2786aaef04b8b79db34e2", "hash": 125123024928884710682759016236200663547, "size": 55, "message": "Fix dnotify/close race\n\nWe have a race between fcntl() and close() that can lead to\ndnotify_struct inserted into inode's list *after* the last descriptor\nhad been gone from current->files.\n\nSince that's the only point where dnotify_struct gets evicted, we are\nscrewed - it will stick around indefinitely.  Even after struct file in\nquestion is gone and freed.  Worse, we can trigger send_sigio() on it at\nany later point, which allows to send an arbitrary signal to arbitrary\nprocess if we manage to apply enough memory pressure to get the page\nthat used to host that struct file and fill it with the right pattern...\n\nSigned-off-by: Al Viro <viro@zeniv.linux.org.uk>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "hrtimer_forward(struct hrtimer *timer, ktime_t now, ktime_t interval)\n{\n\tunsigned long orun = 1;\n\tktime_t delta;\n\n\tdelta = ktime_sub(now, timer->expires);\n\n\tif (delta.tv64 < 0)\n\t\treturn 0;\n\n\tif (interval.tv64 < timer->base->resolution.tv64)\n\t\tinterval.tv64 = timer->base->resolution.tv64;\n\n\tif (unlikely(delta.tv64 >= interval.tv64)) {\n\t\ts64 incr = ktime_to_ns(interval);\n\n\t\torun = ktime_divns(delta, incr);\n\t\ttimer->expires = ktime_add_ns(timer->expires, incr * orun);\n\t\tif (timer->expires.tv64 > now.tv64)\n\t\t\treturn orun;\n\t\t/*\n\t\t * This (and the ktime_add() below) is the\n\t\t * correction for exact:\n\t\t */\n\t\torun++;\n\t}\n\ttimer->expires = ktime_add(timer->expires, interval);\n\n\treturn orun;\n}", "target": 1, "cwe": ["CWE-189"], "project": "linux-2.6", "commit_id": "13788ccc41ceea5893f9c747c59bc0b28f2416c2", "hash": 179936784627311584747550933643377545966, "size": 30, "message": "[PATCH] hrtimer: prevent overrun DoS in hrtimer_forward()\n\nhrtimer_forward() does not check for the possible overflow of\ntimer->expires.  This can happen on 64 bit machines with large interval\nvalues and results currently in an endless loop in the softirq because the\nexpiry value becomes negative and therefor the timer is expired all the\ntime.\n\nCheck for this condition and set the expiry value to the max.  expiry time\nin the future.  The fix should be applied to stable kernel series as well.\n\nSigned-off-by: Thomas Gleixner <tglx@linutronix.de>\nAcked-by: Ingo Molnar <mingo@elte.hu>\nCc: <stable@kernel.org>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "CairoFont *CairoFont::create(GfxFont *gfxFont, XRef *xref, FT_Library lib, GBool useCIDs) {\n  Ref embRef;\n  Object refObj, strObj;\n  GooString *tmpFileName, *fileName,*tmpFileName2;\n  DisplayFontParam *dfp;\n  FILE *tmpFile;\n  int c, i, n;\n  GfxFontType fontType;\n  char **enc;\n  char *name;\n  FoFiTrueType *ff;\n  FoFiType1C *ff1c;\n  Ref ref;\n  static cairo_user_data_key_t cairo_font_face_key;\n  cairo_font_face_t *cairo_font_face;\n  FT_Face face;\n\n  Gushort *codeToGID;\n  int codeToGIDLen;\n  \n  dfp = NULL;\n  codeToGID = NULL;\n  codeToGIDLen = 0;\n  cairo_font_face = NULL;\n  \n  ref = *gfxFont->getID();\n  fontType = gfxFont->getType();\n\n  tmpFileName = NULL;\n\n  if (gfxFont->getEmbeddedFontID(&embRef)) {\n    if (!openTempFile(&tmpFileName, &tmpFile, \"wb\", NULL)) {\n      error(-1, \"Couldn't create temporary font file\");\n      goto err2;\n    }\n    \n    refObj.initRef(embRef.num, embRef.gen);\n    refObj.fetch(xref, &strObj);\n    refObj.free();\n    strObj.streamReset();\n    while ((c = strObj.streamGetChar()) != EOF) {\n      fputc(c, tmpFile);\n    }\n    strObj.streamClose();\n    strObj.free();\n    fclose(tmpFile);\n    fileName = tmpFileName;\n    \n  } else if (!(fileName = gfxFont->getExtFontFile())) {\n    // look for a display font mapping or a substitute font\n    dfp = NULL;\n    if (gfxFont->getName()) {\n      dfp = globalParams->getDisplayFont(gfxFont);\n    }\n    if (!dfp) {\n      error(-1, \"Couldn't find a font for '%s'\",\n\t    gfxFont->getName() ? gfxFont->getName()->getCString()\n\t    : \"(unnamed)\");\n      goto err2;\n    }\n    switch (dfp->kind) {\n    case displayFontT1:\n      fileName = dfp->t1.fileName;\n      fontType = gfxFont->isCIDFont() ? fontCIDType0 : fontType1;\n      break;\n    case displayFontTT:\n      fileName = dfp->tt.fileName;\n      fontType = gfxFont->isCIDFont() ? fontCIDType2 : fontTrueType;\n      break;\n    }\n  }\n\n  switch (fontType) {\n  case fontType1:\n  case fontType1C:\n    if (FT_New_Face(lib, fileName->getCString(), 0, &face)) {\n      error(-1, \"could not create type1 face\");\n      goto err2;\n    }\n    \n    enc = ((Gfx8BitFont *)gfxFont)->getEncoding();\n    \n    codeToGID = (Gushort *)gmallocn(256, sizeof(int));\n    codeToGIDLen = 256;\n    for (i = 0; i < 256; ++i) {\n      codeToGID[i] = 0;\n      if ((name = enc[i])) {\n\tcodeToGID[i] = (Gushort)FT_Get_Name_Index(face, name);\n      }\n    }\n    break;\n    \n  case fontCIDType2:\n    codeToGID = NULL;\n    n = 0;\n    if (((GfxCIDFont *)gfxFont)->getCIDToGID()) {\n      n = ((GfxCIDFont *)gfxFont)->getCIDToGIDLen();\n      if (n) {\n\tcodeToGID = (Gushort *)gmallocn(n, sizeof(Gushort));\n\tmemcpy(codeToGID, ((GfxCIDFont *)gfxFont)->getCIDToGID(),\n\t\tn * sizeof(Gushort));\n      }\n    } else {\n      ff = FoFiTrueType::load(fileName->getCString());\n      if (! ff)\n\tgoto err2;\n      codeToGID = ((GfxCIDFont *)gfxFont)->getCodeToGIDMap(ff, &n);\n      delete ff;\n    }\n    codeToGIDLen = n;\n    /* Fall through */\n  case fontTrueType:\n    if (!(ff = FoFiTrueType::load(fileName->getCString()))) {\n      error(-1, \"failed to load truetype font\\n\");\n      goto err2;\n    }\n    /* This might be set already for the CIDType2 case */\n    if (fontType == fontTrueType) {\n      codeToGID = ((Gfx8BitFont *)gfxFont)->getCodeToGIDMap(ff);\n      codeToGIDLen = 256;\n    }\n    if (!openTempFile(&tmpFileName2, &tmpFile, \"wb\", NULL)) {\n      delete ff;\n      error(-1, \"failed to open truetype tempfile\\n\");\n      goto err2;\n    }\n    ff->writeTTF(&fileWrite, tmpFile);\n    fclose(tmpFile);\n    delete ff;\n\n    if (FT_New_Face(lib, tmpFileName2->getCString(), 0, &face)) {\n      error(-1, \"could not create truetype face\\n\");\n      goto err2;\n    }\n    unlink (tmpFileName2->getCString());\n    delete tmpFileName2;\n    break;\n    \n  case fontCIDType0:\n  case fontCIDType0C:\n\n    codeToGID = NULL;\n    codeToGIDLen = 0;\n\n    if (!useCIDs)\n    {\n      if ((ff1c = FoFiType1C::load(fileName->getCString()))) {\n        codeToGID = ff1c->getCIDToGIDMap(&codeToGIDLen);\n        delete ff1c;\n      }\n    }\n\n    if (FT_New_Face(lib, fileName->getCString(), 0, &face)) {\n      gfree(codeToGID);\n      codeToGID = NULL;\n      error(-1, \"could not create cid face\\n\");\n      goto err2;\n    }\n    break;\n    \n  default:\n    printf (\"font type not handled\\n\");\n    goto err2;\n    break;\n  }\n\n  // delete the (temporary) font file -- with Unix hard link\n  // semantics, this will remove the last link; otherwise it will\n  // return an error, leaving the file to be deleted later\n  if (fileName == tmpFileName) {\n    unlink (fileName->getCString());\n    delete tmpFileName;\n  }\n\n  cairo_font_face = cairo_ft_font_face_create_for_ft_face (face,\n\t\t\t\t\t\t\t   FT_LOAD_NO_HINTING |\n\t\t\t\t\t\t\t   FT_LOAD_NO_BITMAP);\n  if (cairo_font_face == NULL) {\n    error(-1, \"could not create cairo font\\n\");\n    goto err2; /* this doesn't do anything, but it looks like we're\n\t\t* handling the error */\n  } {\n  CairoFont *ret = new CairoFont(ref, cairo_font_face, face, codeToGID, codeToGIDLen);\n  cairo_font_face_set_user_data (cairo_font_face, \n\t\t\t\t &cairo_font_face_key,\n\t\t\t\t ret,\n\t\t\t\t cairo_font_face_destroy);\n\n  return ret;\n  }\n err2:\n  /* hmm? */\n  printf (\"some font thing failed\\n\");\n  return NULL;\n}", "target": 1, "cwe": ["CWE-20"], "project": "poppler", "commit_id": "1a531dcfee1c6fc79a414c38cbe7327fbf9a59d8", "hash": 294666036737394333902439398055542844956, "size": 195, "message": "Fix a crash with invalid embedded fonts"}
{"func": "m4_mkstemp (struct obstack *obs, int argc, token_data **argv)\n{\n  if (bad_argc (argv[0], argc, 2, 2))\n    return;\n  mkstemp_helper (obs, ARG (1));\n}", "target": 1, "cwe": [], "project": "m4", "commit_id": "5345bb49077bfda9fabd048e563f9e7077fe335d", "hash": 318397935641703007412587121061184802559, "size": 6, "message": "Minor security fix: Quote output of mkstemp.\n\n* src/builtin.c (mkstemp_helper): Produce quoted output.\n* doc/m4.texinfo (Mkstemp): Update the documentation and tests.\n* NEWS: Document this change.\n\nSigned-off-by: Eric Blake <ebb9@byu.net>\n(cherry picked from commit bd9900d65eb9cd5add0f107e94b513fa267495ba)"}
{"func": "mkstemp_helper (struct obstack *obs, const char *name)\n{\n  int fd;\n  int len;\n  int i;\n\n  /* Guarantee that there are six trailing 'X' characters, even if the\n     user forgot to supply them.  */\n  len = strlen (name);\n  obstack_grow (obs, name, len);\n  for (i = 0; len > 0 && i < 6; i++)\n    if (name[--len] != 'X')\n      break;\n  for (; i < 6; i++)\n    obstack_1grow (obs, 'X');\n  obstack_1grow (obs, '\\0');\n\n  errno = 0;\n  fd = mkstemp ((char *) obstack_base (obs));\n  if (fd < 0)\n    {\n      M4ERROR ((0, errno, \"cannot create tempfile `%s'\", name));\n      obstack_free (obs, obstack_finish (obs));\n    }\n  else\n    close (fd);\n}", "target": 1, "cwe": [], "project": "m4", "commit_id": "5345bb49077bfda9fabd048e563f9e7077fe335d", "hash": 323725070097395571956742448608555080438, "size": 27, "message": "Minor security fix: Quote output of mkstemp.\n\n* src/builtin.c (mkstemp_helper): Produce quoted output.\n* doc/m4.texinfo (Mkstemp): Update the documentation and tests.\n* NEWS: Document this change.\n\nSigned-off-by: Eric Blake <ebb9@byu.net>\n(cherry picked from commit bd9900d65eb9cd5add0f107e94b513fa267495ba)"}
{"func": "m4_maketemp (struct obstack *obs, int argc, token_data **argv)\n{\n  if (bad_argc (argv[0], argc, 2, 2))\n    return;\n  if (no_gnu_extensions)\n    {\n      /* POSIX states \"any trailing 'X' characters [are] replaced with\n\t the current process ID as a string\", without referencing the\n\t file system.  Horribly insecure, but we have to do it when we\n\t are in traditional mode.\n\n\t For reference, Solaris m4 does:\n\t   maketemp() -> `'\n\t   maketemp(X) -> `X'\n\t   maketemp(XX) -> `Xn', where n is last digit of pid\n\t   maketemp(XXXXXXXX) -> `X00nnnnn', where nnnnn is 16-bit pid\n      */\n      const char *str = ARG (1);\n      int len = strlen (str);\n      int i;\n      int len2;\n\n      M4ERROR ((warning_status, 0, \"recommend using mkstemp instead\"));\n      for (i = len; i > 1; i--)\n\tif (str[i - 1] != 'X')\n\t  break;\n      obstack_grow (obs, str, i);\n      str = ntoa ((int32_t) getpid (), 10);\n      len2 = strlen (str);\n      if (len2 > len - i)\n\tobstack_grow0 (obs, str + len2 - (len - i), len - i);\n      else\n\t{\n\t  while (i++ < len - len2)\n\t    obstack_1grow (obs, '0');\n\t  obstack_grow0 (obs, str, len2);\n\t}\n    }\n  else\n    mkstemp_helper (obs, ARG (1));\n}", "target": 1, "cwe": [], "project": "m4", "commit_id": "5345bb49077bfda9fabd048e563f9e7077fe335d", "hash": 14712089961255949909474829467913790190, "size": 41, "message": "Minor security fix: Quote output of mkstemp.\n\n* src/builtin.c (mkstemp_helper): Produce quoted output.\n* doc/m4.texinfo (Mkstemp): Update the documentation and tests.\n* NEWS: Document this change.\n\nSigned-off-by: Eric Blake <ebb9@byu.net>\n(cherry picked from commit bd9900d65eb9cd5add0f107e94b513fa267495ba)"}
{"func": "produce_frozen_state (const char *name)\n{\n  FILE *file;\n  int h;\n  symbol *sym;\n  const builtin *bp;\n\n  if (file = fopen (name, O_BINARY ? \"wb\" : \"w\"), !file)\n    {\n      M4ERROR ((warning_status, errno, name));\n      return;\n    }\n\n  /* Write a recognizable header.  */\n\n  xfprintf (file, \"# This is a frozen state file generated by %s\\n\",\n\t   PACKAGE_STRING);\n  xfprintf (file, \"V1\\n\");\n\n  /* Dump quote delimiters.  */\n\n  if (strcmp (lquote.string, DEF_LQUOTE) || strcmp (rquote.string, DEF_RQUOTE))\n    {\n      xfprintf (file, \"Q%d,%d\\n\", (int) lquote.length, (int) rquote.length);\n      fputs (lquote.string, file);\n      fputs (rquote.string, file);\n      fputc ('\\n', file);\n    }\n\n  /* Dump comment delimiters.  */\n\n  if (strcmp (bcomm.string, DEF_BCOMM) || strcmp (ecomm.string, DEF_ECOMM))\n    {\n      xfprintf (file, \"C%d,%d\\n\", (int) bcomm.length, (int) ecomm.length);\n      fputs (bcomm.string, file);\n      fputs (ecomm.string, file);\n      fputc ('\\n', file);\n    }\n\n  /* Dump all symbols.  */\n\n  for (h = 0; h < hash_table_size; h++)\n    {\n\n      /* Process all entries in one bucket, from the last to the first.\n\t This order ensures that, at reload time, pushdef's will be\n\t executed with the oldest definitions first.  */\n\n      symtab[h] = reverse_symbol_list (symtab[h]);\n      for (sym = symtab[h]; sym; sym = SYMBOL_NEXT (sym))\n\t{\n\t  switch (SYMBOL_TYPE (sym))\n\t    {\n\t    case TOKEN_TEXT:\n\t      xfprintf (file, \"T%d,%d\\n\",\n\t\t\t(int) strlen (SYMBOL_NAME (sym)),\n\t\t\t(int) strlen (SYMBOL_TEXT (sym)));\n\t      fputs (SYMBOL_NAME (sym), file);\n\t      fputs (SYMBOL_TEXT (sym), file);\n\t      fputc ('\\n', file);\n\t      break;\n\n\t    case TOKEN_FUNC:\n\t      bp = find_builtin_by_addr (SYMBOL_FUNC (sym));\n\t      if (bp == NULL)\n\t\t{\n\t\t  M4ERROR ((warning_status, 0, \"\\\nINTERNAL ERROR: builtin not found in builtin table!\"));\n\t\t  abort ();\n\t\t}\n\t      xfprintf (file, \"F%d,%d\\n\",\n\t\t\t(int) strlen (SYMBOL_NAME (sym)),\n\t\t\t(int) strlen (bp->name));\n\t      fputs (SYMBOL_NAME (sym), file);\n\t      fputs (bp->name, file);\n\t      fputc ('\\n', file);\n\t      break;\n\n\t    case TOKEN_VOID:\n\t      /* Ignore placeholder tokens that exist due to traceon.  */\n\t      break;\n\n\t    default:\n\t      M4ERROR ((warning_status, 0, \"\\\nINTERNAL ERROR: bad token data type in freeze_one_symbol ()\"));\n\t      abort ();\n\t      break;\n\t    }\n\t}\n\n      /* Reverse the bucket once more, putting it back as it was.  */\n\n      symtab[h] = reverse_symbol_list (symtab[h]);\n    }\n\n  /* Let diversions be issued from output.c module, its cleaner to have this\n     piece of code there.  */\n\n  freeze_diversions (file);\n\n  /* All done.  */\n\n  fputs (\"# End of frozen state file\\n\", file);\n  if (close_stream (file) != 0)\n    M4ERROR ((EXIT_FAILURE, errno, \"unable to create frozen state\"));\n}", "target": 1, "cwe": [], "project": "m4", "commit_id": "035998112737e52cb229e342913ef404e5a51040", "hash": 263127698236721605389098427202622408056, "size": 106, "message": "Security fix: avoid arbitrary code execution with 'm4 -F'.\n\n* src/freeze.c (produce_frozen_state): Never pass raw file name as\nprintf format.\n* NEWS: Document this fix.\n\nSigned-off-by: Eric Blake <ebb9@byu.net>\n(cherry picked from commit 031a71a80442ed2ad3c2ee14d5811c786a12c51b)"}
{"func": "static unsigned char asn1_oid_decode(struct asn1_ctx *ctx,\n\t\t\t\t     unsigned char *eoc,\n\t\t\t\t     unsigned long **oid,\n\t\t\t\t     unsigned int *len)\n{\n\tunsigned long subid;\n\tunsigned int  size;\n\tunsigned long *optr;\n\n\tsize = eoc - ctx->pointer + 1;\n\t*oid = kmalloc(size * sizeof(unsigned long), GFP_ATOMIC);\n\tif (*oid == NULL) {\n\t\tif (net_ratelimit())\n\t\t\tprintk(\"OOM in bsalg (%d)\\n\", __LINE__);\n\t\treturn 0;\n\t}\n\n\toptr = *oid;\n\n\tif (!asn1_subid_decode(ctx, &subid)) {\n\t\tkfree(*oid);\n\t\t*oid = NULL;\n\t\treturn 0;\n\t}\n\n\tif (subid < 40) {\n\t\toptr [0] = 0;\n\t\toptr [1] = subid;\n\t} else if (subid < 80) {\n\t\toptr [0] = 1;\n\t\toptr [1] = subid - 40;\n\t} else {\n\t\toptr [0] = 2;\n\t\toptr [1] = subid - 80;\n\t}\n\n\t*len = 2;\n\toptr += 2;\n\n\twhile (ctx->pointer < eoc) {\n\t\tif (++(*len) > size) {\n\t\t\tctx->error = ASN1_ERR_DEC_BADVALUE;\n\t\t\tkfree(*oid);\n\t\t\t*oid = NULL;\n\t\t\treturn 0;\n\t\t}\n\n\t\tif (!asn1_subid_decode(ctx, optr++)) {\n\t\t\tkfree(*oid);\n\t\t\t*oid = NULL;\n\t\t\treturn 0;\n\t\t}\n\t}\n\treturn 1;\n}", "target": 1, "cwe": ["CWE-119"], "project": "linux-2.6", "commit_id": "ddb2c43594f22843e9f3153da151deaba1a834c5", "hash": 258736852088289996589788699342684506403, "size": 55, "message": "asn1: additional sanity checking during BER decoding\n\n- Don't trust a length which is greater than the working buffer.\n  An invalid length could cause overflow when calculating buffer size\n  for decoding oid.\n\n- An oid length of zero is invalid and allows for an off-by-one error when\n  decoding oid because the first subid actually encodes first 2 subids.\n\n- A primitive encoding may not have an indefinite length.\n\nThanks to Wei Wang from McAfee for report.\n\nCc: Steven French <sfrench@us.ibm.com>\nCc: stable@kernel.org\nAcked-by: Patrick McHardy <kaber@trash.net>\nSigned-off-by: Chris Wright <chrisw@sous-sol.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "asn1_oid_decode(struct asn1_ctx *ctx,\n\t\tunsigned char *eoc, unsigned long **oid, unsigned int *len)\n{\n\tunsigned long subid;\n\tunsigned int size;\n\tunsigned long *optr;\n\n\tsize = eoc - ctx->pointer + 1;\n\t*oid = kmalloc(size * sizeof(unsigned long), GFP_ATOMIC);\n\tif (*oid == NULL)\n\t\treturn 0;\n\n\toptr = *oid;\n\n\tif (!asn1_subid_decode(ctx, &subid)) {\n\t\tkfree(*oid);\n\t\t*oid = NULL;\n\t\treturn 0;\n\t}\n\n\tif (subid < 40) {\n\t\toptr[0] = 0;\n\t\toptr[1] = subid;\n\t} else if (subid < 80) {\n\t\toptr[0] = 1;\n\t\toptr[1] = subid - 40;\n\t} else {\n\t\toptr[0] = 2;\n\t\toptr[1] = subid - 80;\n\t}\n\n\t*len = 2;\n\toptr += 2;\n\n\twhile (ctx->pointer < eoc) {\n\t\tif (++(*len) > size) {\n\t\t\tctx->error = ASN1_ERR_DEC_BADVALUE;\n\t\t\tkfree(*oid);\n\t\t\t*oid = NULL;\n\t\t\treturn 0;\n\t\t}\n\n\t\tif (!asn1_subid_decode(ctx, optr++)) {\n\t\t\tkfree(*oid);\n\t\t\t*oid = NULL;\n\t\t\treturn 0;\n\t\t}\n\t}\n\treturn 1;\n}", "target": 1, "cwe": ["CWE-119"], "project": "linux-2.6", "commit_id": "ddb2c43594f22843e9f3153da151deaba1a834c5", "hash": 24934009460877332029578215926851751208, "size": 50, "message": "asn1: additional sanity checking during BER decoding\n\n- Don't trust a length which is greater than the working buffer.\n  An invalid length could cause overflow when calculating buffer size\n  for decoding oid.\n\n- An oid length of zero is invalid and allows for an off-by-one error when\n  decoding oid because the first subid actually encodes first 2 subids.\n\n- A primitive encoding may not have an indefinite length.\n\nThanks to Wei Wang from McAfee for report.\n\nCc: Steven French <sfrench@us.ibm.com>\nCc: stable@kernel.org\nAcked-by: Patrick McHardy <kaber@trash.net>\nSigned-off-by: Chris Wright <chrisw@sous-sol.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "asn1_header_decode(struct asn1_ctx *ctx,\n\t\t   unsigned char **eoc,\n\t\t   unsigned int *cls, unsigned int *con, unsigned int *tag)\n{\n\tunsigned int def = 0;\n\tunsigned int len = 0;\n\n\tif (!asn1_id_decode(ctx, cls, con, tag))\n\t\treturn 0;\n\n\tif (!asn1_length_decode(ctx, &def, &len))\n\t\treturn 0;\n\n\tif (def)\n\t\t*eoc = ctx->pointer + len;\n\telse\n\t\t*eoc = NULL;\n\treturn 1;\n}", "target": 1, "cwe": ["CWE-119"], "project": "linux-2.6", "commit_id": "ddb2c43594f22843e9f3153da151deaba1a834c5", "hash": 100827339625052954108223001238225390166, "size": 19, "message": "asn1: additional sanity checking during BER decoding\n\n- Don't trust a length which is greater than the working buffer.\n  An invalid length could cause overflow when calculating buffer size\n  for decoding oid.\n\n- An oid length of zero is invalid and allows for an off-by-one error when\n  decoding oid because the first subid actually encodes first 2 subids.\n\n- A primitive encoding may not have an indefinite length.\n\nThanks to Wei Wang from McAfee for report.\n\nCc: Steven French <sfrench@us.ibm.com>\nCc: stable@kernel.org\nAcked-by: Patrick McHardy <kaber@trash.net>\nSigned-off-by: Chris Wright <chrisw@sous-sol.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "static unsigned char asn1_header_decode(struct asn1_ctx *ctx,\n\t\t\t\t\tunsigned char **eoc,\n\t\t\t\t\tunsigned int *cls,\n\t\t\t\t\tunsigned int *con,\n\t\t\t\t\tunsigned int *tag)\n{\n\tunsigned int def, len;\n\n\tif (!asn1_id_decode(ctx, cls, con, tag))\n\t\treturn 0;\n\n\tdef = len = 0;\n\tif (!asn1_length_decode(ctx, &def, &len))\n\t\treturn 0;\n\n\tif (def)\n\t\t*eoc = ctx->pointer + len;\n\telse\n\t\t*eoc = NULL;\n\treturn 1;\n}", "target": 1, "cwe": ["CWE-119"], "project": "linux-2.6", "commit_id": "ddb2c43594f22843e9f3153da151deaba1a834c5", "hash": 228756596288618045464924038405659988128, "size": 21, "message": "asn1: additional sanity checking during BER decoding\n\n- Don't trust a length which is greater than the working buffer.\n  An invalid length could cause overflow when calculating buffer size\n  for decoding oid.\n\n- An oid length of zero is invalid and allows for an off-by-one error when\n  decoding oid because the first subid actually encodes first 2 subids.\n\n- A primitive encoding may not have an indefinite length.\n\nThanks to Wei Wang from McAfee for report.\n\nCc: Steven French <sfrench@us.ibm.com>\nCc: stable@kernel.org\nAcked-by: Patrick McHardy <kaber@trash.net>\nSigned-off-by: Chris Wright <chrisw@sous-sol.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "static unsigned char asn1_length_decode(struct asn1_ctx *ctx,\n\t\t\t\t\tunsigned int *def,\n\t\t\t\t\tunsigned int *len)\n{\n\tunsigned char ch, cnt;\n\n\tif (!asn1_octet_decode(ctx, &ch))\n\t\treturn 0;\n\n\tif (ch == 0x80)\n\t\t*def = 0;\n\telse {\n\t\t*def = 1;\n\n\t\tif (ch < 0x80)\n\t\t\t*len = ch;\n\t\telse {\n\t\t\tcnt = ch & 0x7F;\n\t\t\t*len = 0;\n\n\t\t\twhile (cnt > 0) {\n\t\t\t\tif (!asn1_octet_decode(ctx, &ch))\n\t\t\t\t\treturn 0;\n\t\t\t\t*len <<= 8;\n\t\t\t\t*len |= ch;\n\t\t\t\tcnt--;\n\t\t\t}\n\t\t}\n\t}\n\treturn 1;\n}", "target": 1, "cwe": ["CWE-119"], "project": "linux-2.6", "commit_id": "ddb2c43594f22843e9f3153da151deaba1a834c5", "hash": 214953782388236534754341406713123646165, "size": 31, "message": "asn1: additional sanity checking during BER decoding\n\n- Don't trust a length which is greater than the working buffer.\n  An invalid length could cause overflow when calculating buffer size\n  for decoding oid.\n\n- An oid length of zero is invalid and allows for an off-by-one error when\n  decoding oid because the first subid actually encodes first 2 subids.\n\n- A primitive encoding may not have an indefinite length.\n\nThanks to Wei Wang from McAfee for report.\n\nCc: Steven French <sfrench@us.ibm.com>\nCc: stable@kernel.org\nAcked-by: Patrick McHardy <kaber@trash.net>\nSigned-off-by: Chris Wright <chrisw@sous-sol.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "asn1_length_decode(struct asn1_ctx *ctx, unsigned int *def, unsigned int *len)\n{\n\tunsigned char ch, cnt;\n\n\tif (!asn1_octet_decode(ctx, &ch))\n\t\treturn 0;\n\n\tif (ch == 0x80)\n\t\t*def = 0;\n\telse {\n\t\t*def = 1;\n\n\t\tif (ch < 0x80)\n\t\t\t*len = ch;\n\t\telse {\n\t\t\tcnt = (unsigned char) (ch & 0x7F);\n\t\t\t*len = 0;\n\n\t\t\twhile (cnt > 0) {\n\t\t\t\tif (!asn1_octet_decode(ctx, &ch))\n\t\t\t\t\treturn 0;\n\t\t\t\t*len <<= 8;\n\t\t\t\t*len |= ch;\n\t\t\t\tcnt--;\n\t\t\t}\n\t\t}\n\t}\n\treturn 1;\n}", "target": 1, "cwe": ["CWE-119"], "project": "linux-2.6", "commit_id": "ddb2c43594f22843e9f3153da151deaba1a834c5", "hash": 188088692906320605891566647399338031473, "size": 29, "message": "asn1: additional sanity checking during BER decoding\n\n- Don't trust a length which is greater than the working buffer.\n  An invalid length could cause overflow when calculating buffer size\n  for decoding oid.\n\n- An oid length of zero is invalid and allows for an off-by-one error when\n  decoding oid because the first subid actually encodes first 2 subids.\n\n- A primitive encoding may not have an indefinite length.\n\nThanks to Wei Wang from McAfee for report.\n\nCc: Steven French <sfrench@us.ibm.com>\nCc: stable@kernel.org\nAcked-by: Patrick McHardy <kaber@trash.net>\nSigned-off-by: Chris Wright <chrisw@sous-sol.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "static int ipip6_rcv(struct sk_buff *skb)\n{\n\tstruct iphdr *iph;\n\tstruct ip_tunnel *tunnel;\n\n\tif (!pskb_may_pull(skb, sizeof(struct ipv6hdr)))\n\t\tgoto out;\n\n\tiph = ip_hdr(skb);\n\n\tread_lock(&ipip6_lock);\n\tif ((tunnel = ipip6_tunnel_lookup(dev_net(skb->dev),\n\t\t\t\t\tiph->saddr, iph->daddr)) != NULL) {\n\t\tsecpath_reset(skb);\n\t\tskb->mac_header = skb->network_header;\n\t\tskb_reset_network_header(skb);\n\t\tIPCB(skb)->flags = 0;\n\t\tskb->protocol = htons(ETH_P_IPV6);\n\t\tskb->pkt_type = PACKET_HOST;\n\n\t\tif ((tunnel->dev->priv_flags & IFF_ISATAP) &&\n\t\t    !isatap_chksrc(skb, iph, tunnel)) {\n\t\t\ttunnel->stat.rx_errors++;\n\t\t\tread_unlock(&ipip6_lock);\n\t\t\tkfree_skb(skb);\n\t\t\treturn 0;\n\t\t}\n\t\ttunnel->stat.rx_packets++;\n\t\ttunnel->stat.rx_bytes += skb->len;\n\t\tskb->dev = tunnel->dev;\n\t\tdst_release(skb->dst);\n\t\tskb->dst = NULL;\n\t\tnf_reset(skb);\n\t\tipip6_ecn_decapsulate(iph, skb);\n\t\tnetif_rx(skb);\n\t\tread_unlock(&ipip6_lock);\n\t\treturn 0;\n\t}\n\n\ticmp_send(skb, ICMP_DEST_UNREACH, ICMP_PORT_UNREACH, 0);\n\tkfree_skb(skb);\n\tread_unlock(&ipip6_lock);\nout:\n\treturn 0;\n}", "target": 1, "cwe": ["CWE-399"], "project": "linux-2.6", "commit_id": "36ca34cc3b8335eb1fe8bd9a1d0a2592980c3f02", "hash": 33362704464284364551880964600617727631, "size": 45, "message": "sit: Add missing kfree_skb() on pskb_may_pull() failure.\n\nNoticed by Paul Marks <paul@pmarks.net>.\n\nSigned-off-by: David S. Miller <davem@davemloft.net>"}
{"func": "static u64 sched_slice(struct cfs_rq *cfs_rq, struct sched_entity *se)\n{\n\tu64 slice = __sched_period(cfs_rq->nr_running);\n\n\tslice *= se->load.weight;\n\tdo_div(slice, cfs_rq->load.weight);\n\n\treturn slice;\n}", "target": 1, "cwe": [], "project": "linux-2.6", "commit_id": "6a6029b8cefe0ca7e82f27f3904dbedba3de4e06", "hash": 58865871396891118754639920075524021506, "size": 9, "message": "sched: simplify sched_slice()\n\nUse the existing calc_delta_mine() calculation for sched_slice(). This\nsaves a divide and simplifies the code because we share it with the\nother /cfs_rq->load users.\n\nIt also improves code size:\n\n      text    data     bss     dec     hex filename\n     42659    2740     144   45543    b1e7 sched.o.before\n     42093    2740     144   44977    afb1 sched.o.after\n\nSigned-off-by: Ingo Molnar <mingo@elte.hu>\nSigned-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>"}
{"func": "static u64 sched_vslice_add(struct cfs_rq *cfs_rq, struct sched_entity *se)\n{\n\treturn __sched_vslice(cfs_rq->load.weight + se->load.weight,\n\t\t\tcfs_rq->nr_running + 1);\n}", "target": 1, "cwe": [], "project": "linux-2.6", "commit_id": "ac884dec6d4a7df252150af875cffddf8f1d9c15", "hash": 22178641074713844516345826435813180596, "size": 5, "message": "sched: fair-group scheduling vs latency\n\nCurrently FAIR_GROUP sched grows the scheduler latency outside of\nsysctl_sched_latency, invert this so it stays within.\n\nSigned-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>\nSigned-off-by: Ingo Molnar <mingo@elte.hu>"}
{"func": "static u64 __sched_vslice(unsigned long rq_weight, unsigned long nr_running)\n{\n\tu64 vslice = __sched_period(nr_running);\n\n\tvslice *= NICE_0_LOAD;\n\tdo_div(vslice, rq_weight);\n\n\treturn vslice;\n}", "target": 1, "cwe": [], "project": "linux-2.6", "commit_id": "ac884dec6d4a7df252150af875cffddf8f1d9c15", "hash": 26078873616473646001296634476156282378, "size": 9, "message": "sched: fair-group scheduling vs latency\n\nCurrently FAIR_GROUP sched grows the scheduler latency outside of\nsysctl_sched_latency, invert this so it stays within.\n\nSigned-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>\nSigned-off-by: Ingo Molnar <mingo@elte.hu>"}
{"func": "static u64 sched_slice(struct cfs_rq *cfs_rq, struct sched_entity *se)\n{\n\treturn calc_delta_mine(__sched_period(cfs_rq->nr_running),\n\t\t\t       se->load.weight, &cfs_rq->load);\n}", "target": 1, "cwe": [], "project": "linux-2.6", "commit_id": "ac884dec6d4a7df252150af875cffddf8f1d9c15", "hash": 242984434542507599503181154553976580439, "size": 5, "message": "sched: fair-group scheduling vs latency\n\nCurrently FAIR_GROUP sched grows the scheduler latency outside of\nsysctl_sched_latency, invert this so it stays within.\n\nSigned-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>\nSigned-off-by: Ingo Molnar <mingo@elte.hu>"}
{"func": "static u64 sched_vslice_add(struct cfs_rq *cfs_rq, struct sched_entity *se)\n{\n\tunsigned long nr_running = cfs_rq->nr_running;\n\tunsigned long weight;\n\tu64 vslice;\n\n\tif (!se->on_rq)\n\t\tnr_running++;\n\n\tvslice = __sched_period(nr_running);\n\n\tfor_each_sched_entity(se) {\n\t\tcfs_rq = cfs_rq_of(se);\n\n\t\tweight = cfs_rq->load.weight;\n\t\tif (!se->on_rq)\n\t\t\tweight += se->load.weight;\n\n\t\tvslice *= NICE_0_LOAD;\n\t\tdo_div(vslice, weight);\n\t}\n\n\treturn vslice;\n}", "target": 1, "cwe": [], "project": "linux-2.6", "commit_id": "8f1bc385cfbab474db6c27b5af1e439614f3025c", "hash": 199943656571357591846689473102776500500, "size": 24, "message": "sched: fair: weight calculations\n\nIn order to level the hierarchy, we need to calculate load based on the\nroot view. That is, each task's load is in the same unit.\n\n             A\n            / \\\n           B   1\n          / \\\n         2   3\n\nTo compute 1's load we do:\n\n\t   weight(1)\n\t--------------\n\t rq_weight(A)\n\nTo compute 2's load we do:\n\n\t  weight(2)      weight(B)\n\t------------ * -----------\n\trq_weight(B)   rw_weight(A)\n\nThis yields load fractions in comparable units.\n\nThe consequence is that it changes virtual time. We used to have:\n\n                time_{i}\n  vtime_{i} = ------------\n               weight_{i}\n\n  vtime = \\Sum vtime_{i} = time / rq_weight.\n\nBut with the new way of load calculation we get that vtime equals time.\n\nSigned-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>\nSigned-off-by: Ingo Molnar <mingo@elte.hu>"}
{"func": "static unsigned long wakeup_gran(struct sched_entity *se)\n{\n\tunsigned long gran = sysctl_sched_wakeup_granularity;\n\n\t/*\n\t * More easily preempt - nice tasks, while not making\n\t * it harder for + nice tasks.\n\t */\n\tif (unlikely(se->load.weight > NICE_0_LOAD))\n\t\tgran = calc_delta_fair(gran, &se->load);\n\n\treturn gran;\n}", "target": 1, "cwe": [], "project": "linux-2.6", "commit_id": "8f1bc385cfbab474db6c27b5af1e439614f3025c", "hash": 314868220618263729085248506628771974784, "size": 13, "message": "sched: fair: weight calculations\n\nIn order to level the hierarchy, we need to calculate load based on the\nroot view. That is, each task's load is in the same unit.\n\n             A\n            / \\\n           B   1\n          / \\\n         2   3\n\nTo compute 1's load we do:\n\n\t   weight(1)\n\t--------------\n\t rq_weight(A)\n\nTo compute 2's load we do:\n\n\t  weight(2)      weight(B)\n\t------------ * -----------\n\trq_weight(B)   rw_weight(A)\n\nThis yields load fractions in comparable units.\n\nThe consequence is that it changes virtual time. We used to have:\n\n                time_{i}\n  vtime_{i} = ------------\n               weight_{i}\n\n  vtime = \\Sum vtime_{i} = time / rq_weight.\n\nBut with the new way of load calculation we get that vtime equals time.\n\nSigned-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>\nSigned-off-by: Ingo Molnar <mingo@elte.hu>"}
{"func": "static u64 sched_slice(struct cfs_rq *cfs_rq, struct sched_entity *se)\n{\n\tu64 slice = __sched_period(cfs_rq->nr_running);\n\n\tfor_each_sched_entity(se) {\n\t\tcfs_rq = cfs_rq_of(se);\n\n\t\tslice *= se->load.weight;\n\t\tdo_div(slice, cfs_rq->load.weight);\n\t}\n\n\n\treturn slice;\n}", "target": 1, "cwe": [], "project": "linux-2.6", "commit_id": "8f1bc385cfbab474db6c27b5af1e439614f3025c", "hash": 20493139195104024011277989870755546981, "size": 14, "message": "sched: fair: weight calculations\n\nIn order to level the hierarchy, we need to calculate load based on the\nroot view. That is, each task's load is in the same unit.\n\n             A\n            / \\\n           B   1\n          / \\\n         2   3\n\nTo compute 1's load we do:\n\n\t   weight(1)\n\t--------------\n\t rq_weight(A)\n\nTo compute 2's load we do:\n\n\t  weight(2)      weight(B)\n\t------------ * -----------\n\trq_weight(B)   rw_weight(A)\n\nThis yields load fractions in comparable units.\n\nThe consequence is that it changes virtual time. We used to have:\n\n                time_{i}\n  vtime_{i} = ------------\n               weight_{i}\n\n  vtime = \\Sum vtime_{i} = time / rq_weight.\n\nBut with the new way of load calculation we get that vtime equals time.\n\nSigned-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>\nSigned-off-by: Ingo Molnar <mingo@elte.hu>"}
{"func": "calc_delta_fair(unsigned long delta_exec, struct load_weight *lw)\n{\n\treturn calc_delta_mine(delta_exec, NICE_0_LOAD, lw);\n}", "target": 1, "cwe": [], "project": "linux-2.6", "commit_id": "8f1bc385cfbab474db6c27b5af1e439614f3025c", "hash": 275354062946871065189509316823270452840, "size": 4, "message": "sched: fair: weight calculations\n\nIn order to level the hierarchy, we need to calculate load based on the\nroot view. That is, each task's load is in the same unit.\n\n             A\n            / \\\n           B   1\n          / \\\n         2   3\n\nTo compute 1's load we do:\n\n\t   weight(1)\n\t--------------\n\t rq_weight(A)\n\nTo compute 2's load we do:\n\n\t  weight(2)      weight(B)\n\t------------ * -----------\n\trq_weight(B)   rw_weight(A)\n\nThis yields load fractions in comparable units.\n\nThe consequence is that it changes virtual time. We used to have:\n\n                time_{i}\n  vtime_{i} = ------------\n               weight_{i}\n\n  vtime = \\Sum vtime_{i} = time / rq_weight.\n\nBut with the new way of load calculation we get that vtime equals time.\n\nSigned-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>\nSigned-off-by: Ingo Molnar <mingo@elte.hu>"}
{"func": "place_entity(struct cfs_rq *cfs_rq, struct sched_entity *se, int initial)\n{\n\tu64 vruntime;\n\n\tif (first_fair(cfs_rq)) {\n\t\tvruntime = min_vruntime(cfs_rq->min_vruntime,\n\t\t\t\t__pick_next_entity(cfs_rq)->vruntime);\n\t} else\n\t\tvruntime = cfs_rq->min_vruntime;\n\n\t/*\n\t * The 'current' period is already promised to the current tasks,\n\t * however the extra weight of the new task will slow them down a\n\t * little, place the new task so that it fits in the slot that\n\t * stays open at the end.\n\t */\n\tif (initial && sched_feat(START_DEBIT))\n\t\tvruntime += sched_vslice_add(cfs_rq, se);\n\n\tif (!initial) {\n\t\t/* sleeps upto a single latency don't count. */\n\t\tif (sched_feat(NEW_FAIR_SLEEPERS)) {\n\t\t\tif (sched_feat(NORMALIZED_SLEEPER))\n\t\t\t\tvruntime -= calc_delta_fair(sysctl_sched_latency,\n\t\t\t\t\t\t&cfs_rq->load);\n\t\t\telse\n\t\t\t\tvruntime -= sysctl_sched_latency;\n\t\t}\n\n\t\t/* ensure we never gain time by being placed backwards. */\n\t\tvruntime = max_vruntime(se->vruntime, vruntime);\n\t}\n\n\tse->vruntime = vruntime;\n}", "target": 1, "cwe": [], "project": "linux-2.6", "commit_id": "8f1bc385cfbab474db6c27b5af1e439614f3025c", "hash": 308682937641422833765183420086525125925, "size": 35, "message": "sched: fair: weight calculations\n\nIn order to level the hierarchy, we need to calculate load based on the\nroot view. That is, each task's load is in the same unit.\n\n             A\n            / \\\n           B   1\n          / \\\n         2   3\n\nTo compute 1's load we do:\n\n\t   weight(1)\n\t--------------\n\t rq_weight(A)\n\nTo compute 2's load we do:\n\n\t  weight(2)      weight(B)\n\t------------ * -----------\n\trq_weight(B)   rw_weight(A)\n\nThis yields load fractions in comparable units.\n\nThe consequence is that it changes virtual time. We used to have:\n\n                time_{i}\n  vtime_{i} = ------------\n               weight_{i}\n\n  vtime = \\Sum vtime_{i} = time / rq_weight.\n\nBut with the new way of load calculation we get that vtime equals time.\n\nSigned-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>\nSigned-off-by: Ingo Molnar <mingo@elte.hu>"}
{"func": "__update_curr(struct cfs_rq *cfs_rq, struct sched_entity *curr,\n\t      unsigned long delta_exec)\n{\n\tunsigned long delta_exec_weighted;\n\n\tschedstat_set(curr->exec_max, max((u64)delta_exec, curr->exec_max));\n\n\tcurr->sum_exec_runtime += delta_exec;\n\tschedstat_add(cfs_rq, exec_clock, delta_exec);\n\tdelta_exec_weighted = delta_exec;\n\tif (unlikely(curr->load.weight != NICE_0_LOAD)) {\n\t\tdelta_exec_weighted = calc_delta_fair(delta_exec_weighted,\n\t\t\t\t\t\t\t&curr->load);\n\t}\n\tcurr->vruntime += delta_exec_weighted;\n}", "target": 1, "cwe": [], "project": "linux-2.6", "commit_id": "8f1bc385cfbab474db6c27b5af1e439614f3025c", "hash": 65520173795750994905270968391954591377, "size": 16, "message": "sched: fair: weight calculations\n\nIn order to level the hierarchy, we need to calculate load based on the\nroot view. That is, each task's load is in the same unit.\n\n             A\n            / \\\n           B   1\n          / \\\n         2   3\n\nTo compute 1's load we do:\n\n\t   weight(1)\n\t--------------\n\t rq_weight(A)\n\nTo compute 2's load we do:\n\n\t  weight(2)      weight(B)\n\t------------ * -----------\n\trq_weight(B)   rw_weight(A)\n\nThis yields load fractions in comparable units.\n\nThe consequence is that it changes virtual time. We used to have:\n\n                time_{i}\n  vtime_{i} = ------------\n               weight_{i}\n\n  vtime = \\Sum vtime_{i} = time / rq_weight.\n\nBut with the new way of load calculation we get that vtime equals time.\n\nSigned-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>\nSigned-off-by: Ingo Molnar <mingo@elte.hu>"}
{"func": "_gnutls_server_name_recv_params (gnutls_session_t session,\n\t\t\t\t const opaque * data, size_t _data_size)\n{\n  int i;\n  const unsigned char *p;\n  uint16_t len, type;\n  ssize_t data_size = _data_size;\n  int server_names = 0;\n\n  if (session->security_parameters.entity == GNUTLS_SERVER)\n    {\n      DECR_LENGTH_RET (data_size, 2, 0);\n      len = _gnutls_read_uint16 (data);\n\n      if (len != data_size)\n\t{\n\t  /* This is unexpected packet length, but\n\t   * just ignore it, for now.\n\t   */\n\t  gnutls_assert ();\n\t  return 0;\n\t}\n\n      p = data + 2;\n\n      /* Count all server_names in the packet. */\n      while (data_size > 0)\n\t{\n\t  DECR_LENGTH_RET (data_size, 1, 0);\n\t  p++;\n\n\t  DECR_LEN (data_size, 2);\n\t  len = _gnutls_read_uint16 (p);\n\t  p += 2;\n\n\t  DECR_LENGTH_RET (data_size, len, 0);\n\t  server_names++;\n\n\t  p += len;\n\t}\n\n      session->security_parameters.extensions.server_names_size =\n\tserver_names;\n      if (server_names == 0)\n\treturn 0;\t\t/* no names found */\n\n      /* we cannot accept more server names.\n       */\n      if (server_names > MAX_SERVER_NAME_EXTENSIONS)\n\tserver_names = MAX_SERVER_NAME_EXTENSIONS;\n\n      p = data + 2;\n      for (i = 0; i < server_names; i++)\n\t{\n\t  type = *p;\n\t  p++;\n\n\t  len = _gnutls_read_uint16 (p);\n\t  p += 2;\n\n\t  switch (type)\n\t    {\n\t    case 0:\t\t/* NAME_DNS */\n\t      if (len <= MAX_SERVER_NAME_SIZE)\n\t\t{\n\t\t  memcpy (session->security_parameters.extensions.\n\t\t\t  server_names[i].name, p, len);\n\t\t  session->security_parameters.extensions.\n\t\t    server_names[i].name_length = len;\n\t\t  session->security_parameters.extensions.\n\t\t    server_names[i].type = GNUTLS_NAME_DNS;\n\t\t  break;\n\t\t}\n\t    }\n\n\t  /* move to next record */\n\t  p += len;\n\t}\n    }\n  return 0;\n}", "target": 1, "cwe": ["CWE-189"], "project": "gnutls", "commit_id": "bc8102405fda11ea00ca3b42acc4f4bce9d6e97b", "hash": 168266384151590392485061020862846264327, "size": 81, "message": "Fix GNUTLS-SA-2008-1 security vulnerabilities.\nSee http://www.gnu.org/software/gnutls/security.html for updates."}
{"func": "_gnutls_ciphertext2compressed (gnutls_session_t session,\n\t\t\t       opaque * compress_data,\n\t\t\t       int compress_size,\n\t\t\t       gnutls_datum_t ciphertext, uint8_t type)\n{\n  uint8_t MAC[MAX_HASH_SIZE];\n  uint16_t c_length;\n  uint8_t pad;\n  int length;\n  digest_hd_st td;\n  uint16_t blocksize;\n  int ret, i, pad_failed = 0;\n  uint8_t major, minor;\n  gnutls_protocol_t ver;\n  int hash_size =\n    _gnutls_hash_get_algo_len (session->security_parameters.\n\t\t\t       read_mac_algorithm);\n\n  ver = gnutls_protocol_get_version (session);\n  minor = _gnutls_version_get_minor (ver);\n  major = _gnutls_version_get_major (ver);\n\n  blocksize = _gnutls_cipher_get_block_size (session->security_parameters.\n\t\t\t\t\t     read_bulk_cipher_algorithm);\n\n  /* initialize MAC \n   */\n  ret = mac_init (&td, session->security_parameters.read_mac_algorithm,\n\t\t session->connection_state.read_mac_secret.data,\n\t\t session->connection_state.read_mac_secret.size, ver);\n\n  if (ret < 0\n      && session->security_parameters.read_mac_algorithm != GNUTLS_MAC_NULL)\n    {\n      gnutls_assert ();\n      return GNUTLS_E_INTERNAL_ERROR;\n    }\n\n\n  /* actual decryption (inplace)\n   */\n  switch (_gnutls_cipher_is_block\n\t  (session->security_parameters.read_bulk_cipher_algorithm))\n    {\n    case CIPHER_STREAM:\n      if ((ret = _gnutls_cipher_decrypt (&session->connection_state.\n\t\t\t\t\t read_cipher_state,\n\t\t\t\t\t ciphertext.data,\n\t\t\t\t\t ciphertext.size)) < 0)\n\t{\n\t  gnutls_assert ();\n\t  return ret;\n\t}\n\n      length = ciphertext.size - hash_size;\n\n      break;\n    case CIPHER_BLOCK:\n      if ((ciphertext.size < blocksize) || (ciphertext.size % blocksize != 0))\n\t{\n\t  gnutls_assert ();\n\t  return GNUTLS_E_DECRYPTION_FAILED;\n\t}\n\n      if ((ret = _gnutls_cipher_decrypt (&session->connection_state.\n\t\t\t\t\t read_cipher_state,\n\t\t\t\t\t ciphertext.data,\n\t\t\t\t\t ciphertext.size)) < 0)\n\t{\n\t  gnutls_assert ();\n\t  return ret;\n\t}\n\n      /* ignore the IV in TLS 1.1.\n       */\n      if (session->security_parameters.version >= GNUTLS_TLS1_1)\n\t{\n\t  ciphertext.size -= blocksize;\n\t  ciphertext.data += blocksize;\n\n\t  if (ciphertext.size == 0)\n\t    {\n\t      gnutls_assert ();\n\t      return GNUTLS_E_DECRYPTION_FAILED;\n\t    }\n\t}\n\n      pad = ciphertext.data[ciphertext.size - 1] + 1;\t/* pad */\n\n      length = ciphertext.size - hash_size - pad;\n\n      if (pad > ciphertext.size - hash_size)\n\t{\n\t  gnutls_assert ();\n\t  /* We do not fail here. We check below for the\n\t   * the pad_failed. If zero means success.\n\t   */\n\t  pad_failed = GNUTLS_E_DECRYPTION_FAILED;\n\t}\n\n      /* Check the pading bytes (TLS 1.x)\n       */\n      if (ver >= GNUTLS_TLS1 && pad_failed == 0)\n\tfor (i = 2; i < pad; i++)\n\t  {\n\t    if (ciphertext.data[ciphertext.size - i] !=\n\t\tciphertext.data[ciphertext.size - 1])\n\t      pad_failed = GNUTLS_E_DECRYPTION_FAILED;\n\t  }\n      break;\n    default:\n      gnutls_assert ();\n      return GNUTLS_E_INTERNAL_ERROR;\n    }\n\n  if (length < 0)\n    length = 0;\n  c_length = _gnutls_conv_uint16 ((uint16_t) length);\n\n  /* Pass the type, version, length and compressed through\n   * MAC.\n   */\n  if (session->security_parameters.read_mac_algorithm != GNUTLS_MAC_NULL)\n    {\n      _gnutls_hmac (&td,\n\t\t    UINT64DATA (session->connection_state.\n\t\t\t\tread_sequence_number), 8);\n\n      _gnutls_hmac (&td, &type, 1);\n      if (ver >= GNUTLS_TLS1)\n\t{\t\t\t/* TLS 1.x */\n\t  _gnutls_hmac (&td, &major, 1);\n\t  _gnutls_hmac (&td, &minor, 1);\n\t}\n      _gnutls_hmac (&td, &c_length, 2);\n\n      if (length > 0)\n\t_gnutls_hmac (&td, ciphertext.data, length);\n\n      mac_deinit (&td, MAC, ver);\n    }\n\n  /* This one was introduced to avoid a timing attack against the TLS\n   * 1.0 protocol.\n   */\n  if (pad_failed != 0)\n    return pad_failed;\n\n  /* HMAC was not the same. \n   */\n  if (memcmp (MAC, &ciphertext.data[length], hash_size) != 0)\n    {\n      gnutls_assert ();\n      return GNUTLS_E_DECRYPTION_FAILED;\n    }\n\n  /* copy the decrypted stuff to compress_data.\n   */\n  if (compress_size < length)\n    {\n      gnutls_assert ();\n      return GNUTLS_E_DECOMPRESSION_FAILED;\n    }\n  memcpy (compress_data, ciphertext.data, length);\n\n  return length;\n}", "target": 1, "cwe": ["CWE-189"], "project": "gnutls", "commit_id": "bc8102405fda11ea00ca3b42acc4f4bce9d6e97b", "hash": 137431019550729333496535558945842202837, "size": 167, "message": "Fix GNUTLS-SA-2008-1 security vulnerabilities.\nSee http://www.gnu.org/software/gnutls/security.html for updates."}
{"func": "_gnutls_recv_handshake_header (gnutls_session_t session,\n\t\t\t       gnutls_handshake_description_t type,\n\t\t\t       gnutls_handshake_description_t * recv_type)\n{\n  int ret;\n  uint32_t length32 = 0;\n  uint8_t *dataptr = NULL;\t/* for realloc */\n  size_t handshake_header_size = HANDSHAKE_HEADER_SIZE;\n\n  /* if we have data into the buffer then return them, do not read the next packet.\n   * In order to return we need a full TLS handshake header, or in case of a version 2\n   * packet, then we return the first byte.\n   */\n  if (session->internals.handshake_header_buffer.header_size ==\n      handshake_header_size || (session->internals.v2_hello != 0\n\t\t\t\t&& type == GNUTLS_HANDSHAKE_CLIENT_HELLO\n\t\t\t\t&& session->internals.\n\t\t\t\thandshake_header_buffer.packet_length > 0))\n    {\n\n      *recv_type = session->internals.handshake_header_buffer.recv_type;\n\n      return session->internals.handshake_header_buffer.packet_length;\n    }\n\n  /* Note: SSL2_HEADERS == 1 */\n\n  dataptr = session->internals.handshake_header_buffer.header;\n\n  /* If we haven't already read the handshake headers.\n   */\n  if (session->internals.handshake_header_buffer.header_size < SSL2_HEADERS)\n    {\n      ret =\n\t_gnutls_handshake_io_recv_int (session, GNUTLS_HANDSHAKE,\n\t\t\t\t       type, dataptr, SSL2_HEADERS);\n\n      if (ret < 0)\n\t{\n\t  gnutls_assert ();\n\t  return ret;\n\t}\n\n      /* The case ret==0 is caught here.\n       */\n      if (ret != SSL2_HEADERS)\n\t{\n\t  gnutls_assert ();\n\t  return GNUTLS_E_UNEXPECTED_PACKET_LENGTH;\n\t}\n      session->internals.handshake_header_buffer.header_size = SSL2_HEADERS;\n    }\n\n  if (session->internals.v2_hello == 0\n      || type != GNUTLS_HANDSHAKE_CLIENT_HELLO)\n    {\n      ret =\n\t_gnutls_handshake_io_recv_int (session, GNUTLS_HANDSHAKE,\n\t\t\t\t       type,\n\t\t\t\t       &dataptr[session->\n\t\t\t\t\t\tinternals.\n\t\t\t\t\t\thandshake_header_buffer.\n\t\t\t\t\t\theader_size],\n\t\t\t\t       HANDSHAKE_HEADER_SIZE -\n\t\t\t\t       session->internals.\n\t\t\t\t       handshake_header_buffer.header_size);\n      if (ret <= 0)\n\t{\n\t  gnutls_assert ();\n\t  return (ret < 0) ? ret : GNUTLS_E_UNEXPECTED_PACKET_LENGTH;\n\t}\n      if ((size_t) ret !=\n\t  HANDSHAKE_HEADER_SIZE -\n\t  session->internals.handshake_header_buffer.header_size)\n\t{\n\t  gnutls_assert ();\n\t  return GNUTLS_E_UNEXPECTED_PACKET_LENGTH;\n\t}\n      *recv_type = dataptr[0];\n\n      /* we do not use DECR_LEN because we know\n       * that the packet has enough data.\n       */\n      length32 = _gnutls_read_uint24 (&dataptr[1]);\n      handshake_header_size = HANDSHAKE_HEADER_SIZE;\n\n      _gnutls_handshake_log (\"HSK[%x]: %s was received [%ld bytes]\\n\",\n\t\t\t     session, _gnutls_handshake2str (dataptr[0]),\n\t\t\t     length32 + HANDSHAKE_HEADER_SIZE);\n\n    }\n  else\n    {\t\t\t\t/* v2 hello */\n      length32 = session->internals.v2_hello - SSL2_HEADERS;\t/* we've read the first byte */\n\n      handshake_header_size = SSL2_HEADERS;\t/* we've already read one byte */\n\n      *recv_type = dataptr[0];\n\n      _gnutls_handshake_log (\"HSK[%x]: %s(v2) was received [%ld bytes]\\n\",\n\t\t\t     session, _gnutls_handshake2str (*recv_type),\n\t\t\t     length32 + handshake_header_size);\n\n      if (*recv_type != GNUTLS_HANDSHAKE_CLIENT_HELLO)\n\t{\t\t\t/* it should be one or nothing */\n\t  gnutls_assert ();\n\t  return GNUTLS_E_UNEXPECTED_HANDSHAKE_PACKET;\n\t}\n    }\n\n  /* put the packet into the buffer */\n  session->internals.handshake_header_buffer.header_size =\n    handshake_header_size;\n  session->internals.handshake_header_buffer.packet_length = length32;\n  session->internals.handshake_header_buffer.recv_type = *recv_type;\n\n  if (*recv_type != type)\n    {\n      gnutls_assert ();\n      return GNUTLS_E_UNEXPECTED_HANDSHAKE_PACKET;\n    }\n\n  return length32;\n}", "target": 1, "cwe": ["CWE-189"], "project": "gnutls", "commit_id": "bc8102405fda11ea00ca3b42acc4f4bce9d6e97b", "hash": 205220500280194884766195233361120369735, "size": 124, "message": "Fix GNUTLS-SA-2008-1 security vulnerabilities.\nSee http://www.gnu.org/software/gnutls/security.html for updates."}
{"func": "_gnutls_ciphertext2compressed (gnutls_session_t session,\n\t\t\t       opaque * compress_data,\n\t\t\t       int compress_size,\n\t\t\t       gnutls_datum_t ciphertext, uint8_t type)\n{\n  uint8_t MAC[MAX_HASH_SIZE];\n  uint16_t c_length;\n  uint8_t pad;\n  int length;\n  digest_hd_st td;\n  uint16_t blocksize;\n  int ret, i, pad_failed = 0;\n  uint8_t major, minor;\n  gnutls_protocol_t ver;\n  int hash_size =\n    _gnutls_hash_get_algo_len (session->security_parameters.\n\t\t\t       read_mac_algorithm);\n\n  ver = gnutls_protocol_get_version (session);\n  minor = _gnutls_version_get_minor (ver);\n  major = _gnutls_version_get_major (ver);\n\n  blocksize = _gnutls_cipher_get_block_size (session->security_parameters.\n\t\t\t\t\t     read_bulk_cipher_algorithm);\n\n  /* initialize MAC \n   */\n  ret = mac_init (&td, session->security_parameters.read_mac_algorithm,\n\t\t session->connection_state.read_mac_secret.data,\n\t\t session->connection_state.read_mac_secret.size, ver);\n\n  if (ret < 0\n      && session->security_parameters.read_mac_algorithm != GNUTLS_MAC_NULL)\n    {\n      gnutls_assert ();\n      return GNUTLS_E_INTERNAL_ERROR;\n    }\n\n  if (ciphertext.size < (unsigned) blocksize + hash_size)\n    {\n      _gnutls_record_log\n\t(\"REC[%x]: Short record length %d < %d + %d (under attack?)\\n\",\n\t session, ciphertext.size, blocksize, hash_size);\n      gnutls_assert ();\n      return GNUTLS_E_DECRYPTION_FAILED;\n    }\n\n  /* actual decryption (inplace)\n   */\n  switch (_gnutls_cipher_is_block\n\t  (session->security_parameters.read_bulk_cipher_algorithm))\n    {\n    case CIPHER_STREAM:\n      if ((ret = _gnutls_cipher_decrypt (&session->connection_state.\n\t\t\t\t\t read_cipher_state,\n\t\t\t\t\t ciphertext.data,\n\t\t\t\t\t ciphertext.size)) < 0)\n\t{\n\t  gnutls_assert ();\n\t  return ret;\n\t}\n\n      length = ciphertext.size - hash_size;\n\n      break;\n    case CIPHER_BLOCK:\n      if ((ciphertext.size < blocksize) || (ciphertext.size % blocksize != 0))\n\t{\n\t  gnutls_assert ();\n\t  return GNUTLS_E_DECRYPTION_FAILED;\n\t}\n\n      if ((ret = _gnutls_cipher_decrypt (&session->connection_state.\n\t\t\t\t\t read_cipher_state,\n\t\t\t\t\t ciphertext.data,\n\t\t\t\t\t ciphertext.size)) < 0)\n\t{\n\t  gnutls_assert ();\n\t  return ret;\n\t}\n\n      /* ignore the IV in TLS 1.1.\n       */\n      if (session->security_parameters.version >= GNUTLS_TLS1_1)\n\t{\n\t  ciphertext.size -= blocksize;\n\t  ciphertext.data += blocksize;\n\n\t  if (ciphertext.size == 0)\n\t    {\n\t      gnutls_assert ();\n\t      return GNUTLS_E_DECRYPTION_FAILED;\n\t    }\n\t}\n\n      pad = ciphertext.data[ciphertext.size - 1] + 1;\t/* pad */\n\n      if ((int)pad > (int)ciphertext.size - hash_size)\n\t{\n\t  gnutls_assert ();\n\t  /* We do not fail here. We check below for the\n\t   * the pad_failed. If zero means success.\n\t   */\n\t  pad_failed = GNUTLS_E_DECRYPTION_FAILED;\n\t}\n\n      length = ciphertext.size - hash_size - pad;\n\n      /* Check the pading bytes (TLS 1.x)\n       */\n      if (ver >= GNUTLS_TLS1 && pad_failed == 0)\n\tfor (i = 2; i < pad; i++)\n\t  {\n\t    if (ciphertext.data[ciphertext.size - i] !=\n\t\tciphertext.data[ciphertext.size - 1])\n\t      pad_failed = GNUTLS_E_DECRYPTION_FAILED;\n\t  }\n      break;\n    default:\n      gnutls_assert ();\n      return GNUTLS_E_INTERNAL_ERROR;\n    }\n\n  if (length < 0)\n    length = 0;\n  c_length = _gnutls_conv_uint16 ((uint16_t) length);\n\n  /* Pass the type, version, length and compressed through\n   * MAC.\n   */\n  if (session->security_parameters.read_mac_algorithm != GNUTLS_MAC_NULL)\n    {\n      _gnutls_hmac (&td,\n\t\t    UINT64DATA (session->connection_state.\n\t\t\t\tread_sequence_number), 8);\n\n      _gnutls_hmac (&td, &type, 1);\n      if (ver >= GNUTLS_TLS1)\n\t{\t\t\t/* TLS 1.x */\n\t  _gnutls_hmac (&td, &major, 1);\n\t  _gnutls_hmac (&td, &minor, 1);\n\t}\n      _gnutls_hmac (&td, &c_length, 2);\n\n      if (length > 0)\n\t_gnutls_hmac (&td, ciphertext.data, length);\n\n      mac_deinit (&td, MAC, ver);\n    }\n\n  /* This one was introduced to avoid a timing attack against the TLS\n   * 1.0 protocol.\n   */\n  if (pad_failed != 0)\n    return pad_failed;\n\n  /* HMAC was not the same. \n   */\n  if (memcmp (MAC, &ciphertext.data[length], hash_size) != 0)\n    {\n      gnutls_assert ();\n      return GNUTLS_E_DECRYPTION_FAILED;\n    }\n\n  /* copy the decrypted stuff to compress_data.\n   */\n  if (compress_size < length)\n    {\n      gnutls_assert ();\n      return GNUTLS_E_DECOMPRESSION_FAILED;\n    }\n  memcpy (compress_data, ciphertext.data, length);\n\n  return length;\n}", "target": 1, "cwe": ["CWE-189"], "project": "gnutls", "commit_id": "d223040e498bd50a4b9e0aa493e78587ae1ed653", "hash": 133466176970244054302162994213823627570, "size": 175, "message": "Fix broken debug check for GNUTLS-SA-2008-1."}
{"func": "int get_user_pages(struct task_struct *tsk, struct mm_struct *mm,\n\t\tunsigned long start, int len, int write, int force,\n\t\tstruct page **pages, struct vm_area_struct **vmas)\n{\n\tint i;\n\tunsigned int vm_flags;\n\n\tif (len <= 0)\n\t\treturn 0;\n\t/* \n\t * Require read or write permissions.\n\t * If 'force' is set, we only require the \"MAY\" flags.\n\t */\n\tvm_flags  = write ? (VM_WRITE | VM_MAYWRITE) : (VM_READ | VM_MAYREAD);\n\tvm_flags &= force ? (VM_MAYREAD | VM_MAYWRITE) : (VM_READ | VM_WRITE);\n\ti = 0;\n\n\tdo {\n\t\tstruct vm_area_struct *vma;\n\t\tunsigned int foll_flags;\n\n\t\tvma = find_extend_vma(mm, start);\n\t\tif (!vma && in_gate_area(tsk, start)) {\n\t\t\tunsigned long pg = start & PAGE_MASK;\n\t\t\tstruct vm_area_struct *gate_vma = get_gate_vma(tsk);\n\t\t\tpgd_t *pgd;\n\t\t\tpud_t *pud;\n\t\t\tpmd_t *pmd;\n\t\t\tpte_t *pte;\n\t\t\tif (write) /* user gate pages are read-only */\n\t\t\t\treturn i ? : -EFAULT;\n\t\t\tif (pg > TASK_SIZE)\n\t\t\t\tpgd = pgd_offset_k(pg);\n\t\t\telse\n\t\t\t\tpgd = pgd_offset_gate(mm, pg);\n\t\t\tBUG_ON(pgd_none(*pgd));\n\t\t\tpud = pud_offset(pgd, pg);\n\t\t\tBUG_ON(pud_none(*pud));\n\t\t\tpmd = pmd_offset(pud, pg);\n\t\t\tif (pmd_none(*pmd))\n\t\t\t\treturn i ? : -EFAULT;\n\t\t\tpte = pte_offset_map(pmd, pg);\n\t\t\tif (pte_none(*pte)) {\n\t\t\t\tpte_unmap(pte);\n\t\t\t\treturn i ? : -EFAULT;\n\t\t\t}\n\t\t\tif (pages) {\n\t\t\t\tstruct page *page = vm_normal_page(gate_vma, start, *pte);\n\t\t\t\tpages[i] = page;\n\t\t\t\tif (page)\n\t\t\t\t\tget_page(page);\n\t\t\t}\n\t\t\tpte_unmap(pte);\n\t\t\tif (vmas)\n\t\t\t\tvmas[i] = gate_vma;\n\t\t\ti++;\n\t\t\tstart += PAGE_SIZE;\n\t\t\tlen--;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!vma || (vma->vm_flags & (VM_IO | VM_PFNMAP))\n\t\t\t\t|| !(vm_flags & vma->vm_flags))\n\t\t\treturn i ? : -EFAULT;\n\n\t\tif (is_vm_hugetlb_page(vma)) {\n\t\t\ti = follow_hugetlb_page(mm, vma, pages, vmas,\n\t\t\t\t\t\t&start, &len, i, write);\n\t\t\tcontinue;\n\t\t}\n\n\t\tfoll_flags = FOLL_TOUCH;\n\t\tif (pages)\n\t\t\tfoll_flags |= FOLL_GET;\n\t\tif (!write && !(vma->vm_flags & VM_LOCKED) &&\n\t\t    (!vma->vm_ops || !vma->vm_ops->fault))\n\t\t\tfoll_flags |= FOLL_ANON;\n\n\t\tdo {\n\t\t\tstruct page *page;\n\n\t\t\t/*\n\t\t\t * If tsk is ooming, cut off its access to large memory\n\t\t\t * allocations. It has a pending SIGKILL, but it can't\n\t\t\t * be processed until returning to user space.\n\t\t\t */\n\t\t\tif (unlikely(test_tsk_thread_flag(tsk, TIF_MEMDIE)))\n\t\t\t\treturn -ENOMEM;\n\n\t\t\tif (write)\n\t\t\t\tfoll_flags |= FOLL_WRITE;\n\n\t\t\tcond_resched();\n\t\t\twhile (!(page = follow_page(vma, start, foll_flags))) {\n\t\t\t\tint ret;\n\t\t\t\tret = handle_mm_fault(mm, vma, start,\n\t\t\t\t\t\tfoll_flags & FOLL_WRITE);\n\t\t\t\tif (ret & VM_FAULT_ERROR) {\n\t\t\t\t\tif (ret & VM_FAULT_OOM)\n\t\t\t\t\t\treturn i ? i : -ENOMEM;\n\t\t\t\t\telse if (ret & VM_FAULT_SIGBUS)\n\t\t\t\t\t\treturn i ? i : -EFAULT;\n\t\t\t\t\tBUG();\n\t\t\t\t}\n\t\t\t\tif (ret & VM_FAULT_MAJOR)\n\t\t\t\t\ttsk->maj_flt++;\n\t\t\t\telse\n\t\t\t\t\ttsk->min_flt++;\n\n\t\t\t\t/*\n\t\t\t\t * The VM_FAULT_WRITE bit tells us that\n\t\t\t\t * do_wp_page has broken COW when necessary,\n\t\t\t\t * even if maybe_mkwrite decided not to set\n\t\t\t\t * pte_write. We can thus safely do subsequent\n\t\t\t\t * page lookups as if they were reads.\n\t\t\t\t */\n\t\t\t\tif (ret & VM_FAULT_WRITE)\n\t\t\t\t\tfoll_flags &= ~FOLL_WRITE;\n\n\t\t\t\tcond_resched();\n\t\t\t}\n\t\t\tif (pages) {\n\t\t\t\tpages[i] = page;\n\n\t\t\t\tflush_anon_page(vma, page, start);\n\t\t\t\tflush_dcache_page(page);\n\t\t\t}\n\t\t\tif (vmas)\n\t\t\t\tvmas[i] = vma;\n\t\t\ti++;\n\t\t\tstart += PAGE_SIZE;\n\t\t\tlen--;\n\t\t} while (len && start < vma->vm_end);\n\t} while (len);\n\treturn i;\n}", "target": 1, "cwe": ["CWE-20"], "project": "linux-2.6", "commit_id": "89f5b7da2a6bad2e84670422ab8192382a5aeb9f", "hash": 192373302205049669343839180384526250684, "size": 136, "message": "Reinstate ZERO_PAGE optimization in 'get_user_pages()' and fix XIP\n\nKAMEZAWA Hiroyuki and Oleg Nesterov point out that since the commit\n557ed1fa2620dc119adb86b34c614e152a629a80 (\"remove ZERO_PAGE\") removed\nthe ZERO_PAGE from the VM mappings, any users of get_user_pages() will\ngenerally now populate the VM with real empty pages needlessly.\n\nWe used to get the ZERO_PAGE when we did the \"handle_mm_fault()\", but\nsince fault handling no longer uses ZERO_PAGE for new anonymous pages,\nwe now need to handle that special case in follow_page() instead.\n\nIn particular, the removal of ZERO_PAGE effectively removed the core\nfile writing optimization where we would skip writing pages that had not\nbeen populated at all, and increased memory pressure a lot by allocating\nall those useless newly zeroed pages.\n\nThis reinstates the optimization by making the unmapped PTE case the\nsame as for a non-existent page table, which already did this correctly.\n\nWhile at it, this also fixes the XIP case for follow_page(), where the\ncaller could not differentiate between the case of a page that simply\ncould not be used (because it had no \"struct page\" associated with it)\nand a page that just wasn't mapped.\n\nWe do that by simply returning an error pointer for pages that could not\nbe turned into a \"struct page *\".  The error is arbitrarily picked to be\nEFAULT, since that was what get_user_pages() already used for the\nequivalent IO-mapped page case.\n\n[ Also removed an impossible test for pte_offset_map_lock() failing:\n  that's not how that function works ]\n\nAcked-by: Oleg Nesterov <oleg@tv-sign.ru>\nAcked-by: Nick Piggin <npiggin@suse.de>\nCc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>\nCc: Hugh Dickins <hugh@veritas.com>\nCc: Andrew Morton <akpm@linux-foundation.org>\nCc: Ingo Molnar <mingo@elte.hu>\nCc: Roland McGrath <roland@redhat.com>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "static int do_pages_stat(struct mm_struct *mm, struct page_to_node *pm)\n{\n\tdown_read(&mm->mmap_sem);\n\n\tfor ( ; pm->node != MAX_NUMNODES; pm++) {\n\t\tstruct vm_area_struct *vma;\n\t\tstruct page *page;\n\t\tint err;\n\n\t\terr = -EFAULT;\n\t\tvma = find_vma(mm, pm->addr);\n\t\tif (!vma)\n\t\t\tgoto set_status;\n\n\t\tpage = follow_page(vma, pm->addr, 0);\n\t\terr = -ENOENT;\n\t\t/* Use PageReserved to check for zero page */\n\t\tif (!page || PageReserved(page))\n\t\t\tgoto set_status;\n\n\t\terr = page_to_nid(page);\nset_status:\n\t\tpm->status = err;\n\t}\n\n\tup_read(&mm->mmap_sem);\n\treturn 0;\n}", "target": 1, "cwe": ["CWE-20"], "project": "linux-2.6", "commit_id": "89f5b7da2a6bad2e84670422ab8192382a5aeb9f", "hash": 190691605824195418496832518891413550081, "size": 28, "message": "Reinstate ZERO_PAGE optimization in 'get_user_pages()' and fix XIP\n\nKAMEZAWA Hiroyuki and Oleg Nesterov point out that since the commit\n557ed1fa2620dc119adb86b34c614e152a629a80 (\"remove ZERO_PAGE\") removed\nthe ZERO_PAGE from the VM mappings, any users of get_user_pages() will\ngenerally now populate the VM with real empty pages needlessly.\n\nWe used to get the ZERO_PAGE when we did the \"handle_mm_fault()\", but\nsince fault handling no longer uses ZERO_PAGE for new anonymous pages,\nwe now need to handle that special case in follow_page() instead.\n\nIn particular, the removal of ZERO_PAGE effectively removed the core\nfile writing optimization where we would skip writing pages that had not\nbeen populated at all, and increased memory pressure a lot by allocating\nall those useless newly zeroed pages.\n\nThis reinstates the optimization by making the unmapped PTE case the\nsame as for a non-existent page table, which already did this correctly.\n\nWhile at it, this also fixes the XIP case for follow_page(), where the\ncaller could not differentiate between the case of a page that simply\ncould not be used (because it had no \"struct page\" associated with it)\nand a page that just wasn't mapped.\n\nWe do that by simply returning an error pointer for pages that could not\nbe turned into a \"struct page *\".  The error is arbitrarily picked to be\nEFAULT, since that was what get_user_pages() already used for the\nequivalent IO-mapped page case.\n\n[ Also removed an impossible test for pte_offset_map_lock() failing:\n  that's not how that function works ]\n\nAcked-by: Oleg Nesterov <oleg@tv-sign.ru>\nAcked-by: Nick Piggin <npiggin@suse.de>\nCc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>\nCc: Hugh Dickins <hugh@veritas.com>\nCc: Andrew Morton <akpm@linux-foundation.org>\nCc: Ingo Molnar <mingo@elte.hu>\nCc: Roland McGrath <roland@redhat.com>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "static int do_move_pages(struct mm_struct *mm, struct page_to_node *pm,\n\t\t\t\tint migrate_all)\n{\n\tint err;\n\tstruct page_to_node *pp;\n\tLIST_HEAD(pagelist);\n\n\tdown_read(&mm->mmap_sem);\n\n\t/*\n\t * Build a list of pages to migrate\n\t */\n\tmigrate_prep();\n\tfor (pp = pm; pp->node != MAX_NUMNODES; pp++) {\n\t\tstruct vm_area_struct *vma;\n\t\tstruct page *page;\n\n\t\t/*\n\t\t * A valid page pointer that will not match any of the\n\t\t * pages that will be moved.\n\t\t */\n\t\tpp->page = ZERO_PAGE(0);\n\n\t\terr = -EFAULT;\n\t\tvma = find_vma(mm, pp->addr);\n\t\tif (!vma || !vma_migratable(vma))\n\t\t\tgoto set_status;\n\n\t\tpage = follow_page(vma, pp->addr, FOLL_GET);\n\t\terr = -ENOENT;\n\t\tif (!page)\n\t\t\tgoto set_status;\n\n\t\tif (PageReserved(page))\t\t/* Check for zero page */\n\t\t\tgoto put_and_set;\n\n\t\tpp->page = page;\n\t\terr = page_to_nid(page);\n\n\t\tif (err == pp->node)\n\t\t\t/*\n\t\t\t * Node already in the right place\n\t\t\t */\n\t\t\tgoto put_and_set;\n\n\t\terr = -EACCES;\n\t\tif (page_mapcount(page) > 1 &&\n\t\t\t\t!migrate_all)\n\t\t\tgoto put_and_set;\n\n\t\terr = isolate_lru_page(page, &pagelist);\nput_and_set:\n\t\t/*\n\t\t * Either remove the duplicate refcount from\n\t\t * isolate_lru_page() or drop the page ref if it was\n\t\t * not isolated.\n\t\t */\n\t\tput_page(page);\nset_status:\n\t\tpp->status = err;\n\t}\n\n\tif (!list_empty(&pagelist))\n\t\terr = migrate_pages(&pagelist, new_page_node,\n\t\t\t\t(unsigned long)pm);\n\telse\n\t\terr = -ENOENT;\n\n\tup_read(&mm->mmap_sem);\n\treturn err;\n}", "target": 1, "cwe": ["CWE-20"], "project": "linux-2.6", "commit_id": "89f5b7da2a6bad2e84670422ab8192382a5aeb9f", "hash": 18220699088629601462246906502957374129, "size": 71, "message": "Reinstate ZERO_PAGE optimization in 'get_user_pages()' and fix XIP\n\nKAMEZAWA Hiroyuki and Oleg Nesterov point out that since the commit\n557ed1fa2620dc119adb86b34c614e152a629a80 (\"remove ZERO_PAGE\") removed\nthe ZERO_PAGE from the VM mappings, any users of get_user_pages() will\ngenerally now populate the VM with real empty pages needlessly.\n\nWe used to get the ZERO_PAGE when we did the \"handle_mm_fault()\", but\nsince fault handling no longer uses ZERO_PAGE for new anonymous pages,\nwe now need to handle that special case in follow_page() instead.\n\nIn particular, the removal of ZERO_PAGE effectively removed the core\nfile writing optimization where we would skip writing pages that had not\nbeen populated at all, and increased memory pressure a lot by allocating\nall those useless newly zeroed pages.\n\nThis reinstates the optimization by making the unmapped PTE case the\nsame as for a non-existent page table, which already did this correctly.\n\nWhile at it, this also fixes the XIP case for follow_page(), where the\ncaller could not differentiate between the case of a page that simply\ncould not be used (because it had no \"struct page\" associated with it)\nand a page that just wasn't mapped.\n\nWe do that by simply returning an error pointer for pages that could not\nbe turned into a \"struct page *\".  The error is arbitrarily picked to be\nEFAULT, since that was what get_user_pages() already used for the\nequivalent IO-mapped page case.\n\n[ Also removed an impossible test for pte_offset_map_lock() failing:\n  that's not how that function works ]\n\nAcked-by: Oleg Nesterov <oleg@tv-sign.ru>\nAcked-by: Nick Piggin <npiggin@suse.de>\nCc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>\nCc: Hugh Dickins <hugh@veritas.com>\nCc: Andrew Morton <akpm@linux-foundation.org>\nCc: Ingo Molnar <mingo@elte.hu>\nCc: Roland McGrath <roland@redhat.com>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "static void dump_one_vdso_page(struct page *pg, struct page *upg)\n{\n\tprintk(\"kpg: %p (c:%d,f:%08lx)\", __va(page_to_pfn(pg) << PAGE_SHIFT),\n\t       page_count(pg),\n\t       pg->flags);\n\tif (upg/* && pg != upg*/) {\n\t\tprintk(\" upg: %p (c:%d,f:%08lx)\", __va(page_to_pfn(upg)\n\t\t\t\t\t\t       << PAGE_SHIFT),\n\t\t       page_count(upg),\n\t\t       upg->flags);\n\t}\n\tprintk(\"\\n\");\n}", "target": 1, "cwe": ["CWE-20"], "project": "linux-2.6", "commit_id": "89f5b7da2a6bad2e84670422ab8192382a5aeb9f", "hash": 198053340576165894602613243780199057717, "size": 13, "message": "Reinstate ZERO_PAGE optimization in 'get_user_pages()' and fix XIP\n\nKAMEZAWA Hiroyuki and Oleg Nesterov point out that since the commit\n557ed1fa2620dc119adb86b34c614e152a629a80 (\"remove ZERO_PAGE\") removed\nthe ZERO_PAGE from the VM mappings, any users of get_user_pages() will\ngenerally now populate the VM with real empty pages needlessly.\n\nWe used to get the ZERO_PAGE when we did the \"handle_mm_fault()\", but\nsince fault handling no longer uses ZERO_PAGE for new anonymous pages,\nwe now need to handle that special case in follow_page() instead.\n\nIn particular, the removal of ZERO_PAGE effectively removed the core\nfile writing optimization where we would skip writing pages that had not\nbeen populated at all, and increased memory pressure a lot by allocating\nall those useless newly zeroed pages.\n\nThis reinstates the optimization by making the unmapped PTE case the\nsame as for a non-existent page table, which already did this correctly.\n\nWhile at it, this also fixes the XIP case for follow_page(), where the\ncaller could not differentiate between the case of a page that simply\ncould not be used (because it had no \"struct page\" associated with it)\nand a page that just wasn't mapped.\n\nWe do that by simply returning an error pointer for pages that could not\nbe turned into a \"struct page *\".  The error is arbitrarily picked to be\nEFAULT, since that was what get_user_pages() already used for the\nequivalent IO-mapped page case.\n\n[ Also removed an impossible test for pte_offset_map_lock() failing:\n  that's not how that function works ]\n\nAcked-by: Oleg Nesterov <oleg@tv-sign.ru>\nAcked-by: Nick Piggin <npiggin@suse.de>\nCc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>\nCc: Hugh Dickins <hugh@veritas.com>\nCc: Andrew Morton <akpm@linux-foundation.org>\nCc: Ingo Molnar <mingo@elte.hu>\nCc: Roland McGrath <roland@redhat.com>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "struct page *follow_page(struct vm_area_struct *vma, unsigned long address,\n\t\t\tunsigned int flags)\n{\n\tpgd_t *pgd;\n\tpud_t *pud;\n\tpmd_t *pmd;\n\tpte_t *ptep, pte;\n\tspinlock_t *ptl;\n\tstruct page *page;\n\tstruct mm_struct *mm = vma->vm_mm;\n\n\tpage = follow_huge_addr(mm, address, flags & FOLL_WRITE);\n\tif (!IS_ERR(page)) {\n\t\tBUG_ON(flags & FOLL_GET);\n\t\tgoto out;\n\t}\n\n\tpage = NULL;\n\tpgd = pgd_offset(mm, address);\n\tif (pgd_none(*pgd) || unlikely(pgd_bad(*pgd)))\n\t\tgoto no_page_table;\n\n\tpud = pud_offset(pgd, address);\n\tif (pud_none(*pud) || unlikely(pud_bad(*pud)))\n\t\tgoto no_page_table;\n\t\n\tpmd = pmd_offset(pud, address);\n\tif (pmd_none(*pmd))\n\t\tgoto no_page_table;\n\n\tif (pmd_huge(*pmd)) {\n\t\tBUG_ON(flags & FOLL_GET);\n\t\tpage = follow_huge_pmd(mm, address, pmd, flags & FOLL_WRITE);\n\t\tgoto out;\n\t}\n\n\tif (unlikely(pmd_bad(*pmd)))\n\t\tgoto no_page_table;\n\n\tptep = pte_offset_map_lock(mm, pmd, address, &ptl);\n\tif (!ptep)\n\t\tgoto out;\n\n\tpte = *ptep;\n\tif (!pte_present(pte))\n\t\tgoto unlock;\n\tif ((flags & FOLL_WRITE) && !pte_write(pte))\n\t\tgoto unlock;\n\tpage = vm_normal_page(vma, address, pte);\n\tif (unlikely(!page))\n\t\tgoto unlock;\n\n\tif (flags & FOLL_GET)\n\t\tget_page(page);\n\tif (flags & FOLL_TOUCH) {\n\t\tif ((flags & FOLL_WRITE) &&\n\t\t    !pte_dirty(pte) && !PageDirty(page))\n\t\t\tset_page_dirty(page);\n\t\tmark_page_accessed(page);\n\t}\nunlock:\n\tpte_unmap_unlock(ptep, ptl);\nout:\n\treturn page;\n\nno_page_table:\n\t/*\n\t * When core dumping an enormous anonymous area that nobody\n\t * has touched so far, we don't want to allocate page tables.\n\t */\n\tif (flags & FOLL_ANON) {\n\t\tpage = ZERO_PAGE(0);\n\t\tif (flags & FOLL_GET)\n\t\t\tget_page(page);\n\t\tBUG_ON(flags & FOLL_WRITE);\n\t}\n\treturn page;\n}", "target": 1, "cwe": ["CWE-20"], "project": "linux-2.6", "commit_id": "89f5b7da2a6bad2e84670422ab8192382a5aeb9f", "hash": 210867550916712742645262184349384453522, "size": 78, "message": "Reinstate ZERO_PAGE optimization in 'get_user_pages()' and fix XIP\n\nKAMEZAWA Hiroyuki and Oleg Nesterov point out that since the commit\n557ed1fa2620dc119adb86b34c614e152a629a80 (\"remove ZERO_PAGE\") removed\nthe ZERO_PAGE from the VM mappings, any users of get_user_pages() will\ngenerally now populate the VM with real empty pages needlessly.\n\nWe used to get the ZERO_PAGE when we did the \"handle_mm_fault()\", but\nsince fault handling no longer uses ZERO_PAGE for new anonymous pages,\nwe now need to handle that special case in follow_page() instead.\n\nIn particular, the removal of ZERO_PAGE effectively removed the core\nfile writing optimization where we would skip writing pages that had not\nbeen populated at all, and increased memory pressure a lot by allocating\nall those useless newly zeroed pages.\n\nThis reinstates the optimization by making the unmapped PTE case the\nsame as for a non-existent page table, which already did this correctly.\n\nWhile at it, this also fixes the XIP case for follow_page(), where the\ncaller could not differentiate between the case of a page that simply\ncould not be used (because it had no \"struct page\" associated with it)\nand a page that just wasn't mapped.\n\nWe do that by simply returning an error pointer for pages that could not\nbe turned into a \"struct page *\".  The error is arbitrarily picked to be\nEFAULT, since that was what get_user_pages() already used for the\nequivalent IO-mapped page case.\n\n[ Also removed an impossible test for pte_offset_map_lock() failing:\n  that's not how that function works ]\n\nAcked-by: Oleg Nesterov <oleg@tv-sign.ru>\nAcked-by: Nick Piggin <npiggin@suse.de>\nCc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>\nCc: Hugh Dickins <hugh@veritas.com>\nCc: Andrew Morton <akpm@linux-foundation.org>\nCc: Ingo Molnar <mingo@elte.hu>\nCc: Roland McGrath <roland@redhat.com>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "int get_user_pages(struct task_struct *tsk, struct mm_struct *mm,\n\t\tunsigned long start, int len, int write, int force,\n\t\tstruct page **pages, struct vm_area_struct **vmas)\n{\n\tint i;\n\tunsigned int vm_flags;\n\n\tif (len <= 0)\n\t\treturn 0;\n\t/* \n\t * Require read or write permissions.\n\t * If 'force' is set, we only require the \"MAY\" flags.\n\t */\n\tvm_flags  = write ? (VM_WRITE | VM_MAYWRITE) : (VM_READ | VM_MAYREAD);\n\tvm_flags &= force ? (VM_MAYREAD | VM_MAYWRITE) : (VM_READ | VM_WRITE);\n\ti = 0;\n\n\tdo {\n\t\tstruct vm_area_struct *vma;\n\t\tunsigned int foll_flags;\n\n\t\tvma = find_extend_vma(mm, start);\n\t\tif (!vma && in_gate_area(tsk, start)) {\n\t\t\tunsigned long pg = start & PAGE_MASK;\n\t\t\tstruct vm_area_struct *gate_vma = get_gate_vma(tsk);\n\t\t\tpgd_t *pgd;\n\t\t\tpud_t *pud;\n\t\t\tpmd_t *pmd;\n\t\t\tpte_t *pte;\n\t\t\tif (write) /* user gate pages are read-only */\n\t\t\t\treturn i ? : -EFAULT;\n\t\t\tif (pg > TASK_SIZE)\n\t\t\t\tpgd = pgd_offset_k(pg);\n\t\t\telse\n\t\t\t\tpgd = pgd_offset_gate(mm, pg);\n\t\t\tBUG_ON(pgd_none(*pgd));\n\t\t\tpud = pud_offset(pgd, pg);\n\t\t\tBUG_ON(pud_none(*pud));\n\t\t\tpmd = pmd_offset(pud, pg);\n\t\t\tif (pmd_none(*pmd))\n\t\t\t\treturn i ? : -EFAULT;\n\t\t\tpte = pte_offset_map(pmd, pg);\n\t\t\tif (pte_none(*pte)) {\n\t\t\t\tpte_unmap(pte);\n\t\t\t\treturn i ? : -EFAULT;\n\t\t\t}\n\t\t\tif (pages) {\n\t\t\t\tstruct page *page = vm_normal_page(gate_vma, start, *pte);\n\t\t\t\tpages[i] = page;\n\t\t\t\tif (page)\n\t\t\t\t\tget_page(page);\n\t\t\t}\n\t\t\tpte_unmap(pte);\n\t\t\tif (vmas)\n\t\t\t\tvmas[i] = gate_vma;\n\t\t\ti++;\n\t\t\tstart += PAGE_SIZE;\n\t\t\tlen--;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!vma || (vma->vm_flags & (VM_IO | VM_PFNMAP))\n\t\t\t\t|| !(vm_flags & vma->vm_flags))\n\t\t\treturn i ? : -EFAULT;\n\n\t\tif (is_vm_hugetlb_page(vma)) {\n\t\t\ti = follow_hugetlb_page(mm, vma, pages, vmas,\n\t\t\t\t\t\t&start, &len, i, write);\n\t\t\tcontinue;\n\t\t}\n\n\t\tfoll_flags = FOLL_TOUCH;\n\t\tif (pages)\n\t\t\tfoll_flags |= FOLL_GET;\n\t\tif (!write && !(vma->vm_flags & VM_LOCKED) &&\n\t\t    (!vma->vm_ops || !vma->vm_ops->fault))\n\t\t\tfoll_flags |= FOLL_ANON;\n\n\t\tdo {\n\t\t\tstruct page *page;\n\n\t\t\t/*\n\t\t\t * If tsk is ooming, cut off its access to large memory\n\t\t\t * allocations. It has a pending SIGKILL, but it can't\n\t\t\t * be processed until returning to user space.\n\t\t\t */\n\t\t\tif (unlikely(test_tsk_thread_flag(tsk, TIF_MEMDIE)))\n\t\t\t\treturn -ENOMEM;\n\n\t\t\tif (write)\n\t\t\t\tfoll_flags |= FOLL_WRITE;\n\n\t\t\tcond_resched();\n\t\t\twhile (!(page = follow_page(vma, start, foll_flags))) {\n\t\t\t\tint ret;\n\t\t\t\tret = handle_mm_fault(mm, vma, start,\n\t\t\t\t\t\tfoll_flags & FOLL_WRITE);\n\t\t\t\tif (ret & VM_FAULT_ERROR) {\n\t\t\t\t\tif (ret & VM_FAULT_OOM)\n\t\t\t\t\t\treturn i ? i : -ENOMEM;\n\t\t\t\t\telse if (ret & VM_FAULT_SIGBUS)\n\t\t\t\t\t\treturn i ? i : -EFAULT;\n\t\t\t\t\tBUG();\n\t\t\t\t}\n\t\t\t\tif (ret & VM_FAULT_MAJOR)\n\t\t\t\t\ttsk->maj_flt++;\n\t\t\t\telse\n\t\t\t\t\ttsk->min_flt++;\n\n\t\t\t\t/*\n\t\t\t\t * The VM_FAULT_WRITE bit tells us that\n\t\t\t\t * do_wp_page has broken COW when necessary,\n\t\t\t\t * even if maybe_mkwrite decided not to set\n\t\t\t\t * pte_write. We can thus safely do subsequent\n\t\t\t\t * page lookups as if they were reads.\n\t\t\t\t */\n\t\t\t\tif (ret & VM_FAULT_WRITE)\n\t\t\t\t\tfoll_flags &= ~FOLL_WRITE;\n\n\t\t\t\tcond_resched();\n\t\t\t}\n\t\t\tif (IS_ERR(page))\n\t\t\t\treturn i ? i : PTR_ERR(page);\n\t\t\tif (pages) {\n\t\t\t\tpages[i] = page;\n\n\t\t\t\tflush_anon_page(vma, page, start);\n\t\t\t\tflush_dcache_page(page);\n\t\t\t}\n\t\t\tif (vmas)\n\t\t\t\tvmas[i] = vma;\n\t\t\ti++;\n\t\t\tstart += PAGE_SIZE;\n\t\t\tlen--;\n\t\t} while (len && start < vma->vm_end);\n\t} while (len);\n\treturn i;\n}", "target": 1, "cwe": ["CWE-20"], "project": "linux-2.6", "commit_id": "672ca28e300c17bf8d792a2a7a8631193e580c74", "hash": 139010725753363214663812040837173395590, "size": 138, "message": "Fix ZERO_PAGE breakage with vmware\n\nCommit 89f5b7da2a6bad2e84670422ab8192382a5aeb9f (\"Reinstate ZERO_PAGE\noptimization in 'get_user_pages()' and fix XIP\") broke vmware, as\nreported by Jeff Chua:\n\n  \"This broke vmware 6.0.4.\n   Jun 22 14:53:03.845: vmx| NOT_IMPLEMENTED\n   /build/mts/release/bora-93057/bora/vmx/main/vmmonPosix.c:774\"\n\nand the reason seems to be that there's an old bug in how we handle do\nFOLL_ANON on VM_SHARED areas in get_user_pages(), but since it only\ntriggered if the whole page table was missing, nobody had apparently hit\nit before.\n\nThe recent changes to 'follow_page()' made the FOLL_ANON logic trigger\nnot just for whole missing page tables, but for individual pages as\nwell, and exposed this problem.\n\nThis fixes it by making the test for when FOLL_ANON is used more\ncareful, and also makes the code easier to read and understand by moving\nthe logic to a separate inline function.\n\nReported-and-tested-by: Jeff Chua <jeff.chua.linux@gmail.com>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "static int do_change_type(struct nameidata *nd, int flag)\n{\n\tstruct vfsmount *m, *mnt = nd->mnt;\n\tint recurse = flag & MS_REC;\n\tint type = flag & ~MS_REC;\n\n\tif (nd->dentry != nd->mnt->mnt_root)\n\t\treturn -EINVAL;\n\n\tdown_write(&namespace_sem);\n\tspin_lock(&vfsmount_lock);\n\tfor (m = mnt; m; m = (recurse ? next_mnt(m, mnt) : NULL))\n\t\tchange_mnt_propagation(m, type);\n\tspin_unlock(&vfsmount_lock);\n\tup_write(&namespace_sem);\n\treturn 0;\n}", "target": 1, "cwe": ["CWE-269"], "project": "linux-2.6", "commit_id": "ee6f958291e2a768fd727e7a67badfff0b67711a", "hash": 286192975191664146611435120749571622707, "size": 17, "message": "check privileges before setting mount propagation\n\nThere's a missing check for CAP_SYS_ADMIN in do_change_type().\n\nSigned-off-by: Miklos Szeredi <mszeredi@suse.cz>\nCc: Al Viro <viro@zeniv.linux.org.uk>\nCc: Christoph Hellwig <hch@lst.de>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "int udp_get_port(struct sock *sk, unsigned short snum,\n\t\t\tint (*scmp)(const struct sock *, const struct sock *))\n{\n\treturn  __udp_lib_get_port(sk, snum, udp_hash, &udp_port_rover, scmp);\n}", "target": 1, "cwe": [], "project": "linux-2.6", "commit_id": "32c1da70810017a98aa6c431a5494a302b6b9a30", "hash": 275970421660632915992664670799860183687, "size": 5, "message": "[UDP]: Randomize port selection.\n\nThis patch causes UDP port allocation to be randomized like TCP.\nThe earlier code would always choose same port (ie first empty list).\n\nSigned-off-by: Stephen Hemminger <shemminger@linux-foundation.org>\nSigned-off-by: David S. Miller <davem@davemloft.net>"}
{"func": "int udplite_get_port(struct sock *sk, unsigned short p,\n\t\t     int (*c)(const struct sock *, const struct sock *))\n{\n\treturn  __udp_lib_get_port(sk, p, udplite_hash, &udplite_port_rover, c);\n}", "target": 1, "cwe": [], "project": "linux-2.6", "commit_id": "32c1da70810017a98aa6c431a5494a302b6b9a30", "hash": 251875682803410308601689328159301471717, "size": 5, "message": "[UDP]: Randomize port selection.\n\nThis patch causes UDP port allocation to be randomized like TCP.\nThe earlier code would always choose same port (ie first empty list).\n\nSigned-off-by: Stephen Hemminger <shemminger@linux-foundation.org>\nSigned-off-by: David S. Miller <davem@davemloft.net>"}
{"func": "int __udp_lib_get_port(struct sock *sk, unsigned short snum,\n\t\t       struct hlist_head udptable[], int *port_rover,\n\t\t       int (*saddr_comp)(const struct sock *sk1,\n\t\t\t\t\t const struct sock *sk2 )    )\n{\n\tstruct hlist_node *node;\n\tstruct hlist_head *head;\n\tstruct sock *sk2;\n\tint    error = 1;\n\n\twrite_lock_bh(&udp_hash_lock);\n\tif (snum == 0) {\n\t\tint best_size_so_far, best, result, i;\n\n\t\tif (*port_rover > sysctl_local_port_range[1] ||\n\t\t    *port_rover < sysctl_local_port_range[0])\n\t\t\t*port_rover = sysctl_local_port_range[0];\n\t\tbest_size_so_far = 32767;\n\t\tbest = result = *port_rover;\n\t\tfor (i = 0; i < UDP_HTABLE_SIZE; i++, result++) {\n\t\t\tint size;\n\n\t\t\thead = &udptable[result & (UDP_HTABLE_SIZE - 1)];\n\t\t\tif (hlist_empty(head)) {\n\t\t\t\tif (result > sysctl_local_port_range[1])\n\t\t\t\t\tresult = sysctl_local_port_range[0] +\n\t\t\t\t\t\t((result - sysctl_local_port_range[0]) &\n\t\t\t\t\t\t (UDP_HTABLE_SIZE - 1));\n\t\t\t\tgoto gotit;\n\t\t\t}\n\t\t\tsize = 0;\n\t\t\tsk_for_each(sk2, node, head) {\n\t\t\t\tif (++size >= best_size_so_far)\n\t\t\t\t\tgoto next;\n\t\t\t}\n\t\t\tbest_size_so_far = size;\n\t\t\tbest = result;\n\t\tnext:\n\t\t\t;\n\t\t}\n\t\tresult = best;\n\t\tfor (i = 0; i < (1 << 16) / UDP_HTABLE_SIZE;\n\t\t     i++, result += UDP_HTABLE_SIZE) {\n\t\t\tif (result > sysctl_local_port_range[1])\n\t\t\t\tresult = sysctl_local_port_range[0]\n\t\t\t\t\t+ ((result - sysctl_local_port_range[0]) &\n\t\t\t\t\t   (UDP_HTABLE_SIZE - 1));\n\t\t\tif (! __udp_lib_lport_inuse(result, udptable))\n\t\t\t\tbreak;\n\t\t}\n\t\tif (i >= (1 << 16) / UDP_HTABLE_SIZE)\n\t\t\tgoto fail;\ngotit:\n\t\t*port_rover = snum = result;\n\t} else {\n\t\thead = &udptable[snum & (UDP_HTABLE_SIZE - 1)];\n\n\t\tsk_for_each(sk2, node, head)\n\t\t\tif (sk2->sk_hash == snum                             &&\n\t\t\t    sk2 != sk                                        &&\n\t\t\t    (!sk2->sk_reuse        || !sk->sk_reuse)         &&\n\t\t\t    (!sk2->sk_bound_dev_if || !sk->sk_bound_dev_if\n\t\t\t     || sk2->sk_bound_dev_if == sk->sk_bound_dev_if) &&\n\t\t\t    (*saddr_comp)(sk, sk2)                             )\n\t\t\t\tgoto fail;\n\t}\n\tinet_sk(sk)->num = snum;\n\tsk->sk_hash = snum;\n\tif (sk_unhashed(sk)) {\n\t\thead = &udptable[snum & (UDP_HTABLE_SIZE - 1)];\n\t\tsk_add_node(sk, head);\n\t\tsock_prot_inc_use(sk->sk_prot);\n\t}\n\terror = 0;\nfail:\n\twrite_unlock_bh(&udp_hash_lock);\n\treturn error;\n}", "target": 1, "cwe": [], "project": "linux-2.6", "commit_id": "32c1da70810017a98aa6c431a5494a302b6b9a30", "hash": 203541452275097511036718495362639492064, "size": 78, "message": "[UDP]: Randomize port selection.\n\nThis patch causes UDP port allocation to be randomized like TCP.\nThe earlier code would always choose same port (ie first empty list).\n\nSigned-off-by: Stephen Hemminger <shemminger@linux-foundation.org>\nSigned-off-by: David S. Miller <davem@davemloft.net>"}
{"func": "static inline int __udp_lib_lport_inuse(__u16 num, struct hlist_head udptable[])\n{\n\tstruct sock *sk;\n\tstruct hlist_node *node;\n\n\tsk_for_each(sk, node, &udptable[num & (UDP_HTABLE_SIZE - 1)])\n\t\tif (sk->sk_hash == num)\n\t\t\treturn 1;\n\treturn 0;\n}", "target": 1, "cwe": [], "project": "linux-2.6", "commit_id": "32c1da70810017a98aa6c431a5494a302b6b9a30", "hash": 227489957878901417285044484110058943296, "size": 10, "message": "[UDP]: Randomize port selection.\n\nThis patch causes UDP port allocation to be randomized like TCP.\nThe earlier code would always choose same port (ie first empty list).\n\nSigned-off-by: Stephen Hemminger <shemminger@linux-foundation.org>\nSigned-off-by: David S. Miller <davem@davemloft.net>"}
{"func": "static inline void native_set_ldt(const void *addr, unsigned int entries)\n{\n\tif (likely(entries == 0))\n\t\tasm volatile(\"lldt %w0\"::\"q\" (0));\n\telse {\n\t\tunsigned cpu = smp_processor_id();\n\t\tldt_desc ldt;\n\n\t\tset_tssldt_descriptor(&ldt, (unsigned long)addr,\n\t\t\t\t      DESC_LDT, entries * sizeof(ldt) - 1);\n\t\twrite_gdt_entry(get_cpu_gdt_table(cpu), GDT_ENTRY_LDT,\n\t\t\t\t&ldt, DESC_LDT);\n\t\tasm volatile(\"lldt %w0\"::\"q\" (GDT_ENTRY_LDT*8));\n\t}\n}", "target": 1, "cwe": ["CWE-119"], "project": "linux-2.6", "commit_id": "5ac37f87ff18843aabab84cf75b2f8504c2d81fe", "hash": 201156650941371891932740762763197038172, "size": 15, "message": "x86: fix ldt limit for 64 bit\n\nFix size of LDT entries. On x86-64, ldt_desc is a double-sized descriptor.\n\nSigned-off-by: Michael Karcher <kernel@mkarcher.dialup.fu-berlin.de>\nSigned-off-by: Ingo Molnar <mingo@elte.hu>"}
{"func": "shmem_get_inode(struct super_block *sb, int mode, dev_t dev)\n{\n\tstruct inode *inode;\n\tstruct shmem_inode_info *info;\n\tstruct shmem_sb_info *sbinfo = SHMEM_SB(sb);\n\n\tif (shmem_reserve_inode(sb))\n\t\treturn NULL;\n\n\tinode = new_inode(sb);\n\tif (inode) {\n\t\tinode->i_mode = mode;\n\t\tinode->i_uid = current->fsuid;\n\t\tinode->i_gid = current->fsgid;\n\t\tinode->i_blocks = 0;\n\t\tinode->i_mapping->a_ops = &shmem_aops;\n\t\tinode->i_mapping->backing_dev_info = &shmem_backing_dev_info;\n\t\tinode->i_atime = inode->i_mtime = inode->i_ctime = CURRENT_TIME;\n\t\tinode->i_generation = get_seconds();\n\t\tinfo = SHMEM_I(inode);\n\t\tmemset(info, 0, (char *)inode - (char *)info);\n\t\tspin_lock_init(&info->lock);\n\t\tINIT_LIST_HEAD(&info->swaplist);\n\n\t\tswitch (mode & S_IFMT) {\n\t\tdefault:\n\t\t\tinode->i_op = &shmem_special_inode_operations;\n\t\t\tinit_special_inode(inode, mode, dev);\n\t\t\tbreak;\n\t\tcase S_IFREG:\n\t\t\tinode->i_op = &shmem_inode_operations;\n\t\t\tinode->i_fop = &shmem_file_operations;\n\t\t\tmpol_shared_policy_init(&info->policy,\n\t\t\t\t\t\t shmem_get_sbmpol(sbinfo));\n\t\t\tbreak;\n\t\tcase S_IFDIR:\n\t\t\tinc_nlink(inode);\n\t\t\t/* Some things misbehave if size == 0 on a directory */\n\t\t\tinode->i_size = 2 * BOGO_DIRENT_SIZE;\n\t\t\tinode->i_op = &shmem_dir_inode_operations;\n\t\t\tinode->i_fop = &simple_dir_operations;\n\t\t\tbreak;\n\t\tcase S_IFLNK:\n\t\t\t/*\n\t\t\t * Must not load anything in the rbtree,\n\t\t\t * mpol_free_shared_policy will not be called.\n\t\t\t */\n\t\t\tmpol_shared_policy_init(&info->policy, NULL);\n\t\t\tbreak;\n\t\t}\n\t} else\n\t\tshmem_free_inode(sb);\n\treturn inode;\n}", "target": 1, "cwe": ["CWE-400"], "project": "linux-2.6", "commit_id": "14fcc23fdc78e9d32372553ccf21758a9bd56fa1", "hash": 191822221605702952187300311435824960255, "size": 54, "message": "tmpfs: fix kernel BUG in shmem_delete_inode\n\nSuSE's insserve initscript ordering program hits kernel BUG at mm/shmem.c:814\non 2.6.26.  It's using posix_fadvise on directories, and the shmem_readpage\nmethod added in 2.6.23 is letting POSIX_FADV_WILLNEED allocate useless pages\nto a tmpfs directory, incrementing i_blocks count but never decrementing it.\n\nFix this by assigning shmem_aops (pointing to readpage and writepage and\nset_page_dirty) only when it's needed, on a regular file or a long symlink.\n\nMany thanks to Kel for outstanding bugreport and steps to reproduce it.\n\nReported-by: Kel Modderman <kel@otaku42.de>\nTested-by: Kel Modderman <kel@otaku42.de>\nSigned-off-by: Hugh Dickins <hugh@veritas.com>\nCc: <stable@kernel.org>\t\t[2.6.25.x, 2.6.26.x]\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "static int shmem_symlink(struct inode *dir, struct dentry *dentry, const char *symname)\n{\n\tint error;\n\tint len;\n\tstruct inode *inode;\n\tstruct page *page = NULL;\n\tchar *kaddr;\n\tstruct shmem_inode_info *info;\n\n\tlen = strlen(symname) + 1;\n\tif (len > PAGE_CACHE_SIZE)\n\t\treturn -ENAMETOOLONG;\n\n\tinode = shmem_get_inode(dir->i_sb, S_IFLNK|S_IRWXUGO, 0);\n\tif (!inode)\n\t\treturn -ENOSPC;\n\n\terror = security_inode_init_security(inode, dir, NULL, NULL,\n\t\t\t\t\t     NULL);\n\tif (error) {\n\t\tif (error != -EOPNOTSUPP) {\n\t\t\tiput(inode);\n\t\t\treturn error;\n\t\t}\n\t\terror = 0;\n\t}\n\n\tinfo = SHMEM_I(inode);\n\tinode->i_size = len-1;\n\tif (len <= (char *)inode - (char *)info) {\n\t\t/* do it inline */\n\t\tmemcpy(info, symname, len);\n\t\tinode->i_op = &shmem_symlink_inline_operations;\n\t} else {\n\t\terror = shmem_getpage(inode, 0, &page, SGP_WRITE, NULL);\n\t\tif (error) {\n\t\t\tiput(inode);\n\t\t\treturn error;\n\t\t}\n\t\tunlock_page(page);\n\t\tinode->i_op = &shmem_symlink_inode_operations;\n\t\tkaddr = kmap_atomic(page, KM_USER0);\n\t\tmemcpy(kaddr, symname, len);\n\t\tkunmap_atomic(kaddr, KM_USER0);\n\t\tset_page_dirty(page);\n\t\tpage_cache_release(page);\n\t}\n\tif (dir->i_mode & S_ISGID)\n\t\tinode->i_gid = dir->i_gid;\n\tdir->i_size += BOGO_DIRENT_SIZE;\n\tdir->i_ctime = dir->i_mtime = CURRENT_TIME;\n\td_instantiate(dentry, inode);\n\tdget(dentry);\n\treturn 0;\n}", "target": 1, "cwe": ["CWE-400"], "project": "linux-2.6", "commit_id": "14fcc23fdc78e9d32372553ccf21758a9bd56fa1", "hash": 266120824639631291487771165811942379940, "size": 55, "message": "tmpfs: fix kernel BUG in shmem_delete_inode\n\nSuSE's insserve initscript ordering program hits kernel BUG at mm/shmem.c:814\non 2.6.26.  It's using posix_fadvise on directories, and the shmem_readpage\nmethod added in 2.6.23 is letting POSIX_FADV_WILLNEED allocate useless pages\nto a tmpfs directory, incrementing i_blocks count but never decrementing it.\n\nFix this by assigning shmem_aops (pointing to readpage and writepage and\nset_page_dirty) only when it's needed, on a regular file or a long symlink.\n\nMany thanks to Kel for outstanding bugreport and steps to reproduce it.\n\nReported-by: Kel Modderman <kel@otaku42.de>\nTested-by: Kel Modderman <kel@otaku42.de>\nSigned-off-by: Hugh Dickins <hugh@veritas.com>\nCc: <stable@kernel.org>\t\t[2.6.25.x, 2.6.26.x]\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "void iov_iter_advance(struct iov_iter *i, size_t bytes)\n{\n\tBUG_ON(i->count < bytes);\n\n\tif (likely(i->nr_segs == 1)) {\n\t\ti->iov_offset += bytes;\n\t\ti->count -= bytes;\n\t} else {\n\t\tconst struct iovec *iov = i->iov;\n\t\tsize_t base = i->iov_offset;\n\n\t\t/*\n\t\t * The !iov->iov_len check ensures we skip over unlikely\n\t\t * zero-length segments (without overruning the iovec).\n\t\t */\n\t\twhile (bytes || unlikely(!iov->iov_len && i->count)) {\n\t\t\tint copy;\n\n\t\t\tcopy = min(bytes, iov->iov_len - base);\n\t\t\tBUG_ON(!i->count || i->count < copy);\n\t\t\ti->count -= copy;\n\t\t\tbytes -= copy;\n\t\t\tbase += copy;\n\t\t\tif (iov->iov_len == base) {\n\t\t\t\tiov++;\n\t\t\t\tbase = 0;\n\t\t\t}\n\t\t}\n\t\ti->iov = iov;\n\t\ti->iov_offset = base;\n\t}\n}", "target": 1, "cwe": ["CWE-193"], "project": "linux-2.6", "commit_id": "94ad374a0751f40d25e22e036c37f7263569d24c", "hash": 175485022128206961019473290671619525643, "size": 32, "message": "Fix off-by-one error in iov_iter_advance()\n\nThe iov_iter_advance() function would look at the iov->iov_len entry\neven though it might have iterated over the whole array, and iov was\npointing past the end.  This would cause DEBUG_PAGEALLOC to trigger a\nkernel page fault if the allocation was at the end of a page, and the\nnext page was unallocated.\n\nThe quick fix is to just change the order of the tests: check that there\nis any iovec data left before we check the iov entry itself.\n\nThanks to Alexey Dobriyan for finding this case, and testing the fix.\n\nReported-and-tested-by: Alexey Dobriyan <adobriyan@gmail.com>\nCc: Nick Piggin <npiggin@suse.de>\nCc: Andrew Morton <akpm@linux-foundation.org>\nCc: <stable@kernel.org> [2.6.25.x, 2.6.26.x]\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "void __cpuinit cpu_init (void)\n{\n\tint cpu = stack_smp_processor_id();\n\tstruct tss_struct *t = &per_cpu(init_tss, cpu);\n\tstruct orig_ist *orig_ist = &per_cpu(orig_ist, cpu);\n\tunsigned long v; \n\tchar *estacks = NULL; \n\tstruct task_struct *me;\n\tint i;\n\n\t/* CPU 0 is initialised in head64.c */\n\tif (cpu != 0) {\n\t\tpda_init(cpu);\n\t\tzap_low_mappings(cpu);\n\t} else \n\t\testacks = boot_exception_stacks; \n\n\tme = current;\n\n\tif (cpu_test_and_set(cpu, cpu_initialized))\n\t\tpanic(\"CPU#%d already initialized!\\n\", cpu);\n\n\tprintk(\"Initializing CPU#%d\\n\", cpu);\n\n\tclear_in_cr4(X86_CR4_VME|X86_CR4_PVI|X86_CR4_TSD|X86_CR4_DE);\n\n\t/*\n\t * Initialize the per-CPU GDT with the boot GDT,\n\t * and set up the GDT descriptor:\n\t */\n\tif (cpu)\n \t\tmemcpy(cpu_gdt(cpu), cpu_gdt_table, GDT_SIZE);\n\n\tcpu_gdt_descr[cpu].size = GDT_SIZE;\n\tasm volatile(\"lgdt %0\" :: \"m\" (cpu_gdt_descr[cpu]));\n\tasm volatile(\"lidt %0\" :: \"m\" (idt_descr));\n\n\tmemset(me->thread.tls_array, 0, GDT_ENTRY_TLS_ENTRIES * 8);\n\tsyscall_init();\n\n\twrmsrl(MSR_FS_BASE, 0);\n\twrmsrl(MSR_KERNEL_GS_BASE, 0);\n\tbarrier(); \n\n\tcheck_efer();\n\n\t/*\n\t * set up and load the per-CPU TSS\n\t */\n\tfor (v = 0; v < N_EXCEPTION_STACKS; v++) {\n\t\tstatic const unsigned int order[N_EXCEPTION_STACKS] = {\n\t\t\t[0 ... N_EXCEPTION_STACKS - 1] = EXCEPTION_STACK_ORDER,\n\t\t\t[DEBUG_STACK - 1] = DEBUG_STACK_ORDER\n\t\t};\n\t\tif (cpu) {\n\t\t\testacks = (char *)__get_free_pages(GFP_ATOMIC, order[v]);\n\t\t\tif (!estacks)\n\t\t\t\tpanic(\"Cannot allocate exception stack %ld %d\\n\",\n\t\t\t\t      v, cpu); \n\t\t}\n\t\testacks += PAGE_SIZE << order[v];\n\t\torig_ist->ist[v] = t->ist[v] = (unsigned long)estacks;\n\t}\n\n\tt->io_bitmap_base = offsetof(struct tss_struct, io_bitmap);\n\t/*\n\t * <= is required because the CPU will access up to\n\t * 8 bits beyond the end of the IO permission bitmap.\n\t */\n\tfor (i = 0; i <= IO_BITMAP_LONGS; i++)\n\t\tt->io_bitmap[i] = ~0UL;\n\n\tatomic_inc(&init_mm.mm_count);\n\tme->active_mm = &init_mm;\n\tif (me->mm)\n\t\tBUG();\n\tenter_lazy_tlb(&init_mm, me);\n\n\tset_tss_desc(cpu, t);\n\tload_TR_desc();\n\tload_LDT(&init_mm.context);\n\n\t/*\n\t * Clear all 6 debug registers:\n\t */\n\n\tset_debugreg(0UL, 0);\n\tset_debugreg(0UL, 1);\n\tset_debugreg(0UL, 2);\n\tset_debugreg(0UL, 3);\n\tset_debugreg(0UL, 6);\n\tset_debugreg(0UL, 7);\n\n\tfpu_init(); \n}", "target": 1, "cwe": [], "project": "linux-2.6", "commit_id": "658fdbef66e5e9be79b457edc2cbbb3add840aa9", "hash": 221407552807869822177652012963063257933, "size": 95, "message": "[PATCH] Don't leak NT bit into next task\n\nSYSENTER can cause a NT to be set which might cause crashes on the IRET\nin the next task.\n\nFollowing similar i386 patch from Linus.\n\nSigned-off-by: Andi Kleen <ak@suse.de>"}
{"func": "static struct dentry * real_lookup(struct dentry * parent, struct qstr * name, struct nameidata *nd)\n{\n\tstruct dentry * result;\n\tstruct inode *dir = parent->d_inode;\n\n\tmutex_lock(&dir->i_mutex);\n\t/*\n\t * First re-do the cached lookup just in case it was created\n\t * while we waited for the directory semaphore..\n\t *\n\t * FIXME! This could use version numbering or similar to\n\t * avoid unnecessary cache lookups.\n\t *\n\t * The \"dcache_lock\" is purely to protect the RCU list walker\n\t * from concurrent renames at this point (we mustn't get false\n\t * negatives from the RCU list walk here, unlike the optimistic\n\t * fast walk).\n\t *\n\t * so doing d_lookup() (with seqlock), instead of lockfree __d_lookup\n\t */\n\tresult = d_lookup(parent, name);\n\tif (!result) {\n\t\tstruct dentry * dentry = d_alloc(parent, name);\n\t\tresult = ERR_PTR(-ENOMEM);\n\t\tif (dentry) {\n\t\t\tresult = dir->i_op->lookup(dir, dentry, nd);\n\t\t\tif (result)\n\t\t\t\tdput(dentry);\n\t\t\telse\n\t\t\t\tresult = dentry;\n\t\t}\n\t\tmutex_unlock(&dir->i_mutex);\n\t\treturn result;\n\t}\n\n\t/*\n\t * Uhhuh! Nasty case: the cache was re-populated while\n\t * we waited on the semaphore. Need to revalidate.\n\t */\n\tmutex_unlock(&dir->i_mutex);\n\tif (result->d_op && result->d_op->d_revalidate) {\n\t\tresult = do_revalidate(result, nd);\n\t\tif (!result)\n\t\t\tresult = ERR_PTR(-ENOENT);\n\t}\n\treturn result;\n}", "target": 1, "cwe": ["CWE-120"], "project": "linux-2.6", "commit_id": "d70b67c8bc72ee23b55381bd6a884f4796692f77", "hash": 146062967520408128878566719995370385746, "size": 47, "message": "[patch] vfs: fix lookup on deleted directory\n\nLookup can install a child dentry for a deleted directory.  This keeps\nthe directory dentry alive, and the inode pinned in the cache and on\ndisk, even after all external references have gone away.\n\nThis isn't a big problem normally, since memory pressure or umount\nwill clear out the directory dentry and its children, releasing the\ninode.  But for UBIFS this causes problems because its orphan area can\noverflow.\n\nFix this by returning ENOENT for all lookups on a S_DEAD directory\nbefore creating a child dentry.\n\nThanks to Zoltan Sogor for noticing this while testing UBIFS, and\nArtem for the excellent analysis of the problem and testing.\n\nReported-by: Artem Bityutskiy <Artem.Bityutskiy@nokia.com>\nTested-by: Artem Bityutskiy <Artem.Bityutskiy@nokia.com>\nSigned-off-by: Miklos Szeredi <mszeredi@suse.cz>\nSigned-off-by: Al Viro <viro@zeniv.linux.org.uk>"}
{"func": "static struct dentry *__lookup_hash(struct qstr *name,\n\t\tstruct dentry *base, struct nameidata *nd)\n{\n\tstruct dentry *dentry;\n\tstruct inode *inode;\n\tint err;\n\n\tinode = base->d_inode;\n\n\t/*\n\t * See if the low-level filesystem might want\n\t * to use its own hash..\n\t */\n\tif (base->d_op && base->d_op->d_hash) {\n\t\terr = base->d_op->d_hash(base, name);\n\t\tdentry = ERR_PTR(err);\n\t\tif (err < 0)\n\t\t\tgoto out;\n\t}\n\n\tdentry = cached_lookup(base, name, nd);\n\tif (!dentry) {\n\t\tstruct dentry *new = d_alloc(base, name);\n\t\tdentry = ERR_PTR(-ENOMEM);\n\t\tif (!new)\n\t\t\tgoto out;\n\t\tdentry = inode->i_op->lookup(inode, new, nd);\n\t\tif (!dentry)\n\t\t\tdentry = new;\n\t\telse\n\t\t\tdput(new);\n\t}\nout:\n\treturn dentry;\n}", "target": 1, "cwe": ["CWE-120"], "project": "linux-2.6", "commit_id": "d70b67c8bc72ee23b55381bd6a884f4796692f77", "hash": 78432281267930381618573272186063978285, "size": 35, "message": "[patch] vfs: fix lookup on deleted directory\n\nLookup can install a child dentry for a deleted directory.  This keeps\nthe directory dentry alive, and the inode pinned in the cache and on\ndisk, even after all external references have gone away.\n\nThis isn't a big problem normally, since memory pressure or umount\nwill clear out the directory dentry and its children, releasing the\ninode.  But for UBIFS this causes problems because its orphan area can\noverflow.\n\nFix this by returning ENOENT for all lookups on a S_DEAD directory\nbefore creating a child dentry.\n\nThanks to Zoltan Sogor for noticing this while testing UBIFS, and\nArtem for the excellent analysis of the problem and testing.\n\nReported-by: Artem Bityutskiy <Artem.Bityutskiy@nokia.com>\nTested-by: Artem Bityutskiy <Artem.Bityutskiy@nokia.com>\nSigned-off-by: Miklos Szeredi <mszeredi@suse.cz>\nSigned-off-by: Al Viro <viro@zeniv.linux.org.uk>"}
{"func": "snd_seq_oss_synth_make_info(struct seq_oss_devinfo *dp, int dev, struct synth_info *inf)\n{\n\tstruct seq_oss_synth *rec;\n\n\tif (dp->synths[dev].is_midi) {\n\t\tstruct midi_info minf;\n\t\tsnd_seq_oss_midi_make_info(dp, dp->synths[dev].midi_mapped, &minf);\n\t\tinf->synth_type = SYNTH_TYPE_MIDI;\n\t\tinf->synth_subtype = 0;\n\t\tinf->nr_voices = 16;\n\t\tinf->device = dev;\n\t\tstrlcpy(inf->name, minf.name, sizeof(inf->name));\n\t} else {\n\t\tif ((rec = get_synthdev(dp, dev)) == NULL)\n\t\t\treturn -ENXIO;\n\t\tinf->synth_type = rec->synth_type;\n\t\tinf->synth_subtype = rec->synth_subtype;\n\t\tinf->nr_voices = rec->nr_voices;\n\t\tinf->device = dev;\n\t\tstrlcpy(inf->name, rec->name, sizeof(inf->name));\n\t\tsnd_use_lock_free(&rec->use_lock);\n\t}\n\treturn 0;\n}", "target": 1, "cwe": ["CWE-200"], "project": "linux-2.6", "commit_id": "82e68f7ffec3800425f2391c8c86277606860442", "hash": 216166856109438494603854090593555238735, "size": 24, "message": "sound: ensure device number is valid in snd_seq_oss_synth_make_info\n\nsnd_seq_oss_synth_make_info() incorrectly reports information\nto userspace without first checking for the validity of the\ndevice number, leading to possible information leak (CVE-2008-3272).\n\nReported-By: Tobias Klein <tk@trapkit.de>\nAcked-and-tested-by: Takashi Iwai <tiwai@suse.de>\nCc: stable@kernel.org\nSigned-off-by: Willy Tarreau <w@1wt.eu>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>"}
{"func": "static void file_add_remove(struct diff_options *options,\n\t\t    int addremove, unsigned mode,\n\t\t    const unsigned char *sha1,\n\t\t    const char *base, const char *path)\n{\n\tint diff = REV_TREE_DIFFERENT;\n\n\t/*\n\t * Is it an add of a new file? It means that the old tree\n\t * didn't have it at all, so we will turn \"REV_TREE_SAME\" ->\n\t * \"REV_TREE_NEW\", but leave any \"REV_TREE_DIFFERENT\" alone\n\t * (and if it already was \"REV_TREE_NEW\", we'll keep it\n\t * \"REV_TREE_NEW\" of course).\n\t */\n\tif (addremove == '+') {\n\t\tdiff = tree_difference;\n\t\tif (diff != REV_TREE_SAME)\n\t\t\treturn;\n\t\tdiff = REV_TREE_NEW;\n\t}\n\ttree_difference = diff;\n\tif (tree_difference == REV_TREE_DIFFERENT)\n\t\tDIFF_OPT_SET(options, HAS_CHANGES);\n}", "target": 1, "cwe": ["CWE-119"], "project": "git", "commit_id": "fd55a19eb1d49ae54008d932a65f79cd6fda45c9", "hash": 220776526793639941070950330016667509112, "size": 24, "message": "Fix buffer overflow in git diff\n\nIf PATH_MAX on your system is smaller than a path stored, it may cause\nbuffer overflow and stack corruption in diff_addremove() and diff_change()\nfunctions when running git-diff\n\nSigned-off-by: Dmitry Potapov <dpotapov@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>"}
{"func": "static int show_modified(struct oneway_unpack_data *cbdata,\n\t\t\t struct cache_entry *old,\n\t\t\t struct cache_entry *new,\n\t\t\t int report_missing,\n\t\t\t int cached, int match_missing)\n{\n\tunsigned int mode, oldmode;\n\tconst unsigned char *sha1;\n\tstruct rev_info *revs = cbdata->revs;\n\n\tif (get_stat_data(new, &sha1, &mode, cached, match_missing, cbdata) < 0) {\n\t\tif (report_missing)\n\t\t\tdiff_index_show_file(revs, \"-\", old,\n\t\t\t\t\t     old->sha1, old->ce_mode);\n\t\treturn -1;\n\t}\n\n\tif (revs->combine_merges && !cached &&\n\t    (hashcmp(sha1, old->sha1) || hashcmp(old->sha1, new->sha1))) {\n\t\tstruct combine_diff_path *p;\n\t\tint pathlen = ce_namelen(new);\n\n\t\tp = xmalloc(combine_diff_path_size(2, pathlen));\n\t\tp->path = (char *) &p->parent[2];\n\t\tp->next = NULL;\n\t\tp->len = pathlen;\n\t\tmemcpy(p->path, new->name, pathlen);\n\t\tp->path[pathlen] = 0;\n\t\tp->mode = mode;\n\t\thashclr(p->sha1);\n\t\tmemset(p->parent, 0, 2 * sizeof(struct combine_diff_parent));\n\t\tp->parent[0].status = DIFF_STATUS_MODIFIED;\n\t\tp->parent[0].mode = new->ce_mode;\n\t\thashcpy(p->parent[0].sha1, new->sha1);\n\t\tp->parent[1].status = DIFF_STATUS_MODIFIED;\n\t\tp->parent[1].mode = old->ce_mode;\n\t\thashcpy(p->parent[1].sha1, old->sha1);\n\t\tshow_combined_diff(p, 2, revs->dense_combined_merges, revs);\n\t\tfree(p);\n\t\treturn 0;\n\t}\n\n\toldmode = old->ce_mode;\n\tif (mode == oldmode && !hashcmp(sha1, old->sha1) &&\n\t    !DIFF_OPT_TST(&revs->diffopt, FIND_COPIES_HARDER))\n\t\treturn 0;\n\n\tdiff_change(&revs->diffopt, oldmode, mode,\n\t\t    old->sha1, sha1, old->name, NULL);\n\treturn 0;\n}", "target": 1, "cwe": ["CWE-119"], "project": "git", "commit_id": "fd55a19eb1d49ae54008d932a65f79cd6fda45c9", "hash": 226800970801831651701634172156640358788, "size": 51, "message": "Fix buffer overflow in git diff\n\nIf PATH_MAX on your system is smaller than a path stored, it may cause\nbuffer overflow and stack corruption in diff_addremove() and diff_change()\nfunctions when running git-diff\n\nSigned-off-by: Dmitry Potapov <dpotapov@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>"}
{"func": "static int compare_tree_entry(struct tree_desc *t1, struct tree_desc *t2, const char *base, int baselen, struct diff_options *opt)\n{\n\tunsigned mode1, mode2;\n\tconst char *path1, *path2;\n\tconst unsigned char *sha1, *sha2;\n\tint cmp, pathlen1, pathlen2;\n\n\tsha1 = tree_entry_extract(t1, &path1, &mode1);\n\tsha2 = tree_entry_extract(t2, &path2, &mode2);\n\n\tpathlen1 = tree_entry_len(path1, sha1);\n\tpathlen2 = tree_entry_len(path2, sha2);\n\tcmp = base_name_compare(path1, pathlen1, mode1, path2, pathlen2, mode2);\n\tif (cmp < 0) {\n\t\tshow_entry(opt, \"-\", t1, base, baselen);\n\t\treturn -1;\n\t}\n\tif (cmp > 0) {\n\t\tshow_entry(opt, \"+\", t2, base, baselen);\n\t\treturn 1;\n\t}\n\tif (!DIFF_OPT_TST(opt, FIND_COPIES_HARDER) && !hashcmp(sha1, sha2) && mode1 == mode2)\n\t\treturn 0;\n\n\t/*\n\t * If the filemode has changed to/from a directory from/to a regular\n\t * file, we need to consider it a remove and an add.\n\t */\n\tif (S_ISDIR(mode1) != S_ISDIR(mode2)) {\n\t\tshow_entry(opt, \"-\", t1, base, baselen);\n\t\tshow_entry(opt, \"+\", t2, base, baselen);\n\t\treturn 0;\n\t}\n\n\tif (DIFF_OPT_TST(opt, RECURSIVE) && S_ISDIR(mode1)) {\n\t\tint retval;\n\t\tchar *newbase = malloc_base(base, baselen, path1, pathlen1);\n\t\tif (DIFF_OPT_TST(opt, TREE_IN_RECURSIVE))\n\t\t\topt->change(opt, mode1, mode2,\n\t\t\t\t    sha1, sha2, base, path1);\n\t\tretval = diff_tree_sha1(sha1, sha2, newbase, opt);\n\t\tfree(newbase);\n\t\treturn retval;\n\t}\n\n\topt->change(opt, mode1, mode2, sha1, sha2, base, path1);\n\treturn 0;\n}", "target": 1, "cwe": ["CWE-119"], "project": "git", "commit_id": "fd55a19eb1d49ae54008d932a65f79cd6fda45c9", "hash": 275627253054133418702464627151159595261, "size": 48, "message": "Fix buffer overflow in git diff\n\nIf PATH_MAX on your system is smaller than a path stored, it may cause\nbuffer overflow and stack corruption in diff_addremove() and diff_change()\nfunctions when running git-diff\n\nSigned-off-by: Dmitry Potapov <dpotapov@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>"}
{"func": "static void diff_index_show_file(struct rev_info *revs,\n\t\t\t\t const char *prefix,\n\t\t\t\t struct cache_entry *ce,\n\t\t\t\t const unsigned char *sha1, unsigned int mode)\n{\n\tdiff_addremove(&revs->diffopt, prefix[0], mode,\n\t\t       sha1, ce->name, NULL);\n}", "target": 1, "cwe": ["CWE-119"], "project": "git", "commit_id": "fd55a19eb1d49ae54008d932a65f79cd6fda45c9", "hash": 30420025918771510190524987331796513235, "size": 8, "message": "Fix buffer overflow in git diff\n\nIf PATH_MAX on your system is smaller than a path stored, it may cause\nbuffer overflow and stack corruption in diff_addremove() and diff_change()\nfunctions when running git-diff\n\nSigned-off-by: Dmitry Potapov <dpotapov@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>"}
{"func": "void diff_addremove(struct diff_options *options,\n\t\t    int addremove, unsigned mode,\n\t\t    const unsigned char *sha1,\n\t\t    const char *base, const char *path)\n{\n\tchar concatpath[PATH_MAX];\n\tstruct diff_filespec *one, *two;\n\n\tif (DIFF_OPT_TST(options, IGNORE_SUBMODULES) && S_ISGITLINK(mode))\n\t\treturn;\n\n\t/* This may look odd, but it is a preparation for\n\t * feeding \"there are unchanged files which should\n\t * not produce diffs, but when you are doing copy\n\t * detection you would need them, so here they are\"\n\t * entries to the diff-core.  They will be prefixed\n\t * with something like '=' or '*' (I haven't decided\n\t * which but should not make any difference).\n\t * Feeding the same new and old to diff_change()\n\t * also has the same effect.\n\t * Before the final output happens, they are pruned after\n\t * merged into rename/copy pairs as appropriate.\n\t */\n\tif (DIFF_OPT_TST(options, REVERSE_DIFF))\n\t\taddremove = (addremove == '+' ? '-' :\n\t\t\t     addremove == '-' ? '+' : addremove);\n\n\tif (!path) path = \"\";\n\tsprintf(concatpath, \"%s%s\", base, path);\n\n\tif (options->prefix &&\n\t    strncmp(concatpath, options->prefix, options->prefix_length))\n\t\treturn;\n\n\tone = alloc_filespec(concatpath);\n\ttwo = alloc_filespec(concatpath);\n\n\tif (addremove != '+')\n\t\tfill_filespec(one, sha1, mode);\n\tif (addremove != '-')\n\t\tfill_filespec(two, sha1, mode);\n\n\tdiff_queue(&diff_queued_diff, one, two);\n\tDIFF_OPT_SET(options, HAS_CHANGES);\n}", "target": 1, "cwe": ["CWE-119"], "project": "git", "commit_id": "fd55a19eb1d49ae54008d932a65f79cd6fda45c9", "hash": 121643038194642882186344342235023262689, "size": 45, "message": "Fix buffer overflow in git diff\n\nIf PATH_MAX on your system is smaller than a path stored, it may cause\nbuffer overflow and stack corruption in diff_addremove() and diff_change()\nfunctions when running git-diff\n\nSigned-off-by: Dmitry Potapov <dpotapov@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>"}
{"func": "int llhttp__after_headers_complete(llhttp_t* parser, const char* p,\n                                   const char* endp) {\n  int hasBody;\n\n  hasBody = parser->flags & F_CHUNKED || parser->content_length > 0;\n  if (parser->upgrade && (parser->method == HTTP_CONNECT ||\n                          (parser->flags & F_SKIPBODY) || !hasBody)) {\n    /* Exit, the rest of the message is in a different protocol. */\n    return 1;\n  }\n\n  if (parser->flags & F_SKIPBODY) {\n    return 0;\n  } else if (parser->flags & F_CHUNKED) {\n    /* chunked encoding - ignore Content-Length header, prepare for a chunk */\n    return 2;\n  } else if (parser->flags & F_TRANSFER_ENCODING) {\n    if (parser->type == HTTP_REQUEST &&\n        (parser->lenient_flags & LENIENT_CHUNKED_LENGTH) == 0) {\n      /* RFC 7230 3.3.3 */\n\n      /* If a Transfer-Encoding header field\n       * is present in a request and the chunked transfer coding is not\n       * the final encoding, the message body length cannot be determined\n       * reliably; the server MUST respond with the 400 (Bad Request)\n       * status code and then close the connection.\n       */\n      return 5;\n    } else {\n      /* RFC 7230 3.3.3 */\n\n      /* If a Transfer-Encoding header field is present in a response and\n       * the chunked transfer coding is not the final encoding, the\n       * message body length is determined by reading the connection until\n       * it is closed by the server.\n       */\n      return 4;\n    }\n  } else {\n    if (!(parser->flags & F_CONTENT_LENGTH)) {\n      if (!llhttp_message_needs_eof(parser)) {\n        /* Assume content-length 0 - read the next */\n        return 0;\n      } else {\n        /* Read body until EOF */\n        return 4;\n      }\n    } else if (parser->content_length == 0) {\n      /* Content-Length header given but zero: Content-Length: 0\\r\\n */\n      return 0;\n    } else {\n      /* Content-Length header given and non-zero */\n      return 3;\n    }\n  }\n}", "target": 1, "cwe": ["CWE-444"], "project": "node", "commit_id": "1da22eb48254f8c2d5f3c5865bb9f46e8b09ec60", "hash": 224699785160385777517316019396106321957, "size": 56, "message": "http: stricter Transfer-Encoding and header separator parsing\n\nReviewed-By: Matteo Collina <matteo.collina@gmail.com>\nReviewed-By: James M Snell <jasnell@gmail.com>\nReviewed-By: Rich Trott <rtrott@gmail.com>\nReviewed-By: Vladimir de Turckheim <vlad2t@hotmail.com>\nPR-URL: https://github.com/nodejs-private/node-private/pull/315\nCVE-ID: CVE-2022-32215,CVE-2022-32214,CVE-2022-32212\n\nBackport-PR-URL: https://github.com/nodejs-private/node-private/pull/326"}
{"func": "int setup_order(THD *thd, Ref_ptr_array ref_pointer_array, TABLE_LIST *tables,\n                List<Item> &fields, List<Item> &all_fields, ORDER *order,\n                bool from_window_spec)\n{ \n  SELECT_LEX *select = thd->lex->current_select;\n  enum_parsing_place context_analysis_place=\n                     thd->lex->current_select->context_analysis_place;\n  thd->where=\"order clause\";\n  const bool for_union = select->master_unit()->is_union() &&\n                         select == select->master_unit()->fake_select_lex;\n  for (uint number = 1; order; order=order->next, number++)\n  {\n    if (find_order_in_list(thd, ref_pointer_array, tables, order, fields,\n                           all_fields, false, true, from_window_spec))\n      return 1;\n    if ((*order->item)->with_window_func &&\n        context_analysis_place != IN_ORDER_BY)\n    {\n      my_error(ER_WINDOW_FUNCTION_IN_WINDOW_SPEC, MYF(0));\n      return 1;\n    }\n\n    /*\n      UNION queries cannot be used with an aggregate function in\n      an ORDER BY clause\n    */\n\n    if (for_union && (*order->item)->with_sum_func)\n    {\n      my_error(ER_AGGREGATE_ORDER_FOR_UNION, MYF(0), number);\n      return 1;\n    }\n\n    if (from_window_spec && (*order->item)->with_sum_func &&\n        (*order->item)->type() != Item::SUM_FUNC_ITEM)\n      (*order->item)->split_sum_func(thd, ref_pointer_array,\n                                     all_fields, SPLIT_SUM_SELECT);\n  }\n  return 0;\n}", "target": 1, "cwe": [], "project": "server", "commit_id": "942a9791b2231273ba20649a658c856641268fae", "hash": 226164707700979054576557213872753892865, "size": 40, "message": "MDEV-15208: server crashed, when using ORDER BY with window function and UNION\n\nSELECTs inside a UNION can have window function but not the global ORDER BY clause of the UNION."}
{"func": "address_space_translate_for_iotlb(CPUState *cpu, int asidx, hwaddr addr,\n                                  hwaddr *xlat, hwaddr *plen,\n                                  MemTxAttrs attrs, int *prot)\n{\n    MemoryRegionSection *section;\n    IOMMUMemoryRegion *iommu_mr;\n    IOMMUMemoryRegionClass *imrc;\n    IOMMUTLBEntry iotlb;\n    int iommu_idx;\n    AddressSpaceDispatch *d =\n        qatomic_rcu_read(&cpu->cpu_ases[asidx].memory_dispatch);\n\n    for (;;) {\n        section = address_space_translate_internal(d, addr, &addr, plen, false);\n\n        iommu_mr = memory_region_get_iommu(section->mr);\n        if (!iommu_mr) {\n            break;\n        }\n\n        imrc = memory_region_get_iommu_class_nocheck(iommu_mr);\n\n        iommu_idx = imrc->attrs_to_index(iommu_mr, attrs);\n        tcg_register_iommu_notifier(cpu, iommu_mr, iommu_idx);\n        /* We need all the permissions, so pass IOMMU_NONE so the IOMMU\n         * doesn't short-cut its translation table walk.\n         */\n        iotlb = imrc->translate(iommu_mr, addr, IOMMU_NONE, iommu_idx);\n        addr = ((iotlb.translated_addr & ~iotlb.addr_mask)\n                | (addr & iotlb.addr_mask));\n        /* Update the caller's prot bits to remove permissions the IOMMU\n         * is giving us a failure response for. If we get down to no\n         * permissions left at all we can give up now.\n         */\n        if (!(iotlb.perm & IOMMU_RO)) {\n            *prot &= ~(PAGE_READ | PAGE_EXEC);\n        }\n        if (!(iotlb.perm & IOMMU_WO)) {\n            *prot &= ~PAGE_WRITE;\n        }\n\n        if (!*prot) {\n            goto translate_fail;\n        }\n\n        d = flatview_to_dispatch(address_space_to_flatview(iotlb.target_as));\n    }\n\n    assert(!memory_region_is_iommu(section->mr));\n    *xlat = addr;\n    return section;\n\ntranslate_fail:\n    return &d->map.sections[PHYS_SECTION_UNASSIGNED];\n}", "target": 1, "cwe": ["CWE-908"], "project": "qemu", "commit_id": "418ade7849ce7641c0f7333718caf5091a02fd4c", "hash": 270213508919707612636527664610402006659, "size": 55, "message": "softmmu: Always initialize xlat in address_space_translate_for_iotlb\n\nThe bug is an uninitialized memory read, along the translate_fail\npath, which results in garbage being read from iotlb_to_section,\nwhich can lead to a crash in io_readx/io_writex.\n\nThe bug may be fixed by writing any value with zero\nin ~TARGET_PAGE_MASK, so that the call to iotlb_to_section using\nthe xlat'ed address returns io_mem_unassigned, as desired by the\ntranslate_fail path.\n\nIt is most useful to record the original physical page address,\nwhich will eventually be logged by memory_region_access_valid\nwhen the access is rejected by unassigned_mem_accepts.\n\nResolves: https://gitlab.com/qemu-project/qemu/-/issues/1065\nSigned-off-by: Richard Henderson <richard.henderson@linaro.org>\nReviewed-by: Peter Maydell <peter.maydell@linaro.org>\nMessage-Id: <20220621153829.366423-1-richard.henderson@linaro.org>"}
{"func": "create_node(Subnet *parent_subnet, int the_entry)\n{\n  Node *new_node;\n  new_node = MallocNew(Node);\n  parent_subnet->entry[the_entry] = (void *) new_node;\n  clear_node(new_node);\n\n  if (n_nodes == max_nodes) {\n    if (nodes) {\n      max_nodes += NODE_TABLE_INCREMENT;\n      nodes = ReallocArray(Node *, max_nodes, nodes);\n    } else {\n      if (max_nodes != 0) {\n        CROAK(\"max_nodes should be 0\");\n      }\n      max_nodes = NODE_TABLE_INCREMENT;\n      nodes = MallocArray(Node *, max_nodes);\n    }\n  }\n  nodes[n_nodes++] = (Node *) new_node;\n}", "target": 1, "cwe": [], "project": "chrony", "commit_id": "8f72155b438494e6d8e9e75920c36fd88d90f5b2", "hash": 159217215290764873946180900950625068365, "size": 21, "message": "Multiply clientlog node table size when reallocating"}
{"func": "CLG_LogCommandAccess(IPAddr *client, CLG_Command_Type type, time_t now)\n{\n  uint32_t ip6[4];\n  Node *node;\n\n  if (active) {\n    switch (client->family) {\n      case IPADDR_INET4:\n        node = (Node *) find_subnet(&top_subnet4, &client->addr.in4, 1, 0);\n        break;\n      case IPADDR_INET6:\n        split_ip6(client, ip6);\n        node = (Node *) find_subnet(&top_subnet6, ip6, 4, 0);\n        break;\n      default:\n        assert(0);\n    }\n\n    node->ip_addr = *client;\n    node->last_cmd_hit = now;\n    switch (type) {\n      case CLG_CMD_AUTH:\n        ++node->cmd_hits_auth;\n        break;\n      case CLG_CMD_NORMAL:\n        ++node->cmd_hits_normal;\n        break;\n      case CLG_CMD_BAD_PKT:\n        ++node->cmd_hits_bad;\n        break;\n      default:\n        CROAK(\"Impossible\");\n        break;\n    }\n  }\n}", "target": 1, "cwe": [], "project": "chrony", "commit_id": "8f72155b438494e6d8e9e75920c36fd88d90f5b2", "hash": 37105525159507091341927964059098054394, "size": 36, "message": "Multiply clientlog node table size when reallocating"}
{"func": "int ssl3_get_server_hello(SSL *s)\n\t{\n\tSTACK_OF(SSL_CIPHER) *sk;\n\tconst SSL_CIPHER *c;\n\tCERT *ct = s->cert;\n\tunsigned char *p,*d;\n\tint i,al=SSL_AD_INTERNAL_ERROR,ok;\n\tunsigned int j;\n\tlong n;\n#ifndef OPENSSL_NO_COMP\n\tSSL_COMP *comp;\n#endif\n\t/* Hello verify request and/or server hello version may not\n\t * match so set first packet if we're negotiating version.\n\t */\n\tif (SSL_IS_DTLS(s))\n\t\ts->first_packet = 1;\n\n\tn=s->method->ssl_get_message(s,\n\t\tSSL3_ST_CR_SRVR_HELLO_A,\n\t\tSSL3_ST_CR_SRVR_HELLO_B,\n\t\t-1,\n\t\t20000, /* ?? */\n\t\t&ok);\n\n\tif (!ok) return((int)n);\n\n\tif (SSL_IS_DTLS(s))\n\t\t{\n\t\ts->first_packet = 0;\n\t\tif ( s->s3->tmp.message_type == DTLS1_MT_HELLO_VERIFY_REQUEST)\n\t\t\t{\n\t\t\tif ( s->d1->send_cookie == 0)\n\t\t\t\t{\n\t\t\t\ts->s3->tmp.reuse_message = 1;\n\t\t\t\treturn 1;\n\t\t\t\t}\n\t\t\telse /* already sent a cookie */\n\t\t\t\t{\n\t\t\t\tal=SSL_AD_UNEXPECTED_MESSAGE;\n\t\t\t\tSSLerr(SSL_F_SSL3_GET_SERVER_HELLO,SSL_R_BAD_MESSAGE_TYPE);\n\t\t\t\tgoto f_err;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\n\tif ( s->s3->tmp.message_type != SSL3_MT_SERVER_HELLO)\n\t\t{\n\t\tal=SSL_AD_UNEXPECTED_MESSAGE;\n\t\tSSLerr(SSL_F_SSL3_GET_SERVER_HELLO,SSL_R_BAD_MESSAGE_TYPE);\n\t\tgoto f_err;\n\t\t}\n\n\td=p=(unsigned char *)s->init_msg;\n\tif (s->method->version == DTLS_ANY_VERSION)\n\t\t{\n\t\t/* Work out correct protocol version to use */\n\t\tint hversion = (p[0] << 8)|p[1];\n\t\tint options = s->options;\n\t\tif (hversion == DTLS1_2_VERSION\n\t\t\t&& !(options & SSL_OP_NO_DTLSv1_2))\n\t\t\ts->method = DTLSv1_2_client_method();\n\t\telse if (tls1_suiteb(s))\n\t\t\t{\n\t\t\tSSLerr(SSL_F_SSL3_GET_SERVER_HELLO, SSL_R_ONLY_DTLS_1_2_ALLOWED_IN_SUITEB_MODE);\n\t\t\ts->version = hversion;\n\t\t\tal = SSL_AD_PROTOCOL_VERSION;\n\t\t\tgoto f_err;\n\t\t\t}\n\t\telse if (hversion == DTLS1_VERSION\n\t\t\t&& !(options & SSL_OP_NO_DTLSv1))\n\t\t\ts->method = DTLSv1_client_method();\n\t\telse\n\t\t\t{\n\t\t\tSSLerr(SSL_F_SSL3_GET_SERVER_HELLO,SSL_R_WRONG_SSL_VERSION);\n\t\t\ts->version = hversion;\n\t\t\tal = SSL_AD_PROTOCOL_VERSION;\n\t\t\tgoto f_err;\n\t\t\t}\n\t\ts->version = s->client_version = s->method->version;\n\t\t}\n\n\tif ((p[0] != (s->version>>8)) || (p[1] != (s->version&0xff)))\n\t\t{\n\t\tSSLerr(SSL_F_SSL3_GET_SERVER_HELLO,SSL_R_WRONG_SSL_VERSION);\n\t\ts->version=(s->version&0xff00)|p[1];\n\t\tal=SSL_AD_PROTOCOL_VERSION;\n\t\tgoto f_err;\n\t\t}\n\tp+=2;\n\n\t/* load the server hello data */\n\t/* load the server random */\n\tmemcpy(s->s3->server_random,p,SSL3_RANDOM_SIZE);\n\tp+=SSL3_RANDOM_SIZE;\n\n\t/* get the session-id */\n\tj= *(p++);\n\n\tif ((j > sizeof s->session->session_id) || (j > SSL3_SESSION_ID_SIZE))\n\t\t{\n\t\tal=SSL_AD_ILLEGAL_PARAMETER;\n\t\tSSLerr(SSL_F_SSL3_GET_SERVER_HELLO,SSL_R_SSL3_SESSION_ID_TOO_LONG);\n\t\tgoto f_err;\n\t\t}\n\n#ifndef OPENSSL_NO_TLSEXT\n\t/* check if we want to resume the session based on external pre-shared secret */\n\tif (s->version >= TLS1_VERSION && s->tls_session_secret_cb)\n\t\t{\n\t\tSSL_CIPHER *pref_cipher=NULL;\n\t\ts->session->master_key_length=sizeof(s->session->master_key);\n\t\tif (s->tls_session_secret_cb(s, s->session->master_key,\n\t\t\t\t\t     &s->session->master_key_length,\n\t\t\t\t\t     NULL, &pref_cipher,\n\t\t\t\t\t     s->tls_session_secret_cb_arg))\n\t\t\t{\n\t\t\ts->session->cipher = pref_cipher ?\n\t\t\t\tpref_cipher : ssl_get_cipher_by_char(s, p+j);\n\t\t\t}\n\t\t}\n#endif /* OPENSSL_NO_TLSEXT */\n\n\tif (j != 0 && j == s->session->session_id_length\n\t    && memcmp(p,s->session->session_id,j) == 0)\n\t    {\n\t    if(s->sid_ctx_length != s->session->sid_ctx_length\n\t       || memcmp(s->session->sid_ctx,s->sid_ctx,s->sid_ctx_length))\n\t\t{\n\t\t/* actually a client application bug */\n\t\tal=SSL_AD_ILLEGAL_PARAMETER;\n\t\tSSLerr(SSL_F_SSL3_GET_SERVER_HELLO,SSL_R_ATTEMPT_TO_REUSE_SESSION_IN_DIFFERENT_CONTEXT);\n\t\tgoto f_err;\n\t\t}\n\t    s->s3->flags |= SSL3_FLAGS_CCS_OK;\n\t    s->hit=1;\n\t    }\n\telse\t/* a miss or crap from the other end */\n\t\t{\n\t\t/* If we were trying for session-id reuse, make a new\n\t\t * SSL_SESSION so we don't stuff up other people */\n\t\ts->hit=0;\n\t\tif (s->session->session_id_length > 0)\n\t\t\t{\n\t\t\tif (!ssl_get_new_session(s,0))\n\t\t\t\t{\n\t\t\t\tgoto f_err;\n\t\t\t\t}\n\t\t\t}\n\t\ts->session->session_id_length=j;\n\t\tmemcpy(s->session->session_id,p,j); /* j could be 0 */\n\t\t}\n\tp+=j;\n\tc=ssl_get_cipher_by_char(s,p);\n\tif (c == NULL)\n\t\t{\n\t\t/* unknown cipher */\n\t\tal=SSL_AD_ILLEGAL_PARAMETER;\n\t\tSSLerr(SSL_F_SSL3_GET_SERVER_HELLO,SSL_R_UNKNOWN_CIPHER_RETURNED);\n\t\tgoto f_err;\n\t\t}\n\t/* Set version disabled mask now we know version */\n\tif (!SSL_USE_TLS1_2_CIPHERS(s))\n\t\tct->mask_ssl = SSL_TLSV1_2;\n\telse\n\t\tct->mask_ssl = 0;\n\t/* If it is a disabled cipher we didn't send it in client hello,\n\t * so return an error.\n\t */\n\tif (ssl_cipher_disabled(s, c, SSL_SECOP_CIPHER_CHECK))\n\t\t{\n\t\tal=SSL_AD_ILLEGAL_PARAMETER;\n\t\tSSLerr(SSL_F_SSL3_GET_SERVER_HELLO,SSL_R_WRONG_CIPHER_RETURNED);\n\t\tgoto f_err;\n\t\t}\n\tp+=ssl_put_cipher_by_char(s,NULL,NULL);\n\n\tsk=ssl_get_ciphers_by_id(s);\n\ti=sk_SSL_CIPHER_find(sk,c);\n\tif (i < 0)\n\t\t{\n\t\t/* we did not say we would use this cipher */\n\t\tal=SSL_AD_ILLEGAL_PARAMETER;\n\t\tSSLerr(SSL_F_SSL3_GET_SERVER_HELLO,SSL_R_WRONG_CIPHER_RETURNED);\n\t\tgoto f_err;\n\t\t}\n\n\t/* Depending on the session caching (internal/external), the cipher\n\t   and/or cipher_id values may not be set. Make sure that\n\t   cipher_id is set and use it for comparison. */\n\tif (s->session->cipher)\n\t\ts->session->cipher_id = s->session->cipher->id;\n\tif (s->hit && (s->session->cipher_id != c->id))\n\t\t{\n/* Workaround is now obsolete */\n#if 0\n\t\tif (!(s->options &\n\t\t\tSSL_OP_NETSCAPE_REUSE_CIPHER_CHANGE_BUG))\n#endif\n\t\t\t{\n\t\t\tal=SSL_AD_ILLEGAL_PARAMETER;\n\t\t\tSSLerr(SSL_F_SSL3_GET_SERVER_HELLO,SSL_R_OLD_SESSION_CIPHER_NOT_RETURNED);\n\t\t\tgoto f_err;\n\t\t\t}\n\t\t}\n\ts->s3->tmp.new_cipher=c;\n\t/* Don't digest cached records if no sigalgs: we may need them for\n\t * client authentication.\n\t */\n\tif (!SSL_USE_SIGALGS(s) && !ssl3_digest_cached_records(s))\n\t\tgoto f_err;\n\t/* lets get the compression algorithm */\n\t/* COMPRESSION */\n#ifdef OPENSSL_NO_COMP\n\tif (*(p++) != 0)\n\t\t{\n\t\tal=SSL_AD_ILLEGAL_PARAMETER;\n\t\tSSLerr(SSL_F_SSL3_GET_SERVER_HELLO,SSL_R_UNSUPPORTED_COMPRESSION_ALGORITHM);\n\t\tgoto f_err;\n\t\t}\n\t/* If compression is disabled we'd better not try to resume a session\n\t * using compression.\n\t */\n\tif (s->session->compress_meth != 0)\n\t\t{\n\t\tSSLerr(SSL_F_SSL3_GET_SERVER_HELLO,SSL_R_INCONSISTENT_COMPRESSION);\n\t\tgoto f_err;\n\t\t}\n#else\n\tj= *(p++);\n\tif (s->hit && j != s->session->compress_meth)\n\t\t{\n\t\tal=SSL_AD_ILLEGAL_PARAMETER;\n\t\tSSLerr(SSL_F_SSL3_GET_SERVER_HELLO,SSL_R_OLD_SESSION_COMPRESSION_ALGORITHM_NOT_RETURNED);\n\t\tgoto f_err;\n\t\t}\n\tif (j == 0)\n\t\tcomp=NULL;\n\telse if (!ssl_allow_compression(s))\n\t\t{\n\t\tal=SSL_AD_ILLEGAL_PARAMETER;\n\t\tSSLerr(SSL_F_SSL3_GET_SERVER_HELLO,SSL_R_COMPRESSION_DISABLED);\n\t\tgoto f_err;\n\t\t}\n\telse\n\t\tcomp=ssl3_comp_find(s->ctx->comp_methods,j);\n\t\n\tif ((j != 0) && (comp == NULL))\n\t\t{\n\t\tal=SSL_AD_ILLEGAL_PARAMETER;\n\t\tSSLerr(SSL_F_SSL3_GET_SERVER_HELLO,SSL_R_UNSUPPORTED_COMPRESSION_ALGORITHM);\n\t\tgoto f_err;\n\t\t}\n\telse\n\t\t{\n\t\ts->s3->tmp.new_compression=comp;\n\t\t}\n#endif\n\n#ifndef OPENSSL_NO_TLSEXT\n\t/* TLS extensions*/\n\tif (!ssl_parse_serverhello_tlsext(s,&p,d,n))\n\t\t{\n\t\tSSLerr(SSL_F_SSL3_GET_SERVER_HELLO,SSL_R_PARSE_TLSEXT);\n\t\tgoto err; \n\t\t}\n#endif\n\n\tif (p != (d+n))\n\t\t{\n\t\t/* wrong packet length */\n\t\tal=SSL_AD_DECODE_ERROR;\n\t\tSSLerr(SSL_F_SSL3_GET_SERVER_HELLO,SSL_R_BAD_PACKET_LENGTH);\n\t\tgoto f_err;\n\t\t}\n\n\treturn(1);\nf_err:\n\tssl3_send_alert(s,SSL3_AL_FATAL,al);\nerr:\n\treturn(-1);\n\t}", "target": 1, "cwe": ["CWE-326"], "project": "openssl", "commit_id": "fb8d9ddb9dc19d84dffa84932f75e607c8a3ffe6", "hash": 109850082437134814483841337074658187186, "size": 282, "message": "Make tls_session_secret_cb work with CVE-2014-0224 fix.\n\nIf application uses tls_session_secret_cb for session resumption\nset the CCS_OK flag."}
{"func": "static void tulip_desc_read(TULIPState *s, hwaddr p,\n        struct tulip_descriptor *desc)\n{\n    const MemTxAttrs attrs = MEMTXATTRS_UNSPECIFIED;\n\n    if (s->csr[0] & CSR0_DBO) {\n        ldl_be_pci_dma(&s->dev, p, &desc->status, attrs);\n        ldl_be_pci_dma(&s->dev, p + 4, &desc->control, attrs);\n        ldl_be_pci_dma(&s->dev, p + 8, &desc->buf_addr1, attrs);\n        ldl_be_pci_dma(&s->dev, p + 12, &desc->buf_addr2, attrs);\n    } else {\n        ldl_le_pci_dma(&s->dev, p, &desc->status, attrs);\n        ldl_le_pci_dma(&s->dev, p + 4, &desc->control, attrs);\n        ldl_le_pci_dma(&s->dev, p + 8, &desc->buf_addr1, attrs);\n        ldl_le_pci_dma(&s->dev, p + 12, &desc->buf_addr2, attrs);\n    }\n}", "target": 1, "cwe": [], "project": "qemu", "commit_id": "36a894aeb64a2e02871016da1c37d4a4ca109182", "hash": 137786824944513040842839465829254728146, "size": 17, "message": "net: tulip: Restrict DMA engine to memories\n\nThe DMA engine is started by I/O access and then itself accesses the\nI/O registers, triggering a reentrancy bug.\n\nThe following log can reveal it:\n==5637==ERROR: AddressSanitizer: stack-overflow\n    #0 0x5595435f6078 in tulip_xmit_list_update qemu/hw/net/tulip.c:673\n    #1 0x5595435f204a in tulip_write qemu/hw/net/tulip.c:805:13\n    #2 0x559544637f86 in memory_region_write_accessor qemu/softmmu/memory.c:492:5\n    #3 0x5595446379fa in access_with_adjusted_size qemu/softmmu/memory.c:554:18\n    #4 0x5595446372fa in memory_region_dispatch_write qemu/softmmu/memory.c\n    #5 0x55954468b74c in flatview_write_continue qemu/softmmu/physmem.c:2825:23\n    #6 0x559544683662 in flatview_write qemu/softmmu/physmem.c:2867:12\n    #7 0x5595446833f3 in address_space_write qemu/softmmu/physmem.c:2963:18\n    #8 0x5595435fb082 in dma_memory_rw_relaxed qemu/include/sysemu/dma.h:87:12\n    #9 0x5595435fb082 in dma_memory_rw qemu/include/sysemu/dma.h:130:12\n    #10 0x5595435fb082 in dma_memory_write qemu/include/sysemu/dma.h:171:12\n    #11 0x5595435fb082 in stl_le_dma qemu/include/sysemu/dma.h:272:1\n    #12 0x5595435fb082 in stl_le_pci_dma qemu/include/hw/pci/pci.h:910:1\n    #13 0x5595435fb082 in tulip_desc_write qemu/hw/net/tulip.c:101:9\n    #14 0x5595435f7e3d in tulip_xmit_list_update qemu/hw/net/tulip.c:706:9\n    #15 0x5595435f204a in tulip_write qemu/hw/net/tulip.c:805:13\n\nFix this bug by restricting the DMA engine to memories regions.\n\nSigned-off-by: Zheyu Ma <zheyuma97@gmail.com>\nSigned-off-by: Jason Wang <jasowang@redhat.com>"}
{"func": "static void tulip_desc_write(TULIPState *s, hwaddr p,\n        struct tulip_descriptor *desc)\n{\n    const MemTxAttrs attrs = MEMTXATTRS_UNSPECIFIED;\n\n    if (s->csr[0] & CSR0_DBO) {\n        stl_be_pci_dma(&s->dev, p, desc->status, attrs);\n        stl_be_pci_dma(&s->dev, p + 4, desc->control, attrs);\n        stl_be_pci_dma(&s->dev, p + 8, desc->buf_addr1, attrs);\n        stl_be_pci_dma(&s->dev, p + 12, desc->buf_addr2, attrs);\n    } else {\n        stl_le_pci_dma(&s->dev, p, desc->status, attrs);\n        stl_le_pci_dma(&s->dev, p + 4, desc->control, attrs);\n        stl_le_pci_dma(&s->dev, p + 8, desc->buf_addr1, attrs);\n        stl_le_pci_dma(&s->dev, p + 12, desc->buf_addr2, attrs);\n    }\n}", "target": 1, "cwe": [], "project": "qemu", "commit_id": "36a894aeb64a2e02871016da1c37d4a4ca109182", "hash": 110431876439403030034899121103051834136, "size": 17, "message": "net: tulip: Restrict DMA engine to memories\n\nThe DMA engine is started by I/O access and then itself accesses the\nI/O registers, triggering a reentrancy bug.\n\nThe following log can reveal it:\n==5637==ERROR: AddressSanitizer: stack-overflow\n    #0 0x5595435f6078 in tulip_xmit_list_update qemu/hw/net/tulip.c:673\n    #1 0x5595435f204a in tulip_write qemu/hw/net/tulip.c:805:13\n    #2 0x559544637f86 in memory_region_write_accessor qemu/softmmu/memory.c:492:5\n    #3 0x5595446379fa in access_with_adjusted_size qemu/softmmu/memory.c:554:18\n    #4 0x5595446372fa in memory_region_dispatch_write qemu/softmmu/memory.c\n    #5 0x55954468b74c in flatview_write_continue qemu/softmmu/physmem.c:2825:23\n    #6 0x559544683662 in flatview_write qemu/softmmu/physmem.c:2867:12\n    #7 0x5595446833f3 in address_space_write qemu/softmmu/physmem.c:2963:18\n    #8 0x5595435fb082 in dma_memory_rw_relaxed qemu/include/sysemu/dma.h:87:12\n    #9 0x5595435fb082 in dma_memory_rw qemu/include/sysemu/dma.h:130:12\n    #10 0x5595435fb082 in dma_memory_write qemu/include/sysemu/dma.h:171:12\n    #11 0x5595435fb082 in stl_le_dma qemu/include/sysemu/dma.h:272:1\n    #12 0x5595435fb082 in stl_le_pci_dma qemu/include/hw/pci/pci.h:910:1\n    #13 0x5595435fb082 in tulip_desc_write qemu/hw/net/tulip.c:101:9\n    #14 0x5595435f7e3d in tulip_xmit_list_update qemu/hw/net/tulip.c:706:9\n    #15 0x5595435f204a in tulip_write qemu/hw/net/tulip.c:805:13\n\nFix this bug by restricting the DMA engine to memories regions.\n\nSigned-off-by: Zheyu Ma <zheyuma97@gmail.com>\nSigned-off-by: Jason Wang <jasowang@redhat.com>"}
{"func": "zfs_fuid_create(zfsvfs_t *zfsvfs, uint64_t id, cred_t *cr,\n    zfs_fuid_type_t type, zfs_fuid_info_t **fuidpp)\n{\n#ifdef HAVE_KSID\n\tconst char *domain;\n\tchar *kdomain;\n\tuint32_t fuid_idx = FUID_INDEX(id);\n\tuint32_t rid;\n\tidmap_stat status;\n\tuint64_t idx = 0;\n\tzfs_fuid_t *zfuid = NULL;\n\tzfs_fuid_info_t *fuidp = NULL;\n\n\t/*\n\t * If POSIX ID, or entry is already a FUID then\n\t * just return the id\n\t *\n\t * We may also be handed an already FUID'ized id via\n\t * chmod.\n\t */\n\n\tif (!zfsvfs->z_use_fuids || !IS_EPHEMERAL(id) || fuid_idx != 0)\n\t\treturn (id);\n\n\tif (zfsvfs->z_replay) {\n\t\tfuidp = zfsvfs->z_fuid_replay;\n\n\t\t/*\n\t\t * If we are passed an ephemeral id, but no\n\t\t * fuid_info was logged then return NOBODY.\n\t\t * This is most likely a result of idmap service\n\t\t * not being available.\n\t\t */\n\t\tif (fuidp == NULL)\n\t\t\treturn (UID_NOBODY);\n\n\t\tVERIFY3U(type, >=, ZFS_OWNER);\n\t\tVERIFY3U(type, <=, ZFS_ACE_GROUP);\n\n\t\tswitch (type) {\n\t\tcase ZFS_ACE_USER:\n\t\tcase ZFS_ACE_GROUP:\n\t\t\tzfuid = list_head(&fuidp->z_fuids);\n\t\t\trid = FUID_RID(zfuid->z_logfuid);\n\t\t\tidx = FUID_INDEX(zfuid->z_logfuid);\n\t\t\tbreak;\n\t\tcase ZFS_OWNER:\n\t\t\trid = FUID_RID(fuidp->z_fuid_owner);\n\t\t\tidx = FUID_INDEX(fuidp->z_fuid_owner);\n\t\t\tbreak;\n\t\tcase ZFS_GROUP:\n\t\t\trid = FUID_RID(fuidp->z_fuid_group);\n\t\t\tidx = FUID_INDEX(fuidp->z_fuid_group);\n\t\t\tbreak;\n\t\t};\n\t\tdomain = fuidp->z_domain_table[idx - 1];\n\t} else {\n\t\tif (type == ZFS_OWNER || type == ZFS_ACE_USER)\n\t\t\tstatus = kidmap_getsidbyuid(crgetzone(cr), id,\n\t\t\t    &domain, &rid);\n\t\telse\n\t\t\tstatus = kidmap_getsidbygid(crgetzone(cr), id,\n\t\t\t    &domain, &rid);\n\n\t\tif (status != 0) {\n\t\t\t/*\n\t\t\t * When returning nobody we will need to\n\t\t\t * make a dummy fuid table entry for logging\n\t\t\t * purposes.\n\t\t\t */\n\t\t\trid = UID_NOBODY;\n\t\t\tdomain = nulldomain;\n\t\t}\n\t}\n\n\tidx = zfs_fuid_find_by_domain(zfsvfs, domain, &kdomain, B_TRUE);\n\n\tif (!zfsvfs->z_replay)\n\t\tzfs_fuid_node_add(fuidpp, kdomain,\n\t\t    rid, idx, id, type);\n\telse if (zfuid != NULL) {\n\t\tlist_remove(&fuidp->z_fuids, zfuid);\n\t\tkmem_free(zfuid, sizeof (zfs_fuid_t));\n\t}\n\treturn (FUID_ENCODE(idx, rid));\n#else\n\t/*\n\t * The Linux port only supports POSIX IDs, use the passed id.\n\t */\n\treturn (id);\n#endif\n}", "target": 1, "cwe": ["CWE-200", "CWE-732"], "project": "zfs", "commit_id": "716b53d0a14c72bda16c0872565dd1909757e73f", "hash": 115117577215824350160594834830046446769, "size": 92, "message": "FreeBSD: Fix UNIX permissions checking\n\nReviewed-by: Ryan Moeller <ryan@iXsystems.com>\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: Matt Macy <mmacy@FreeBSD.org>\r\nCloses #10727"}
{"func": "zfs_fuid_map_id(zfsvfs_t *zfsvfs, uint64_t fuid,\n    cred_t *cr, zfs_fuid_type_t type)\n{\n#ifdef HAVE_KSID\n\tuint32_t index = FUID_INDEX(fuid);\n\tconst char *domain;\n\tuid_t id;\n\n\tif (index == 0)\n\t\treturn (fuid);\n\n\tdomain = zfs_fuid_find_by_idx(zfsvfs, index);\n\tASSERT(domain != NULL);\n\n\tif (type == ZFS_OWNER || type == ZFS_ACE_USER) {\n\t\t(void) kidmap_getuidbysid(crgetzone(cr), domain,\n\t\t    FUID_RID(fuid), &id);\n\t} else {\n\t\t(void) kidmap_getgidbysid(crgetzone(cr), domain,\n\t\t    FUID_RID(fuid), &id);\n\t}\n\treturn (id);\n#else\n\t/*\n\t * The Linux port only supports POSIX IDs, use the passed id.\n\t */\n\treturn (fuid);\n#endif /* HAVE_KSID */\n}", "target": 1, "cwe": ["CWE-200", "CWE-732"], "project": "zfs", "commit_id": "716b53d0a14c72bda16c0872565dd1909757e73f", "hash": 141391251058409255705568933645791807531, "size": 29, "message": "FreeBSD: Fix UNIX permissions checking\n\nReviewed-by: Ryan Moeller <ryan@iXsystems.com>\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: Matt Macy <mmacy@FreeBSD.org>\r\nCloses #10727"}
{"func": "zfs_fuid_create_cred(zfsvfs_t *zfsvfs, zfs_fuid_type_t type,\n    cred_t *cr, zfs_fuid_info_t **fuidp)\n{\n\tuid_t\t\tid;\n\n\tVERIFY(type == ZFS_OWNER || type == ZFS_GROUP);\n\n\tid = (type == ZFS_OWNER) ? crgetuid(cr) : crgetgid(cr);\n\n\tif (IS_EPHEMERAL(id))\n\t\treturn ((type == ZFS_OWNER) ? UID_NOBODY : GID_NOBODY);\n\n\treturn ((uint64_t)id);\n}", "target": 1, "cwe": ["CWE-200", "CWE-732"], "project": "zfs", "commit_id": "716b53d0a14c72bda16c0872565dd1909757e73f", "hash": 73053503321509833936455533161580713621, "size": 14, "message": "FreeBSD: Fix UNIX permissions checking\n\nReviewed-by: Ryan Moeller <ryan@iXsystems.com>\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: Matt Macy <mmacy@FreeBSD.org>\r\nCloses #10727"}
{"func": "zfs_fastaccesschk_execute(znode_t *zdp, cred_t *cr)\n{\n\tboolean_t owner = B_FALSE;\n\tboolean_t groupmbr = B_FALSE;\n\tboolean_t is_attr;\n\tuid_t uid = crgetuid(cr);\n\n\tif (zdp->z_pflags & ZFS_AV_QUARANTINED)\n\t\treturn (1);\n\n\tis_attr = ((zdp->z_pflags & ZFS_XATTR) &&\n\t    (ZTOV(zdp)->v_type == VDIR));\n\tif (is_attr)\n\t\treturn (1);\n\n\tif (zdp->z_pflags & ZFS_NO_EXECS_DENIED)\n\t\treturn (0);\n\n\tmutex_enter(&zdp->z_acl_lock);\n\tif (FUID_INDEX(zdp->z_uid) != 0 || FUID_INDEX(zdp->z_gid) != 0) {\n\t\tgoto out_slow;\n\t}\n\n\tif (uid == zdp->z_uid) {\n\t\towner = B_TRUE;\n\t\tif (zdp->z_mode & S_IXUSR) {\n\t\t\tgoto out;\n\t\t} else {\n\t\t\tgoto out_slow;\n\t\t}\n\t}\n\tif (groupmember(zdp->z_gid, cr)) {\n\t\tgroupmbr = B_TRUE;\n\t\tif (zdp->z_mode & S_IXGRP) {\n\t\t\tgoto out;\n\t\t} else {\n\t\t\tgoto out_slow;\n\t\t}\n\t}\n\tif (!owner && !groupmbr) {\n\t\tif (zdp->z_mode & S_IXOTH) {\n\t\t\tgoto out;\n\t\t}\n\t}\nout:\n\tmutex_exit(&zdp->z_acl_lock);\n\treturn (0);\nout_slow:\n\tmutex_exit(&zdp->z_acl_lock);\n\treturn (1);\n}", "target": 1, "cwe": ["CWE-200", "CWE-732"], "project": "zfs", "commit_id": "716b53d0a14c72bda16c0872565dd1909757e73f", "hash": 138106547912761146095264922730373268580, "size": 51, "message": "FreeBSD: Fix UNIX permissions checking\n\nReviewed-by: Ryan Moeller <ryan@iXsystems.com>\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: Matt Macy <mmacy@FreeBSD.org>\r\nCloses #10727"}
{"func": "zfs_groupmember(zfsvfs_t *zfsvfs, uint64_t id, cred_t *cr)\n{\n#ifdef HAVE_KSID\n\tksid_t\t\t*ksid = crgetsid(cr, KSID_GROUP);\n\tksidlist_t\t*ksidlist = crgetsidlist(cr);\n\tuid_t\t\tgid;\n\n\tif (ksid && ksidlist) {\n\t\tint\t\ti;\n\t\tksid_t\t\t*ksid_groups;\n\t\tuint32_t\tidx = FUID_INDEX(id);\n\t\tuint32_t\trid = FUID_RID(id);\n\n\t\tksid_groups = ksidlist->ksl_sids;\n\n\t\tfor (i = 0; i != ksidlist->ksl_nsid; i++) {\n\t\t\tif (idx == 0) {\n\t\t\t\tif (id != IDMAP_WK_CREATOR_GROUP_GID &&\n\t\t\t\t    id == ksid_groups[i].ks_id) {\n\t\t\t\t\treturn (B_TRUE);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tconst char *domain;\n\n\t\t\t\tdomain = zfs_fuid_find_by_idx(zfsvfs, idx);\n\t\t\t\tASSERT(domain != NULL);\n\n\t\t\t\tif (strcmp(domain,\n\t\t\t\t    IDMAP_WK_CREATOR_SID_AUTHORITY) == 0)\n\t\t\t\t\treturn (B_FALSE);\n\n\t\t\t\tif ((strcmp(domain,\n\t\t\t\t    ksid_groups[i].ks_domain->kd_name) == 0) &&\n\t\t\t\t    rid == ksid_groups[i].ks_rid)\n\t\t\t\t\treturn (B_TRUE);\n\t\t\t}\n\t\t}\n\t}\n\n\t/*\n\t * Not found in ksidlist, check posix groups\n\t */\n\tgid = zfs_fuid_map_id(zfsvfs, id, cr, ZFS_GROUP);\n\treturn (groupmember(gid, cr));\n#else\n\treturn (B_TRUE);\n#endif\n}", "target": 1, "cwe": ["CWE-200", "CWE-732"], "project": "zfs", "commit_id": "716b53d0a14c72bda16c0872565dd1909757e73f", "hash": 285154739991858380781519390216649432106, "size": 48, "message": "FreeBSD: Fix UNIX permissions checking\n\nReviewed-by: Ryan Moeller <ryan@iXsystems.com>\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: Matt Macy <mmacy@FreeBSD.org>\r\nCloses #10727"}
{"func": "push_new_name_resolution_context(THD *thd,\n                                 TABLE_LIST *left_op, TABLE_LIST *right_op)\n{\n  Name_resolution_context *on_context;\n  if (!(on_context= new (thd->mem_root) Name_resolution_context))\n    return TRUE;\n  on_context->init();\n  on_context->first_name_resolution_table=\n    left_op->first_leaf_for_name_resolution();\n  on_context->last_name_resolution_table=\n    right_op->last_leaf_for_name_resolution();\n  LEX *lex= thd->lex;\n  on_context->select_lex = lex->current_select;\n  st_select_lex *curr_select= lex->pop_select();\n  st_select_lex *outer_sel= lex->select_stack_head();\n  lex->push_select(curr_select);\n  on_context->outer_context = outer_sel ? &outer_sel->context : 0;\n  return lex->push_context(on_context);\n}", "target": 1, "cwe": ["CWE-703"], "project": "server", "commit_id": "39feab3cd31b5414aa9b428eaba915c251ac34a2", "hash": 113975435971676800689783835505835352436, "size": 19, "message": "MDEV-26412 Server crash in Item_field::fix_outer_field for INSERT SELECT\n\nIF an INSERT/REPLACE SELECT statement contained an ON expression in the top\nlevel select and this expression used a subquery with a column reference\nthat could not be resolved then an attempt to resolve this reference as\nan outer reference caused a crash of the server. This happened because the\nouter context field in the Name_resolution_context structure was not set\nto NULL for such references. Rather it pointed to the first element in\nthe select_stack.\n\nNote that starting from 10.4 we cannot use the SELECT_LEX::outer_select()\nmethod when parsing a SELECT construct.\n\nApproved by Oleksandr Byelkin <sanja@mariadb.com>"}
{"func": "void LEX::start(THD *thd_arg)\n{\n  DBUG_ENTER(\"LEX::start\");\n  DBUG_PRINT(\"info\", (\"This: %p thd_arg->lex: %p\", this, thd_arg->lex));\n\n  thd= unit.thd= thd_arg;\n  stmt_lex= this; // default, should be rewritten for VIEWs And CTEs\n\n  DBUG_ASSERT(!explain);\n\n  builtin_select.lex_start(this);\n  lex_options= 0;\n  context_stack.empty();\n  //empty select_stack\n  select_stack_top= 0;\n  unit.init_query();\n  current_select_number= 0;\n  curr_with_clause= 0;\n  with_clauses_list= 0;\n  with_clauses_list_last_next= &with_clauses_list;\n  clone_spec_offset= 0;\n  create_view= NULL;\n  field_list.empty();\n  value_list.empty();\n  update_list.empty();\n  set_var_list.empty();\n  param_list.empty();\n  view_list.empty();\n  with_column_list.empty();\n  with_persistent_for_clause= FALSE;\n  column_list= NULL;\n  index_list= NULL;\n  prepared_stmt.lex_start();\n  auxiliary_table_list.empty();\n  unit.next= unit.master= unit.link_next= unit.return_to= 0;\n  unit.prev= unit.link_prev= 0;\n  unit.slave= current_select= all_selects_list= &builtin_select;\n  sql_cache= LEX::SQL_CACHE_UNSPECIFIED;\n  describe= 0;\n  analyze_stmt= 0;\n  explain_json= false;\n  context_analysis_only= 0;\n  derived_tables= 0;\n  with_cte_resolution= false;\n  only_cte_resolution= false;\n  safe_to_cache_query= 1;\n  parsing_options.reset();\n  empty_field_list_on_rset= 0;\n  part_info= 0;\n  m_sql_cmd= NULL;\n  duplicates= DUP_ERROR;\n  ignore= 0;\n  spname= NULL;\n  spcont= NULL;\n  proc_list.first= 0;\n  escape_used= FALSE;\n  default_used= FALSE;\n  query_tables= 0;\n  reset_query_tables_list(FALSE);\n  clause_that_disallows_subselect= NULL;\n  selects_allow_into= FALSE;\n  selects_allow_procedure= FALSE;\n  use_only_table_context= FALSE;\n  parse_vcol_expr= FALSE;\n  check_exists= FALSE;\n  create_info.lex_start();\n  verbose= 0;\n\n  name= null_clex_str;\n  event_parse_data= NULL;\n  profile_options= PROFILE_NONE;\n  nest_level= 0;\n  builtin_select.nest_level_base= &unit;\n  allow_sum_func.clear_all();\n  in_sum_func= NULL;\n\n  used_tables= 0;\n  table_type= TABLE_TYPE_UNKNOWN;\n  reset_slave_info.all= false;\n  limit_rows_examined= 0;\n  limit_rows_examined_cnt= ULONGLONG_MAX;\n  var_list.empty();\n  stmt_var_list.empty();\n  proc_list.elements=0;\n\n  save_group_list.empty();\n  save_order_list.empty();\n  win_ref= NULL;\n  win_frame= NULL;\n  frame_top_bound= NULL;\n  frame_bottom_bound= NULL;\n  win_spec= NULL;\n\n  vers_conditions.empty();\n  period_conditions.empty();\n\n  is_lex_started= TRUE;\n\n  next_is_main= FALSE;\n  next_is_down= FALSE;\n\n  wild= 0;\n  exchange= 0;\n\n  DBUG_VOID_RETURN;\n}", "target": 1, "cwe": ["CWE-703"], "project": "server", "commit_id": "39feab3cd31b5414aa9b428eaba915c251ac34a2", "hash": 26699921584460092807999602188958188903, "size": 106, "message": "MDEV-26412 Server crash in Item_field::fix_outer_field for INSERT SELECT\n\nIF an INSERT/REPLACE SELECT statement contained an ON expression in the top\nlevel select and this expression used a subquery with a column reference\nthat could not be resolved then an attempt to resolve this reference as\nan outer reference caused a crash of the server. This happened because the\nouter context field in the Name_resolution_context structure was not set\nto NULL for such references. Rather it pointed to the first element in\nthe select_stack.\n\nNote that starting from 10.4 we cannot use the SELECT_LEX::outer_select()\nmethod when parsing a SELECT construct.\n\nApproved by Oleksandr Byelkin <sanja@mariadb.com>"}
{"func": "static int post_msg(struct pptp_conn_t *conn, void *buf, int size)\n{\n\tint n;\n\tif (conn->out_size) {\n\t\tlog_error(\"pptp: buffer is not empty\\n\");\n\t\treturn -1;\n\t}\n\nagain:\n\tn=write(conn->hnd.fd, buf, size);\n\tif (n < 0) {\n\t\tif (errno == EINTR)\n\t\t\tgoto again;\n\t\telse if (errno == EAGAIN)\n\t\t\tn = 0;\n\t\telse {\n\t\t\tif (errno != EPIPE) {\n\t\t\t\tif (conf_verbose)\n\t\t\t\t\tlog_ppp_info2(\"pptp: write: %s\\n\", strerror(errno));\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\t}\n\n\tif ( n<size ) {\n\t\tmemcpy(conn->out_buf, (uint8_t *)buf + n, size - n);\n\t\ttriton_md_enable_handler(&conn->hnd, MD_MODE_WRITE);\n\t}\n\n\treturn 0;\n}", "target": 1, "cwe": ["CWE-787"], "project": "accel-ppp", "commit_id": "a0b8bfc4e74ff31b15ccfa6c626e3bbc591ba98f", "hash": 330227030877580280456793267806417303182, "size": 31, "message": "Fix post_msg implementation bug\n\nI think the error handling code of `post_msg` is wrongly implemented due to coding typo. The `EPIPE` should be also considered and then return -1, just like `PPTP_write`:\r\nhttps://github.com/xebd/accel-ppp/blob/1b8711cf75a7c278d99840112bc7a396398e0205/accel-pppd/ctrl/pptp/pptp.c#L539-L570\r\n\r\nThis pr fixes #158."}
{"func": "int ossl_rsaz_mod_exp_avx512_x2(BN_ULONG *res1,\n                                const BN_ULONG *base1,\n                                const BN_ULONG *exp1,\n                                const BN_ULONG *m1,\n                                const BN_ULONG *rr1,\n                                BN_ULONG k0_1,\n                                BN_ULONG *res2,\n                                const BN_ULONG *base2,\n                                const BN_ULONG *exp2,\n                                const BN_ULONG *m2,\n                                const BN_ULONG *rr2,\n                                BN_ULONG k0_2,\n                                int factor_size)\n{\n    int ret = 0;\n\n    /*\n     * Number of word-size (BN_ULONG) digits to store exponent in redundant\n     * representation.\n     */\n    int exp_digits = number_of_digits(factor_size + 2, DIGIT_SIZE);\n    int coeff_pow = 4 * (DIGIT_SIZE * exp_digits - factor_size);\n    BN_ULONG *base1_red, *m1_red, *rr1_red;\n    BN_ULONG *base2_red, *m2_red, *rr2_red;\n    BN_ULONG *coeff_red;\n    BN_ULONG *storage = NULL;\n    BN_ULONG *storage_aligned = NULL;\n    BN_ULONG storage_len_bytes = 7 * exp_digits * sizeof(BN_ULONG);\n\n    /* AMM = Almost Montgomery Multiplication */\n    AMM52 amm = NULL;\n    /* Dual (2-exps in parallel) exponentiation */\n    EXP52_x2 exp_x2 = NULL;\n\n    const BN_ULONG *exp[2] = {0};\n    BN_ULONG k0[2] = {0};\n\n    /* Only 1024-bit factor size is supported now */\n    switch (factor_size) {\n    case 1024:\n        amm = ossl_rsaz_amm52x20_x1_256;\n        exp_x2 = RSAZ_exp52x20_x2_256;\n        break;\n    default:\n        goto err;\n    }\n\n    storage = (BN_ULONG *)OPENSSL_malloc(storage_len_bytes + 64);\n    if (storage == NULL)\n        goto err;\n    storage_aligned = (BN_ULONG *)ALIGN_OF(storage, 64);\n\n    /* Memory layout for red(undant) representations */\n    base1_red = storage_aligned;\n    base2_red = storage_aligned + 1 * exp_digits;\n    m1_red    = storage_aligned + 2 * exp_digits;\n    m2_red    = storage_aligned + 3 * exp_digits;\n    rr1_red   = storage_aligned + 4 * exp_digits;\n    rr2_red   = storage_aligned + 5 * exp_digits;\n    coeff_red = storage_aligned + 6 * exp_digits;\n\n    /* Convert base_i, m_i, rr_i, from regular to 52-bit radix */\n    to_words52(base1_red, exp_digits, base1, factor_size);\n    to_words52(base2_red, exp_digits, base2, factor_size);\n    to_words52(m1_red, exp_digits, m1, factor_size);\n    to_words52(m2_red, exp_digits, m2, factor_size);\n    to_words52(rr1_red, exp_digits, rr1, factor_size);\n    to_words52(rr2_red, exp_digits, rr2, factor_size);\n\n    /*\n     * Compute target domain Montgomery converters RR' for each modulus\n     * based on precomputed original domain's RR.\n     *\n     * RR -> RR' transformation steps:\n     *  (1) coeff = 2^k\n     *  (2) t = AMM(RR,RR) = RR^2 / R' mod m\n     *  (3) RR' = AMM(t, coeff) = RR^2 * 2^k / R'^2 mod m\n     * where\n     *  k = 4 * (52 * digits52 - modlen)\n     *  R  = 2^(64 * ceil(modlen/64)) mod m\n     *  RR = R^2 mod M\n     *  R' = 2^(52 * ceil(modlen/52)) mod m\n     *\n     *  modlen = 1024: k = 64, RR = 2^2048 mod m, RR' = 2^2080 mod m\n     */\n    memset(coeff_red, 0, exp_digits * sizeof(BN_ULONG));\n    /* (1) in reduced domain representation */\n    set_bit(coeff_red, 64 * (int)(coeff_pow / 52) + coeff_pow % 52);\n\n    amm(rr1_red, rr1_red, rr1_red, m1_red, k0_1);     /* (2) for m1 */\n    amm(rr1_red, rr1_red, coeff_red, m1_red, k0_1);   /* (3) for m1 */\n\n    amm(rr2_red, rr2_red, rr2_red, m2_red, k0_2);     /* (2) for m2 */\n    amm(rr2_red, rr2_red, coeff_red, m2_red, k0_2);   /* (3) for m2 */\n\n    exp[0] = exp1;\n    exp[1] = exp2;\n\n    k0[0] = k0_1;\n    k0[1] = k0_2;\n\n    exp_x2(rr1_red, base1_red, exp, m1_red, rr1_red, k0);\n\n    /* Convert rr_i back to regular radix */\n    from_words52(res1, factor_size, rr1_red);\n    from_words52(res2, factor_size, rr2_red);\n\n    bn_reduce_once_in_place(res1, /*carry=*/0, m1, storage, factor_size);\n    bn_reduce_once_in_place(res2, /*carry=*/0, m2, storage, factor_size);\n\n    ret = 1;\nerr:\n    if (storage != NULL) {\n        OPENSSL_cleanse(storage, storage_len_bytes);\n        OPENSSL_free(storage);\n    }\n    return ret;\n}", "target": 1, "cwe": ["CWE-787"], "project": "openssl", "commit_id": "a1f7034bbd8f0730d360211f5ba0feeaef0b7b2c", "hash": 54910092100460222083027232944043080083, "size": 118, "message": "rsa: fix bn_reduce_once_in_place call for rsaz_mod_exp_avx512_x2\n\nbn_reduce_once_in_place expects the number of BN_ULONG, but factor_size\nis moduli bit size.\n\nFixes #18625.\n\nSigned-off-by: Xi Ruoyao <xry111@xry111.site>\n\nReviewed-by: Tomas Mraz <tomas@openssl.org>\nReviewed-by: Paul Dale <pauli@openssl.org>\n(Merged from https://github.com/openssl/openssl/pull/18626)\n\n(cherry picked from commit 4d8a88c134df634ba610ff8db1eb8478ac5fd345)"}
{"func": "static void dtls1_clear_queues(SSL *s)\n\t{\n    pitem *item = NULL;\n    hm_fragment *frag = NULL;\n\tDTLS1_RECORD_DATA *rdata;\n\n    while( (item = pqueue_pop(s->d1->unprocessed_rcds.q)) != NULL)\n        {\n\t\trdata = (DTLS1_RECORD_DATA *) item->data;\n\t\tif (rdata->rbuf.buf)\n\t\t\t{\n\t\t\tOPENSSL_free(rdata->rbuf.buf);\n\t\t\t}\n        OPENSSL_free(item->data);\n        pitem_free(item);\n        }\n\n    while( (item = pqueue_pop(s->d1->processed_rcds.q)) != NULL)\n        {\n\t\trdata = (DTLS1_RECORD_DATA *) item->data;\n\t\tif (rdata->rbuf.buf)\n\t\t\t{\n\t\t\tOPENSSL_free(rdata->rbuf.buf);\n\t\t\t}\n        OPENSSL_free(item->data);\n        pitem_free(item);\n        }\n\n    while( (item = pqueue_pop(s->d1->buffered_messages)) != NULL)\n        {\n        frag = (hm_fragment *)item->data;\n        OPENSSL_free(frag->fragment);\n        OPENSSL_free(frag);\n        pitem_free(item);\n        }\n\n    while ( (item = pqueue_pop(s->d1->sent_messages)) != NULL)\n        {\n        frag = (hm_fragment *)item->data;\n        OPENSSL_free(frag->fragment);\n        OPENSSL_free(frag);\n        pitem_free(item);\n        }\n\n\twhile ( (item = pqueue_pop(s->d1->buffered_app_data.q)) != NULL)\n\t\t{\n\t\tfrag = (hm_fragment *)item->data;\n\t\tOPENSSL_free(frag->fragment);\n\t\tOPENSSL_free(frag);\n\t\tpitem_free(item);\n\t\t}\n\t}", "target": 1, "cwe": ["CWE-119", "CWE-787"], "project": "openssl", "commit_id": "470990fee0182566d439ef7e82d1abf18b7085d7", "hash": 225400983112650092140449666894345670350, "size": 52, "message": "Free up s->d1->buffered_app_data.q properly.\n\nPR#3286"}
{"func": "cl_ulong4 Dispatcher::Device::createSeed() {\n#ifdef PROFANITY_DEBUG\n\tcl_ulong4 r;\n\tr.s[0] = 1;\n\tr.s[1] = 1;\n\tr.s[2] = 1;\n\tr.s[3] = 1;\n\treturn r;\n#else\n\t// Randomize private keys\n\tstd::random_device rd;\n\tstd::mt19937_64 eng(rd());\n\tstd::uniform_int_distribution<cl_ulong> distr;\n\n\tcl_ulong4 r;\n\tr.s[0] = distr(eng);\n\tr.s[1] = distr(eng);\n\tr.s[2] = distr(eng);\n\tr.s[3] = distr(eng);\n\treturn r;\n#endif\n}", "target": 1, "cwe": ["CWE-703"], "project": "profanity", "commit_id": "69ff010c14ff80ec14246772db6a245aa59e6689", "hash": 53102944657719213427114258545200757332, "size": 22, "message": "[FIX] pritive key seed ."}
{"func": "int main(int argc, char * * argv) {\n\tTHIS LINE WILL LEAD TO A COMPILE ERROR. THIS TOOL SHOULD NOT BE USED, SEE README.\n\n\ttry {\n\t\tArgParser argp(argc, argv);\n\t\tbool bHelp = false;\n\t\tbool bModeBenchmark = false;\n\t\tbool bModeZeros = false;\n\t\tbool bModeLetters = false;\n\t\tbool bModeNumbers = false;\n\t\tstd::string strModeLeading;\n\t\tstd::string strModeMatching;\n\t\tbool bModeLeadingRange = false;\n\t\tbool bModeRange = false;\n\t\tbool bModeMirror = false;\n\t\tbool bModeDoubles = false;\n\t\tint rangeMin = 0;\n\t\tint rangeMax = 0;\n\t\tstd::vector<size_t> vDeviceSkipIndex;\n\t\tsize_t worksizeLocal = 64;\n\t\tsize_t worksizeMax = 0; // Will be automatically determined later if not overriden by user\n\t\tbool bNoCache = false;\n\t\tsize_t inverseSize = 255;\n\t\tsize_t inverseMultiple = 16384;\n\t\tbool bMineContract = false;\n\n\t\targp.addSwitch('h', \"help\", bHelp);\n\t\targp.addSwitch('0', \"benchmark\", bModeBenchmark);\n\t\targp.addSwitch('1', \"zeros\", bModeZeros);\n\t\targp.addSwitch('2', \"letters\", bModeLetters);\n\t\targp.addSwitch('3', \"numbers\", bModeNumbers);\n\t\targp.addSwitch('4', \"leading\", strModeLeading);\n\t\targp.addSwitch('5', \"matching\", strModeMatching);\n\t\targp.addSwitch('6', \"leading-range\", bModeLeadingRange);\n\t\targp.addSwitch('7', \"range\", bModeRange);\n\t\targp.addSwitch('8', \"mirror\", bModeMirror);\n\t\targp.addSwitch('9', \"leading-doubles\", bModeDoubles);\n\t\targp.addSwitch('m', \"min\", rangeMin);\n\t\targp.addSwitch('M', \"max\", rangeMax);\n\t\targp.addMultiSwitch('s', \"skip\", vDeviceSkipIndex);\n\t\targp.addSwitch('w', \"work\", worksizeLocal);\n\t\targp.addSwitch('W', \"work-max\", worksizeMax);\n\t\targp.addSwitch('n', \"no-cache\", bNoCache);\n\t\targp.addSwitch('i', \"inverse-size\", inverseSize);\n\t\targp.addSwitch('I', \"inverse-multiple\", inverseMultiple);\n\t\targp.addSwitch('c', \"contract\", bMineContract);\n\n\t\tif (!argp.parse()) {\n\t\t\tstd::cout << \"error: bad arguments, try again :<\" << std::endl;\n\t\t\treturn 1;\n\t\t}\n\n\t\tif (bHelp) {\n\t\t\tstd::cout << g_strHelp << std::endl;\n\t\t\treturn 0;\n\t\t}\n\n\t\tMode mode = Mode::benchmark();\n\t\tif (bModeBenchmark) {\n\t\t\tmode = Mode::benchmark();\n\t\t} else if (bModeZeros) {\n\t\t\tmode = Mode::zeros();\n\t\t} else if (bModeLetters) {\n\t\t\tmode = Mode::letters();\n\t\t} else if (bModeNumbers) {\n\t\t\tmode = Mode::numbers();\n\t\t} else if (!strModeLeading.empty()) {\n\t\t\tmode = Mode::leading(strModeLeading.front());\n\t\t} else if (!strModeMatching.empty()) {\n\t\t\tmode = Mode::matching(strModeMatching);\n\t\t} else if (bModeLeadingRange) {\n\t\t\tmode = Mode::leadingRange(rangeMin, rangeMax);\n\t\t} else if (bModeRange) {\n\t\t\tmode = Mode::range(rangeMin, rangeMax);\n\t\t} else if(bModeMirror) {\n\t\t\tmode = Mode::mirror();\n\t\t} else if (bModeDoubles) {\n\t\t\tmode = Mode::doubles();\n\t\t} else {\n\t\t\tstd::cout << g_strHelp << std::endl;\n\t\t\treturn 0;\n\t\t}\n\t\tstd::cout << \"Mode: \" << mode.name << std::endl;\n\n\t\tif (bMineContract) {\n\t\t\tmode.target = CONTRACT;\n\t\t} else {\n\t\t\tmode.target = ADDRESS;\n\t\t}\n\t\tstd::cout << \"Target: \" << mode.transformName() << std:: endl;\n\n\t\tstd::vector<cl_device_id> vFoundDevices = getAllDevices();\n\t\tstd::vector<cl_device_id> vDevices;\n\t\tstd::map<cl_device_id, size_t> mDeviceIndex;\n\n\t\tstd::vector<std::string> vDeviceBinary;\n\t\tstd::vector<size_t> vDeviceBinarySize;\n\t\tcl_int errorCode;\n\t\tbool bUsedCache = false;\n\n\t\tstd::cout << \"Devices:\" << std::endl;\n\t\tfor (size_t i = 0; i < vFoundDevices.size(); ++i) {\n\t\t\t// Ignore devices in skip index\n\t\t\tif (std::find(vDeviceSkipIndex.begin(), vDeviceSkipIndex.end(), i) != vDeviceSkipIndex.end()) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tcl_device_id & deviceId = vFoundDevices[i];\n\n\t\t\tconst auto strName = clGetWrapperString(clGetDeviceInfo, deviceId, CL_DEVICE_NAME);\n\t\t\tconst auto computeUnits = clGetWrapper<cl_uint>(clGetDeviceInfo, deviceId, CL_DEVICE_MAX_COMPUTE_UNITS);\n\t\t\tconst auto globalMemSize = clGetWrapper<cl_ulong>(clGetDeviceInfo, deviceId, CL_DEVICE_GLOBAL_MEM_SIZE);\n\t\t\tbool precompiled = false;\n\n\t\t\t// Check if there's a prebuilt binary for this device and load it\n\t\t\tif(!bNoCache) {\n\t\t\t\tstd::ifstream fileIn(getDeviceCacheFilename(deviceId, inverseSize), std::ios::binary);\n\t\t\t\tif (fileIn.is_open()) {\n\t\t\t\t\tvDeviceBinary.push_back(std::string((std::istreambuf_iterator<char>(fileIn)), std::istreambuf_iterator<char>()));\n\t\t\t\t\tvDeviceBinarySize.push_back(vDeviceBinary.back().size());\n\t\t\t\t\tprecompiled = true;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tstd::cout << \"  GPU\" << i << \": \" << strName << \", \" << globalMemSize << \" bytes available, \" << computeUnits << \" compute units (precompiled = \" << (precompiled ? \"yes\" : \"no\") << \")\" << std::endl;\n\t\t\tvDevices.push_back(vFoundDevices[i]);\n\t\t\tmDeviceIndex[vFoundDevices[i]] = i;\n\t\t}\n\n\t\tif (vDevices.empty()) {\n\t\t\treturn 1;\n\t\t}\n\n\t\tstd::cout << std::endl;\n\t\tstd::cout << \"Initializing OpenCL...\" << std::endl;\n\t\tstd::cout << \"  Creating context...\" << std::flush;\n\t\tauto clContext = clCreateContext( NULL, vDevices.size(), vDevices.data(), NULL, NULL, &errorCode);\n\t\tif (printResult(clContext, errorCode)) {\n\t\t\treturn 1;\n\t\t}\n\n\t\tcl_program clProgram;\n\t\tif (vDeviceBinary.size() == vDevices.size()) {\n\t\t\t// Create program from binaries\n\t\t\tbUsedCache = true;\n\n\t\t\tstd::cout << \"  Loading kernel from binary...\" << std::flush;\n\t\t\tconst unsigned char * * pKernels = new const unsigned char *[vDevices.size()];\n\t\t\tfor (size_t i = 0; i < vDeviceBinary.size(); ++i) {\n\t\t\t\tpKernels[i] = reinterpret_cast<const unsigned char *>(vDeviceBinary[i].data());\n\t\t\t}\n\n\t\t\tcl_int * pStatus = new cl_int[vDevices.size()];\n\n\t\t\tclProgram = clCreateProgramWithBinary(clContext, vDevices.size(), vDevices.data(), vDeviceBinarySize.data(), pKernels, pStatus, &errorCode);\n\t\t\tif(printResult(clProgram, errorCode)) {\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t} else {\n\t\t\t// Create a program from the kernel source\n\t\t\tstd::cout << \"  Compiling kernel...\" << std::flush;\n\t\t\tconst std::string strKeccak = readFile(\"keccak.cl\");\n\t\t\tconst std::string strVanity = readFile(\"profanity.cl\");\n\t\t\tconst char * szKernels[] = { strKeccak.c_str(), strVanity.c_str() };\n\n\t\t\tclProgram = clCreateProgramWithSource(clContext, sizeof(szKernels) / sizeof(char *), szKernels, NULL, &errorCode);\n\t\t\tif (printResult(clProgram, errorCode)) {\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t}\n\n\t\t// Build the program\n\t\tstd::cout << \"  Building program...\" << std::flush;\n\t\tconst std::string strBuildOptions = \"-D PROFANITY_INVERSE_SIZE=\" + toString(inverseSize) + \" -D PROFANITY_MAX_SCORE=\" + toString(PROFANITY_MAX_SCORE);\n\t\tif (printResult(clBuildProgram(clProgram, vDevices.size(), vDevices.data(), strBuildOptions.c_str(), NULL, NULL))) {\n#ifdef PROFANITY_DEBUG\n\t\t\tstd::cout << std::endl;\n\t\t\tstd::cout << \"build log:\" << std::endl;\n\n\t\t\tsize_t sizeLog;\n\t\t\tclGetProgramBuildInfo(clProgram, vDevices[0], CL_PROGRAM_BUILD_LOG, 0, NULL, &sizeLog);\n\t\t\tchar * const szLog = new char[sizeLog];\n\t\t\tclGetProgramBuildInfo(clProgram, vDevices[0], CL_PROGRAM_BUILD_LOG, sizeLog, szLog, NULL);\n\n\t\t\tstd::cout << szLog << std::endl;\n\t\t\tdelete[] szLog;\n#endif\n\t\t\treturn 1;\n\t\t}\n\n\t\t// Save binary to improve future start times\n\t\tif( !bUsedCache && !bNoCache ) {\n\t\t\tstd::cout << \"  Saving program...\" << std::flush;\n\t\t\tauto binaries = getBinaries(clProgram);\n\t\t\tfor (size_t i = 0; i < binaries.size(); ++i) {\n\t\t\t\tstd::ofstream fileOut(getDeviceCacheFilename(vDevices[i], inverseSize), std::ios::binary);\n\t\t\t\tfileOut.write(binaries[i].data(), binaries[i].size());\n\t\t\t}\n\t\t\tstd::cout << \"OK\" << std::endl;\n\t\t}\n\n\t\tstd::cout << std::endl;\n\n\t\tDispatcher d(clContext, clProgram, mode, worksizeMax == 0 ? inverseSize * inverseMultiple : worksizeMax, inverseSize, inverseMultiple, 0);\n\t\tfor (auto & i : vDevices) {\n\t\t\td.addDevice(i, worksizeLocal, mDeviceIndex[i]);\n\t\t}\n\n\t\td.run();\n\t\tclReleaseContext(clContext);\n\t\treturn 0;\n\t} catch (std::runtime_error & e) {\n\t\tstd::cout << \"std::runtime_error - \" << e.what() << std::endl;\n\t} catch (...) {\n\t\tstd::cout << \"unknown exception occured\" << std::endl;\n\t}\n\n\treturn 1;\n}", "target": 1, "cwe": ["CWE-703"], "project": "profanity", "commit_id": "69ff010c14ff80ec14246772db6a245aa59e6689", "hash": 123898114788643709639118529723954760476, "size": 219, "message": "[FIX] pritive key seed ."}
{"func": "process(register int code, unsigned char** fill)\n{\n    int incode;\n    static unsigned char firstchar;\n\n    if (code == clear) {\n\tcodesize = datasize + 1;\n\tcodemask = (1 << codesize) - 1;\n\tavail = clear + 2;\n\toldcode = -1;\n\treturn 1;\n    }\n\n    if (oldcode == -1) {\n\t*(*fill)++ = suffix[code];\n\tfirstchar = oldcode = code;\n\treturn 1;\n    }\n    if (code > avail) {\n\tfprintf(stderr, \"code %d too large for %d\\n\", code, avail);\n\treturn 0; \n    }\n\n    incode = code;\n    if (code == avail) {      /* the first code is always < avail */\n\t*stackp++ = firstchar;\n\tcode = oldcode;\n    }\n    while (code > clear) {\n\t*stackp++ = suffix[code];\n\tcode = prefix[code];\n    }\n\n    *stackp++ = firstchar = suffix[code];\n    prefix[avail] = oldcode;\n    suffix[avail] = firstchar;\n    avail++;\n\n    if (((avail & codemask) == 0) && (avail < 4096)) {\n\tcodesize++;\n\tcodemask += avail;\n    }\n    oldcode = incode;\n    do {\n\t*(*fill)++ = *--stackp;\n    } while (stackp > stack);\n    return 1;\n}", "target": 1, "cwe": ["CWE-119", "CWE-787"], "project": "libtiff", "commit_id": "ce6841d9e41d621ba23cf18b190ee6a23b2cc833", "hash": 114389091137169326256738672610964076040, "size": 48, "message": "fix possible OOB write in gif2tiff.c"}
{"func": "  inline st_select_lex_node* get_slave() { return slave; }", "target": 1, "cwe": ["CWE-703"], "project": "server", "commit_id": "f439cfdf93691d451a2efe075a90526bd67b8278", "hash": 38997554567659386533772990859763285692, "size": 1, "message": "MDEV-22001: Server crashes in st_select_lex_unit::exclude_level upon execution of SP\n\nRunning some statements that use IN subqueries outside context of a regular\nquery could result in server abnormal termination.\n\nThe reason for failure is that internal structures SELECT_LEX/SELECT_LEX_UNIT\ncreated on behalf of parsed query were initialized incorrectly. Incorrect\ninitialization of the structures SELECT_LEX/SELECT_LEX_UNIT was introduced\nby the commit de745ecf29721795710910a19bd0ea3389da804c\n(MDEV-11953: support of brackets in UNION/EXCEPT/INTERSECT operations)\npushed into 10.4, that is the reason this bug report is not reproduced in 10.3.\n\nTo fix the issue the method SLECTE_LEX::register_unit is used for proper\ninitialization of the data structures SELECT_LEX/SELECT_LEX_UNIT. Additionally,\nthe method SELECT_LEX::get_slave() was removed from the source code base\nsince for those use cases where it is used it can be replaced by the method\nfirst_inner_unit()."}
{"func": "void LEX::relink_hack(st_select_lex *select_lex)\n{\n  if (!select_stack_top) // Statements of the second type\n  {\n    if (!select_lex->get_master()->get_master())\n      ((st_select_lex *) select_lex->get_master())->\n        set_master(&builtin_select);\n    if (!builtin_select.get_slave())\n      builtin_select.set_slave(select_lex->get_master());\n  }\n}", "target": 1, "cwe": ["CWE-703"], "project": "server", "commit_id": "f439cfdf93691d451a2efe075a90526bd67b8278", "hash": 74201819947962751402067538177469068566, "size": 11, "message": "MDEV-22001: Server crashes in st_select_lex_unit::exclude_level upon execution of SP\n\nRunning some statements that use IN subqueries outside context of a regular\nquery could result in server abnormal termination.\n\nThe reason for failure is that internal structures SELECT_LEX/SELECT_LEX_UNIT\ncreated on behalf of parsed query were initialized incorrectly. Incorrect\ninitialization of the structures SELECT_LEX/SELECT_LEX_UNIT was introduced\nby the commit de745ecf29721795710910a19bd0ea3389da804c\n(MDEV-11953: support of brackets in UNION/EXCEPT/INTERSECT operations)\npushed into 10.4, that is the reason this bug report is not reproduced in 10.3.\n\nTo fix the issue the method SLECTE_LEX::register_unit is used for proper\ninitialization of the data structures SELECT_LEX/SELECT_LEX_UNIT. Additionally,\nthe method SELECT_LEX::get_slave() was removed from the source code base\nsince for those use cases where it is used it can be replaced by the method\nfirst_inner_unit()."}
{"func": "int tls1_mac(SSL *ssl, SSL3_RECORD *rec, unsigned char *md, int send)\n{\n    unsigned char *seq;\n    EVP_MD_CTX *hash;\n    size_t md_size;\n    int i;\n    EVP_MD_CTX *hmac = NULL, *mac_ctx;\n    unsigned char header[13];\n    int stream_mac = (send ? (ssl->mac_flags & SSL_MAC_FLAG_WRITE_MAC_STREAM)\n                      : (ssl->mac_flags & SSL_MAC_FLAG_READ_MAC_STREAM));\n    int t;\n\n    if (send) {\n        seq = RECORD_LAYER_get_write_sequence(&ssl->rlayer);\n        hash = ssl->write_hash;\n    } else {\n        seq = RECORD_LAYER_get_read_sequence(&ssl->rlayer);\n        hash = ssl->read_hash;\n    }\n\n    t = EVP_MD_CTX_size(hash);\n    OPENSSL_assert(t >= 0);\n    md_size = t;\n\n    /* I should fix this up TLS TLS TLS TLS TLS XXXXXXXX */\n    if (stream_mac) {\n        mac_ctx = hash;\n    } else {\n        hmac = EVP_MD_CTX_new();\n        if (hmac == NULL || !EVP_MD_CTX_copy(hmac, hash))\n            return -1;\n        mac_ctx = hmac;\n    }\n\n    if (SSL_IS_DTLS(ssl)) {\n        unsigned char dtlsseq[8], *p = dtlsseq;\n\n        s2n(send ? DTLS_RECORD_LAYER_get_w_epoch(&ssl->rlayer) :\n            DTLS_RECORD_LAYER_get_r_epoch(&ssl->rlayer), p);\n        memcpy(p, &seq[2], 6);\n\n        memcpy(header, dtlsseq, 8);\n    } else\n        memcpy(header, seq, 8);\n\n    header[8] = rec->type;\n    header[9] = (unsigned char)(ssl->version >> 8);\n    header[10] = (unsigned char)(ssl->version);\n    header[11] = (rec->length) >> 8;\n    header[12] = (rec->length) & 0xff;\n\n    if (!send && !SSL_USE_ETM(ssl) &&\n        EVP_CIPHER_CTX_mode(ssl->enc_read_ctx) == EVP_CIPH_CBC_MODE &&\n        ssl3_cbc_record_digest_supported(mac_ctx)) {\n        /*\n         * This is a CBC-encrypted record. We must avoid leaking any\n         * timing-side channel information about how many blocks of data we\n         * are hashing because that gives an attacker a timing-oracle.\n         */\n        /* Final param == not SSLv3 */\n        if (ssl3_cbc_digest_record(mac_ctx,\n                                   md, &md_size,\n                                   header, rec->input,\n                                   rec->length + md_size, rec->orig_len,\n                                   ssl->s3->read_mac_secret,\n                                   ssl->s3->read_mac_secret_size, 0) <= 0) {\n            EVP_MD_CTX_free(hmac);\n            return -1;\n        }\n    } else {\n        if (EVP_DigestSignUpdate(mac_ctx, header, sizeof(header)) <= 0\n            || EVP_DigestSignUpdate(mac_ctx, rec->input, rec->length) <= 0\n            || EVP_DigestSignFinal(mac_ctx, md, &md_size) <= 0) {\n            EVP_MD_CTX_free(hmac);\n            return -1;\n        }\n        if (!send && !SSL_USE_ETM(ssl) && FIPS_mode())\n            if (!tls_fips_digest_extra(ssl->enc_read_ctx,\n                                       mac_ctx, rec->input,\n                                       rec->length, rec->orig_len)) {\n                EVP_MD_CTX_free(hmac);\n                return -1;\n            }\n    }\n\n    EVP_MD_CTX_free(hmac);\n\n#ifdef SSL_DEBUG\n    fprintf(stderr, \"seq=\");\n    {\n        int z;\n        for (z = 0; z < 8; z++)\n            fprintf(stderr, \"%02X \", seq[z]);\n        fprintf(stderr, \"\\n\");\n    }\n    fprintf(stderr, \"rec=\");\n    {\n        unsigned int z;\n        for (z = 0; z < rec->length; z++)\n            fprintf(stderr, \"%02X \", rec->data[z]);\n        fprintf(stderr, \"\\n\");\n    }\n#endif\n\n    if (!SSL_IS_DTLS(ssl)) {\n        for (i = 7; i >= 0; i--) {\n            ++seq[i];\n            if (seq[i] != 0)\n                break;\n        }\n    }\n#ifdef SSL_DEBUG\n    {\n        unsigned int z;\n        for (z = 0; z < md_size; z++)\n            fprintf(stderr, \"%02X \", md[z]);\n        fprintf(stderr, \"\\n\");\n    }\n#endif\n    return (md_size);\n}", "target": 1, "cwe": ["CWE-20"], "project": "openssl", "commit_id": "4ad93618d26a3ea23d36ad5498ff4f59eff3a4d2", "hash": 45438025606438848636782311096436622207, "size": 121, "message": "Don't change the state of the ETM flags until CCS processing\n\nChanging the ciphersuite during a renegotiation can result in a crash\nleading to a DoS attack. ETM has not been implemented in 1.1.0 for DTLS\nso this is TLS only.\n\nThe problem is caused by changing the flag indicating whether to use ETM\nor not immediately on negotiation of ETM, rather than at CCS. Therefore,\nduring a renegotiation, if the ETM state is changing (usually due to a\nchange of ciphersuite), then an error/crash will occur.\n\nDue to the fact that there are separate CCS messages for read and write\nwe actually now need two flags to determine whether to use ETM or not.\n\nCVE-2017-3733\n\nReviewed-by: Richard Levitte <levitte@openssl.org>"}
{"func": "static int ssl_scan_clienthello_tlsext(SSL *s, PACKET *pkt, int *al)\n{\n    unsigned int type;\n    int renegotiate_seen = 0;\n    PACKET extensions;\n\n    *al = SSL_AD_DECODE_ERROR;\n    s->servername_done = 0;\n    s->tlsext_status_type = -1;\n#ifndef OPENSSL_NO_NEXTPROTONEG\n    s->s3->next_proto_neg_seen = 0;\n#endif\n\n    OPENSSL_free(s->s3->alpn_selected);\n    s->s3->alpn_selected = NULL;\n    s->s3->alpn_selected_len = 0;\n    OPENSSL_free(s->s3->alpn_proposed);\n    s->s3->alpn_proposed = NULL;\n    s->s3->alpn_proposed_len = 0;\n#ifndef OPENSSL_NO_HEARTBEATS\n    s->tlsext_heartbeat &= ~(SSL_DTLSEXT_HB_ENABLED |\n                             SSL_DTLSEXT_HB_DONT_SEND_REQUESTS);\n#endif\n\n#ifndef OPENSSL_NO_EC\n    if (s->options & SSL_OP_SAFARI_ECDHE_ECDSA_BUG)\n        ssl_check_for_safari(s, pkt);\n#endif                          /* !OPENSSL_NO_EC */\n\n    /* Clear any signature algorithms extension received */\n    OPENSSL_free(s->s3->tmp.peer_sigalgs);\n    s->s3->tmp.peer_sigalgs = NULL;\n    s->s3->flags &= ~TLS1_FLAGS_ENCRYPT_THEN_MAC;\n\n#ifndef OPENSSL_NO_SRP\n    OPENSSL_free(s->srp_ctx.login);\n    s->srp_ctx.login = NULL;\n#endif\n\n    s->srtp_profile = NULL;\n\n    if (PACKET_remaining(pkt) == 0)\n        goto ri_check;\n\n    if (!PACKET_as_length_prefixed_2(pkt, &extensions))\n        return 0;\n\n    if (!tls1_check_duplicate_extensions(&extensions))\n        return 0;\n\n    /*\n     * We parse all extensions to ensure the ClientHello is well-formed but,\n     * unless an extension specifies otherwise, we ignore extensions upon\n     * resumption.\n     */\n    while (PACKET_get_net_2(&extensions, &type)) {\n        PACKET extension;\n        if (!PACKET_get_length_prefixed_2(&extensions, &extension))\n            return 0;\n\n        if (s->tlsext_debug_cb)\n            s->tlsext_debug_cb(s, 0, type, PACKET_data(&extension),\n                               PACKET_remaining(&extension),\n                               s->tlsext_debug_arg);\n\n        if (type == TLSEXT_TYPE_renegotiate) {\n            if (!ssl_parse_clienthello_renegotiate_ext(s, &extension, al))\n                return 0;\n            renegotiate_seen = 1;\n        } else if (s->version == SSL3_VERSION) {\n        }\n/*-\n * The servername extension is treated as follows:\n *\n * - Only the hostname type is supported with a maximum length of 255.\n * - The servername is rejected if too long or if it contains zeros,\n *   in which case an fatal alert is generated.\n * - The servername field is maintained together with the session cache.\n * - When a session is resumed, the servername call back invoked in order\n *   to allow the application to position itself to the right context.\n * - The servername is acknowledged if it is new for a session or when\n *   it is identical to a previously used for the same session.\n *   Applications can control the behaviour.  They can at any time\n *   set a 'desirable' servername for a new SSL object. This can be the\n *   case for example with HTTPS when a Host: header field is received and\n *   a renegotiation is requested. In this case, a possible servername\n *   presented in the new client hello is only acknowledged if it matches\n *   the value of the Host: field.\n * - Applications must  use SSL_OP_NO_SESSION_RESUMPTION_ON_RENEGOTIATION\n *   if they provide for changing an explicit servername context for the\n *   session, i.e. when the session has been established with a servername\n *   extension.\n * - On session reconnect, the servername extension may be absent.\n *\n */\n\n        else if (type == TLSEXT_TYPE_server_name) {\n            unsigned int servname_type;\n            PACKET sni, hostname;\n\n            if (!PACKET_as_length_prefixed_2(&extension, &sni)\n                /* ServerNameList must be at least 1 byte long. */\n                || PACKET_remaining(&sni) == 0) {\n                return 0;\n            }\n\n            /*\n             * Although the server_name extension was intended to be\n             * extensible to new name types, RFC 4366 defined the\n             * syntax inextensibility and OpenSSL 1.0.x parses it as\n             * such.\n             * RFC 6066 corrected the mistake but adding new name types\n             * is nevertheless no longer feasible, so act as if no other\n             * SNI types can exist, to simplify parsing.\n             *\n             * Also note that the RFC permits only one SNI value per type,\n             * i.e., we can only have a single hostname.\n             */\n            if (!PACKET_get_1(&sni, &servname_type)\n                || servname_type != TLSEXT_NAMETYPE_host_name\n                || !PACKET_as_length_prefixed_2(&sni, &hostname)) {\n                return 0;\n            }\n\n            if (!s->hit) {\n                if (PACKET_remaining(&hostname) > TLSEXT_MAXLEN_host_name) {\n                    *al = TLS1_AD_UNRECOGNIZED_NAME;\n                    return 0;\n                }\n\n                if (PACKET_contains_zero_byte(&hostname)) {\n                    *al = TLS1_AD_UNRECOGNIZED_NAME;\n                    return 0;\n                }\n\n                if (!PACKET_strndup(&hostname, &s->session->tlsext_hostname)) {\n                    *al = TLS1_AD_INTERNAL_ERROR;\n                    return 0;\n                }\n\n                s->servername_done = 1;\n            } else {\n                /*\n                 * TODO(openssl-team): if the SNI doesn't match, we MUST\n                 * fall back to a full handshake.\n                 */\n                s->servername_done = s->session->tlsext_hostname\n                    && PACKET_equal(&hostname, s->session->tlsext_hostname,\n                                    strlen(s->session->tlsext_hostname));\n            }\n        }\n#ifndef OPENSSL_NO_SRP\n        else if (type == TLSEXT_TYPE_srp) {\n            PACKET srp_I;\n\n            if (!PACKET_as_length_prefixed_1(&extension, &srp_I))\n                return 0;\n\n            if (PACKET_contains_zero_byte(&srp_I))\n                return 0;\n\n            /*\n             * TODO(openssl-team): currently, we re-authenticate the user\n             * upon resumption. Instead, we MUST ignore the login.\n             */\n            if (!PACKET_strndup(&srp_I, &s->srp_ctx.login)) {\n                *al = TLS1_AD_INTERNAL_ERROR;\n                return 0;\n            }\n        }\n#endif\n\n#ifndef OPENSSL_NO_EC\n        else if (type == TLSEXT_TYPE_ec_point_formats) {\n            PACKET ec_point_format_list;\n\n            if (!PACKET_as_length_prefixed_1(&extension, &ec_point_format_list)\n                || PACKET_remaining(&ec_point_format_list) == 0) {\n                return 0;\n            }\n\n            if (!s->hit) {\n                if (!PACKET_memdup(&ec_point_format_list,\n                                   &s->session->tlsext_ecpointformatlist,\n                                   &s->\n                                   session->tlsext_ecpointformatlist_length)) {\n                    *al = TLS1_AD_INTERNAL_ERROR;\n                    return 0;\n                }\n            }\n        } else if (type == TLSEXT_TYPE_elliptic_curves) {\n            PACKET elliptic_curve_list;\n\n            /* Each NamedCurve is 2 bytes and we must have at least 1. */\n            if (!PACKET_as_length_prefixed_2(&extension, &elliptic_curve_list)\n                || PACKET_remaining(&elliptic_curve_list) == 0\n                || (PACKET_remaining(&elliptic_curve_list) % 2) != 0) {\n                return 0;\n            }\n\n            if (!s->hit) {\n                if (!PACKET_memdup(&elliptic_curve_list,\n                                   &s->session->tlsext_ellipticcurvelist,\n                                   &s->\n                                   session->tlsext_ellipticcurvelist_length)) {\n                    *al = TLS1_AD_INTERNAL_ERROR;\n                    return 0;\n                }\n            }\n        }\n#endif                          /* OPENSSL_NO_EC */\n        else if (type == TLSEXT_TYPE_session_ticket) {\n            if (s->tls_session_ticket_ext_cb &&\n                !s->tls_session_ticket_ext_cb(s, PACKET_data(&extension),\n                                              PACKET_remaining(&extension),\n                                              s->tls_session_ticket_ext_cb_arg))\n            {\n                *al = TLS1_AD_INTERNAL_ERROR;\n                return 0;\n            }\n        } else if (type == TLSEXT_TYPE_signature_algorithms) {\n            PACKET supported_sig_algs;\n\n            if (!PACKET_as_length_prefixed_2(&extension, &supported_sig_algs)\n                || (PACKET_remaining(&supported_sig_algs) % 2) != 0\n                || PACKET_remaining(&supported_sig_algs) == 0) {\n                return 0;\n            }\n\n            if (!s->hit) {\n                if (!tls1_save_sigalgs(s, PACKET_data(&supported_sig_algs),\n                                       PACKET_remaining(&supported_sig_algs))) {\n                    return 0;\n                }\n            }\n        } else if (type == TLSEXT_TYPE_status_request) {\n            if (!PACKET_get_1(&extension,\n                              (unsigned int *)&s->tlsext_status_type)) {\n                return 0;\n            }\n#ifndef OPENSSL_NO_OCSP\n            if (s->tlsext_status_type == TLSEXT_STATUSTYPE_ocsp) {\n                const unsigned char *ext_data;\n                PACKET responder_id_list, exts;\n                if (!PACKET_get_length_prefixed_2\n                    (&extension, &responder_id_list))\n                    return 0;\n\n                /*\n                 * We remove any OCSP_RESPIDs from a previous handshake\n                 * to prevent unbounded memory growth - CVE-2016-6304\n                 */\n                sk_OCSP_RESPID_pop_free(s->tlsext_ocsp_ids,\n                                        OCSP_RESPID_free);\n                if (PACKET_remaining(&responder_id_list) > 0) {\n                    s->tlsext_ocsp_ids = sk_OCSP_RESPID_new_null();\n                    if (s->tlsext_ocsp_ids == NULL) {\n                        *al = SSL_AD_INTERNAL_ERROR;\n                        return 0;\n                    }\n                } else {\n                    s->tlsext_ocsp_ids = NULL;\n                }\n\n                while (PACKET_remaining(&responder_id_list) > 0) {\n                    OCSP_RESPID *id;\n                    PACKET responder_id;\n                    const unsigned char *id_data;\n\n                    if (!PACKET_get_length_prefixed_2(&responder_id_list,\n                                                      &responder_id)\n                        || PACKET_remaining(&responder_id) == 0) {\n                        return 0;\n                    }\n\n                    id_data = PACKET_data(&responder_id);\n                    id = d2i_OCSP_RESPID(NULL, &id_data,\n                                         PACKET_remaining(&responder_id));\n                    if (id == NULL)\n                        return 0;\n\n                    if (id_data != PACKET_end(&responder_id)) {\n                        OCSP_RESPID_free(id);\n                        return 0;\n                    }\n\n                    if (!sk_OCSP_RESPID_push(s->tlsext_ocsp_ids, id)) {\n                        OCSP_RESPID_free(id);\n                        *al = SSL_AD_INTERNAL_ERROR;\n                        return 0;\n                    }\n                }\n\n                /* Read in request_extensions */\n                if (!PACKET_as_length_prefixed_2(&extension, &exts))\n                    return 0;\n\n                if (PACKET_remaining(&exts) > 0) {\n                    ext_data = PACKET_data(&exts);\n                    sk_X509_EXTENSION_pop_free(s->tlsext_ocsp_exts,\n                                               X509_EXTENSION_free);\n                    s->tlsext_ocsp_exts =\n                        d2i_X509_EXTENSIONS(NULL, &ext_data,\n                                            PACKET_remaining(&exts));\n                    if (s->tlsext_ocsp_exts == NULL\n                        || ext_data != PACKET_end(&exts)) {\n                        return 0;\n                    }\n                }\n            } else\n#endif\n            {\n                /*\n                 * We don't know what to do with any other type so ignore it.\n                 */\n                s->tlsext_status_type = -1;\n            }\n        }\n#ifndef OPENSSL_NO_HEARTBEATS\n        else if (SSL_IS_DTLS(s) && type == TLSEXT_TYPE_heartbeat) {\n            unsigned int hbtype;\n\n            if (!PACKET_get_1(&extension, &hbtype)\n                || PACKET_remaining(&extension)) {\n                *al = SSL_AD_DECODE_ERROR;\n                return 0;\n            }\n            switch (hbtype) {\n            case 0x01:         /* Client allows us to send HB requests */\n                s->tlsext_heartbeat |= SSL_DTLSEXT_HB_ENABLED;\n                break;\n            case 0x02:         /* Client doesn't accept HB requests */\n                s->tlsext_heartbeat |= SSL_DTLSEXT_HB_ENABLED;\n                s->tlsext_heartbeat |= SSL_DTLSEXT_HB_DONT_SEND_REQUESTS;\n                break;\n            default:\n                *al = SSL_AD_ILLEGAL_PARAMETER;\n                return 0;\n            }\n        }\n#endif\n#ifndef OPENSSL_NO_NEXTPROTONEG\n        else if (type == TLSEXT_TYPE_next_proto_neg &&\n                 s->s3->tmp.finish_md_len == 0) {\n            /*-\n             * We shouldn't accept this extension on a\n             * renegotiation.\n             *\n             * s->new_session will be set on renegotiation, but we\n             * probably shouldn't rely that it couldn't be set on\n             * the initial renegotiation too in certain cases (when\n             * there's some other reason to disallow resuming an\n             * earlier session -- the current code won't be doing\n             * anything like that, but this might change).\n             *\n             * A valid sign that there's been a previous handshake\n             * in this connection is if s->s3->tmp.finish_md_len >\n             * 0.  (We are talking about a check that will happen\n             * in the Hello protocol round, well before a new\n             * Finished message could have been computed.)\n             */\n            s->s3->next_proto_neg_seen = 1;\n        }\n#endif\n\n        else if (type == TLSEXT_TYPE_application_layer_protocol_negotiation &&\n                 s->s3->tmp.finish_md_len == 0) {\n            if (!tls1_alpn_handle_client_hello(s, &extension, al))\n                return 0;\n        }\n\n        /* session ticket processed earlier */\n#ifndef OPENSSL_NO_SRTP\n        else if (SSL_IS_DTLS(s) && SSL_get_srtp_profiles(s)\n                 && type == TLSEXT_TYPE_use_srtp) {\n            if (ssl_parse_clienthello_use_srtp_ext(s, &extension, al))\n                return 0;\n        }\n#endif\n        else if (type == TLSEXT_TYPE_encrypt_then_mac)\n            s->s3->flags |= TLS1_FLAGS_ENCRYPT_THEN_MAC;\n        /*\n         * Note: extended master secret extension handled in\n         * tls_check_serverhello_tlsext_early()\n         */\n\n        /*\n         * If this ClientHello extension was unhandled and this is a\n         * nonresumed connection, check whether the extension is a custom\n         * TLS Extension (has a custom_srv_ext_record), and if so call the\n         * callback and record the extension number so that an appropriate\n         * ServerHello may be later returned.\n         */\n        else if (!s->hit) {\n            if (custom_ext_parse(s, 1, type, PACKET_data(&extension),\n                                 PACKET_remaining(&extension), al) <= 0)\n                return 0;\n        }\n    }\n\n    if (PACKET_remaining(pkt) != 0) {\n        /*\n         * tls1_check_duplicate_extensions should ensure this never happens.\n         */\n        *al = SSL_AD_INTERNAL_ERROR;\n        return 0;\n    }\n\n ri_check:\n\n    /* Need RI if renegotiating */\n\n    if (!renegotiate_seen && s->renegotiate &&\n        !(s->options & SSL_OP_ALLOW_UNSAFE_LEGACY_RENEGOTIATION)) {\n        *al = SSL_AD_HANDSHAKE_FAILURE;\n        SSLerr(SSL_F_SSL_SCAN_CLIENTHELLO_TLSEXT,\n               SSL_R_UNSAFE_LEGACY_RENEGOTIATION_DISABLED);\n        return 0;\n    }\n\n    /*\n     * This function currently has no state to clean up, so it returns directly.\n     * If parsing fails at any point, the function returns early.\n     * The SSL object may be left with partial data from extensions, but it must\n     * then no longer be used, and clearing it up will free the leftovers.\n     */\n    return 1;\n}", "target": 1, "cwe": ["CWE-20"], "project": "openssl", "commit_id": "4ad93618d26a3ea23d36ad5498ff4f59eff3a4d2", "hash": 90954600261504759805449028797884562674, "size": 428, "message": "Don't change the state of the ETM flags until CCS processing\n\nChanging the ciphersuite during a renegotiation can result in a crash\nleading to a DoS attack. ETM has not been implemented in 1.1.0 for DTLS\nso this is TLS only.\n\nThe problem is caused by changing the flag indicating whether to use ETM\nor not immediately on negotiation of ETM, rather than at CCS. Therefore,\nduring a renegotiation, if the ETM state is changing (usually due to a\nchange of ciphersuite), then an error/crash will occur.\n\nDue to the fact that there are separate CCS messages for read and write\nwe actually now need two flags to determine whether to use ETM or not.\n\nCVE-2017-3733\n\nReviewed-by: Richard Levitte <levitte@openssl.org>"}
{"func": "int tls1_setup_key_block(SSL *s)\n{\n    unsigned char *p;\n    const EVP_CIPHER *c;\n    const EVP_MD *hash;\n    int num;\n    SSL_COMP *comp;\n    int mac_type = NID_undef, mac_secret_size = 0;\n    int ret = 0;\n\n    if (s->s3->tmp.key_block_length != 0)\n        return (1);\n\n    if (!ssl_cipher_get_evp\n        (s->session, &c, &hash, &mac_type, &mac_secret_size, &comp,\n         SSL_USE_ETM(s))) {\n        SSLerr(SSL_F_TLS1_SETUP_KEY_BLOCK, SSL_R_CIPHER_OR_HASH_UNAVAILABLE);\n        return (0);\n    }\n\n    s->s3->tmp.new_sym_enc = c;\n    s->s3->tmp.new_hash = hash;\n    s->s3->tmp.new_mac_pkey_type = mac_type;\n    s->s3->tmp.new_mac_secret_size = mac_secret_size;\n    num = EVP_CIPHER_key_length(c) + mac_secret_size + EVP_CIPHER_iv_length(c);\n    num *= 2;\n\n    ssl3_cleanup_key_block(s);\n\n    if ((p = OPENSSL_malloc(num)) == NULL) {\n        SSLerr(SSL_F_TLS1_SETUP_KEY_BLOCK, ERR_R_MALLOC_FAILURE);\n        goto err;\n    }\n\n    s->s3->tmp.key_block_length = num;\n    s->s3->tmp.key_block = p;\n\n#ifdef SSL_DEBUG\n    printf(\"client random\\n\");\n    {\n        int z;\n        for (z = 0; z < SSL3_RANDOM_SIZE; z++)\n            printf(\"%02X%c\", s->s3->client_random[z],\n                   ((z + 1) % 16) ? ' ' : '\\n');\n    }\n    printf(\"server random\\n\");\n    {\n        int z;\n        for (z = 0; z < SSL3_RANDOM_SIZE; z++)\n            printf(\"%02X%c\", s->s3->server_random[z],\n                   ((z + 1) % 16) ? ' ' : '\\n');\n    }\n    printf(\"master key\\n\");\n    {\n        int z;\n        for (z = 0; z < s->session->master_key_length; z++)\n            printf(\"%02X%c\", s->session->master_key[z],\n                   ((z + 1) % 16) ? ' ' : '\\n');\n    }\n#endif\n    if (!tls1_generate_key_block(s, p, num))\n        goto err;\n#ifdef SSL_DEBUG\n    printf(\"\\nkey block\\n\");\n    {\n        int z;\n        for (z = 0; z < num; z++)\n            printf(\"%02X%c\", p[z], ((z + 1) % 16) ? ' ' : '\\n');\n    }\n#endif\n\n    if (!(s->options & SSL_OP_DONT_INSERT_EMPTY_FRAGMENTS)\n        && s->method->version <= TLS1_VERSION) {\n        /*\n         * enable vulnerability countermeasure for CBC ciphers with known-IV\n         * problem (http://www.openssl.org/~bodo/tls-cbc.txt)\n         */\n        s->s3->need_empty_fragments = 1;\n\n        if (s->session->cipher != NULL) {\n            if (s->session->cipher->algorithm_enc == SSL_eNULL)\n                s->s3->need_empty_fragments = 0;\n\n#ifndef OPENSSL_NO_RC4\n            if (s->session->cipher->algorithm_enc == SSL_RC4)\n                s->s3->need_empty_fragments = 0;\n#endif\n        }\n    }\n\n    ret = 1;\n err:\n    return (ret);\n}", "target": 1, "cwe": ["CWE-20"], "project": "openssl", "commit_id": "4ad93618d26a3ea23d36ad5498ff4f59eff3a4d2", "hash": 43023828588320891839283524710785442560, "size": 94, "message": "Don't change the state of the ETM flags until CCS processing\n\nChanging the ciphersuite during a renegotiation can result in a crash\nleading to a DoS attack. ETM has not been implemented in 1.1.0 for DTLS\nso this is TLS only.\n\nThe problem is caused by changing the flag indicating whether to use ETM\nor not immediately on negotiation of ETM, rather than at CCS. Therefore,\nduring a renegotiation, if the ETM state is changing (usually due to a\nchange of ciphersuite), then an error/crash will occur.\n\nDue to the fact that there are separate CCS messages for read and write\nwe actually now need two flags to determine whether to use ETM or not.\n\nCVE-2017-3733\n\nReviewed-by: Richard Levitte <levitte@openssl.org>"}
{"func": "static int ssl_scan_serverhello_tlsext(SSL *s, PACKET *pkt, int *al)\n{\n    unsigned int length, type, size;\n    int tlsext_servername = 0;\n    int renegotiate_seen = 0;\n\n#ifndef OPENSSL_NO_NEXTPROTONEG\n    s->s3->next_proto_neg_seen = 0;\n#endif\n    s->tlsext_ticket_expected = 0;\n\n    OPENSSL_free(s->s3->alpn_selected);\n    s->s3->alpn_selected = NULL;\n#ifndef OPENSSL_NO_HEARTBEATS\n    s->tlsext_heartbeat &= ~(SSL_DTLSEXT_HB_ENABLED |\n                             SSL_DTLSEXT_HB_DONT_SEND_REQUESTS);\n#endif\n\n    s->s3->flags &= ~TLS1_FLAGS_ENCRYPT_THEN_MAC;\n\n    s->s3->flags &= ~TLS1_FLAGS_RECEIVED_EXTMS;\n\n    if (!PACKET_get_net_2(pkt, &length))\n        goto ri_check;\n\n    if (PACKET_remaining(pkt) != length) {\n        *al = SSL_AD_DECODE_ERROR;\n        return 0;\n    }\n\n    if (!tls1_check_duplicate_extensions(pkt)) {\n        *al = SSL_AD_DECODE_ERROR;\n        return 0;\n    }\n\n    while (PACKET_get_net_2(pkt, &type) && PACKET_get_net_2(pkt, &size)) {\n        const unsigned char *data;\n        PACKET spkt;\n\n        if (!PACKET_get_sub_packet(pkt, &spkt, size)\n            || !PACKET_peek_bytes(&spkt, &data, size))\n            goto ri_check;\n\n        if (s->tlsext_debug_cb)\n            s->tlsext_debug_cb(s, 1, type, data, size, s->tlsext_debug_arg);\n\n        if (type == TLSEXT_TYPE_renegotiate) {\n            if (!ssl_parse_serverhello_renegotiate_ext(s, &spkt, al))\n                return 0;\n            renegotiate_seen = 1;\n        } else if (s->version == SSL3_VERSION) {\n        } else if (type == TLSEXT_TYPE_server_name) {\n            if (s->tlsext_hostname == NULL || size > 0) {\n                *al = TLS1_AD_UNRECOGNIZED_NAME;\n                return 0;\n            }\n            tlsext_servername = 1;\n        }\n#ifndef OPENSSL_NO_EC\n        else if (type == TLSEXT_TYPE_ec_point_formats) {\n            unsigned int ecpointformatlist_length;\n            if (!PACKET_get_1(&spkt, &ecpointformatlist_length)\n                || ecpointformatlist_length != size - 1) {\n                *al = TLS1_AD_DECODE_ERROR;\n                return 0;\n            }\n            if (!s->hit) {\n                s->session->tlsext_ecpointformatlist_length = 0;\n                OPENSSL_free(s->session->tlsext_ecpointformatlist);\n                if ((s->session->tlsext_ecpointformatlist =\n                     OPENSSL_malloc(ecpointformatlist_length)) == NULL) {\n                    *al = TLS1_AD_INTERNAL_ERROR;\n                    return 0;\n                }\n                s->session->tlsext_ecpointformatlist_length =\n                    ecpointformatlist_length;\n                if (!PACKET_copy_bytes(&spkt,\n                                       s->session->tlsext_ecpointformatlist,\n                                       ecpointformatlist_length)) {\n                    *al = TLS1_AD_DECODE_ERROR;\n                    return 0;\n                }\n\n            }\n        }\n#endif                          /* OPENSSL_NO_EC */\n\n        else if (type == TLSEXT_TYPE_session_ticket) {\n            if (s->tls_session_ticket_ext_cb &&\n                !s->tls_session_ticket_ext_cb(s, data, size,\n                                              s->tls_session_ticket_ext_cb_arg))\n            {\n                *al = TLS1_AD_INTERNAL_ERROR;\n                return 0;\n            }\n            if (!tls_use_ticket(s) || (size > 0)) {\n                *al = TLS1_AD_UNSUPPORTED_EXTENSION;\n                return 0;\n            }\n            s->tlsext_ticket_expected = 1;\n        } else if (type == TLSEXT_TYPE_status_request) {\n            /*\n             * MUST be empty and only sent if we've requested a status\n             * request message.\n             */\n            if ((s->tlsext_status_type == -1) || (size > 0)) {\n                *al = TLS1_AD_UNSUPPORTED_EXTENSION;\n                return 0;\n            }\n            /* Set flag to expect CertificateStatus message */\n            s->tlsext_status_expected = 1;\n        }\n#ifndef OPENSSL_NO_CT\n        /*\n         * Only take it if we asked for it - i.e if there is no CT validation\n         * callback set, then a custom extension MAY be processing it, so we\n         * need to let control continue to flow to that.\n         */\n        else if (type == TLSEXT_TYPE_signed_certificate_timestamp &&\n                 s->ct_validation_callback != NULL) {\n            /* Simply copy it off for later processing */\n            if (s->tlsext_scts != NULL) {\n                OPENSSL_free(s->tlsext_scts);\n                s->tlsext_scts = NULL;\n            }\n            s->tlsext_scts_len = size;\n            if (size > 0) {\n                s->tlsext_scts = OPENSSL_malloc(size);\n                if (s->tlsext_scts == NULL) {\n                    *al = TLS1_AD_INTERNAL_ERROR;\n                    return 0;\n                }\n                memcpy(s->tlsext_scts, data, size);\n            }\n        }\n#endif\n#ifndef OPENSSL_NO_NEXTPROTONEG\n        else if (type == TLSEXT_TYPE_next_proto_neg &&\n                 s->s3->tmp.finish_md_len == 0) {\n            unsigned char *selected;\n            unsigned char selected_len;\n            /* We must have requested it. */\n            if (s->ctx->next_proto_select_cb == NULL) {\n                *al = TLS1_AD_UNSUPPORTED_EXTENSION;\n                return 0;\n            }\n            /* The data must be valid */\n            if (!ssl_next_proto_validate(&spkt)) {\n                *al = TLS1_AD_DECODE_ERROR;\n                return 0;\n            }\n            if (s->ctx->next_proto_select_cb(s, &selected, &selected_len, data,\n                                             size,\n                                             s->\n                                             ctx->next_proto_select_cb_arg) !=\n                SSL_TLSEXT_ERR_OK) {\n                *al = TLS1_AD_INTERNAL_ERROR;\n                return 0;\n            }\n            /*\n             * Could be non-NULL if server has sent multiple NPN extensions in\n             * a single Serverhello\n             */\n            OPENSSL_free(s->next_proto_negotiated);\n            s->next_proto_negotiated = OPENSSL_malloc(selected_len);\n            if (s->next_proto_negotiated == NULL) {\n                *al = TLS1_AD_INTERNAL_ERROR;\n                return 0;\n            }\n            memcpy(s->next_proto_negotiated, selected, selected_len);\n            s->next_proto_negotiated_len = selected_len;\n            s->s3->next_proto_neg_seen = 1;\n        }\n#endif\n\n        else if (type == TLSEXT_TYPE_application_layer_protocol_negotiation) {\n            unsigned len;\n            /* We must have requested it. */\n            if (!s->s3->alpn_sent) {\n                *al = TLS1_AD_UNSUPPORTED_EXTENSION;\n                return 0;\n            }\n            /*-\n             * The extension data consists of:\n             *   uint16 list_length\n             *   uint8 proto_length;\n             *   uint8 proto[proto_length];\n             */\n            if (!PACKET_get_net_2(&spkt, &len)\n                || PACKET_remaining(&spkt) != len || !PACKET_get_1(&spkt, &len)\n                || PACKET_remaining(&spkt) != len) {\n                *al = TLS1_AD_DECODE_ERROR;\n                return 0;\n            }\n            OPENSSL_free(s->s3->alpn_selected);\n            s->s3->alpn_selected = OPENSSL_malloc(len);\n            if (s->s3->alpn_selected == NULL) {\n                *al = TLS1_AD_INTERNAL_ERROR;\n                return 0;\n            }\n            if (!PACKET_copy_bytes(&spkt, s->s3->alpn_selected, len)) {\n                *al = TLS1_AD_DECODE_ERROR;\n                return 0;\n            }\n            s->s3->alpn_selected_len = len;\n        }\n#ifndef OPENSSL_NO_HEARTBEATS\n        else if (SSL_IS_DTLS(s) && type == TLSEXT_TYPE_heartbeat) {\n            unsigned int hbtype;\n            if (!PACKET_get_1(&spkt, &hbtype)) {\n                *al = SSL_AD_DECODE_ERROR;\n                return 0;\n            }\n            switch (hbtype) {\n            case 0x01:         /* Server allows us to send HB requests */\n                s->tlsext_heartbeat |= SSL_DTLSEXT_HB_ENABLED;\n                break;\n            case 0x02:         /* Server doesn't accept HB requests */\n                s->tlsext_heartbeat |= SSL_DTLSEXT_HB_ENABLED;\n                s->tlsext_heartbeat |= SSL_DTLSEXT_HB_DONT_SEND_REQUESTS;\n                break;\n            default:\n                *al = SSL_AD_ILLEGAL_PARAMETER;\n                return 0;\n            }\n        }\n#endif\n#ifndef OPENSSL_NO_SRTP\n        else if (SSL_IS_DTLS(s) && type == TLSEXT_TYPE_use_srtp) {\n            if (ssl_parse_serverhello_use_srtp_ext(s, &spkt, al))\n                return 0;\n        }\n#endif\n        else if (type == TLSEXT_TYPE_encrypt_then_mac) {\n            /* Ignore if inappropriate ciphersuite */\n            if (s->s3->tmp.new_cipher->algorithm_mac != SSL_AEAD\n                && s->s3->tmp.new_cipher->algorithm_enc != SSL_RC4)\n                s->s3->flags |= TLS1_FLAGS_ENCRYPT_THEN_MAC;\n        } else if (type == TLSEXT_TYPE_extended_master_secret) {\n            s->s3->flags |= TLS1_FLAGS_RECEIVED_EXTMS;\n            if (!s->hit)\n                s->session->flags |= SSL_SESS_FLAG_EXTMS;\n        }\n        /*\n         * If this extension type was not otherwise handled, but matches a\n         * custom_cli_ext_record, then send it to the c callback\n         */\n        else if (custom_ext_parse(s, 0, type, data, size, al) <= 0)\n            return 0;\n    }\n\n    if (PACKET_remaining(pkt) != 0) {\n        *al = SSL_AD_DECODE_ERROR;\n        return 0;\n    }\n\n    if (!s->hit && tlsext_servername == 1) {\n        if (s->tlsext_hostname) {\n            if (s->session->tlsext_hostname == NULL) {\n                s->session->tlsext_hostname =\n                    OPENSSL_strdup(s->tlsext_hostname);\n                if (!s->session->tlsext_hostname) {\n                    *al = SSL_AD_UNRECOGNIZED_NAME;\n                    return 0;\n                }\n            } else {\n                *al = SSL_AD_DECODE_ERROR;\n                return 0;\n            }\n        }\n    }\n\n ri_check:\n\n    /*\n     * Determine if we need to see RI. Strictly speaking if we want to avoid\n     * an attack we should *always* see RI even on initial server hello\n     * because the client doesn't see any renegotiation during an attack.\n     * However this would mean we could not connect to any server which\n     * doesn't support RI so for the immediate future tolerate RI absence\n     */\n    if (!renegotiate_seen && !(s->options & SSL_OP_LEGACY_SERVER_CONNECT)\n        && !(s->options & SSL_OP_ALLOW_UNSAFE_LEGACY_RENEGOTIATION)) {\n        *al = SSL_AD_HANDSHAKE_FAILURE;\n        SSLerr(SSL_F_SSL_SCAN_SERVERHELLO_TLSEXT,\n               SSL_R_UNSAFE_LEGACY_RENEGOTIATION_DISABLED);\n        return 0;\n    }\n\n    if (s->hit) {\n        /*\n         * Check extended master secret extension is consistent with\n         * original session.\n         */\n        if (!(s->s3->flags & TLS1_FLAGS_RECEIVED_EXTMS) !=\n            !(s->session->flags & SSL_SESS_FLAG_EXTMS)) {\n            *al = SSL_AD_HANDSHAKE_FAILURE;\n            SSLerr(SSL_F_SSL_SCAN_SERVERHELLO_TLSEXT, SSL_R_INCONSISTENT_EXTMS);\n            return 0;\n        }\n    }\n\n    return 1;\n}", "target": 1, "cwe": ["CWE-20"], "project": "openssl", "commit_id": "4ad93618d26a3ea23d36ad5498ff4f59eff3a4d2", "hash": 105087991897575092046711600406602883801, "size": 304, "message": "Don't change the state of the ETM flags until CCS processing\n\nChanging the ciphersuite during a renegotiation can result in a crash\nleading to a DoS attack. ETM has not been implemented in 1.1.0 for DTLS\nso this is TLS only.\n\nThe problem is caused by changing the flag indicating whether to use ETM\nor not immediately on negotiation of ETM, rather than at CCS. Therefore,\nduring a renegotiation, if the ETM state is changing (usually due to a\nchange of ciphersuite), then an error/crash will occur.\n\nDue to the fact that there are separate CCS messages for read and write\nwe actually now need two flags to determine whether to use ETM or not.\n\nCVE-2017-3733\n\nReviewed-by: Richard Levitte <levitte@openssl.org>"}
{"func": "int tls1_change_cipher_state(SSL *s, int which)\n{\n    unsigned char *p, *mac_secret;\n    unsigned char tmp1[EVP_MAX_KEY_LENGTH];\n    unsigned char tmp2[EVP_MAX_KEY_LENGTH];\n    unsigned char iv1[EVP_MAX_IV_LENGTH * 2];\n    unsigned char iv2[EVP_MAX_IV_LENGTH * 2];\n    unsigned char *ms, *key, *iv;\n    EVP_CIPHER_CTX *dd;\n    const EVP_CIPHER *c;\n#ifndef OPENSSL_NO_COMP\n    const SSL_COMP *comp;\n#endif\n    const EVP_MD *m;\n    int mac_type;\n    int *mac_secret_size;\n    EVP_MD_CTX *mac_ctx;\n    EVP_PKEY *mac_key;\n    int n, i, j, k, cl;\n    int reuse_dd = 0;\n\n    c = s->s3->tmp.new_sym_enc;\n    m = s->s3->tmp.new_hash;\n    mac_type = s->s3->tmp.new_mac_pkey_type;\n#ifndef OPENSSL_NO_COMP\n    comp = s->s3->tmp.new_compression;\n#endif\n\n    if (which & SSL3_CC_READ) {\n        if (s->s3->tmp.new_cipher->algorithm2 & TLS1_STREAM_MAC)\n            s->mac_flags |= SSL_MAC_FLAG_READ_MAC_STREAM;\n        else\n            s->mac_flags &= ~SSL_MAC_FLAG_READ_MAC_STREAM;\n\n        if (s->enc_read_ctx != NULL)\n            reuse_dd = 1;\n        else if ((s->enc_read_ctx = EVP_CIPHER_CTX_new()) == NULL)\n            goto err;\n        else\n            /*\n             * make sure it's initialised in case we exit later with an error\n             */\n            EVP_CIPHER_CTX_reset(s->enc_read_ctx);\n        dd = s->enc_read_ctx;\n        mac_ctx = ssl_replace_hash(&s->read_hash, NULL);\n        if (mac_ctx == NULL)\n            goto err;\n#ifndef OPENSSL_NO_COMP\n        COMP_CTX_free(s->expand);\n        s->expand = NULL;\n        if (comp != NULL) {\n            s->expand = COMP_CTX_new(comp->method);\n            if (s->expand == NULL) {\n                SSLerr(SSL_F_TLS1_CHANGE_CIPHER_STATE,\n                       SSL_R_COMPRESSION_LIBRARY_ERROR);\n                goto err2;\n            }\n        }\n#endif\n        /*\n         * this is done by dtls1_reset_seq_numbers for DTLS\n         */\n        if (!SSL_IS_DTLS(s))\n            RECORD_LAYER_reset_read_sequence(&s->rlayer);\n        mac_secret = &(s->s3->read_mac_secret[0]);\n        mac_secret_size = &(s->s3->read_mac_secret_size);\n    } else {\n        if (s->s3->tmp.new_cipher->algorithm2 & TLS1_STREAM_MAC)\n            s->mac_flags |= SSL_MAC_FLAG_WRITE_MAC_STREAM;\n        else\n            s->mac_flags &= ~SSL_MAC_FLAG_WRITE_MAC_STREAM;\n        if (s->enc_write_ctx != NULL && !SSL_IS_DTLS(s))\n            reuse_dd = 1;\n        else if ((s->enc_write_ctx = EVP_CIPHER_CTX_new()) == NULL)\n            goto err;\n        dd = s->enc_write_ctx;\n        if (SSL_IS_DTLS(s)) {\n            mac_ctx = EVP_MD_CTX_new();\n            if (mac_ctx == NULL)\n                goto err;\n            s->write_hash = mac_ctx;\n        } else {\n            mac_ctx = ssl_replace_hash(&s->write_hash, NULL);\n            if (mac_ctx == NULL)\n                goto err;\n        }\n#ifndef OPENSSL_NO_COMP\n        COMP_CTX_free(s->compress);\n        s->compress = NULL;\n        if (comp != NULL) {\n            s->compress = COMP_CTX_new(comp->method);\n            if (s->compress == NULL) {\n                SSLerr(SSL_F_TLS1_CHANGE_CIPHER_STATE,\n                       SSL_R_COMPRESSION_LIBRARY_ERROR);\n                goto err2;\n            }\n        }\n#endif\n        /*\n         * this is done by dtls1_reset_seq_numbers for DTLS\n         */\n        if (!SSL_IS_DTLS(s))\n            RECORD_LAYER_reset_write_sequence(&s->rlayer);\n        mac_secret = &(s->s3->write_mac_secret[0]);\n        mac_secret_size = &(s->s3->write_mac_secret_size);\n    }\n\n    if (reuse_dd)\n        EVP_CIPHER_CTX_reset(dd);\n\n    p = s->s3->tmp.key_block;\n    i = *mac_secret_size = s->s3->tmp.new_mac_secret_size;\n\n    cl = EVP_CIPHER_key_length(c);\n    j = cl;\n    /* Was j=(exp)?5:EVP_CIPHER_key_length(c); */\n    /* If GCM/CCM mode only part of IV comes from PRF */\n    if (EVP_CIPHER_mode(c) == EVP_CIPH_GCM_MODE)\n        k = EVP_GCM_TLS_FIXED_IV_LEN;\n    else if (EVP_CIPHER_mode(c) == EVP_CIPH_CCM_MODE)\n        k = EVP_CCM_TLS_FIXED_IV_LEN;\n    else\n        k = EVP_CIPHER_iv_length(c);\n    if ((which == SSL3_CHANGE_CIPHER_CLIENT_WRITE) ||\n        (which == SSL3_CHANGE_CIPHER_SERVER_READ)) {\n        ms = &(p[0]);\n        n = i + i;\n        key = &(p[n]);\n        n += j + j;\n        iv = &(p[n]);\n        n += k + k;\n    } else {\n        n = i;\n        ms = &(p[n]);\n        n += i + j;\n        key = &(p[n]);\n        n += j + k;\n        iv = &(p[n]);\n        n += k;\n    }\n\n    if (n > s->s3->tmp.key_block_length) {\n        SSLerr(SSL_F_TLS1_CHANGE_CIPHER_STATE, ERR_R_INTERNAL_ERROR);\n        goto err2;\n    }\n\n    memcpy(mac_secret, ms, i);\n\n    if (!(EVP_CIPHER_flags(c) & EVP_CIPH_FLAG_AEAD_CIPHER)) {\n        mac_key = EVP_PKEY_new_mac_key(mac_type, NULL,\n                                       mac_secret, *mac_secret_size);\n        if (mac_key == NULL\n            || EVP_DigestSignInit(mac_ctx, NULL, m, NULL, mac_key) <= 0) {\n            EVP_PKEY_free(mac_key);\n            SSLerr(SSL_F_TLS1_CHANGE_CIPHER_STATE, ERR_R_INTERNAL_ERROR);\n            goto err2;\n        }\n        EVP_PKEY_free(mac_key);\n    }\n#ifdef SSL_DEBUG\n    printf(\"which = %04X\\nmac key=\", which);\n    {\n        int z;\n        for (z = 0; z < i; z++)\n            printf(\"%02X%c\", ms[z], ((z + 1) % 16) ? ' ' : '\\n');\n    }\n#endif\n\n    if (EVP_CIPHER_mode(c) == EVP_CIPH_GCM_MODE) {\n        if (!EVP_CipherInit_ex(dd, c, NULL, key, NULL, (which & SSL3_CC_WRITE))\n            || !EVP_CIPHER_CTX_ctrl(dd, EVP_CTRL_GCM_SET_IV_FIXED, k, iv)) {\n            SSLerr(SSL_F_TLS1_CHANGE_CIPHER_STATE, ERR_R_INTERNAL_ERROR);\n            goto err2;\n        }\n    } else if (EVP_CIPHER_mode(c) == EVP_CIPH_CCM_MODE) {\n        int taglen;\n        if (s->s3->tmp.\n            new_cipher->algorithm_enc & (SSL_AES128CCM8 | SSL_AES256CCM8))\n            taglen = 8;\n        else\n            taglen = 16;\n        if (!EVP_CipherInit_ex(dd, c, NULL, NULL, NULL, (which & SSL3_CC_WRITE))\n            || !EVP_CIPHER_CTX_ctrl(dd, EVP_CTRL_AEAD_SET_IVLEN, 12, NULL)\n            || !EVP_CIPHER_CTX_ctrl(dd, EVP_CTRL_AEAD_SET_TAG, taglen, NULL)\n            || !EVP_CIPHER_CTX_ctrl(dd, EVP_CTRL_CCM_SET_IV_FIXED, k, iv)\n            || !EVP_CipherInit_ex(dd, NULL, NULL, key, NULL, -1)) {\n            SSLerr(SSL_F_TLS1_CHANGE_CIPHER_STATE, ERR_R_INTERNAL_ERROR);\n            goto err2;\n        }\n    } else {\n        if (!EVP_CipherInit_ex(dd, c, NULL, key, iv, (which & SSL3_CC_WRITE))) {\n            SSLerr(SSL_F_TLS1_CHANGE_CIPHER_STATE, ERR_R_INTERNAL_ERROR);\n            goto err2;\n        }\n    }\n    /* Needed for \"composite\" AEADs, such as RC4-HMAC-MD5 */\n    if ((EVP_CIPHER_flags(c) & EVP_CIPH_FLAG_AEAD_CIPHER) && *mac_secret_size\n        && !EVP_CIPHER_CTX_ctrl(dd, EVP_CTRL_AEAD_SET_MAC_KEY,\n                                *mac_secret_size, mac_secret)) {\n        SSLerr(SSL_F_TLS1_CHANGE_CIPHER_STATE, ERR_R_INTERNAL_ERROR);\n        goto err2;\n    }\n#ifdef OPENSSL_SSL_TRACE_CRYPTO\n    if (s->msg_callback) {\n        int wh = which & SSL3_CC_WRITE ? TLS1_RT_CRYPTO_WRITE : 0;\n        if (*mac_secret_size)\n            s->msg_callback(2, s->version, wh | TLS1_RT_CRYPTO_MAC,\n                            mac_secret, *mac_secret_size,\n                            s, s->msg_callback_arg);\n        if (c->key_len)\n            s->msg_callback(2, s->version, wh | TLS1_RT_CRYPTO_KEY,\n                            key, c->key_len, s, s->msg_callback_arg);\n        if (k) {\n            if (EVP_CIPHER_mode(c) == EVP_CIPH_GCM_MODE)\n                wh |= TLS1_RT_CRYPTO_FIXED_IV;\n            else\n                wh |= TLS1_RT_CRYPTO_IV;\n            s->msg_callback(2, s->version, wh, iv, k, s, s->msg_callback_arg);\n        }\n    }\n#endif\n\n#ifdef SSL_DEBUG\n    printf(\"which = %04X\\nkey=\", which);\n    {\n        int z;\n        for (z = 0; z < EVP_CIPHER_key_length(c); z++)\n            printf(\"%02X%c\", key[z], ((z + 1) % 16) ? ' ' : '\\n');\n    }\n    printf(\"\\niv=\");\n    {\n        int z;\n        for (z = 0; z < k; z++)\n            printf(\"%02X%c\", iv[z], ((z + 1) % 16) ? ' ' : '\\n');\n    }\n    printf(\"\\n\");\n#endif\n\n    OPENSSL_cleanse(tmp1, sizeof(tmp1));\n    OPENSSL_cleanse(tmp2, sizeof(tmp1));\n    OPENSSL_cleanse(iv1, sizeof(iv1));\n    OPENSSL_cleanse(iv2, sizeof(iv2));\n    return (1);\n err:\n    SSLerr(SSL_F_TLS1_CHANGE_CIPHER_STATE, ERR_R_MALLOC_FAILURE);\n err2:\n    OPENSSL_cleanse(tmp1, sizeof(tmp1));\n    OPENSSL_cleanse(tmp2, sizeof(tmp1));\n    OPENSSL_cleanse(iv1, sizeof(iv1));\n    OPENSSL_cleanse(iv2, sizeof(iv2));\n    return (0);\n}", "target": 1, "cwe": ["CWE-20"], "project": "openssl", "commit_id": "4ad93618d26a3ea23d36ad5498ff4f59eff3a4d2", "hash": 196909120385222406426996451869242879203, "size": 252, "message": "Don't change the state of the ETM flags until CCS processing\n\nChanging the ciphersuite during a renegotiation can result in a crash\nleading to a DoS attack. ETM has not been implemented in 1.1.0 for DTLS\nso this is TLS only.\n\nThe problem is caused by changing the flag indicating whether to use ETM\nor not immediately on negotiation of ETM, rather than at CCS. Therefore,\nduring a renegotiation, if the ETM state is changing (usually due to a\nchange of ciphersuite), then an error/crash will occur.\n\nDue to the fact that there are separate CCS messages for read and write\nwe actually now need two flags to determine whether to use ETM or not.\n\nCVE-2017-3733\n\nReviewed-by: Richard Levitte <levitte@openssl.org>"}
{"func": "int tls1_enc(SSL *s, SSL3_RECORD *recs, unsigned int n_recs, int send)\n{\n    EVP_CIPHER_CTX *ds;\n    size_t reclen[SSL_MAX_PIPELINES];\n    unsigned char buf[SSL_MAX_PIPELINES][EVP_AEAD_TLS1_AAD_LEN];\n    int bs, i, j, k, pad = 0, ret, mac_size = 0;\n    const EVP_CIPHER *enc;\n    unsigned int ctr;\n\n    if (send) {\n        if (EVP_MD_CTX_md(s->write_hash)) {\n            int n = EVP_MD_CTX_size(s->write_hash);\n            OPENSSL_assert(n >= 0);\n        }\n        ds = s->enc_write_ctx;\n        if (s->enc_write_ctx == NULL)\n            enc = NULL;\n        else {\n            int ivlen;\n            enc = EVP_CIPHER_CTX_cipher(s->enc_write_ctx);\n            /* For TLSv1.1 and later explicit IV */\n            if (SSL_USE_EXPLICIT_IV(s)\n                && EVP_CIPHER_mode(enc) == EVP_CIPH_CBC_MODE)\n                ivlen = EVP_CIPHER_iv_length(enc);\n            else\n                ivlen = 0;\n            if (ivlen > 1) {\n                for (ctr = 0; ctr < n_recs; ctr++) {\n                    if (recs[ctr].data != recs[ctr].input) {\n                        /*\n                         * we can't write into the input stream: Can this ever\n                         * happen?? (steve)\n                         */\n                        SSLerr(SSL_F_TLS1_ENC, ERR_R_INTERNAL_ERROR);\n                        return -1;\n                    } else if (RAND_bytes(recs[ctr].input, ivlen) <= 0) {\n                        SSLerr(SSL_F_TLS1_ENC, ERR_R_INTERNAL_ERROR);\n                        return -1;\n                    }\n                }\n            }\n        }\n    } else {\n        if (EVP_MD_CTX_md(s->read_hash)) {\n            int n = EVP_MD_CTX_size(s->read_hash);\n            OPENSSL_assert(n >= 0);\n        }\n        ds = s->enc_read_ctx;\n        if (s->enc_read_ctx == NULL)\n            enc = NULL;\n        else\n            enc = EVP_CIPHER_CTX_cipher(s->enc_read_ctx);\n    }\n\n    if ((s->session == NULL) || (ds == NULL) || (enc == NULL)) {\n        for (ctr = 0; ctr < n_recs; ctr++) {\n            memmove(recs[ctr].data, recs[ctr].input, recs[ctr].length);\n            recs[ctr].input = recs[ctr].data;\n        }\n        ret = 1;\n    } else {\n        bs = EVP_CIPHER_block_size(EVP_CIPHER_CTX_cipher(ds));\n\n        if (n_recs > 1) {\n            if (!(EVP_CIPHER_flags(EVP_CIPHER_CTX_cipher(ds))\n                  & EVP_CIPH_FLAG_PIPELINE)) {\n                /*\n                 * We shouldn't have been called with pipeline data if the\n                 * cipher doesn't support pipelining\n                 */\n                SSLerr(SSL_F_TLS1_ENC, SSL_R_PIPELINE_FAILURE);\n                return -1;\n            }\n        }\n        for (ctr = 0; ctr < n_recs; ctr++) {\n            reclen[ctr] = recs[ctr].length;\n\n            if (EVP_CIPHER_flags(EVP_CIPHER_CTX_cipher(ds))\n                & EVP_CIPH_FLAG_AEAD_CIPHER) {\n                unsigned char *seq;\n\n                seq = send ? RECORD_LAYER_get_write_sequence(&s->rlayer)\n                    : RECORD_LAYER_get_read_sequence(&s->rlayer);\n\n                if (SSL_IS_DTLS(s)) {\n                    /* DTLS does not support pipelining */\n                    unsigned char dtlsseq[9], *p = dtlsseq;\n\n                    s2n(send ? DTLS_RECORD_LAYER_get_w_epoch(&s->rlayer) :\n                        DTLS_RECORD_LAYER_get_r_epoch(&s->rlayer), p);\n                    memcpy(p, &seq[2], 6);\n                    memcpy(buf[ctr], dtlsseq, 8);\n                } else {\n                    memcpy(buf[ctr], seq, 8);\n                    for (i = 7; i >= 0; i--) { /* increment */\n                        ++seq[i];\n                        if (seq[i] != 0)\n                            break;\n                    }\n                }\n\n                buf[ctr][8] = recs[ctr].type;\n                buf[ctr][9] = (unsigned char)(s->version >> 8);\n                buf[ctr][10] = (unsigned char)(s->version);\n                buf[ctr][11] = recs[ctr].length >> 8;\n                buf[ctr][12] = recs[ctr].length & 0xff;\n                pad = EVP_CIPHER_CTX_ctrl(ds, EVP_CTRL_AEAD_TLS1_AAD,\n                                          EVP_AEAD_TLS1_AAD_LEN, buf[ctr]);\n                if (pad <= 0)\n                    return -1;\n\n                if (send) {\n                    reclen[ctr] += pad;\n                    recs[ctr].length += pad;\n                }\n\n            } else if ((bs != 1) && send) {\n                i = bs - ((int)reclen[ctr] % bs);\n\n                /* Add weird padding of upto 256 bytes */\n\n                /* we need to add 'i' padding bytes of value j */\n                j = i - 1;\n                for (k = (int)reclen[ctr]; k < (int)(reclen[ctr] + i); k++)\n                    recs[ctr].input[k] = j;\n                reclen[ctr] += i;\n                recs[ctr].length += i;\n            }\n\n            if (!send) {\n                if (reclen[ctr] == 0 || reclen[ctr] % bs != 0)\n                    return 0;\n            }\n        }\n        if (n_recs > 1) {\n            unsigned char *data[SSL_MAX_PIPELINES];\n\n            /* Set the output buffers */\n            for (ctr = 0; ctr < n_recs; ctr++) {\n                data[ctr] = recs[ctr].data;\n            }\n            if (EVP_CIPHER_CTX_ctrl(ds, EVP_CTRL_SET_PIPELINE_OUTPUT_BUFS,\n                                    n_recs, data) <= 0) {\n                SSLerr(SSL_F_TLS1_ENC, SSL_R_PIPELINE_FAILURE);\n            }\n            /* Set the input buffers */\n            for (ctr = 0; ctr < n_recs; ctr++) {\n                data[ctr] = recs[ctr].input;\n            }\n            if (EVP_CIPHER_CTX_ctrl(ds, EVP_CTRL_SET_PIPELINE_INPUT_BUFS,\n                                    n_recs, data) <= 0\n                || EVP_CIPHER_CTX_ctrl(ds, EVP_CTRL_SET_PIPELINE_INPUT_LENS,\n                                       n_recs, reclen) <= 0) {\n                SSLerr(SSL_F_TLS1_ENC, SSL_R_PIPELINE_FAILURE);\n                return -1;\n            }\n        }\n\n        i = EVP_Cipher(ds, recs[0].data, recs[0].input, reclen[0]);\n        if ((EVP_CIPHER_flags(EVP_CIPHER_CTX_cipher(ds))\n             & EVP_CIPH_FLAG_CUSTOM_CIPHER)\n            ? (i < 0)\n            : (i == 0))\n            return -1;          /* AEAD can fail to verify MAC */\n        if (send == 0) {\n            if (EVP_CIPHER_mode(enc) == EVP_CIPH_GCM_MODE) {\n                for (ctr = 0; ctr < n_recs; ctr++) {\n                    recs[ctr].data += EVP_GCM_TLS_EXPLICIT_IV_LEN;\n                    recs[ctr].input += EVP_GCM_TLS_EXPLICIT_IV_LEN;\n                    recs[ctr].length -= EVP_GCM_TLS_EXPLICIT_IV_LEN;\n                }\n            } else if (EVP_CIPHER_mode(enc) == EVP_CIPH_CCM_MODE) {\n                for (ctr = 0; ctr < n_recs; ctr++) {\n                    recs[ctr].data += EVP_CCM_TLS_EXPLICIT_IV_LEN;\n                    recs[ctr].input += EVP_CCM_TLS_EXPLICIT_IV_LEN;\n                    recs[ctr].length -= EVP_CCM_TLS_EXPLICIT_IV_LEN;\n                }\n            }\n        }\n\n        ret = 1;\n        if (!SSL_USE_ETM(s) && EVP_MD_CTX_md(s->read_hash) != NULL)\n            mac_size = EVP_MD_CTX_size(s->read_hash);\n        if ((bs != 1) && !send) {\n            int tmpret;\n            for (ctr = 0; ctr < n_recs; ctr++) {\n                tmpret = tls1_cbc_remove_padding(s, &recs[ctr], bs, mac_size);\n                /*\n                 * If tmpret == 0 then this means publicly invalid so we can\n                 * short circuit things here. Otherwise we must respect constant\n                 * time behaviour.\n                 */\n                if (tmpret == 0)\n                    return 0;\n                ret = constant_time_select_int(constant_time_eq_int(tmpret, 1),\n                                               ret, -1);\n            }\n        }\n        if (pad && !send) {\n            for (ctr = 0; ctr < n_recs; ctr++) {\n                recs[ctr].length -= pad;\n            }\n        }\n    }\n    return ret;\n}", "target": 1, "cwe": ["CWE-20"], "project": "openssl", "commit_id": "4ad93618d26a3ea23d36ad5498ff4f59eff3a4d2", "hash": 23541660395881479112199313323679951844, "size": 206, "message": "Don't change the state of the ETM flags until CCS processing\n\nChanging the ciphersuite during a renegotiation can result in a crash\nleading to a DoS attack. ETM has not been implemented in 1.1.0 for DTLS\nso this is TLS only.\n\nThe problem is caused by changing the flag indicating whether to use ETM\nor not immediately on negotiation of ETM, rather than at CCS. Therefore,\nduring a renegotiation, if the ETM state is changing (usually due to a\nchange of ciphersuite), then an error/crash will occur.\n\nDue to the fact that there are separate CCS messages for read and write\nwe actually now need two flags to determine whether to use ETM or not.\n\nCVE-2017-3733\n\nReviewed-by: Richard Levitte <levitte@openssl.org>"}
{"func": "int ssl3_get_record(SSL *s)\n{\n    int ssl_major, ssl_minor, al;\n    int enc_err, n, i, ret = -1;\n    SSL3_RECORD *rr;\n    SSL3_BUFFER *rbuf;\n    SSL_SESSION *sess;\n    unsigned char *p;\n    unsigned char md[EVP_MAX_MD_SIZE];\n    short version;\n    unsigned mac_size;\n    unsigned int num_recs = 0;\n    unsigned int max_recs;\n    unsigned int j;\n\n    rr = RECORD_LAYER_get_rrec(&s->rlayer);\n    rbuf = RECORD_LAYER_get_rbuf(&s->rlayer);\n    max_recs = s->max_pipelines;\n    if (max_recs == 0)\n        max_recs = 1;\n    sess = s->session;\n\n    do {\n        /* check if we have the header */\n        if ((RECORD_LAYER_get_rstate(&s->rlayer) != SSL_ST_READ_BODY) ||\n            (RECORD_LAYER_get_packet_length(&s->rlayer)\n             < SSL3_RT_HEADER_LENGTH)) {\n            n = ssl3_read_n(s, SSL3_RT_HEADER_LENGTH,\n                            SSL3_BUFFER_get_len(rbuf), 0,\n                            num_recs == 0 ? 1 : 0);\n            if (n <= 0)\n                return (n);     /* error or non-blocking */\n            RECORD_LAYER_set_rstate(&s->rlayer, SSL_ST_READ_BODY);\n\n            p = RECORD_LAYER_get_packet(&s->rlayer);\n\n            /*\n             * The first record received by the server may be a V2ClientHello.\n             */\n            if (s->server && RECORD_LAYER_is_first_record(&s->rlayer)\n                && (p[0] & 0x80) && (p[2] == SSL2_MT_CLIENT_HELLO)) {\n                /*\n                 *  SSLv2 style record\n                 *\n                 * |num_recs| here will actually always be 0 because\n                 * |num_recs > 0| only ever occurs when we are processing\n                 * multiple app data records - which we know isn't the case here\n                 * because it is an SSLv2ClientHello. We keep it using\n                 * |num_recs| for the sake of consistency\n                 */\n                rr[num_recs].type = SSL3_RT_HANDSHAKE;\n                rr[num_recs].rec_version = SSL2_VERSION;\n\n                rr[num_recs].length = ((p[0] & 0x7f) << 8) | p[1];\n\n                if (rr[num_recs].length > SSL3_BUFFER_get_len(rbuf)\n                    - SSL2_RT_HEADER_LENGTH) {\n                    al = SSL_AD_RECORD_OVERFLOW;\n                    SSLerr(SSL_F_SSL3_GET_RECORD, SSL_R_PACKET_LENGTH_TOO_LONG);\n                    goto f_err;\n                }\n\n                if (rr[num_recs].length < MIN_SSL2_RECORD_LEN) {\n                    al = SSL_AD_HANDSHAKE_FAILURE;\n                    SSLerr(SSL_F_SSL3_GET_RECORD, SSL_R_LENGTH_TOO_SHORT);\n                    goto f_err;\n                }\n            } else {\n                /* SSLv3+ style record */\n                if (s->msg_callback)\n                    s->msg_callback(0, 0, SSL3_RT_HEADER, p, 5, s,\n                                    s->msg_callback_arg);\n\n                /* Pull apart the header into the SSL3_RECORD */\n                rr[num_recs].type = *(p++);\n                ssl_major = *(p++);\n                ssl_minor = *(p++);\n                version = (ssl_major << 8) | ssl_minor;\n                rr[num_recs].rec_version = version;\n                n2s(p, rr[num_recs].length);\n\n                /* Lets check version */\n                if (!s->first_packet && version != s->version) {\n                    SSLerr(SSL_F_SSL3_GET_RECORD, SSL_R_WRONG_VERSION_NUMBER);\n                    if ((s->version & 0xFF00) == (version & 0xFF00)\n                        && !s->enc_write_ctx && !s->write_hash) {\n                        if (rr->type == SSL3_RT_ALERT) {\n                            /*\n                             * The record is using an incorrect version number,\n                             * but what we've got appears to be an alert. We\n                             * haven't read the body yet to check whether its a\n                             * fatal or not - but chances are it is. We probably\n                             * shouldn't send a fatal alert back. We'll just\n                             * end.\n                             */\n                            goto err;\n                        }\n                        /*\n                         * Send back error using their minor version number :-)\n                         */\n                        s->version = (unsigned short)version;\n                    }\n                    al = SSL_AD_PROTOCOL_VERSION;\n                    goto f_err;\n                }\n\n                if ((version >> 8) != SSL3_VERSION_MAJOR) {\n                    if (RECORD_LAYER_is_first_record(&s->rlayer)) {\n                        /* Go back to start of packet, look at the five bytes\n                         * that we have. */\n                        p = RECORD_LAYER_get_packet(&s->rlayer);\n                        if (strncmp((char *)p, \"GET \", 4) == 0 ||\n                            strncmp((char *)p, \"POST \", 5) == 0 ||\n                            strncmp((char *)p, \"HEAD \", 5) == 0 ||\n                            strncmp((char *)p, \"PUT \", 4) == 0) {\n                            SSLerr(SSL_F_SSL3_GET_RECORD, SSL_R_HTTP_REQUEST);\n                            goto err;\n                        } else if (strncmp((char *)p, \"CONNE\", 5) == 0) {\n                            SSLerr(SSL_F_SSL3_GET_RECORD,\n                                   SSL_R_HTTPS_PROXY_REQUEST);\n                            goto err;\n                        }\n\n                        /* Doesn't look like TLS - don't send an alert */\n                        SSLerr(SSL_F_SSL3_GET_RECORD,\n                               SSL_R_WRONG_VERSION_NUMBER);\n                        goto err;\n                    } else {\n                        SSLerr(SSL_F_SSL3_GET_RECORD,\n                               SSL_R_WRONG_VERSION_NUMBER);\n                        al = SSL_AD_PROTOCOL_VERSION;\n                        goto f_err;\n                    }\n                }\n\n                if (rr[num_recs].length >\n                    SSL3_BUFFER_get_len(rbuf) - SSL3_RT_HEADER_LENGTH) {\n                    al = SSL_AD_RECORD_OVERFLOW;\n                    SSLerr(SSL_F_SSL3_GET_RECORD, SSL_R_PACKET_LENGTH_TOO_LONG);\n                    goto f_err;\n                }\n            }\n\n            /* now s->rlayer.rstate == SSL_ST_READ_BODY */\n        }\n\n        /*\n         * s->rlayer.rstate == SSL_ST_READ_BODY, get and decode the data.\n         * Calculate how much more data we need to read for the rest of the\n         * record\n         */\n        if (rr[num_recs].rec_version == SSL2_VERSION) {\n            i = rr[num_recs].length + SSL2_RT_HEADER_LENGTH\n                - SSL3_RT_HEADER_LENGTH;\n        } else {\n            i = rr[num_recs].length;\n        }\n        if (i > 0) {\n            /* now s->packet_length == SSL3_RT_HEADER_LENGTH */\n\n            n = ssl3_read_n(s, i, i, 1, 0);\n            if (n <= 0)\n                return (n);     /* error or non-blocking io */\n        }\n\n        /* set state for later operations */\n        RECORD_LAYER_set_rstate(&s->rlayer, SSL_ST_READ_HEADER);\n\n        /*\n         * At this point, s->packet_length == SSL3_RT_HEADER_LENGTH + rr->length,\n         * or s->packet_length == SSL2_RT_HEADER_LENGTH + rr->length\n         * and we have that many bytes in s->packet\n         */\n        if (rr[num_recs].rec_version == SSL2_VERSION) {\n            rr[num_recs].input =\n                &(RECORD_LAYER_get_packet(&s->rlayer)[SSL2_RT_HEADER_LENGTH]);\n        } else {\n            rr[num_recs].input =\n                &(RECORD_LAYER_get_packet(&s->rlayer)[SSL3_RT_HEADER_LENGTH]);\n        }\n\n        /*\n         * ok, we can now read from 's->packet' data into 'rr' rr->input points\n         * at rr->length bytes, which need to be copied into rr->data by either\n         * the decryption or by the decompression When the data is 'copied' into\n         * the rr->data buffer, rr->input will be pointed at the new buffer\n         */\n\n        /*\n         * We now have - encrypted [ MAC [ compressed [ plain ] ] ] rr->length\n         * bytes of encrypted compressed stuff.\n         */\n\n        /* check is not needed I believe */\n        if (rr[num_recs].length > SSL3_RT_MAX_ENCRYPTED_LENGTH) {\n            al = SSL_AD_RECORD_OVERFLOW;\n            SSLerr(SSL_F_SSL3_GET_RECORD, SSL_R_ENCRYPTED_LENGTH_TOO_LONG);\n            goto f_err;\n        }\n\n        /* decrypt in place in 'rr->input' */\n        rr[num_recs].data = rr[num_recs].input;\n        rr[num_recs].orig_len = rr[num_recs].length;\n\n        /* Mark this record as not read by upper layers yet */\n        rr[num_recs].read = 0;\n\n        num_recs++;\n\n        /* we have pulled in a full packet so zero things */\n        RECORD_LAYER_reset_packet_length(&s->rlayer);\n        RECORD_LAYER_clear_first_record(&s->rlayer);\n    } while (num_recs < max_recs\n             && rr[num_recs - 1].type == SSL3_RT_APPLICATION_DATA\n             && SSL_USE_EXPLICIT_IV(s)\n             && s->enc_read_ctx != NULL\n             && (EVP_CIPHER_flags(EVP_CIPHER_CTX_cipher(s->enc_read_ctx))\n                 & EVP_CIPH_FLAG_PIPELINE)\n             && ssl3_record_app_data_waiting(s));\n\n    /*\n     * If in encrypt-then-mac mode calculate mac from encrypted record. All\n     * the details below are public so no timing details can leak.\n     */\n    if (SSL_USE_ETM(s) && s->read_hash) {\n        unsigned char *mac;\n        mac_size = EVP_MD_CTX_size(s->read_hash);\n        OPENSSL_assert(mac_size <= EVP_MAX_MD_SIZE);\n        for (j = 0; j < num_recs; j++) {\n            if (rr[j].length < mac_size) {\n                al = SSL_AD_DECODE_ERROR;\n                SSLerr(SSL_F_SSL3_GET_RECORD, SSL_R_LENGTH_TOO_SHORT);\n                goto f_err;\n            }\n            rr[j].length -= mac_size;\n            mac = rr[j].data + rr[j].length;\n            i = s->method->ssl3_enc->mac(s, &rr[j], md, 0 /* not send */ );\n            if (i < 0 || CRYPTO_memcmp(md, mac, (size_t)mac_size) != 0) {\n                al = SSL_AD_BAD_RECORD_MAC;\n                SSLerr(SSL_F_SSL3_GET_RECORD,\n                       SSL_R_DECRYPTION_FAILED_OR_BAD_RECORD_MAC);\n                goto f_err;\n            }\n        }\n    }\n\n    enc_err = s->method->ssl3_enc->enc(s, rr, num_recs, 0);\n    /*-\n     * enc_err is:\n     *    0: (in non-constant time) if the record is publically invalid.\n     *    1: if the padding is valid\n     *    -1: if the padding is invalid\n     */\n    if (enc_err == 0) {\n        al = SSL_AD_DECRYPTION_FAILED;\n        SSLerr(SSL_F_SSL3_GET_RECORD, SSL_R_BLOCK_CIPHER_PAD_IS_WRONG);\n        goto f_err;\n    }\n#ifdef SSL_DEBUG\n    printf(\"dec %d\\n\", rr->length);\n    {\n        unsigned int z;\n        for (z = 0; z < rr->length; z++)\n            printf(\"%02X%c\", rr->data[z], ((z + 1) % 16) ? ' ' : '\\n');\n    }\n    printf(\"\\n\");\n#endif\n\n    /* r->length is now the compressed data plus mac */\n    if ((sess != NULL) &&\n        (s->enc_read_ctx != NULL) &&\n        (EVP_MD_CTX_md(s->read_hash) != NULL) && !SSL_USE_ETM(s)) {\n        /* s->read_hash != NULL => mac_size != -1 */\n        unsigned char *mac = NULL;\n        unsigned char mac_tmp[EVP_MAX_MD_SIZE];\n\n        mac_size = EVP_MD_CTX_size(s->read_hash);\n        OPENSSL_assert(mac_size <= EVP_MAX_MD_SIZE);\n\n        for (j = 0; j < num_recs; j++) {\n            /*\n             * orig_len is the length of the record before any padding was\n             * removed. This is public information, as is the MAC in use,\n             * therefore we can safely process the record in a different amount\n             * of time if it's too short to possibly contain a MAC.\n             */\n            if (rr[j].orig_len < mac_size ||\n                /* CBC records must have a padding length byte too. */\n                (EVP_CIPHER_CTX_mode(s->enc_read_ctx) == EVP_CIPH_CBC_MODE &&\n                 rr[j].orig_len < mac_size + 1)) {\n                al = SSL_AD_DECODE_ERROR;\n                SSLerr(SSL_F_SSL3_GET_RECORD, SSL_R_LENGTH_TOO_SHORT);\n                goto f_err;\n            }\n\n            if (EVP_CIPHER_CTX_mode(s->enc_read_ctx) == EVP_CIPH_CBC_MODE) {\n                /*\n                 * We update the length so that the TLS header bytes can be\n                 * constructed correctly but we need to extract the MAC in\n                 * constant time from within the record, without leaking the\n                 * contents of the padding bytes.\n                 */\n                mac = mac_tmp;\n                ssl3_cbc_copy_mac(mac_tmp, &rr[j], mac_size);\n                rr[j].length -= mac_size;\n            } else {\n                /*\n                 * In this case there's no padding, so |rec->orig_len| equals\n                 * |rec->length| and we checked that there's enough bytes for\n                 * |mac_size| above.\n                 */\n                rr[j].length -= mac_size;\n                mac = &rr[j].data[rr[j].length];\n            }\n\n            i = s->method->ssl3_enc->mac(s, &rr[j], md, 0 /* not send */ );\n            if (i < 0 || mac == NULL\n                || CRYPTO_memcmp(md, mac, (size_t)mac_size) != 0)\n                enc_err = -1;\n            if (rr->length > SSL3_RT_MAX_COMPRESSED_LENGTH + mac_size)\n                enc_err = -1;\n        }\n    }\n\n    if (enc_err < 0) {\n        /*\n         * A separate 'decryption_failed' alert was introduced with TLS 1.0,\n         * SSL 3.0 only has 'bad_record_mac'.  But unless a decryption\n         * failure is directly visible from the ciphertext anyway, we should\n         * not reveal which kind of error occurred -- this might become\n         * visible to an attacker (e.g. via a logfile)\n         */\n        al = SSL_AD_BAD_RECORD_MAC;\n        SSLerr(SSL_F_SSL3_GET_RECORD,\n               SSL_R_DECRYPTION_FAILED_OR_BAD_RECORD_MAC);\n        goto f_err;\n    }\n\n    for (j = 0; j < num_recs; j++) {\n        /* rr[j].length is now just compressed */\n        if (s->expand != NULL) {\n            if (rr[j].length > SSL3_RT_MAX_COMPRESSED_LENGTH) {\n                al = SSL_AD_RECORD_OVERFLOW;\n                SSLerr(SSL_F_SSL3_GET_RECORD, SSL_R_COMPRESSED_LENGTH_TOO_LONG);\n                goto f_err;\n            }\n            if (!ssl3_do_uncompress(s, &rr[j])) {\n                al = SSL_AD_DECOMPRESSION_FAILURE;\n                SSLerr(SSL_F_SSL3_GET_RECORD, SSL_R_BAD_DECOMPRESSION);\n                goto f_err;\n            }\n        }\n\n        if (rr[j].length > SSL3_RT_MAX_PLAIN_LENGTH) {\n            al = SSL_AD_RECORD_OVERFLOW;\n            SSLerr(SSL_F_SSL3_GET_RECORD, SSL_R_DATA_LENGTH_TOO_LONG);\n            goto f_err;\n        }\n\n        rr[j].off = 0;\n        /*-\n         * So at this point the following is true\n         * rr[j].type   is the type of record\n         * rr[j].length == number of bytes in record\n         * rr[j].off    == offset to first valid byte\n         * rr[j].data   == where to take bytes from, increment after use :-).\n         */\n\n        /* just read a 0 length packet */\n        if (rr[j].length == 0) {\n            RECORD_LAYER_inc_empty_record_count(&s->rlayer);\n            if (RECORD_LAYER_get_empty_record_count(&s->rlayer)\n                > MAX_EMPTY_RECORDS) {\n                al = SSL_AD_UNEXPECTED_MESSAGE;\n                SSLerr(SSL_F_SSL3_GET_RECORD, SSL_R_RECORD_TOO_SMALL);\n                goto f_err;\n            }\n        } else {\n            RECORD_LAYER_reset_empty_record_count(&s->rlayer);\n        }\n    }\n\n    RECORD_LAYER_set_numrpipes(&s->rlayer, num_recs);\n    return 1;\n\n f_err:\n    ssl3_send_alert(s, SSL3_AL_FATAL, al);\n err:\n    return ret;\n}", "target": 1, "cwe": ["CWE-20"], "project": "openssl", "commit_id": "4ad93618d26a3ea23d36ad5498ff4f59eff3a4d2", "hash": 131774431127085806881852428383238110445, "size": 390, "message": "Don't change the state of the ETM flags until CCS processing\n\nChanging the ciphersuite during a renegotiation can result in a crash\nleading to a DoS attack. ETM has not been implemented in 1.1.0 for DTLS\nso this is TLS only.\n\nThe problem is caused by changing the flag indicating whether to use ETM\nor not immediately on negotiation of ETM, rather than at CCS. Therefore,\nduring a renegotiation, if the ETM state is changing (usually due to a\nchange of ciphersuite), then an error/crash will occur.\n\nDue to the fact that there are separate CCS messages for read and write\nwe actually now need two flags to determine whether to use ETM or not.\n\nCVE-2017-3733\n\nReviewed-by: Richard Levitte <levitte@openssl.org>"}
{"func": "unsigned char *ssl_add_serverhello_tlsext(SSL *s, unsigned char *buf,\n                                          unsigned char *limit, int *al)\n{\n    int extdatalen = 0;\n    unsigned char *orig = buf;\n    unsigned char *ret = buf;\n#ifndef OPENSSL_NO_NEXTPROTONEG\n    int next_proto_neg_seen;\n#endif\n#ifndef OPENSSL_NO_EC\n    unsigned long alg_k = s->s3->tmp.new_cipher->algorithm_mkey;\n    unsigned long alg_a = s->s3->tmp.new_cipher->algorithm_auth;\n    int using_ecc = (alg_k & SSL_kECDHE) || (alg_a & SSL_aECDSA);\n    using_ecc = using_ecc && (s->session->tlsext_ecpointformatlist != NULL);\n#endif\n\n    ret += 2;\n    if (ret >= limit)\n        return NULL;            /* this really never occurs, but ... */\n\n    if (s->s3->send_connection_binding) {\n        int el;\n\n        if (!ssl_add_serverhello_renegotiate_ext(s, 0, &el, 0)) {\n            SSLerr(SSL_F_SSL_ADD_SERVERHELLO_TLSEXT, ERR_R_INTERNAL_ERROR);\n            return NULL;\n        }\n\n        /*-\n         * check for enough space.\n         * 4 bytes for the reneg type and extension length\n         * + reneg data length\n         */\n        if (CHECKLEN(ret, 4 + el, limit))\n            return NULL;\n\n        s2n(TLSEXT_TYPE_renegotiate, ret);\n        s2n(el, ret);\n\n        if (!ssl_add_serverhello_renegotiate_ext(s, ret, &el, el)) {\n            SSLerr(SSL_F_SSL_ADD_SERVERHELLO_TLSEXT, ERR_R_INTERNAL_ERROR);\n            return NULL;\n        }\n\n        ret += el;\n    }\n\n    /* Only add RI for SSLv3 */\n    if (s->version == SSL3_VERSION)\n        goto done;\n\n    if (!s->hit && s->servername_done == 1\n        && s->session->tlsext_hostname != NULL) {\n        /*-\n         * check for enough space.\n         * 4 bytes for the server name type and extension length\n         */\n        if (CHECKLEN(ret, 4, limit))\n            return NULL;\n\n        s2n(TLSEXT_TYPE_server_name, ret);\n        s2n(0, ret);\n    }\n#ifndef OPENSSL_NO_EC\n    if (using_ecc) {\n        const unsigned char *plist;\n        size_t plistlen;\n        /*\n         * Add TLS extension ECPointFormats to the ServerHello message\n         */\n\n        tls1_get_formatlist(s, &plist, &plistlen);\n\n        if (plistlen > 255) {\n            SSLerr(SSL_F_SSL_ADD_SERVERHELLO_TLSEXT, ERR_R_INTERNAL_ERROR);\n            return NULL;\n        }\n\n        /*-\n         * check for enough space.\n         * 4 bytes for the ec points format type and extension length\n         * 1 byte for the points format list length\n         * + length of points format list\n         */\n        if (CHECKLEN(ret, 5 + plistlen, limit))\n            return NULL;\n\n        s2n(TLSEXT_TYPE_ec_point_formats, ret);\n        s2n(plistlen + 1, ret);\n        *(ret++) = (unsigned char)plistlen;\n        memcpy(ret, plist, plistlen);\n        ret += plistlen;\n\n    }\n    /*\n     * Currently the server should not respond with a SupportedCurves\n     * extension\n     */\n#endif                          /* OPENSSL_NO_EC */\n\n    if (s->tlsext_ticket_expected && tls_use_ticket(s)) {\n        /*-\n         * check for enough space.\n         * 4 bytes for the Ticket type and extension length\n         */\n        if (CHECKLEN(ret, 4, limit))\n            return NULL;\n        s2n(TLSEXT_TYPE_session_ticket, ret);\n        s2n(0, ret);\n    } else {\n        /*\n         * if we don't add the above TLSEXT, we can't add a session ticket\n         * later\n         */\n        s->tlsext_ticket_expected = 0;\n    }\n\n    if (s->tlsext_status_expected) {\n        /*-\n         * check for enough space.\n         * 4 bytes for the Status request type and extension length\n         */\n        if (CHECKLEN(ret, 4, limit))\n            return NULL;\n        s2n(TLSEXT_TYPE_status_request, ret);\n        s2n(0, ret);\n    }\n#ifndef OPENSSL_NO_SRTP\n    if (SSL_IS_DTLS(s) && s->srtp_profile) {\n        int el;\n\n        /* Returns 0 on success!! */\n        if (ssl_add_serverhello_use_srtp_ext(s, 0, &el, 0)) {\n            SSLerr(SSL_F_SSL_ADD_SERVERHELLO_TLSEXT, ERR_R_INTERNAL_ERROR);\n            return NULL;\n        }\n        /*-\n         * check for enough space.\n         * 4 bytes for the SRTP profiles type and extension length\n         * + length of the SRTP profiles list\n         */\n        if (CHECKLEN(ret, 4 + el, limit))\n            return NULL;\n\n        s2n(TLSEXT_TYPE_use_srtp, ret);\n        s2n(el, ret);\n\n        if (ssl_add_serverhello_use_srtp_ext(s, ret, &el, el)) {\n            SSLerr(SSL_F_SSL_ADD_SERVERHELLO_TLSEXT, ERR_R_INTERNAL_ERROR);\n            return NULL;\n        }\n        ret += el;\n    }\n#endif\n\n    if (((s->s3->tmp.new_cipher->id & 0xFFFF) == 0x80\n         || (s->s3->tmp.new_cipher->id & 0xFFFF) == 0x81)\n        && (SSL_get_options(s) & SSL_OP_CRYPTOPRO_TLSEXT_BUG)) {\n        const unsigned char cryptopro_ext[36] = {\n            0xfd, 0xe8,         /* 65000 */\n            0x00, 0x20,         /* 32 bytes length */\n            0x30, 0x1e, 0x30, 0x08, 0x06, 0x06, 0x2a, 0x85,\n            0x03, 0x02, 0x02, 0x09, 0x30, 0x08, 0x06, 0x06,\n            0x2a, 0x85, 0x03, 0x02, 0x02, 0x16, 0x30, 0x08,\n            0x06, 0x06, 0x2a, 0x85, 0x03, 0x02, 0x02, 0x17\n        };\n\n        /* check for enough space. */\n        if (CHECKLEN(ret, sizeof(cryptopro_ext), limit))\n            return NULL;\n        memcpy(ret, cryptopro_ext, sizeof(cryptopro_ext));\n        ret += sizeof(cryptopro_ext);\n\n    }\n#ifndef OPENSSL_NO_HEARTBEATS\n    /* Add Heartbeat extension if we've received one */\n    if (SSL_IS_DTLS(s) && (s->tlsext_heartbeat & SSL_DTLSEXT_HB_ENABLED)) {\n        /*-\n         * check for enough space.\n         * 4 bytes for the Heartbeat type and extension length\n         * 1 byte for the mode\n         */\n        if (CHECKLEN(ret, 5, limit))\n            return NULL;\n        s2n(TLSEXT_TYPE_heartbeat, ret);\n        s2n(1, ret);\n        /*-\n         * Set mode:\n         * 1: peer may send requests\n         * 2: peer not allowed to send requests\n         */\n        if (s->tlsext_heartbeat & SSL_DTLSEXT_HB_DONT_RECV_REQUESTS)\n            *(ret++) = SSL_DTLSEXT_HB_DONT_SEND_REQUESTS;\n        else\n            *(ret++) = SSL_DTLSEXT_HB_ENABLED;\n\n    }\n#endif\n\n#ifndef OPENSSL_NO_NEXTPROTONEG\n    next_proto_neg_seen = s->s3->next_proto_neg_seen;\n    s->s3->next_proto_neg_seen = 0;\n    if (next_proto_neg_seen && s->ctx->next_protos_advertised_cb) {\n        const unsigned char *npa;\n        unsigned int npalen;\n        int r;\n\n        r = s->ctx->next_protos_advertised_cb(s, &npa, &npalen,\n                                              s->\n                                              ctx->next_protos_advertised_cb_arg);\n        if (r == SSL_TLSEXT_ERR_OK) {\n            /*-\n             * check for enough space.\n             * 4 bytes for the NPN type and extension length\n             * + length of protocols list\n             */\n            if (CHECKLEN(ret, 4 + npalen, limit))\n                return NULL;\n            s2n(TLSEXT_TYPE_next_proto_neg, ret);\n            s2n(npalen, ret);\n            memcpy(ret, npa, npalen);\n            ret += npalen;\n            s->s3->next_proto_neg_seen = 1;\n        }\n    }\n#endif\n    if (!custom_ext_add(s, 1, &ret, limit, al))\n        return NULL;\n    if (s->s3->flags & TLS1_FLAGS_ENCRYPT_THEN_MAC) {\n        /*\n         * Don't use encrypt_then_mac if AEAD or RC4 might want to disable\n         * for other cases too.\n         */\n        if (SSL_IS_DTLS(s) || s->s3->tmp.new_cipher->algorithm_mac == SSL_AEAD\n            || s->s3->tmp.new_cipher->algorithm_enc == SSL_RC4\n            || s->s3->tmp.new_cipher->algorithm_enc == SSL_eGOST2814789CNT\n            || s->s3->tmp.new_cipher->algorithm_enc == SSL_eGOST2814789CNT12)\n            s->s3->flags &= ~TLS1_FLAGS_ENCRYPT_THEN_MAC;\n        else {\n            /*-\n             * check for enough space.\n             * 4 bytes for the ETM type and extension length\n             */\n            if (CHECKLEN(ret, 4, limit))\n                return NULL;\n            s2n(TLSEXT_TYPE_encrypt_then_mac, ret);\n            s2n(0, ret);\n        }\n    }\n    if (s->s3->flags & TLS1_FLAGS_RECEIVED_EXTMS) {\n        /*-\n         * check for enough space.\n         * 4 bytes for the EMS type and extension length\n         */\n        if (CHECKLEN(ret, 4, limit))\n            return NULL;\n        s2n(TLSEXT_TYPE_extended_master_secret, ret);\n        s2n(0, ret);\n    }\n\n    if (s->s3->alpn_selected != NULL) {\n        const unsigned char *selected = s->s3->alpn_selected;\n        size_t len = s->s3->alpn_selected_len;\n\n        /*-\n         * check for enough space.\n         * 4 bytes for the ALPN type and extension length\n         * 2 bytes for ALPN data length\n         * 1 byte for selected protocol length\n         * + length of the selected protocol\n         */\n        if (CHECKLEN(ret, 7 + len, limit))\n            return NULL;\n        s2n(TLSEXT_TYPE_application_layer_protocol_negotiation, ret);\n        s2n(3 + len, ret);\n        s2n(1 + len, ret);\n        *ret++ = len;\n        memcpy(ret, selected, len);\n        ret += len;\n    }\n\n done:\n\n    if ((extdatalen = ret - orig - 2) == 0)\n        return orig;\n\n    s2n(extdatalen, orig);\n    return ret;\n}", "target": 1, "cwe": ["CWE-20"], "project": "openssl", "commit_id": "4ad93618d26a3ea23d36ad5498ff4f59eff3a4d2", "hash": 210636690300422290931289757246152926187, "size": 289, "message": "Don't change the state of the ETM flags until CCS processing\n\nChanging the ciphersuite during a renegotiation can result in a crash\nleading to a DoS attack. ETM has not been implemented in 1.1.0 for DTLS\nso this is TLS only.\n\nThe problem is caused by changing the flag indicating whether to use ETM\nor not immediately on negotiation of ETM, rather than at CCS. Therefore,\nduring a renegotiation, if the ETM state is changing (usually due to a\nchange of ciphersuite), then an error/crash will occur.\n\nDue to the fact that there are separate CCS messages for read and write\nwe actually now need two flags to determine whether to use ETM or not.\n\nCVE-2017-3733\n\nReviewed-by: Richard Levitte <levitte@openssl.org>"}
{"func": "int ssl3_write_bytes(SSL *s, int type, const void *buf_, int len)\n{\n    const unsigned char *buf = buf_;\n    int tot;\n    unsigned int n, split_send_fragment, maxpipes;\n#if !defined(OPENSSL_NO_MULTIBLOCK) && EVP_CIPH_FLAG_TLS1_1_MULTIBLOCK\n    unsigned int max_send_fragment, nw;\n    unsigned int u_len = (unsigned int)len;\n#endif\n    SSL3_BUFFER *wb = &s->rlayer.wbuf[0];\n    int i;\n\n    if (len < 0) {\n        SSLerr(SSL_F_SSL3_WRITE_BYTES, SSL_R_SSL_NEGATIVE_LENGTH);\n        return -1;\n    }\n\n    s->rwstate = SSL_NOTHING;\n    tot = s->rlayer.wnum;\n    /*\n     * ensure that if we end up with a smaller value of data to write out\n     * than the the original len from a write which didn't complete for\n     * non-blocking I/O and also somehow ended up avoiding the check for\n     * this in ssl3_write_pending/SSL_R_BAD_WRITE_RETRY as it must never be\n     * possible to end up with (len-tot) as a large number that will then\n     * promptly send beyond the end of the users buffer ... so we trap and\n     * report the error in a way the user will notice\n     */\n    if ((unsigned int)len < s->rlayer.wnum) {\n        SSLerr(SSL_F_SSL3_WRITE_BYTES, SSL_R_BAD_LENGTH);\n        return -1;\n    }\n\n    s->rlayer.wnum = 0;\n\n    if (SSL_in_init(s) && !ossl_statem_get_in_handshake(s)) {\n        i = s->handshake_func(s);\n        if (i < 0)\n            return (i);\n        if (i == 0) {\n            SSLerr(SSL_F_SSL3_WRITE_BYTES, SSL_R_SSL_HANDSHAKE_FAILURE);\n            return -1;\n        }\n    }\n\n    /*\n     * first check if there is a SSL3_BUFFER still being written out.  This\n     * will happen with non blocking IO\n     */\n    if (wb->left != 0) {\n        i = ssl3_write_pending(s, type, &buf[tot], s->rlayer.wpend_tot);\n        if (i <= 0) {\n            /* XXX should we ssl3_release_write_buffer if i<0? */\n            s->rlayer.wnum = tot;\n            return i;\n        }\n        tot += i;               /* this might be last fragment */\n    }\n#if !defined(OPENSSL_NO_MULTIBLOCK) && EVP_CIPH_FLAG_TLS1_1_MULTIBLOCK\n    /*\n     * Depending on platform multi-block can deliver several *times*\n     * better performance. Downside is that it has to allocate\n     * jumbo buffer to accommodate up to 8 records, but the\n     * compromise is considered worthy.\n     */\n    if (type == SSL3_RT_APPLICATION_DATA &&\n        u_len >= 4 * (max_send_fragment = s->max_send_fragment) &&\n        s->compress == NULL && s->msg_callback == NULL &&\n        !SSL_USE_ETM(s) && SSL_USE_EXPLICIT_IV(s) &&\n        EVP_CIPHER_flags(EVP_CIPHER_CTX_cipher(s->enc_write_ctx)) &\n        EVP_CIPH_FLAG_TLS1_1_MULTIBLOCK) {\n        unsigned char aad[13];\n        EVP_CTRL_TLS1_1_MULTIBLOCK_PARAM mb_param;\n        int packlen;\n\n        /* minimize address aliasing conflicts */\n        if ((max_send_fragment & 0xfff) == 0)\n            max_send_fragment -= 512;\n\n        if (tot == 0 || wb->buf == NULL) { /* allocate jumbo buffer */\n            ssl3_release_write_buffer(s);\n\n            packlen = EVP_CIPHER_CTX_ctrl(s->enc_write_ctx,\n                                          EVP_CTRL_TLS1_1_MULTIBLOCK_MAX_BUFSIZE,\n                                          max_send_fragment, NULL);\n\n            if (u_len >= 8 * max_send_fragment)\n                packlen *= 8;\n            else\n                packlen *= 4;\n\n            if (!ssl3_setup_write_buffer(s, 1, packlen)) {\n                SSLerr(SSL_F_SSL3_WRITE_BYTES, ERR_R_MALLOC_FAILURE);\n                return -1;\n            }\n        } else if (tot == len) { /* done? */\n            /* free jumbo buffer */\n            ssl3_release_write_buffer(s);\n            return tot;\n        }\n\n        n = (len - tot);\n        for (;;) {\n            if (n < 4 * max_send_fragment) {\n                /* free jumbo buffer */\n                ssl3_release_write_buffer(s);\n                break;\n            }\n\n            if (s->s3->alert_dispatch) {\n                i = s->method->ssl_dispatch_alert(s);\n                if (i <= 0) {\n                    s->rlayer.wnum = tot;\n                    return i;\n                }\n            }\n\n            if (n >= 8 * max_send_fragment)\n                nw = max_send_fragment * (mb_param.interleave = 8);\n            else\n                nw = max_send_fragment * (mb_param.interleave = 4);\n\n            memcpy(aad, s->rlayer.write_sequence, 8);\n            aad[8] = type;\n            aad[9] = (unsigned char)(s->version >> 8);\n            aad[10] = (unsigned char)(s->version);\n            aad[11] = 0;\n            aad[12] = 0;\n            mb_param.out = NULL;\n            mb_param.inp = aad;\n            mb_param.len = nw;\n\n            packlen = EVP_CIPHER_CTX_ctrl(s->enc_write_ctx,\n                                          EVP_CTRL_TLS1_1_MULTIBLOCK_AAD,\n                                          sizeof(mb_param), &mb_param);\n\n            if (packlen <= 0 || packlen > (int)wb->len) { /* never happens */\n                /* free jumbo buffer */\n                ssl3_release_write_buffer(s);\n                break;\n            }\n\n            mb_param.out = wb->buf;\n            mb_param.inp = &buf[tot];\n            mb_param.len = nw;\n\n            if (EVP_CIPHER_CTX_ctrl(s->enc_write_ctx,\n                                    EVP_CTRL_TLS1_1_MULTIBLOCK_ENCRYPT,\n                                    sizeof(mb_param), &mb_param) <= 0)\n                return -1;\n\n            s->rlayer.write_sequence[7] += mb_param.interleave;\n            if (s->rlayer.write_sequence[7] < mb_param.interleave) {\n                int j = 6;\n                while (j >= 0 && (++s->rlayer.write_sequence[j--]) == 0) ;\n            }\n\n            wb->offset = 0;\n            wb->left = packlen;\n\n            s->rlayer.wpend_tot = nw;\n            s->rlayer.wpend_buf = &buf[tot];\n            s->rlayer.wpend_type = type;\n            s->rlayer.wpend_ret = nw;\n\n            i = ssl3_write_pending(s, type, &buf[tot], nw);\n            if (i <= 0) {\n                if (i < 0 && (!s->wbio || !BIO_should_retry(s->wbio))) {\n                    /* free jumbo buffer */\n                    ssl3_release_write_buffer(s);\n                }\n                s->rlayer.wnum = tot;\n                return i;\n            }\n            if (i == (int)n) {\n                /* free jumbo buffer */\n                ssl3_release_write_buffer(s);\n                return tot + i;\n            }\n            n -= i;\n            tot += i;\n        }\n    } else\n#endif\n    if (tot == len) {           /* done? */\n        if (s->mode & SSL_MODE_RELEASE_BUFFERS && !SSL_IS_DTLS(s))\n            ssl3_release_write_buffer(s);\n\n        return tot;\n    }\n\n    n = (len - tot);\n\n    split_send_fragment = s->split_send_fragment;\n    /*\n     * If max_pipelines is 0 then this means \"undefined\" and we default to\n     * 1 pipeline. Similarly if the cipher does not support pipelined\n     * processing then we also only use 1 pipeline, or if we're not using\n     * explicit IVs\n     */\n    maxpipes = s->max_pipelines;\n    if (maxpipes > SSL_MAX_PIPELINES) {\n        /*\n         * We should have prevented this when we set max_pipelines so we\n         * shouldn't get here\n         */\n        SSLerr(SSL_F_SSL3_WRITE_BYTES, ERR_R_INTERNAL_ERROR);\n        return -1;\n    }\n    if (maxpipes == 0\n        || s->enc_write_ctx == NULL\n        || !(EVP_CIPHER_flags(EVP_CIPHER_CTX_cipher(s->enc_write_ctx))\n             & EVP_CIPH_FLAG_PIPELINE)\n        || !SSL_USE_EXPLICIT_IV(s))\n        maxpipes = 1;\n    if (s->max_send_fragment == 0 || split_send_fragment > s->max_send_fragment\n        || split_send_fragment == 0) {\n        /*\n         * We should have prevented this when we set the split and max send\n         * fragments so we shouldn't get here\n         */\n        SSLerr(SSL_F_SSL3_WRITE_BYTES, ERR_R_INTERNAL_ERROR);\n        return -1;\n    }\n\n    for (;;) {\n        unsigned int pipelens[SSL_MAX_PIPELINES], tmppipelen, remain;\n        unsigned int numpipes, j;\n\n        if (n == 0)\n            numpipes = 1;\n        else\n            numpipes = ((n - 1) / split_send_fragment) + 1;\n        if (numpipes > maxpipes)\n            numpipes = maxpipes;\n\n        if (n / numpipes >= s->max_send_fragment) {\n            /*\n             * We have enough data to completely fill all available\n             * pipelines\n             */\n            for (j = 0; j < numpipes; j++) {\n                pipelens[j] = s->max_send_fragment;\n            }\n        } else {\n            /* We can partially fill all available pipelines */\n            tmppipelen = n / numpipes;\n            remain = n % numpipes;\n            for (j = 0; j < numpipes; j++) {\n                pipelens[j] = tmppipelen;\n                if (j < remain)\n                    pipelens[j]++;\n            }\n        }\n\n        i = do_ssl3_write(s, type, &(buf[tot]), pipelens, numpipes, 0);\n        if (i <= 0) {\n            /* XXX should we ssl3_release_write_buffer if i<0? */\n            s->rlayer.wnum = tot;\n            return i;\n        }\n\n        if ((i == (int)n) ||\n            (type == SSL3_RT_APPLICATION_DATA &&\n             (s->mode & SSL_MODE_ENABLE_PARTIAL_WRITE))) {\n            /*\n             * next chunk of data should get another prepended empty fragment\n             * in ciphersuites with known-IV weakness:\n             */\n            s->s3->empty_fragment_done = 0;\n\n            if ((i == (int)n) && s->mode & SSL_MODE_RELEASE_BUFFERS &&\n                !SSL_IS_DTLS(s))\n                ssl3_release_write_buffer(s);\n\n            return tot + i;\n        }\n\n        n -= i;\n        tot += i;\n    }\n}", "target": 1, "cwe": ["CWE-20"], "project": "openssl", "commit_id": "4ad93618d26a3ea23d36ad5498ff4f59eff3a4d2", "hash": 69510764376652348284411720437321953312, "size": 282, "message": "Don't change the state of the ETM flags until CCS processing\n\nChanging the ciphersuite during a renegotiation can result in a crash\nleading to a DoS attack. ETM has not been implemented in 1.1.0 for DTLS\nso this is TLS only.\n\nThe problem is caused by changing the flag indicating whether to use ETM\nor not immediately on negotiation of ETM, rather than at CCS. Therefore,\nduring a renegotiation, if the ETM state is changing (usually due to a\nchange of ciphersuite), then an error/crash will occur.\n\nDue to the fact that there are separate CCS messages for read and write\nwe actually now need two flags to determine whether to use ETM or not.\n\nCVE-2017-3733\n\nReviewed-by: Richard Levitte <levitte@openssl.org>"}
{"func": "int do_ssl3_write(SSL *s, int type, const unsigned char *buf,\n                  unsigned int *pipelens, unsigned int numpipes,\n                  int create_empty_fragment)\n{\n    unsigned char *outbuf[SSL_MAX_PIPELINES], *plen[SSL_MAX_PIPELINES];\n    SSL3_RECORD wr[SSL_MAX_PIPELINES];\n    int i, mac_size, clear = 0;\n    int prefix_len = 0;\n    int eivlen;\n    size_t align = 0;\n    SSL3_BUFFER *wb;\n    SSL_SESSION *sess;\n    unsigned int totlen = 0;\n    unsigned int j;\n\n    for (j = 0; j < numpipes; j++)\n        totlen += pipelens[j];\n    /*\n     * first check if there is a SSL3_BUFFER still being written out.  This\n     * will happen with non blocking IO\n     */\n    if (RECORD_LAYER_write_pending(&s->rlayer))\n        return (ssl3_write_pending(s, type, buf, totlen));\n\n    /* If we have an alert to send, lets send it */\n    if (s->s3->alert_dispatch) {\n        i = s->method->ssl_dispatch_alert(s);\n        if (i <= 0)\n            return (i);\n        /* if it went, fall through and send more stuff */\n    }\n\n    if (s->rlayer.numwpipes < numpipes)\n        if (!ssl3_setup_write_buffer(s, numpipes, 0))\n            return -1;\n\n    if (totlen == 0 && !create_empty_fragment)\n        return 0;\n\n    sess = s->session;\n\n    if ((sess == NULL) ||\n        (s->enc_write_ctx == NULL) || (EVP_MD_CTX_md(s->write_hash) == NULL)) {\n        clear = s->enc_write_ctx ? 0 : 1; /* must be AEAD cipher */\n        mac_size = 0;\n    } else {\n        mac_size = EVP_MD_CTX_size(s->write_hash);\n        if (mac_size < 0)\n            goto err;\n    }\n\n    /*\n     * 'create_empty_fragment' is true only when this function calls itself\n     */\n    if (!clear && !create_empty_fragment && !s->s3->empty_fragment_done) {\n        /*\n         * countermeasure against known-IV weakness in CBC ciphersuites (see\n         * http://www.openssl.org/~bodo/tls-cbc.txt)\n         */\n\n        if (s->s3->need_empty_fragments && type == SSL3_RT_APPLICATION_DATA) {\n            /*\n             * recursive function call with 'create_empty_fragment' set; this\n             * prepares and buffers the data for an empty fragment (these\n             * 'prefix_len' bytes are sent out later together with the actual\n             * payload)\n             */\n            unsigned int tmppipelen = 0;\n\n            prefix_len = do_ssl3_write(s, type, buf, &tmppipelen, 1, 1);\n            if (prefix_len <= 0)\n                goto err;\n\n            if (prefix_len >\n                (SSL3_RT_HEADER_LENGTH + SSL3_RT_SEND_MAX_ENCRYPTED_OVERHEAD)) {\n                /* insufficient space */\n                SSLerr(SSL_F_DO_SSL3_WRITE, ERR_R_INTERNAL_ERROR);\n                goto err;\n            }\n        }\n\n        s->s3->empty_fragment_done = 1;\n    }\n\n    if (create_empty_fragment) {\n        wb = &s->rlayer.wbuf[0];\n#if defined(SSL3_ALIGN_PAYLOAD) && SSL3_ALIGN_PAYLOAD!=0\n        /*\n         * extra fragment would be couple of cipher blocks, which would be\n         * multiple of SSL3_ALIGN_PAYLOAD, so if we want to align the real\n         * payload, then we can just pretend we simply have two headers.\n         */\n        align = (size_t)SSL3_BUFFER_get_buf(wb) + 2 * SSL3_RT_HEADER_LENGTH;\n        align = SSL3_ALIGN_PAYLOAD - 1 - ((align - 1) % SSL3_ALIGN_PAYLOAD);\n#endif\n        outbuf[0] = SSL3_BUFFER_get_buf(wb) + align;\n        SSL3_BUFFER_set_offset(wb, align);\n    } else if (prefix_len) {\n        wb = &s->rlayer.wbuf[0];\n        outbuf[0] = SSL3_BUFFER_get_buf(wb) + SSL3_BUFFER_get_offset(wb)\n            + prefix_len;\n    } else {\n        for (j = 0; j < numpipes; j++) {\n            wb = &s->rlayer.wbuf[j];\n#if defined(SSL3_ALIGN_PAYLOAD) && SSL3_ALIGN_PAYLOAD!=0\n            align = (size_t)SSL3_BUFFER_get_buf(wb) + SSL3_RT_HEADER_LENGTH;\n            align = SSL3_ALIGN_PAYLOAD - 1 - ((align - 1) % SSL3_ALIGN_PAYLOAD);\n#endif\n            outbuf[j] = SSL3_BUFFER_get_buf(wb) + align;\n            SSL3_BUFFER_set_offset(wb, align);\n        }\n    }\n\n    /* Explicit IV length, block ciphers appropriate version flag */\n    if (s->enc_write_ctx && SSL_USE_EXPLICIT_IV(s)) {\n        int mode = EVP_CIPHER_CTX_mode(s->enc_write_ctx);\n        if (mode == EVP_CIPH_CBC_MODE) {\n            eivlen = EVP_CIPHER_CTX_iv_length(s->enc_write_ctx);\n            if (eivlen <= 1)\n                eivlen = 0;\n        }\n        /* Need explicit part of IV for GCM mode */\n        else if (mode == EVP_CIPH_GCM_MODE)\n            eivlen = EVP_GCM_TLS_EXPLICIT_IV_LEN;\n        else if (mode == EVP_CIPH_CCM_MODE)\n            eivlen = EVP_CCM_TLS_EXPLICIT_IV_LEN;\n        else\n            eivlen = 0;\n    } else\n        eivlen = 0;\n\n    totlen = 0;\n    /* Clear our SSL3_RECORD structures */\n    memset(wr, 0, sizeof wr);\n    for (j = 0; j < numpipes; j++) {\n        /* write the header */\n        *(outbuf[j]++) = type & 0xff;\n        SSL3_RECORD_set_type(&wr[j], type);\n\n        *(outbuf[j]++) = (s->version >> 8);\n        /*\n         * Some servers hang if initial client hello is larger than 256 bytes\n         * and record version number > TLS 1.0\n         */\n        if (SSL_get_state(s) == TLS_ST_CW_CLNT_HELLO\n            && !s->renegotiate && TLS1_get_version(s) > TLS1_VERSION)\n            *(outbuf[j]++) = 0x1;\n        else\n            *(outbuf[j]++) = s->version & 0xff;\n\n        /* field where we are to write out packet length */\n        plen[j] = outbuf[j];\n        outbuf[j] += 2;\n\n        /* lets setup the record stuff. */\n        SSL3_RECORD_set_data(&wr[j], outbuf[j] + eivlen);\n        SSL3_RECORD_set_length(&wr[j], (int)pipelens[j]);\n        SSL3_RECORD_set_input(&wr[j], (unsigned char *)&buf[totlen]);\n        totlen += pipelens[j];\n\n        /*\n         * we now 'read' from wr->input, wr->length bytes into wr->data\n         */\n\n        /* first we compress */\n        if (s->compress != NULL) {\n            if (!ssl3_do_compress(s, &wr[j])) {\n                SSLerr(SSL_F_DO_SSL3_WRITE, SSL_R_COMPRESSION_FAILURE);\n                goto err;\n            }\n        } else {\n            memcpy(wr[j].data, wr[j].input, wr[j].length);\n            SSL3_RECORD_reset_input(&wr[j]);\n        }\n\n        /*\n         * we should still have the output to wr->data and the input from\n         * wr->input.  Length should be wr->length. wr->data still points in the\n         * wb->buf\n         */\n\n        if (!SSL_USE_ETM(s) && mac_size != 0) {\n            if (s->method->ssl3_enc->mac(s, &wr[j],\n                                         &(outbuf[j][wr[j].length + eivlen]),\n                                         1) < 0)\n                goto err;\n            SSL3_RECORD_add_length(&wr[j], mac_size);\n        }\n\n        SSL3_RECORD_set_data(&wr[j], outbuf[j]);\n        SSL3_RECORD_reset_input(&wr[j]);\n\n        if (eivlen) {\n            /*\n             * if (RAND_pseudo_bytes(p, eivlen) <= 0) goto err;\n             */\n            SSL3_RECORD_add_length(&wr[j], eivlen);\n        }\n    }\n\n    if (s->method->ssl3_enc->enc(s, wr, numpipes, 1) < 1)\n        goto err;\n\n    for (j = 0; j < numpipes; j++) {\n        if (SSL_USE_ETM(s) && mac_size != 0) {\n            if (s->method->ssl3_enc->mac(s, &wr[j],\n                                         outbuf[j] + wr[j].length, 1) < 0)\n                goto err;\n            SSL3_RECORD_add_length(&wr[j], mac_size);\n        }\n\n        /* record length after mac and block padding */\n        s2n(SSL3_RECORD_get_length(&wr[j]), plen[j]);\n\n        if (s->msg_callback)\n            s->msg_callback(1, 0, SSL3_RT_HEADER, plen[j] - 5, 5, s,\n                            s->msg_callback_arg);\n\n        /*\n         * we should now have wr->data pointing to the encrypted data, which is\n         * wr->length long\n         */\n        SSL3_RECORD_set_type(&wr[j], type); /* not needed but helps for\n                                             * debugging */\n        SSL3_RECORD_add_length(&wr[j], SSL3_RT_HEADER_LENGTH);\n\n        if (create_empty_fragment) {\n            /*\n             * we are in a recursive call; just return the length, don't write\n             * out anything here\n             */\n            if (j > 0) {\n                /* We should never be pipelining an empty fragment!! */\n                SSLerr(SSL_F_DO_SSL3_WRITE, ERR_R_INTERNAL_ERROR);\n                goto err;\n            }\n            return SSL3_RECORD_get_length(wr);\n        }\n\n        /* now let's set up wb */\n        SSL3_BUFFER_set_left(&s->rlayer.wbuf[j],\n                             prefix_len + SSL3_RECORD_get_length(&wr[j]));\n    }\n\n    /*\n     * memorize arguments so that ssl3_write_pending can detect bad write\n     * retries later\n     */\n    s->rlayer.wpend_tot = totlen;\n    s->rlayer.wpend_buf = buf;\n    s->rlayer.wpend_type = type;\n    s->rlayer.wpend_ret = totlen;\n\n    /* we now just need to write the buffer */\n    return ssl3_write_pending(s, type, buf, totlen);\n err:\n    return -1;\n}", "target": 1, "cwe": ["CWE-20"], "project": "openssl", "commit_id": "4ad93618d26a3ea23d36ad5498ff4f59eff3a4d2", "hash": 169566362905628907670688734200798997761, "size": 258, "message": "Don't change the state of the ETM flags until CCS processing\n\nChanging the ciphersuite during a renegotiation can result in a crash\nleading to a DoS attack. ETM has not been implemented in 1.1.0 for DTLS\nso this is TLS only.\n\nThe problem is caused by changing the flag indicating whether to use ETM\nor not immediately on negotiation of ETM, rather than at CCS. Therefore,\nduring a renegotiation, if the ETM state is changing (usually due to a\nchange of ciphersuite), then an error/crash will occur.\n\nDue to the fact that there are separate CCS messages for read and write\nwe actually now need two flags to determine whether to use ETM or not.\n\nCVE-2017-3733\n\nReviewed-by: Richard Levitte <levitte@openssl.org>"}
{"func": "int ssl3_get_new_session_ticket(SSL *s)\n{\n    int ok, al, ret = 0, ticklen;\n    long n;\n    const unsigned char *p;\n    unsigned char *d;\n\n    n = s->method->ssl_get_message(s,\n                                   SSL3_ST_CR_SESSION_TICKET_A,\n                                   SSL3_ST_CR_SESSION_TICKET_B,\n                                   SSL3_MT_NEWSESSION_TICKET, 16384, &ok);\n\n    if (!ok)\n        return ((int)n);\n\n    if (n < 6) {\n        /* need at least ticket_lifetime_hint + ticket length */\n        al = SSL_AD_DECODE_ERROR;\n        SSLerr(SSL_F_SSL3_GET_NEW_SESSION_TICKET, SSL_R_LENGTH_MISMATCH);\n        goto f_err;\n    }\n\n    p = d = (unsigned char *)s->init_msg;\n    n2l(p, s->session->tlsext_tick_lifetime_hint);\n    n2s(p, ticklen);\n    /* ticket_lifetime_hint + ticket_length + ticket */\n    if (ticklen + 6 != n) {\n        al = SSL_AD_DECODE_ERROR;\n        SSLerr(SSL_F_SSL3_GET_NEW_SESSION_TICKET, SSL_R_LENGTH_MISMATCH);\n        goto f_err;\n    }\n    OPENSSL_free(s->session->tlsext_tick);\n    s->session->tlsext_ticklen = 0;\n    s->session->tlsext_tick = OPENSSL_malloc(ticklen);\n    if (!s->session->tlsext_tick) {\n        SSLerr(SSL_F_SSL3_GET_NEW_SESSION_TICKET, ERR_R_MALLOC_FAILURE);\n        goto err;\n    }\n    memcpy(s->session->tlsext_tick, p, ticklen);\n    s->session->tlsext_ticklen = ticklen;\n    /*\n     * There are two ways to detect a resumed ticket session. One is to set\n     * an appropriate session ID and then the server must return a match in\n     * ServerHello. This allows the normal client session ID matching to work\n     * and we know much earlier that the ticket has been accepted. The\n     * other way is to set zero length session ID when the ticket is\n     * presented and rely on the handshake to determine session resumption.\n     * We choose the former approach because this fits in with assumptions\n     * elsewhere in OpenSSL. The session ID is set to the SHA256 (or SHA1 is\n     * SHA256 is disabled) hash of the ticket.\n     */\n    EVP_Digest(p, ticklen,\n               s->session->session_id, &s->session->session_id_length,\n               EVP_sha256(), NULL);\n    ret = 1;\n    return (ret);\n f_err:\n    ssl3_send_alert(s, SSL3_AL_FATAL, al);\n err:\n    s->state = SSL_ST_ERR;\n    return (-1);\n}", "target": 1, "cwe": ["CWE-362"], "project": "openssl", "commit_id": "98ece4eebfb6cd45cc8d550c6ac0022965071afc", "hash": 326781244980632505229786316718163898287, "size": 62, "message": "Fix race condition in NewSessionTicket\n\nIf a NewSessionTicket is received by a multi-threaded client when\nattempting to reuse a previous ticket then a race condition can occur\npotentially leading to a double free of the ticket data.\n\nCVE-2015-1791\n\nThis also fixes RT#3808 where a session ID is changed for a session already\nin the client session cache. Since the session ID is the key to the cache\nthis breaks the cache access.\n\nParts of this patch were inspired by this Akamai change:\nhttps://github.com/akamai/openssl/commit/c0bf69a791239ceec64509f9f19fcafb2461b0d3\n\nReviewed-by: Rich Salz <rsalz@openssl.org>"}
{"func": "static void zlib_stateful_free_ex_data(void *obj, void *item,\n\tCRYPTO_EX_DATA *ad, int ind,long argl, void *argp)\n\t{\n\tstruct zlib_state *state = (struct zlib_state *)item;\n\tinflateEnd(&state->istream);\n\tdeflateEnd(&state->ostream);\n\tOPENSSL_free(state);\n\t}", "target": 1, "cwe": ["CWE-399"], "project": "openssl", "commit_id": "1b31b5ad560b16e2fe1cad54a755e3e6b5e778a3", "hash": 103303859307480879424521840407597665803, "size": 8, "message": "Modify compression code so it avoids using ex_data free functions. This\nstops applications that call CRYPTO_free_all_ex_data() prematurely leaking\nmemory."}
{"func": "COMP_METHOD *COMP_zlib(void)\n\t{\n\tCOMP_METHOD *meth = &zlib_method_nozlib;\n\n#ifdef ZLIB_SHARED\n\tif (!zlib_loaded)\n\t\t{\n#if defined(OPENSSL_SYS_WINDOWS) || defined(OPENSSL_SYS_WIN32)\n\t\tzlib_dso = DSO_load(NULL, \"ZLIB1\", NULL, 0);\n#else\n\t\tzlib_dso = DSO_load(NULL, \"z\", NULL, 0);\n#endif\n\t\tif (zlib_dso != NULL)\n\t\t\t{\n\t\t\tp_compress\n\t\t\t\t= (compress_ft) DSO_bind_func(zlib_dso,\n\t\t\t\t\t\"compress\");\n\t\t\tp_inflateEnd\n\t\t\t\t= (inflateEnd_ft) DSO_bind_func(zlib_dso,\n\t\t\t\t\t\"inflateEnd\");\n\t\t\tp_inflate\n\t\t\t\t= (inflate_ft) DSO_bind_func(zlib_dso,\n\t\t\t\t\t\"inflate\");\n\t\t\tp_inflateInit_\n\t\t\t\t= (inflateInit__ft) DSO_bind_func(zlib_dso,\n\t\t\t\t\t\"inflateInit_\");\n\t\t\tp_deflateEnd\n\t\t\t\t= (deflateEnd_ft) DSO_bind_func(zlib_dso,\n\t\t\t\t\t\"deflateEnd\");\n\t\t\tp_deflate\n\t\t\t\t= (deflate_ft) DSO_bind_func(zlib_dso,\n\t\t\t\t\t\"deflate\");\n\t\t\tp_deflateInit_\n\t\t\t\t= (deflateInit__ft) DSO_bind_func(zlib_dso,\n\t\t\t\t\t\"deflateInit_\");\n\t\t\tp_zError\n\t\t\t\t= (zError__ft) DSO_bind_func(zlib_dso,\n\t\t\t\t\t\"zError\");\n\n\t\t\tif (p_compress && p_inflateEnd && p_inflate\n\t\t\t\t&& p_inflateInit_ && p_deflateEnd\n\t\t\t\t&& p_deflate && p_deflateInit_ && p_zError)\n\t\t\t\tzlib_loaded++;\n\t\t\t}\n\t\t}\n\n#endif\n#ifdef ZLIB_SHARED\n\tif (zlib_loaded)\n#endif\n#if defined(ZLIB) || defined(ZLIB_SHARED)\n\t\t{\n\t\t/* init zlib_stateful_ex_idx here so that in a multi-process\n\t\t * application it's enough to intialize openssl before forking\n\t\t * (idx will be inherited in all the children) */\n\t\tif (zlib_stateful_ex_idx == -1)\n\t\t\t{\n\t\t\tCRYPTO_w_lock(CRYPTO_LOCK_COMP);\n\t\t\tif (zlib_stateful_ex_idx == -1)\n\t\t\t\tzlib_stateful_ex_idx =\n\t\t\t\t\tCRYPTO_get_ex_new_index(CRYPTO_EX_INDEX_COMP,\n\t\t\t\t\t\t0,NULL,NULL,NULL,zlib_stateful_free_ex_data);\n\t\t\tCRYPTO_w_unlock(CRYPTO_LOCK_COMP);\n\t\t\tif (zlib_stateful_ex_idx == -1)\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t\n\t\tmeth = &zlib_stateful_method;\n\t\t}\nerr:\t\n#endif\n\n\treturn(meth);\n\t}", "target": 1, "cwe": ["CWE-399"], "project": "openssl", "commit_id": "1b31b5ad560b16e2fe1cad54a755e3e6b5e778a3", "hash": 198073764009354099260377390255427258598, "size": 74, "message": "Modify compression code so it avoids using ex_data free functions. This\nstops applications that call CRYPTO_free_all_ex_data() prematurely leaking\nmemory."}
{"func": "static void zlib_stateful_finish(COMP_CTX *ctx)\n\t{\n\tCRYPTO_free_ex_data(CRYPTO_EX_INDEX_COMP,ctx,&ctx->ex_data);\n\t}", "target": 1, "cwe": ["CWE-399"], "project": "openssl", "commit_id": "1b31b5ad560b16e2fe1cad54a755e3e6b5e778a3", "hash": 227526666652226078098161975961705166937, "size": 4, "message": "Modify compression code so it avoids using ex_data free functions. This\nstops applications that call CRYPTO_free_all_ex_data() prematurely leaking\nmemory."}
{"func": "int ec_wNAF_mul(const EC_GROUP *group, EC_POINT *r, const BIGNUM *scalar,\n                size_t num, const EC_POINT *points[], const BIGNUM *scalars[],\n                BN_CTX *ctx)\n{\n    BN_CTX *new_ctx = NULL;\n    const EC_POINT *generator = NULL;\n    EC_POINT *tmp = NULL;\n    size_t totalnum;\n    size_t blocksize = 0, numblocks = 0; /* for wNAF splitting */\n    size_t pre_points_per_block = 0;\n    size_t i, j;\n    int k;\n    int r_is_inverted = 0;\n    int r_is_at_infinity = 1;\n    size_t *wsize = NULL;       /* individual window sizes */\n    signed char **wNAF = NULL;  /* individual wNAFs */\n    size_t *wNAF_len = NULL;\n    size_t max_len = 0;\n    size_t num_val;\n    EC_POINT **val = NULL;      /* precomputation */\n    EC_POINT **v;\n    EC_POINT ***val_sub = NULL; /* pointers to sub-arrays of 'val' or\n                                 * 'pre_comp->points' */\n    const EC_PRE_COMP *pre_comp = NULL;\n    int num_scalar = 0;         /* flag: will be set to 1 if 'scalar' must be\n                                 * treated like other scalars, i.e.\n                                 * precomputation is not available */\n    int ret = 0;\n\n    if (group->meth != r->meth) {\n        ECerr(EC_F_EC_WNAF_MUL, EC_R_INCOMPATIBLE_OBJECTS);\n        return 0;\n    }\n\n    if ((scalar == NULL) && (num == 0)) {\n        return EC_POINT_set_to_infinity(group, r);\n    }\n\n    for (i = 0; i < num; i++) {\n        if (group->meth != points[i]->meth) {\n            ECerr(EC_F_EC_WNAF_MUL, EC_R_INCOMPATIBLE_OBJECTS);\n            return 0;\n        }\n    }\n\n    if (ctx == NULL) {\n        ctx = new_ctx = BN_CTX_new();\n        if (ctx == NULL)\n            goto err;\n    }\n\n    if (scalar != NULL) {\n        generator = EC_GROUP_get0_generator(group);\n        if (generator == NULL) {\n            ECerr(EC_F_EC_WNAF_MUL, EC_R_UNDEFINED_GENERATOR);\n            goto err;\n        }\n\n        /* look if we can use precomputed multiples of generator */\n\n        pre_comp = group->pre_comp.ec;\n        if (pre_comp && pre_comp->numblocks\n            && (EC_POINT_cmp(group, generator, pre_comp->points[0], ctx) ==\n                0)) {\n            blocksize = pre_comp->blocksize;\n\n            /*\n             * determine maximum number of blocks that wNAF splitting may\n             * yield (NB: maximum wNAF length is bit length plus one)\n             */\n            numblocks = (BN_num_bits(scalar) / blocksize) + 1;\n\n            /*\n             * we cannot use more blocks than we have precomputation for\n             */\n            if (numblocks > pre_comp->numblocks)\n                numblocks = pre_comp->numblocks;\n\n            pre_points_per_block = (size_t)1 << (pre_comp->w - 1);\n\n            /* check that pre_comp looks sane */\n            if (pre_comp->num != (pre_comp->numblocks * pre_points_per_block)) {\n                ECerr(EC_F_EC_WNAF_MUL, ERR_R_INTERNAL_ERROR);\n                goto err;\n            }\n        } else {\n            /* can't use precomputation */\n            pre_comp = NULL;\n            numblocks = 1;\n            num_scalar = 1;     /* treat 'scalar' like 'num'-th element of\n                                 * 'scalars' */\n        }\n    }\n\n    totalnum = num + numblocks;\n\n    wsize = OPENSSL_malloc(totalnum * sizeof(wsize[0]));\n    wNAF_len = OPENSSL_malloc(totalnum * sizeof(wNAF_len[0]));\n    /* include space for pivot */\n    wNAF = OPENSSL_malloc((totalnum + 1) * sizeof(wNAF[0]));\n    val_sub = OPENSSL_malloc(totalnum * sizeof(val_sub[0]));\n\n    /* Ensure wNAF is initialised in case we end up going to err */\n    if (wNAF != NULL)\n        wNAF[0] = NULL;         /* preliminary pivot */\n\n    if (wsize == NULL || wNAF_len == NULL || wNAF == NULL || val_sub == NULL) {\n        ECerr(EC_F_EC_WNAF_MUL, ERR_R_MALLOC_FAILURE);\n        goto err;\n    }\n\n    /*\n     * num_val will be the total number of temporarily precomputed points\n     */\n    num_val = 0;\n\n    for (i = 0; i < num + num_scalar; i++) {\n        size_t bits;\n\n        bits = i < num ? BN_num_bits(scalars[i]) : BN_num_bits(scalar);\n        wsize[i] = EC_window_bits_for_scalar_size(bits);\n        num_val += (size_t)1 << (wsize[i] - 1);\n        wNAF[i + 1] = NULL;     /* make sure we always have a pivot */\n        wNAF[i] =\n            bn_compute_wNAF((i < num ? scalars[i] : scalar), wsize[i],\n                            &wNAF_len[i]);\n        if (wNAF[i] == NULL)\n            goto err;\n        if (wNAF_len[i] > max_len)\n            max_len = wNAF_len[i];\n    }\n\n    if (numblocks) {\n        /* we go here iff scalar != NULL */\n\n        if (pre_comp == NULL) {\n            if (num_scalar != 1) {\n                ECerr(EC_F_EC_WNAF_MUL, ERR_R_INTERNAL_ERROR);\n                goto err;\n            }\n            /* we have already generated a wNAF for 'scalar' */\n        } else {\n            signed char *tmp_wNAF = NULL;\n            size_t tmp_len = 0;\n\n            if (num_scalar != 0) {\n                ECerr(EC_F_EC_WNAF_MUL, ERR_R_INTERNAL_ERROR);\n                goto err;\n            }\n\n            /*\n             * use the window size for which we have precomputation\n             */\n            wsize[num] = pre_comp->w;\n            tmp_wNAF = bn_compute_wNAF(scalar, wsize[num], &tmp_len);\n            if (!tmp_wNAF)\n                goto err;\n\n            if (tmp_len <= max_len) {\n                /*\n                 * One of the other wNAFs is at least as long as the wNAF\n                 * belonging to the generator, so wNAF splitting will not buy\n                 * us anything.\n                 */\n\n                numblocks = 1;\n                totalnum = num + 1; /* don't use wNAF splitting */\n                wNAF[num] = tmp_wNAF;\n                wNAF[num + 1] = NULL;\n                wNAF_len[num] = tmp_len;\n                /*\n                 * pre_comp->points starts with the points that we need here:\n                 */\n                val_sub[num] = pre_comp->points;\n            } else {\n                /*\n                 * don't include tmp_wNAF directly into wNAF array - use wNAF\n                 * splitting and include the blocks\n                 */\n\n                signed char *pp;\n                EC_POINT **tmp_points;\n\n                if (tmp_len < numblocks * blocksize) {\n                    /*\n                     * possibly we can do with fewer blocks than estimated\n                     */\n                    numblocks = (tmp_len + blocksize - 1) / blocksize;\n                    if (numblocks > pre_comp->numblocks) {\n                        ECerr(EC_F_EC_WNAF_MUL, ERR_R_INTERNAL_ERROR);\n                        OPENSSL_free(tmp_wNAF);\n                        goto err;\n                    }\n                    totalnum = num + numblocks;\n                }\n\n                /* split wNAF in 'numblocks' parts */\n                pp = tmp_wNAF;\n                tmp_points = pre_comp->points;\n\n                for (i = num; i < totalnum; i++) {\n                    if (i < totalnum - 1) {\n                        wNAF_len[i] = blocksize;\n                        if (tmp_len < blocksize) {\n                            ECerr(EC_F_EC_WNAF_MUL, ERR_R_INTERNAL_ERROR);\n                            OPENSSL_free(tmp_wNAF);\n                            goto err;\n                        }\n                        tmp_len -= blocksize;\n                    } else\n                        /*\n                         * last block gets whatever is left (this could be\n                         * more or less than 'blocksize'!)\n                         */\n                        wNAF_len[i] = tmp_len;\n\n                    wNAF[i + 1] = NULL;\n                    wNAF[i] = OPENSSL_malloc(wNAF_len[i]);\n                    if (wNAF[i] == NULL) {\n                        ECerr(EC_F_EC_WNAF_MUL, ERR_R_MALLOC_FAILURE);\n                        OPENSSL_free(tmp_wNAF);\n                        goto err;\n                    }\n                    memcpy(wNAF[i], pp, wNAF_len[i]);\n                    if (wNAF_len[i] > max_len)\n                        max_len = wNAF_len[i];\n\n                    if (*tmp_points == NULL) {\n                        ECerr(EC_F_EC_WNAF_MUL, ERR_R_INTERNAL_ERROR);\n                        OPENSSL_free(tmp_wNAF);\n                        goto err;\n                    }\n                    val_sub[i] = tmp_points;\n                    tmp_points += pre_points_per_block;\n                    pp += blocksize;\n                }\n                OPENSSL_free(tmp_wNAF);\n            }\n        }\n    }\n\n    /*\n     * All points we precompute now go into a single array 'val'.\n     * 'val_sub[i]' is a pointer to the subarray for the i-th point, or to a\n     * subarray of 'pre_comp->points' if we already have precomputation.\n     */\n    val = OPENSSL_malloc((num_val + 1) * sizeof(val[0]));\n    if (val == NULL) {\n        ECerr(EC_F_EC_WNAF_MUL, ERR_R_MALLOC_FAILURE);\n        goto err;\n    }\n    val[num_val] = NULL;        /* pivot element */\n\n    /* allocate points for precomputation */\n    v = val;\n    for (i = 0; i < num + num_scalar; i++) {\n        val_sub[i] = v;\n        for (j = 0; j < ((size_t)1 << (wsize[i] - 1)); j++) {\n            *v = EC_POINT_new(group);\n            if (*v == NULL)\n                goto err;\n            v++;\n        }\n    }\n    if (!(v == val + num_val)) {\n        ECerr(EC_F_EC_WNAF_MUL, ERR_R_INTERNAL_ERROR);\n        goto err;\n    }\n\n    if ((tmp = EC_POINT_new(group)) == NULL)\n        goto err;\n\n    /*-\n     * prepare precomputed values:\n     *    val_sub[i][0] :=     points[i]\n     *    val_sub[i][1] := 3 * points[i]\n     *    val_sub[i][2] := 5 * points[i]\n     *    ...\n     */\n    for (i = 0; i < num + num_scalar; i++) {\n        if (i < num) {\n            if (!EC_POINT_copy(val_sub[i][0], points[i]))\n                goto err;\n        } else {\n            if (!EC_POINT_copy(val_sub[i][0], generator))\n                goto err;\n        }\n\n        if (wsize[i] > 1) {\n            if (!EC_POINT_dbl(group, tmp, val_sub[i][0], ctx))\n                goto err;\n            for (j = 1; j < ((size_t)1 << (wsize[i] - 1)); j++) {\n                if (!EC_POINT_add\n                    (group, val_sub[i][j], val_sub[i][j - 1], tmp, ctx))\n                    goto err;\n            }\n        }\n    }\n\n    if (!EC_POINTs_make_affine(group, num_val, val, ctx))\n        goto err;\n\n    r_is_at_infinity = 1;\n\n    for (k = max_len - 1; k >= 0; k--) {\n        if (!r_is_at_infinity) {\n            if (!EC_POINT_dbl(group, r, r, ctx))\n                goto err;\n        }\n\n        for (i = 0; i < totalnum; i++) {\n            if (wNAF_len[i] > (size_t)k) {\n                int digit = wNAF[i][k];\n                int is_neg;\n\n                if (digit) {\n                    is_neg = digit < 0;\n\n                    if (is_neg)\n                        digit = -digit;\n\n                    if (is_neg != r_is_inverted) {\n                        if (!r_is_at_infinity) {\n                            if (!EC_POINT_invert(group, r, ctx))\n                                goto err;\n                        }\n                        r_is_inverted = !r_is_inverted;\n                    }\n\n                    /* digit > 0 */\n\n                    if (r_is_at_infinity) {\n                        if (!EC_POINT_copy(r, val_sub[i][digit >> 1]))\n                            goto err;\n                        r_is_at_infinity = 0;\n                    } else {\n                        if (!EC_POINT_add\n                            (group, r, r, val_sub[i][digit >> 1], ctx))\n                            goto err;\n                    }\n                }\n            }\n        }\n    }\n\n    if (r_is_at_infinity) {\n        if (!EC_POINT_set_to_infinity(group, r))\n            goto err;\n    } else {\n        if (r_is_inverted)\n            if (!EC_POINT_invert(group, r, ctx))\n                goto err;\n    }\n\n    ret = 1;\n\n err:\n    BN_CTX_free(new_ctx);\n    EC_POINT_free(tmp);\n    OPENSSL_free(wsize);\n    OPENSSL_free(wNAF_len);\n    if (wNAF != NULL) {\n        signed char **w;\n\n        for (w = wNAF; *w != NULL; w++)\n            OPENSSL_free(*w);\n\n        OPENSSL_free(wNAF);\n    }\n    if (val != NULL) {\n        for (v = val; *v != NULL; v++)\n            EC_POINT_clear_free(*v);\n\n        OPENSSL_free(val);\n    }\n    OPENSSL_free(val_sub);\n    return ret;\n}", "target": 1, "cwe": ["CWE-310"], "project": "openssl", "commit_id": "aab7c770353b1dc4ba045938c8fb446dd1c4531e", "hash": 213211014372624519953925884438053493570, "size": 378, "message": "Elliptic curve scalar multiplication with timing attack defenses\n\nCo-authored-by: Nicola Tuveri <nic.tuv@gmail.com>\nCo-authored-by: Cesar Pereida Garcia <cesar.pereidagarcia@tut.fi>\nCo-authored-by: Sohaib ul Hassan <soh.19.hassan@gmail.com>\n\nReviewed-by: Andy Polyakov <appro@openssl.org>\nReviewed-by: Matt Caswell <matt@openssl.org>\n(Merged from https://github.com/openssl/openssl/pull/6009)\n\n(cherry picked from commit 40e48e54582e46c1a01e184ecf5bd31f4f7f8294)"}
{"func": "unsigned int X509v3_addr_get_afi(const IPAddressFamily *f)\n{\n    return ((f != NULL &&\n             f->addressFamily != NULL && f->addressFamily->data != NULL)\n            ? ((f->addressFamily->data[0] << 8) | (f->addressFamily->data[1]))\n            : 0);\n}", "target": 1, "cwe": ["CWE-119", "CWE-787"], "project": "openssl", "commit_id": "068b963bb7afc57f5bdd723de0dd15e7795d5822", "hash": 293021528327818861180205732215713601777, "size": 7, "message": "Avoid out-of-bounds read\n\nFixes CVE 2017-3735\n\nReviewed-by: Kurt Roeckx <kurt@roeckx.be>\n(Merged from https://github.com/openssl/openssl/pull/4276)\n\n(cherry picked from commit b23171744b01e473ebbfd6edad70c1c3825ffbcd)"}
{"func": "int BN_mul(BIGNUM *r, const BIGNUM *a, const BIGNUM *b, BN_CTX *ctx)\n\t{\n\tint ret=0;\n\tint top,al,bl;\n\tBIGNUM *rr;\n#if defined(BN_MUL_COMBA) || defined(BN_RECURSION)\n\tint i;\n#endif\n#ifdef BN_RECURSION\n\tBIGNUM *t=NULL;\n\tint j=0,k;\n#endif\n\n#ifdef BN_COUNT\n\tfprintf(stderr,\"BN_mul %d * %d\\n\",a->top,b->top);\n#endif\n\n\tbn_check_top(a);\n\tbn_check_top(b);\n\tbn_check_top(r);\n\n\tal=a->top;\n\tbl=b->top;\n\n\tif ((al == 0) || (bl == 0))\n\t\t{\n\t\tBN_zero(r);\n\t\treturn(1);\n\t\t}\n\ttop=al+bl;\n\n\tBN_CTX_start(ctx);\n\tif ((r == a) || (r == b))\n\t\t{\n\t\tif ((rr = BN_CTX_get(ctx)) == NULL) goto err;\n\t\t}\n\telse\n\t\trr = r;\n\trr->neg=a->neg^b->neg;\n\n#if defined(BN_MUL_COMBA) || defined(BN_RECURSION)\n\ti = al-bl;\n#endif\n#ifdef BN_MUL_COMBA\n\tif (i == 0)\n\t\t{\n# if 0\n\t\tif (al == 4)\n\t\t\t{\n\t\t\tif (bn_wexpand(rr,8) == NULL) goto err;\n\t\t\trr->top=8;\n\t\t\tbn_mul_comba4(rr->d,a->d,b->d);\n\t\t\tgoto end;\n\t\t\t}\n# endif\n\t\tif (al == 8)\n\t\t\t{\n\t\t\tif (bn_wexpand(rr,16) == NULL) goto err;\n\t\t\trr->top=16;\n\t\t\tbn_mul_comba8(rr->d,a->d,b->d);\n\t\t\tgoto end;\n\t\t\t}\n\t\t}\n#endif /* BN_MUL_COMBA */\n#ifdef BN_RECURSION\n\tif ((al >= BN_MULL_SIZE_NORMAL) && (bl >= BN_MULL_SIZE_NORMAL))\n\t\t{\n\t\tif (i >= -1 && i <= 1)\n\t\t\t{\n\t\t\tint sav_j =0;\n\t\t\t/* Find out the power of two lower or equal\n\t\t\t   to the longest of the two numbers */\n\t\t\tif (i >= 0)\n\t\t\t\t{\n\t\t\t\tj = BN_num_bits_word((BN_ULONG)al);\n\t\t\t\t}\n\t\t\tif (i == -1)\n\t\t\t\t{\n\t\t\t\tj = BN_num_bits_word((BN_ULONG)bl);\n\t\t\t\t}\n\t\t\tsav_j = j;\n\t\t\tj = 1<<(j-1);\n\t\t\tassert(j <= al || j <= bl);\n\t\t\tk = j+j;\n\t\t\tt = BN_CTX_get(ctx);\n\t\t\tif (t == NULL)\n\t\t\t\tgoto err;\n\t\t\tif (al > j || bl > j)\n\t\t\t\t{\n\t\t\t\tbn_wexpand(t,k*4);\n\t\t\t\tbn_wexpand(rr,k*4);\n\t\t\t\tbn_mul_part_recursive(rr->d,a->d,b->d,\n\t\t\t\t\tj,al-j,bl-j,t->d);\n\t\t\t\t}\n\t\t\telse\t/* al <= j || bl <= j */\n\t\t\t\t{\n\t\t\t\tbn_wexpand(t,k*2);\n\t\t\t\tbn_wexpand(rr,k*2);\n\t\t\t\tbn_mul_recursive(rr->d,a->d,b->d,\n\t\t\t\t\tj,al-j,bl-j,t->d);\n\t\t\t\t}\n\t\t\trr->top=top;\n\t\t\tgoto end;\n\t\t\t}\n#if 0\n\t\tif (i == 1 && !BN_get_flags(b,BN_FLG_STATIC_DATA))\n\t\t\t{\n\t\t\tBIGNUM *tmp_bn = (BIGNUM *)b;\n\t\t\tif (bn_wexpand(tmp_bn,al) == NULL) goto err;\n\t\t\ttmp_bn->d[bl]=0;\n\t\t\tbl++;\n\t\t\ti--;\n\t\t\t}\n\t\telse if (i == -1 && !BN_get_flags(a,BN_FLG_STATIC_DATA))\n\t\t\t{\n\t\t\tBIGNUM *tmp_bn = (BIGNUM *)a;\n\t\t\tif (bn_wexpand(tmp_bn,bl) == NULL) goto err;\n\t\t\ttmp_bn->d[al]=0;\n\t\t\tal++;\n\t\t\ti++;\n\t\t\t}\n\t\tif (i == 0)\n\t\t\t{\n\t\t\t/* symmetric and > 4 */\n\t\t\t/* 16 or larger */\n\t\t\tj=BN_num_bits_word((BN_ULONG)al);\n\t\t\tj=1<<(j-1);\n\t\t\tk=j+j;\n\t\t\tt = BN_CTX_get(ctx);\n\t\t\tif (al == j) /* exact multiple */\n\t\t\t\t{\n\t\t\t\tif (bn_wexpand(t,k*2) == NULL) goto err;\n\t\t\t\tif (bn_wexpand(rr,k*2) == NULL) goto err;\n\t\t\t\tbn_mul_recursive(rr->d,a->d,b->d,al,t->d);\n\t\t\t\t}\n\t\t\telse\n\t\t\t\t{\n\t\t\t\tif (bn_wexpand(t,k*4) == NULL) goto err;\n\t\t\t\tif (bn_wexpand(rr,k*4) == NULL) goto err;\n\t\t\t\tbn_mul_part_recursive(rr->d,a->d,b->d,al-j,j,t->d);\n\t\t\t\t}\n\t\t\trr->top=top;\n\t\t\tgoto end;\n\t\t\t}\n#endif\n\t\t}\n#endif /* BN_RECURSION */\n\tif (bn_wexpand(rr,top) == NULL) goto err;\n\trr->top=top;\n\tbn_mul_normal(rr->d,a->d,al,b->d,bl);\n\n#if defined(BN_MUL_COMBA) || defined(BN_RECURSION)\nend:\n#endif\n\tbn_correct_top(rr);\n\tif (r != rr) BN_copy(r,rr);\n\tret=1;\nerr:\n\tbn_check_top(r);\n\tBN_CTX_end(ctx);\n\treturn(ret);\n\t}", "target": 1, "cwe": ["CWE-20"], "project": "openssl", "commit_id": "7e4cae1d2f555cbe9226b377aff4b56c9f7ddd4d", "hash": 283618452684822618273379481326746444910, "size": 162, "message": "PR: 2111\nSubmitted by: Martin Olsson <molsson@opera.com>\n\nCheck for bn_wexpand errors in bn_mul.c"}
{"func": "BIO *PKCS7_dataDecode(PKCS7 *p7, EVP_PKEY *pkey, BIO *in_bio, X509 *pcert)\n{\n    int i, j;\n    BIO *out = NULL, *btmp = NULL, *etmp = NULL, *bio = NULL;\n    X509_ALGOR *xa;\n    ASN1_OCTET_STRING *data_body = NULL;\n    const EVP_MD *evp_md;\n    const EVP_CIPHER *evp_cipher = NULL;\n    EVP_CIPHER_CTX *evp_ctx = NULL;\n    X509_ALGOR *enc_alg = NULL;\n    STACK_OF(X509_ALGOR) *md_sk = NULL;\n    STACK_OF(PKCS7_RECIP_INFO) *rsk = NULL;\n    PKCS7_RECIP_INFO *ri = NULL;\n    unsigned char *ek = NULL, *tkey = NULL;\n    int eklen = 0, tkeylen = 0;\n\n    if (p7 == NULL) {\n        PKCS7err(PKCS7_F_PKCS7_DATADECODE, PKCS7_R_INVALID_NULL_POINTER);\n        return NULL;\n    }\n\n    if (p7->d.ptr == NULL) {\n        PKCS7err(PKCS7_F_PKCS7_DATADECODE, PKCS7_R_NO_CONTENT);\n        return NULL;\n    }\n\n    i = OBJ_obj2nid(p7->type);\n    p7->state = PKCS7_S_HEADER;\n\n    switch (i) {\n    case NID_pkcs7_signed:\n        data_body = PKCS7_get_octet_string(p7->d.sign->contents);\n        if (!PKCS7_is_detached(p7) && data_body == NULL) {\n            PKCS7err(PKCS7_F_PKCS7_DATADECODE,\n                     PKCS7_R_INVALID_SIGNED_DATA_TYPE);\n            goto err;\n        }\n        md_sk = p7->d.sign->md_algs;\n        break;\n    case NID_pkcs7_signedAndEnveloped:\n        rsk = p7->d.signed_and_enveloped->recipientinfo;\n        md_sk = p7->d.signed_and_enveloped->md_algs;\n        data_body = p7->d.signed_and_enveloped->enc_data->enc_data;\n        enc_alg = p7->d.signed_and_enveloped->enc_data->algorithm;\n        evp_cipher = EVP_get_cipherbyobj(enc_alg->algorithm);\n        if (evp_cipher == NULL) {\n            PKCS7err(PKCS7_F_PKCS7_DATADECODE,\n                     PKCS7_R_UNSUPPORTED_CIPHER_TYPE);\n            goto err;\n        }\n        break;\n    case NID_pkcs7_enveloped:\n        rsk = p7->d.enveloped->recipientinfo;\n        enc_alg = p7->d.enveloped->enc_data->algorithm;\n        data_body = p7->d.enveloped->enc_data->enc_data;\n        evp_cipher = EVP_get_cipherbyobj(enc_alg->algorithm);\n        if (evp_cipher == NULL) {\n            PKCS7err(PKCS7_F_PKCS7_DATADECODE,\n                     PKCS7_R_UNSUPPORTED_CIPHER_TYPE);\n            goto err;\n        }\n        break;\n    default:\n        PKCS7err(PKCS7_F_PKCS7_DATADECODE, PKCS7_R_UNSUPPORTED_CONTENT_TYPE);\n        goto err;\n    }\n\n    /* We will be checking the signature */\n    if (md_sk != NULL) {\n        for (i = 0; i < sk_X509_ALGOR_num(md_sk); i++) {\n            xa = sk_X509_ALGOR_value(md_sk, i);\n            if ((btmp = BIO_new(BIO_f_md())) == NULL) {\n                PKCS7err(PKCS7_F_PKCS7_DATADECODE, ERR_R_BIO_LIB);\n                goto err;\n            }\n\n            j = OBJ_obj2nid(xa->algorithm);\n            evp_md = EVP_get_digestbynid(j);\n            if (evp_md == NULL) {\n                PKCS7err(PKCS7_F_PKCS7_DATADECODE,\n                         PKCS7_R_UNKNOWN_DIGEST_TYPE);\n                goto err;\n            }\n\n            BIO_set_md(btmp, evp_md);\n            if (out == NULL)\n                out = btmp;\n            else\n                BIO_push(out, btmp);\n            btmp = NULL;\n        }\n    }\n\n    if (evp_cipher != NULL) {\n        if ((etmp = BIO_new(BIO_f_cipher())) == NULL) {\n            PKCS7err(PKCS7_F_PKCS7_DATADECODE, ERR_R_BIO_LIB);\n            goto err;\n        }\n\n        /*\n         * It was encrypted, we need to decrypt the secret key with the\n         * private key\n         */\n\n        /*\n         * Find the recipientInfo which matches the passed certificate (if\n         * any)\n         */\n\n        if (pcert) {\n            for (i = 0; i < sk_PKCS7_RECIP_INFO_num(rsk); i++) {\n                ri = sk_PKCS7_RECIP_INFO_value(rsk, i);\n                if (!pkcs7_cmp_ri(ri, pcert))\n                    break;\n                ri = NULL;\n            }\n            if (ri == NULL) {\n                PKCS7err(PKCS7_F_PKCS7_DATADECODE,\n                         PKCS7_R_NO_RECIPIENT_MATCHES_CERTIFICATE);\n                goto err;\n            }\n        }\n\n        /* If we haven't got a certificate try each ri in turn */\n        if (pcert == NULL) {\n            /*\n             * Always attempt to decrypt all rinfo even after success as a\n             * defence against MMA timing attacks.\n             */\n            for (i = 0; i < sk_PKCS7_RECIP_INFO_num(rsk); i++) {\n                ri = sk_PKCS7_RECIP_INFO_value(rsk, i);\n\n                if (pkcs7_decrypt_rinfo(&ek, &eklen, ri, pkey) < 0)\n                    goto err;\n                ERR_clear_error();\n            }\n        } else {\n            /* Only exit on fatal errors, not decrypt failure */\n            if (pkcs7_decrypt_rinfo(&ek, &eklen, ri, pkey) < 0)\n                goto err;\n            ERR_clear_error();\n        }\n\n        evp_ctx = NULL;\n        BIO_get_cipher_ctx(etmp, &evp_ctx);\n        if (EVP_CipherInit_ex(evp_ctx, evp_cipher, NULL, NULL, NULL, 0) <= 0)\n            goto err;\n        if (EVP_CIPHER_asn1_to_param(evp_ctx, enc_alg->parameter) < 0)\n            goto err;\n        /* Generate random key as MMA defence */\n        tkeylen = EVP_CIPHER_CTX_key_length(evp_ctx);\n        tkey = OPENSSL_malloc(tkeylen);\n        if (!tkey)\n            goto err;\n        if (EVP_CIPHER_CTX_rand_key(evp_ctx, tkey) <= 0)\n            goto err;\n        if (ek == NULL) {\n            ek = tkey;\n            eklen = tkeylen;\n            tkey = NULL;\n        }\n\n        if (eklen != EVP_CIPHER_CTX_key_length(evp_ctx)) {\n            /*\n             * Some S/MIME clients don't use the same key and effective key\n             * length. The key length is determined by the size of the\n             * decrypted RSA key.\n             */\n            if (!EVP_CIPHER_CTX_set_key_length(evp_ctx, eklen)) {\n                /* Use random key as MMA defence */\n                OPENSSL_clear_free(ek, eklen);\n                ek = tkey;\n                eklen = tkeylen;\n                tkey = NULL;\n            }\n        }\n        /* Clear errors so we don't leak information useful in MMA */\n        ERR_clear_error();\n        if (EVP_CipherInit_ex(evp_ctx, NULL, NULL, ek, NULL, 0) <= 0)\n            goto err;\n\n        OPENSSL_clear_free(ek, eklen);\n        ek = NULL;\n        OPENSSL_clear_free(tkey, tkeylen);\n        tkey = NULL;\n\n        if (out == NULL)\n            out = etmp;\n        else\n            BIO_push(out, etmp);\n        etmp = NULL;\n    }\n    if (PKCS7_is_detached(p7) || (in_bio != NULL)) {\n        bio = in_bio;\n    } else {\n        if (data_body->length > 0)\n            bio = BIO_new_mem_buf(data_body->data, data_body->length);\n        else {\n            bio = BIO_new(BIO_s_mem());\n            BIO_set_mem_eof_return(bio, 0);\n        }\n        if (bio == NULL)\n            goto err;\n    }\n    BIO_push(out, bio);\n    bio = NULL;\n    return out;\n\n err:\n    OPENSSL_clear_free(ek, eklen);\n    OPENSSL_clear_free(tkey, tkeylen);\n    BIO_free_all(out);\n    BIO_free_all(btmp);\n    BIO_free_all(etmp);\n    BIO_free_all(bio);\n    return  NULL;\n}", "target": 1, "cwe": ["CWE-703"], "project": "openssl", "commit_id": "59302b600e8d5b77ef144e447bb046fd7ab72686", "hash": 56579458144976803996822874564842207302, "size": 217, "message": "PKCS#7: Fix NULL dereference with missing EncryptedContent.\n\nCVE-2015-1790\n\nReviewed-by: Rich Salz <rsalz@openssl.org>"}
{"func": "passdb_preinit(pool_t pool, const struct auth_passdb_settings *set)\n{\n\tstatic unsigned int auth_passdb_id = 0;\n\tstruct passdb_module_interface *iface;\n\tstruct passdb_module *passdb;\n\tunsigned int idx;\n\n\tiface = passdb_interface_find(set->driver);\n\tif (iface == NULL || iface->verify_plain == NULL) {\n\t\t/* maybe it's a plugin. try to load it. */\n\t\tauth_module_load(t_strconcat(\"authdb_\", set->driver, NULL));\n\t\tiface = passdb_interface_find(set->driver);\n\t}\n\tif (iface == NULL)\n\t\ti_fatal(\"Unknown passdb driver '%s'\", set->driver);\n\tif (iface->verify_plain == NULL) {\n\t\ti_fatal(\"Support not compiled in for passdb driver '%s'\",\n\t\t\tset->driver);\n\t}\n\tif (iface->preinit == NULL && iface->init == NULL &&\n\t    *set->args != '\\0') {\n\t\ti_fatal(\"passdb %s: No args are supported: %s\",\n\t\t\tset->driver, set->args);\n\t}\n\n\tpassdb = passdb_find(set->driver, set->args, &idx);\n\tif (passdb != NULL)\n\t\treturn passdb;\n\n\tif (iface->preinit == NULL)\n\t\tpassdb = p_new(pool, struct passdb_module, 1);\n\telse\n\t\tpassdb = iface->preinit(pool, set->args);\n\tpassdb->id = ++auth_passdb_id;\n\tpassdb->iface = *iface;\n\tpassdb->args = p_strdup(pool, set->args);\n\tif (*set->mechanisms == '\\0') {\n\t\tpassdb->mechanisms = NULL;\n\t} else if (strcasecmp(set->mechanisms, \"none\") == 0) {\n\t\tpassdb->mechanisms = (const char *const[]){NULL};\n\t} else {\n\t\tpassdb->mechanisms = (const char* const*)p_strsplit_spaces(pool, set->mechanisms, \" ,\");\n\t}\n\n\tif (*set->username_filter == '\\0') {\n\t\tpassdb->username_filter = NULL;\n\t} else {\n\t\tpassdb->username_filter = (const char* const*)p_strsplit_spaces(pool, set->username_filter, \" ,\");\n\t}\n\tarray_push_back(&passdb_modules, &passdb);\n\treturn passdb;\n}", "target": 1, "cwe": ["CWE-284"], "project": "core", "commit_id": "7bad6a24160e34bce8f10e73dbbf9e5fbbcd1904", "hash": 171236738619831882072939488649520832106, "size": 52, "message": "auth: Fix handling passdbs with identical driver/args but different mechanisms/username_filter\n\nThe passdb was wrongly deduplicated in this situation, causing wrong\nmechanisms or username_filter setting to be used. This would be a rather\nunlikely configuration though.\n\nFixed by moving mechanisms and username_filter from struct passdb_module\nto struct auth_passdb, which is where they should have been in the first\nplace."}
{"func": "auth_passdb_preinit(struct auth *auth, const struct auth_passdb_settings *set,\n\t\t    struct auth_passdb **passdbs)\n{\n\tstruct auth_passdb *auth_passdb, **dest;\n\n\tauth_passdb = p_new(auth->pool, struct auth_passdb, 1);\n\tauth_passdb->set = set;\n\tauth_passdb->skip = auth_passdb_skip_parse(set->skip);\n\tauth_passdb->result_success =\n\t\tauth_db_rule_parse(set->result_success);\n\tauth_passdb->result_failure =\n\t\tauth_db_rule_parse(set->result_failure);\n\tauth_passdb->result_internalfail =\n\t\tauth_db_rule_parse(set->result_internalfail);\n\n\tauth_passdb->default_fields_tmpl =\n\t\tpassdb_template_build(auth->pool, set->default_fields);\n\tauth_passdb->override_fields_tmpl =\n\t\tpassdb_template_build(auth->pool, set->override_fields);\n\n\t/* for backwards compatibility: */\n\tif (set->pass)\n\t\tauth_passdb->result_success = AUTH_DB_RULE_CONTINUE;\n\n\tfor (dest = passdbs; *dest != NULL; dest = &(*dest)->next) ;\n\t*dest = auth_passdb;\n\n\tauth_passdb->passdb = passdb_preinit(auth->pool, set);\n\t/* make sure any %variables in default_fields exist in cache_key */\n\tif (auth_passdb->passdb->default_cache_key != NULL) {\n\t\tauth_passdb->cache_key =\n\t\t\tp_strconcat(auth->pool, auth_passdb->passdb->default_cache_key,\n\t\t\t\tset->default_fields, NULL);\n\t}\n\telse {\n\t\tauth_passdb->cache_key = NULL;\n\t}\n}", "target": 1, "cwe": ["CWE-284"], "project": "core", "commit_id": "7bad6a24160e34bce8f10e73dbbf9e5fbbcd1904", "hash": 156512071185038905071082963759912204894, "size": 38, "message": "auth: Fix handling passdbs with identical driver/args but different mechanisms/username_filter\n\nThe passdb was wrongly deduplicated in this situation, causing wrong\nmechanisms or username_filter setting to be used. This would be a rather\nunlikely configuration though.\n\nFixed by moving mechanisms and username_filter from struct passdb_module\nto struct auth_passdb, which is where they should have been in the first\nplace."}
{"func": "auth_request_want_skip_passdb(struct auth_request *request,\n\t\t\t      struct auth_passdb *passdb)\n{\n\t/* if mechanism is not supported, skip */\n\tconst char *const *mechs = passdb->passdb->mechanisms;\n\tconst char *const *username_filter = passdb->passdb->username_filter;\n\tconst char *username;\n\n\tusername = request->fields.user;\n\n\tif (!auth_request_mechanism_accepted(mechs, request->mech)) {\n\t\tauth_request_log_debug(request,\n\t\t\t\t       request->mech != NULL ? AUTH_SUBSYS_MECH\n\t\t\t\t\t\t\t      : \"none\",\n\t\t\t\t       \"skipping passdb: mechanism filtered\");\n\t\treturn TRUE;\n\t}\n\n\tif (passdb->passdb->username_filter != NULL &&\n\t    !auth_request_username_accepted(username_filter, username)) {\n\t\tauth_request_log_debug(request,\n\t\t\t\t       request->mech != NULL ? AUTH_SUBSYS_MECH\n\t\t\t\t\t\t\t      : \"none\",\n\t\t\t\t       \"skipping passdb: username filtered\");\n\t\treturn TRUE;\n\t}\n\n\t/* skip_password_check basically specifies if authentication is\n\t   finished */\n\tbool authenticated = request->fields.skip_password_check;\n\n\tswitch (passdb->skip) {\n\tcase AUTH_PASSDB_SKIP_NEVER:\n\t\treturn FALSE;\n\tcase AUTH_PASSDB_SKIP_AUTHENTICATED:\n\t\treturn authenticated;\n\tcase AUTH_PASSDB_SKIP_UNAUTHENTICATED:\n\t\treturn !authenticated;\n\t}\n\ti_unreached();\n}", "target": 1, "cwe": ["CWE-284"], "project": "core", "commit_id": "7bad6a24160e34bce8f10e73dbbf9e5fbbcd1904", "hash": 40359836661542547631562067370048584499, "size": 41, "message": "auth: Fix handling passdbs with identical driver/args but different mechanisms/username_filter\n\nThe passdb was wrongly deduplicated in this situation, causing wrong\nmechanisms or username_filter setting to be used. This would be a rather\nunlikely configuration though.\n\nFixed by moving mechanisms and username_filter from struct passdb_module\nto struct auth_passdb, which is where they should have been in the first\nplace."}
{"func": "static void do_free_upto(BIO *f, BIO *upto)\n\t{\n\tif (upto)\n\t\t{\n\t\tBIO *tbio;\n\t\tdo \n\t\t\t{\n\t\t\ttbio = BIO_pop(f);\n\t\t\tBIO_free(f);\n\t\t\tf = tbio;\n\t\t\t}\n\t\twhile (f != upto);\n\t\t}\n\telse\n\t\tBIO_free_all(f);\n\t}", "target": 1, "cwe": ["CWE-399", "CWE-703"], "project": "openssl", "commit_id": "cd30f03ac5bf2962f44bd02ae8d88245dff2f12c", "hash": 66354926616808912028767182253962976873, "size": 16, "message": "Canonicalise input in CMS_verify.\n\nIf content is detached and not binary mode translate the input to\nCRLF format. Before this change the input was verified verbatim\nwhich lead to a discrepancy between sign and verify."}
{"func": "int CMS_verify(CMS_ContentInfo *cms, STACK_OF(X509) *certs,\n\t\t X509_STORE *store, BIO *dcont, BIO *out, unsigned int flags)\n\t{\n\tCMS_SignerInfo *si;\n\tSTACK_OF(CMS_SignerInfo) *sinfos;\n\tSTACK_OF(X509) *cms_certs = NULL;\n\tSTACK_OF(X509_CRL) *crls = NULL;\n\tX509 *signer;\n\tint i, scount = 0, ret = 0;\n\tBIO *cmsbio = NULL, *tmpin = NULL;\n\n\tif (!dcont && !check_content(cms))\n\t\treturn 0;\n\n\t/* Attempt to find all signer certificates */\n\n\tsinfos = CMS_get0_SignerInfos(cms);\n\n\tif (sk_CMS_SignerInfo_num(sinfos) <= 0)\n\t\t{\n\t\tCMSerr(CMS_F_CMS_VERIFY, CMS_R_NO_SIGNERS);\n\t\tgoto err;\n\t\t}\n\n\tfor (i = 0; i < sk_CMS_SignerInfo_num(sinfos); i++)\n\t\t{\n\t\tsi = sk_CMS_SignerInfo_value(sinfos, i);\n\t\tCMS_SignerInfo_get0_algs(si, NULL, &signer, NULL, NULL);\n\t\tif (signer)\n\t\t\tscount++;\n\t\t}\n\n\tif (scount != sk_CMS_SignerInfo_num(sinfos))\n\t\tscount += CMS_set1_signers_certs(cms, certs, flags);\n\n\tif (scount != sk_CMS_SignerInfo_num(sinfos))\n\t\t{\n\t\tCMSerr(CMS_F_CMS_VERIFY, CMS_R_SIGNER_CERTIFICATE_NOT_FOUND);\n\t\tgoto err;\n\t\t}\n\n\t/* Attempt to verify all signers certs */\n\n\tif (!(flags & CMS_NO_SIGNER_CERT_VERIFY))\n\t\t{\n\t\tcms_certs = CMS_get1_certs(cms);\n\t\tif (!(flags & CMS_NOCRL))\n\t\t\tcrls = CMS_get1_crls(cms);\n\t\tfor (i = 0; i < sk_CMS_SignerInfo_num(sinfos); i++)\n\t\t\t{\n\t\t\tsi = sk_CMS_SignerInfo_value(sinfos, i);\n\t\t\tif (!cms_signerinfo_verify_cert(si, store,\n\t\t\t\t\t\t\tcms_certs, crls, flags))\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t}\n\n\t/* Attempt to verify all SignerInfo signed attribute signatures */\n\n\tif (!(flags & CMS_NO_ATTR_VERIFY))\n\t\t{\n\t\tfor (i = 0; i < sk_CMS_SignerInfo_num(sinfos); i++)\n\t\t\t{\n\t\t\tsi = sk_CMS_SignerInfo_value(sinfos, i);\n\t\t\tif (CMS_signed_get_attr_count(si) < 0)\n\t\t\t\tcontinue;\n\t\t\tif (CMS_SignerInfo_verify(si) <= 0)\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t}\n\n\t/* Performance optimization: if the content is a memory BIO then\n\t * store its contents in a temporary read only memory BIO. This\n\t * avoids potentially large numbers of slow copies of data which will\n\t * occur when reading from a read write memory BIO when signatures\n\t * are calculated.\n\t */\n\n\tif (dcont && (BIO_method_type(dcont) == BIO_TYPE_MEM))\n\t\t{\n\t\tchar *ptr;\n\t\tlong len;\n\t\tlen = BIO_get_mem_data(dcont, &ptr);\n\t\ttmpin = BIO_new_mem_buf(ptr, len);\n\t\tif (tmpin == NULL)\n\t\t\t{\n\t\t\tCMSerr(CMS_F_CMS_VERIFY,ERR_R_MALLOC_FAILURE);\n\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\telse\n\t\ttmpin = dcont;\n\t\t\n\n\tcmsbio=CMS_dataInit(cms, tmpin);\n\tif (!cmsbio)\n\t\tgoto err;\n\n\tif (!cms_copy_content(out, cmsbio, flags))\n\t\tgoto err;\n\n\tif (!(flags & CMS_NO_CONTENT_VERIFY))\n\t\t{\n\t\tfor (i = 0; i < sk_CMS_SignerInfo_num(sinfos); i++)\n\t\t\t{\n\t\t\tsi = sk_CMS_SignerInfo_value(sinfos, i);\n\t\t\tif (CMS_SignerInfo_verify_content(si, cmsbio) <= 0)\n\t\t\t\t{\n\t\t\t\tCMSerr(CMS_F_CMS_VERIFY,\n\t\t\t\t\tCMS_R_CONTENT_VERIFY_ERROR);\n\t\t\t\tgoto err;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\tret = 1;\n\n\terr:\n\t\n\tif (dcont && (tmpin == dcont))\n\t\tdo_free_upto(cmsbio, dcont);\n\telse\n\t\tBIO_free_all(cmsbio);\n\n\tif (cms_certs)\n\t\tsk_X509_pop_free(cms_certs, X509_free);\n\tif (crls)\n\t\tsk_X509_CRL_pop_free(crls, X509_CRL_free);\n\n\treturn ret;\n\t}", "target": 1, "cwe": ["CWE-399", "CWE-703"], "project": "openssl", "commit_id": "cd30f03ac5bf2962f44bd02ae8d88245dff2f12c", "hash": 24743731068362085870333855901190707715, "size": 131, "message": "Canonicalise input in CMS_verify.\n\nIf content is detached and not binary mode translate the input to\nCRLF format. Before this change the input was verified verbatim\nwhich lead to a discrepancy between sign and verify."}
{"func": "static int cms_copy_content(BIO *out, BIO *in, unsigned int flags)\n\t{\n\tunsigned char buf[4096];\n\tint r = 0, i;\n\tBIO *tmpout = NULL;\n\n\tif (out == NULL)\n\t\ttmpout = BIO_new(BIO_s_null());\n\telse if (flags & CMS_TEXT)\n\t\t{\n\t\ttmpout = BIO_new(BIO_s_mem());\n\t\tBIO_set_mem_eof_return(tmpout, 0);\n\t\t}\n\telse\n\t\ttmpout = out;\n\n\tif(!tmpout)\n\t\t{\n\t\tCMSerr(CMS_F_CMS_COPY_CONTENT,ERR_R_MALLOC_FAILURE);\n\t\tgoto err;\n\t\t}\n\n\t/* Read all content through chain to process digest, decrypt etc */\n\tfor (;;)\n\t{\n\t\ti=BIO_read(in,buf,sizeof(buf));\n\t\tif (i <= 0)\n\t\t\t{\n\t\t\tif (BIO_method_type(in) == BIO_TYPE_CIPHER)\n\t\t\t\t{\n\t\t\t\tif (!BIO_get_cipher_status(in))\n\t\t\t\t\tgoto err;\n\t\t\t\t}\n\t\t\tif (i < 0)\n\t\t\t\tgoto err;\n\t\t\tbreak;\n\t\t\t}\n\t\t\t\t\n\t\tif (tmpout && (BIO_write(tmpout, buf, i) != i))\n\t\t\tgoto err;\n\t}\n\n\tif(flags & CMS_TEXT)\n\t\t{\n\t\tif(!SMIME_text(tmpout, out))\n\t\t\t{\n\t\t\tCMSerr(CMS_F_CMS_COPY_CONTENT,CMS_R_SMIME_TEXT_ERROR);\n\t\t\tgoto err;\n\t\t\t}\n\t\t}\n\n\tr = 1;\n\n\terr:\n\tif (tmpout && (tmpout != out))\n\t\tBIO_free(tmpout);\n\treturn r;\n\n\t}", "target": 1, "cwe": ["CWE-399", "CWE-703"], "project": "openssl", "commit_id": "cd30f03ac5bf2962f44bd02ae8d88245dff2f12c", "hash": 259481123232658542083612354493787993447, "size": 59, "message": "Canonicalise input in CMS_verify.\n\nIf content is detached and not binary mode translate the input to\nCRLF format. Before this change the input was verified verbatim\nwhich lead to a discrepancy between sign and verify."}
{"func": "BIGNUM *BN_mod_sqrt(BIGNUM *in, const BIGNUM *a, const BIGNUM *p, BN_CTX *ctx)\n/*\n * Returns 'ret' such that ret^2 == a (mod p), using the Tonelli/Shanks\n * algorithm (cf. Henri Cohen, \"A Course in Algebraic Computational Number\n * Theory\", algorithm 1.5.1). 'p' must be prime!\n */\n{\n    BIGNUM *ret = in;\n    int err = 1;\n    int r;\n    BIGNUM *A, *b, *q, *t, *x, *y;\n    int e, i, j;\n    int used_ctx = 0;\n\n    if (!BN_is_odd(p) || BN_abs_is_word(p, 1)) {\n        if (BN_abs_is_word(p, 2)) {\n            if (ret == NULL)\n                ret = BN_new();\n            if (ret == NULL)\n                goto end;\n            if (!BN_set_word(ret, BN_is_bit_set(a, 0))) {\n                if (ret != in)\n                    BN_free(ret);\n                return NULL;\n            }\n            bn_check_top(ret);\n            return ret;\n        }\n\n        ERR_raise(ERR_LIB_BN, BN_R_P_IS_NOT_PRIME);\n        return NULL;\n    }\n\n    if (BN_is_zero(a) || BN_is_one(a)) {\n        if (ret == NULL)\n            ret = BN_new();\n        if (ret == NULL)\n            goto end;\n        if (!BN_set_word(ret, BN_is_one(a))) {\n            if (ret != in)\n                BN_free(ret);\n            return NULL;\n        }\n        bn_check_top(ret);\n        return ret;\n    }\n\n    BN_CTX_start(ctx);\n    used_ctx = 1;\n    A = BN_CTX_get(ctx);\n    b = BN_CTX_get(ctx);\n    q = BN_CTX_get(ctx);\n    t = BN_CTX_get(ctx);\n    x = BN_CTX_get(ctx);\n    y = BN_CTX_get(ctx);\n    if (y == NULL)\n        goto end;\n\n    if (ret == NULL)\n        ret = BN_new();\n    if (ret == NULL)\n        goto end;\n\n    /* A = a mod p */\n    if (!BN_nnmod(A, a, p, ctx))\n        goto end;\n\n    /* now write  |p| - 1  as  2^e*q  where  q  is odd */\n    e = 1;\n    while (!BN_is_bit_set(p, e))\n        e++;\n    /* we'll set  q  later (if needed) */\n\n    if (e == 1) {\n        /*-\n         * The easy case:  (|p|-1)/2  is odd, so 2 has an inverse\n         * modulo  (|p|-1)/2,  and square roots can be computed\n         * directly by modular exponentiation.\n         * We have\n         *     2 * (|p|+1)/4 == 1   (mod (|p|-1)/2),\n         * so we can use exponent  (|p|+1)/4,  i.e.  (|p|-3)/4 + 1.\n         */\n        if (!BN_rshift(q, p, 2))\n            goto end;\n        q->neg = 0;\n        if (!BN_add_word(q, 1))\n            goto end;\n        if (!BN_mod_exp(ret, A, q, p, ctx))\n            goto end;\n        err = 0;\n        goto vrfy;\n    }\n\n    if (e == 2) {\n        /*-\n         * |p| == 5  (mod 8)\n         *\n         * In this case  2  is always a non-square since\n         * Legendre(2,p) = (-1)^((p^2-1)/8)  for any odd prime.\n         * So if  a  really is a square, then  2*a  is a non-square.\n         * Thus for\n         *      b := (2*a)^((|p|-5)/8),\n         *      i := (2*a)*b^2\n         * we have\n         *     i^2 = (2*a)^((1 + (|p|-5)/4)*2)\n         *         = (2*a)^((p-1)/2)\n         *         = -1;\n         * so if we set\n         *      x := a*b*(i-1),\n         * then\n         *     x^2 = a^2 * b^2 * (i^2 - 2*i + 1)\n         *         = a^2 * b^2 * (-2*i)\n         *         = a*(-i)*(2*a*b^2)\n         *         = a*(-i)*i\n         *         = a.\n         *\n         * (This is due to A.O.L. Atkin,\n         * Subject: Square Roots and Cognate Matters modulo p=8n+5.\n         * URL: https://listserv.nodak.edu/cgi-bin/wa.exe?A2=ind9211&L=NMBRTHRY&P=4026\n         * November 1992.)\n         */\n\n        /* t := 2*a */\n        if (!BN_mod_lshift1_quick(t, A, p))\n            goto end;\n\n        /* b := (2*a)^((|p|-5)/8) */\n        if (!BN_rshift(q, p, 3))\n            goto end;\n        q->neg = 0;\n        if (!BN_mod_exp(b, t, q, p, ctx))\n            goto end;\n\n        /* y := b^2 */\n        if (!BN_mod_sqr(y, b, p, ctx))\n            goto end;\n\n        /* t := (2*a)*b^2 - 1 */\n        if (!BN_mod_mul(t, t, y, p, ctx))\n            goto end;\n        if (!BN_sub_word(t, 1))\n            goto end;\n\n        /* x = a*b*t */\n        if (!BN_mod_mul(x, A, b, p, ctx))\n            goto end;\n        if (!BN_mod_mul(x, x, t, p, ctx))\n            goto end;\n\n        if (!BN_copy(ret, x))\n            goto end;\n        err = 0;\n        goto vrfy;\n    }\n\n    /*\n     * e > 2, so we really have to use the Tonelli/Shanks algorithm. First,\n     * find some y that is not a square.\n     */\n    if (!BN_copy(q, p))\n        goto end;               /* use 'q' as temp */\n    q->neg = 0;\n    i = 2;\n    do {\n        /*\n         * For efficiency, try small numbers first; if this fails, try random\n         * numbers.\n         */\n        if (i < 22) {\n            if (!BN_set_word(y, i))\n                goto end;\n        } else {\n            if (!BN_priv_rand_ex(y, BN_num_bits(p), 0, 0, 0, ctx))\n                goto end;\n            if (BN_ucmp(y, p) >= 0) {\n                if (!(p->neg ? BN_add : BN_sub) (y, y, p))\n                    goto end;\n            }\n            /* now 0 <= y < |p| */\n            if (BN_is_zero(y))\n                if (!BN_set_word(y, i))\n                    goto end;\n        }\n\n        r = BN_kronecker(y, q, ctx); /* here 'q' is |p| */\n        if (r < -1)\n            goto end;\n        if (r == 0) {\n            /* m divides p */\n            ERR_raise(ERR_LIB_BN, BN_R_P_IS_NOT_PRIME);\n            goto end;\n        }\n    }\n    while (r == 1 && ++i < 82);\n\n    if (r != -1) {\n        /*\n         * Many rounds and still no non-square -- this is more likely a bug\n         * than just bad luck. Even if p is not prime, we should have found\n         * some y such that r == -1.\n         */\n        ERR_raise(ERR_LIB_BN, BN_R_TOO_MANY_ITERATIONS);\n        goto end;\n    }\n\n    /* Here's our actual 'q': */\n    if (!BN_rshift(q, q, e))\n        goto end;\n\n    /*\n     * Now that we have some non-square, we can find an element of order 2^e\n     * by computing its q'th power.\n     */\n    if (!BN_mod_exp(y, y, q, p, ctx))\n        goto end;\n    if (BN_is_one(y)) {\n        ERR_raise(ERR_LIB_BN, BN_R_P_IS_NOT_PRIME);\n        goto end;\n    }\n\n    /*-\n     * Now we know that (if  p  is indeed prime) there is an integer\n     * k,  0 <= k < 2^e,  such that\n     *\n     *      a^q * y^k == 1   (mod p).\n     *\n     * As  a^q  is a square and  y  is not,  k  must be even.\n     * q+1  is even, too, so there is an element\n     *\n     *     X := a^((q+1)/2) * y^(k/2),\n     *\n     * and it satisfies\n     *\n     *     X^2 = a^q * a     * y^k\n     *         = a,\n     *\n     * so it is the square root that we are looking for.\n     */\n\n    /* t := (q-1)/2  (note that  q  is odd) */\n    if (!BN_rshift1(t, q))\n        goto end;\n\n    /* x := a^((q-1)/2) */\n    if (BN_is_zero(t)) {        /* special case: p = 2^e + 1 */\n        if (!BN_nnmod(t, A, p, ctx))\n            goto end;\n        if (BN_is_zero(t)) {\n            /* special case: a == 0  (mod p) */\n            BN_zero(ret);\n            err = 0;\n            goto end;\n        } else if (!BN_one(x))\n            goto end;\n    } else {\n        if (!BN_mod_exp(x, A, t, p, ctx))\n            goto end;\n        if (BN_is_zero(x)) {\n            /* special case: a == 0  (mod p) */\n            BN_zero(ret);\n            err = 0;\n            goto end;\n        }\n    }\n\n    /* b := a*x^2  (= a^q) */\n    if (!BN_mod_sqr(b, x, p, ctx))\n        goto end;\n    if (!BN_mod_mul(b, b, A, p, ctx))\n        goto end;\n\n    /* x := a*x    (= a^((q+1)/2)) */\n    if (!BN_mod_mul(x, x, A, p, ctx))\n        goto end;\n\n    while (1) {\n        /*-\n         * Now  b  is  a^q * y^k  for some even  k  (0 <= k < 2^E\n         * where  E  refers to the original value of  e,  which we\n         * don't keep in a variable),  and  x  is  a^((q+1)/2) * y^(k/2).\n         *\n         * We have  a*b = x^2,\n         *    y^2^(e-1) = -1,\n         *    b^2^(e-1) = 1.\n         */\n\n        if (BN_is_one(b)) {\n            if (!BN_copy(ret, x))\n                goto end;\n            err = 0;\n            goto vrfy;\n        }\n\n        /* find smallest  i  such that  b^(2^i) = 1 */\n        i = 1;\n        if (!BN_mod_sqr(t, b, p, ctx))\n            goto end;\n        while (!BN_is_one(t)) {\n            i++;\n            if (i == e) {\n                ERR_raise(ERR_LIB_BN, BN_R_NOT_A_SQUARE);\n                goto end;\n            }\n            if (!BN_mod_mul(t, t, t, p, ctx))\n                goto end;\n        }\n\n        /* t := y^2^(e - i - 1) */\n        if (!BN_copy(t, y))\n            goto end;\n        for (j = e - i - 1; j > 0; j--) {\n            if (!BN_mod_sqr(t, t, p, ctx))\n                goto end;\n        }\n        if (!BN_mod_mul(y, t, t, p, ctx))\n            goto end;\n        if (!BN_mod_mul(x, x, t, p, ctx))\n            goto end;\n        if (!BN_mod_mul(b, b, y, p, ctx))\n            goto end;\n        e = i;\n    }\n\n vrfy:\n    if (!err) {\n        /*\n         * verify the result -- the input might have been not a square (test\n         * added in 0.9.8)\n         */\n\n        if (!BN_mod_sqr(x, ret, p, ctx))\n            err = 1;\n\n        if (!err && 0 != BN_cmp(x, A)) {\n            ERR_raise(ERR_LIB_BN, BN_R_NOT_A_SQUARE);\n            err = 1;\n        }\n    }\n\n end:\n    if (err) {\n        if (ret != in)\n            BN_clear_free(ret);\n        ret = NULL;\n    }\n    if (used_ctx)\n        BN_CTX_end(ctx);\n    bn_check_top(ret);\n    return ret;\n}", "target": 1, "cwe": [], "project": "openssl", "commit_id": "9eafb53614bf65797db25f467946e735e1b43dc9", "hash": 292506106842733760171896209269368748784, "size": 350, "message": "Fix possible infinite loop in BN_mod_sqrt()\n\nThe calculation in some cases does not finish for non-prime p.\n\nThis fixes CVE-2022-0778.\n\nBased on patch by David Benjamin <davidben@google.com>.\n\nReviewed-by: Paul Dale <pauli@openssl.org>\nReviewed-by: Matt Caswell <matt@openssl.org>"}
{"func": "static void loongarch_cpu_reset(DeviceState *dev)\n{\n    CPUState *cs = CPU(dev);\n    LoongArchCPU *cpu = LOONGARCH_CPU(cs);\n    LoongArchCPUClass *lacc = LOONGARCH_CPU_GET_CLASS(cpu);\n    CPULoongArchState *env = &cpu->env;\n\n    lacc->parent_reset(dev);\n\n    env->fcsr0_mask = FCSR0_M1 | FCSR0_M2 | FCSR0_M3;\n    env->fcsr0 = 0x0;\n\n    int n;\n    /* Set csr registers value after reset */\n    env->CSR_CRMD = FIELD_DP64(env->CSR_CRMD, CSR_CRMD, PLV, 0);\n    env->CSR_CRMD = FIELD_DP64(env->CSR_CRMD, CSR_CRMD, IE, 0);\n    env->CSR_CRMD = FIELD_DP64(env->CSR_CRMD, CSR_CRMD, DA, 1);\n    env->CSR_CRMD = FIELD_DP64(env->CSR_CRMD, CSR_CRMD, PG, 0);\n    env->CSR_CRMD = FIELD_DP64(env->CSR_CRMD, CSR_CRMD, DATF, 1);\n    env->CSR_CRMD = FIELD_DP64(env->CSR_CRMD, CSR_CRMD, DATM, 1);\n\n    env->CSR_EUEN = FIELD_DP64(env->CSR_EUEN, CSR_EUEN, FPE, 0);\n    env->CSR_EUEN = FIELD_DP64(env->CSR_EUEN, CSR_EUEN, SXE, 0);\n    env->CSR_EUEN = FIELD_DP64(env->CSR_EUEN, CSR_EUEN, ASXE, 0);\n    env->CSR_EUEN = FIELD_DP64(env->CSR_EUEN, CSR_EUEN, BTE, 0);\n\n    env->CSR_MISC = 0;\n\n    env->CSR_ECFG = FIELD_DP64(env->CSR_ECFG, CSR_ECFG, VS, 0);\n    env->CSR_ECFG = FIELD_DP64(env->CSR_ECFG, CSR_ECFG, LIE, 0);\n\n    env->CSR_ESTAT = env->CSR_ESTAT & (~MAKE_64BIT_MASK(0, 2));\n    env->CSR_RVACFG = FIELD_DP64(env->CSR_RVACFG, CSR_RVACFG, RBITS, 0);\n    env->CSR_TCFG = FIELD_DP64(env->CSR_TCFG, CSR_TCFG, EN, 0);\n    env->CSR_LLBCTL = FIELD_DP64(env->CSR_LLBCTL, CSR_LLBCTL, KLO, 0);\n    env->CSR_TLBRERA = FIELD_DP64(env->CSR_TLBRERA, CSR_TLBRERA, ISTLBR, 0);\n    env->CSR_MERRCTL = FIELD_DP64(env->CSR_MERRCTL, CSR_MERRCTL, ISMERR, 0);\n\n    env->CSR_PRCFG3 = FIELD_DP64(env->CSR_PRCFG3, CSR_PRCFG3, TLB_TYPE, 2);\n    env->CSR_PRCFG3 = FIELD_DP64(env->CSR_PRCFG3, CSR_PRCFG3, MTLB_ENTRY, 63);\n    env->CSR_PRCFG3 = FIELD_DP64(env->CSR_PRCFG3, CSR_PRCFG3, STLB_WAYS, 7);\n    env->CSR_PRCFG3 = FIELD_DP64(env->CSR_PRCFG3, CSR_PRCFG3, STLB_SETS, 8);\n\n    for (n = 0; n < 4; n++) {\n        env->CSR_DMW[n] = FIELD_DP64(env->CSR_DMW[n], CSR_DMW, PLV0, 0);\n        env->CSR_DMW[n] = FIELD_DP64(env->CSR_DMW[n], CSR_DMW, PLV1, 0);\n        env->CSR_DMW[n] = FIELD_DP64(env->CSR_DMW[n], CSR_DMW, PLV2, 0);\n        env->CSR_DMW[n] = FIELD_DP64(env->CSR_DMW[n], CSR_DMW, PLV3, 0);\n    }\n\n#ifndef CONFIG_USER_ONLY\n    env->pc = 0x1c000000;\n#endif\n\n    restore_fp_status(env);\n    cs->exception_index = -1;\n}", "target": 1, "cwe": [], "project": "qemu", "commit_id": "3517fb726741c109cae7995f9ea46f0cab6187d6", "hash": 182659130472244166990759470535201909060, "size": 57, "message": "target/loongarch: Clean up tlb when cpu reset\n\nWe should make sure that tlb is clean when cpu reset.\n\nSigned-off-by: Song Gao <gaosong@loongson.cn>\nMessage-Id: <20220705070950.2364243-1-gaosong@loongson.cn>\nReviewed-by: Richard Henderson <richard.henderson@linaro.org>\nSigned-off-by: Richard Henderson <richard.henderson@linaro.org>"}
{"func": "int _gnutls_compressed2ciphertext(gnutls_session_t session,\n\t\t\t\t  opaque * cipher_data, int cipher_size,\n\t\t\t\t  gnutls_datum_t compressed,\n\t\t\t\t  content_type_t _type, int random_pad)\n{\n    uint8 MAC[MAX_HASH_SIZE];\n    uint16 c_length;\n    uint8 pad;\n    int length, ret;\n    mac_hd_t td;\n    uint8 type = _type;\n    uint8 major, minor;\n    int hash_size =\n\t_gnutls_hash_get_algo_len(session->security_parameters.\n\t\t\t\t  write_mac_algorithm);\n    gnutls_protocol_t ver;\n    int blocksize =\n\t_gnutls_cipher_get_block_size(session->security_parameters.\n\t\t\t\t      write_bulk_cipher_algorithm);\n    cipher_type_t block_algo =\n\t_gnutls_cipher_is_block(session->security_parameters.\n\t\t\t\twrite_bulk_cipher_algorithm);\n    opaque *data_ptr;\n\n\n    ver = gnutls_protocol_get_version(session);\n    minor = _gnutls_version_get_minor(ver);\n    major = _gnutls_version_get_major(ver);\n\n\n    /* Initialize MAC */\n    td = mac_init(session->security_parameters.write_mac_algorithm,\n\t\t  session->connection_state.write_mac_secret.data,\n\t\t  session->connection_state.write_mac_secret.size, ver);\n\n    if (td == GNUTLS_MAC_FAILED\n\t&& session->security_parameters.write_mac_algorithm !=\n\tGNUTLS_MAC_NULL) {\n\tgnutls_assert();\n\treturn GNUTLS_E_INTERNAL_ERROR;\n    }\n\n    c_length = _gnutls_conv_uint16(compressed.size);\n\n    if (td != GNUTLS_MAC_FAILED) {\t/* actually when the algorithm in not the NULL one */\n\t_gnutls_hmac(td,\n\t\t     UINT64DATA(session->connection_state.\n\t\t\t\twrite_sequence_number), 8);\n\n\t_gnutls_hmac(td, &type, 1);\n\tif (ver >= GNUTLS_TLS1) {\t/* TLS 1.0 or higher */\n\t    _gnutls_hmac(td, &major, 1);\n\t    _gnutls_hmac(td, &minor, 1);\n\t}\n\t_gnutls_hmac(td, &c_length, 2);\n\t_gnutls_hmac(td, compressed.data, compressed.size);\n\tmac_deinit(td, MAC, ver);\n    }\n\n\n    /* Calculate the encrypted length (padding etc.)\n     */\n    length =\n\tcalc_enc_length(session, compressed.size, hash_size, &pad,\n\t\t\trandom_pad, block_algo, blocksize);\n    if (length < 0) {\n\tgnutls_assert();\n\treturn length;\n    }\n\n    /* copy the encrypted data to cipher_data.\n     */\n    if (cipher_size < length) {\n\tgnutls_assert();\n\treturn GNUTLS_E_MEMORY_ERROR;\n    }\n\n    data_ptr = cipher_data;\n    if (block_algo == CIPHER_BLOCK &&\n\tsession->security_parameters.version >= GNUTLS_TLS1_1) {\n\t/* copy the random IV.\n\t */\n\tif (_gnutls_get_random(data_ptr, blocksize, GNUTLS_WEAK_RANDOM) <\n\t    0) {\n\t    gnutls_assert();\n\t    return GNUTLS_E_MEMORY_ERROR;\n\t}\n\tdata_ptr += blocksize;\n    }\n\n    memcpy(data_ptr, compressed.data, compressed.size);\n    data_ptr += compressed.size;\n\n    if (hash_size > 0) {\n\tmemcpy(data_ptr, MAC, hash_size);\n\tdata_ptr += hash_size;\n    }\n    if (block_algo == CIPHER_BLOCK && pad > 0) {\n\tmemset(data_ptr, pad - 1, pad);\n    }\n\n\n    /* Actual encryption (inplace).\n     */\n    ret = _gnutls_cipher_encrypt(session->connection_state.\n\t\t\t\t write_cipher_state, cipher_data, length);\n    if (ret < 0) {\n\tgnutls_assert();\n\treturn ret;\n    }\n\n    return length;\n}", "target": 0, "cwe": [], "project": "gnutls", "commit_id": "7ad6162573ba79a4392c63b453ad0220ca6c5ace", "hash": 302704395810417563643447139814305076342, "size": 113, "message": "added an extra check while checking the padding."}
{"func": "int _gnutls_decrypt(gnutls_session_t session, opaque * ciphertext,\n\t\t    size_t ciphertext_size, uint8 * data,\n\t\t    size_t max_data_size, content_type_t type)\n{\n    gnutls_datum_t gtxt;\n    gnutls_datum_t gcipher;\n    int ret;\n\n    if (ciphertext_size == 0)\n\treturn 0;\n\n    gcipher.size = ciphertext_size;\n    gcipher.data = ciphertext;\n\n    ret =\n\t_gnutls_ciphertext2compressed(session, data, max_data_size,\n\t\t\t\t      gcipher, type);\n    if (ret < 0) {\n\treturn ret;\n    }\n\n    if (ret == 0 || is_read_comp_null(session) == 0) {\n\t/* ret == ret */\n\n    } else {\n\tgnutls_datum_t gcomp;\n\n\t/* compression has this malloc overhead.\n\t */\n\n\tgcomp.data = data;\n\tgcomp.size = ret;\n\tret = _gnutls_m_compressed2plaintext(session, &gtxt, gcomp);\n\tif (ret < 0) {\n\t    return ret;\n\t}\n\n\tif (gtxt.size > max_data_size) {\n\t    gnutls_assert();\n\t    _gnutls_free_datum(&gtxt);\n\t    /* This shouldn't have happen and\n\t     * is a TLS fatal error.\n\t     */\n\t    return GNUTLS_E_INTERNAL_ERROR;\n\t}\n\n\tmemcpy(data, gtxt.data, gtxt.size);\n\tret = gtxt.size;\n\n\t_gnutls_free_datum(&gtxt);\n    }\n\n    return ret;\n}", "target": 0, "cwe": [], "project": "gnutls", "commit_id": "7ad6162573ba79a4392c63b453ad0220ca6c5ace", "hash": 39646836574886987410506857697928534487, "size": 54, "message": "added an extra check while checking the padding."}
{"func": "int _gnutls_ciphertext2compressed(gnutls_session_t session,\n\t\t\t\t  opaque * compress_data,\n\t\t\t\t  int compress_size,\n\t\t\t\t  gnutls_datum_t ciphertext, uint8 type)\n{\n    uint8 MAC[MAX_HASH_SIZE];\n    uint16 c_length;\n    uint8 pad;\n    int length;\n    mac_hd_t td;\n    uint16 blocksize;\n    int ret, i, pad_failed = 0;\n    uint8 major, minor;\n    gnutls_protocol_t ver;\n    int hash_size =\n\t_gnutls_hash_get_algo_len(session->security_parameters.\n\t\t\t\t  read_mac_algorithm);\n\n    ver = gnutls_protocol_get_version(session);\n    minor = _gnutls_version_get_minor(ver);\n    major = _gnutls_version_get_major(ver);\n\n    blocksize = _gnutls_cipher_get_block_size(session->security_parameters.\n\t\t\t\t\t      read_bulk_cipher_algorithm);\n\n    /* initialize MAC \n     */\n    td = mac_init(session->security_parameters.read_mac_algorithm,\n\t\t  session->connection_state.read_mac_secret.data,\n\t\t  session->connection_state.read_mac_secret.size, ver);\n\n    if (td == GNUTLS_MAC_FAILED\n\t&& session->security_parameters.read_mac_algorithm !=\n\tGNUTLS_MAC_NULL) {\n\tgnutls_assert();\n\treturn GNUTLS_E_INTERNAL_ERROR;\n    }\n\n\n    /* actual decryption (inplace)\n     */\n    switch (_gnutls_cipher_is_block\n\t    (session->security_parameters.read_bulk_cipher_algorithm)) {\n    case CIPHER_STREAM:\n\tif ((ret = _gnutls_cipher_decrypt(session->connection_state.\n\t\t\t\t\t  read_cipher_state,\n\t\t\t\t\t  ciphertext.data,\n\t\t\t\t\t  ciphertext.size)) < 0) {\n\t    gnutls_assert();\n\t    return ret;\n\t}\n\n\tlength = ciphertext.size - hash_size;\n\n\tbreak;\n    case CIPHER_BLOCK:\n\tif ((ciphertext.size < blocksize)\n\t    || (ciphertext.size % blocksize != 0)) {\n\t    gnutls_assert();\n\t    return GNUTLS_E_DECRYPTION_FAILED;\n\t}\n\n\tif ((ret = _gnutls_cipher_decrypt(session->connection_state.\n\t\t\t\t\t  read_cipher_state,\n\t\t\t\t\t  ciphertext.data,\n\t\t\t\t\t  ciphertext.size)) < 0) {\n\t    gnutls_assert();\n\t    return ret;\n\t}\n\n\t/* ignore the IV in TLS 1.1.\n\t */\n\tif (session->security_parameters.version >= GNUTLS_TLS1_1) {\n\t    ciphertext.size -= blocksize;\n\t    ciphertext.data += blocksize;\n\n\t    if (ciphertext.size == 0) {\n\t\tgnutls_assert();\n\t\treturn GNUTLS_E_DECRYPTION_FAILED;\n\t    }\n\t}\n\n\tpad = ciphertext.data[ciphertext.size - 1] + 1;\t/* pad */\n\n\tlength = ciphertext.size - hash_size - pad;\n\n\tif (pad > ciphertext.size - hash_size) {\n\t    gnutls_assert();\n\t    /* We do not fail here. We check below for the\n\t     * the pad_failed. If zero means success.\n\t     */\n\t    pad_failed = GNUTLS_E_DECRYPTION_FAILED;\n\t}\n\n\t/* Check the pading bytes (TLS 1.x)\n\t */\n\tif (ver >= GNUTLS_TLS1 && pad_failed==0)\n\t    for (i = 2; i < pad; i++) {\n\t\tif (ciphertext.data[ciphertext.size - i] !=\n\t\t    ciphertext.data[ciphertext.size - 1])\n\t\t    pad_failed = GNUTLS_E_DECRYPTION_FAILED;\n\t    }\n\tbreak;\n    default:\n\tgnutls_assert();\n\treturn GNUTLS_E_INTERNAL_ERROR;\n    }\n\n    if (length < 0)\n\tlength = 0;\n    c_length = _gnutls_conv_uint16((uint16) length);\n\n    /* Pass the type, version, length and compressed through\n     * MAC.\n     */\n    if (td != GNUTLS_MAC_FAILED) {\n\t_gnutls_hmac(td,\n\t\t     UINT64DATA(session->connection_state.\n\t\t\t\tread_sequence_number), 8);\n\n\t_gnutls_hmac(td, &type, 1);\n\tif (ver >= GNUTLS_TLS1) {\t/* TLS 1.x */\n\t    _gnutls_hmac(td, &major, 1);\n\t    _gnutls_hmac(td, &minor, 1);\n\t}\n\t_gnutls_hmac(td, &c_length, 2);\n\n\tif (length > 0)\n\t    _gnutls_hmac(td, ciphertext.data, length);\n\n\tmac_deinit(td, MAC, ver);\n    }\n\n    /* This one was introduced to avoid a timing attack against the TLS\n     * 1.0 protocol.\n     */\n    if (pad_failed != 0)\n\treturn pad_failed;\n\n    /* HMAC was not the same. \n     */\n    if (memcmp(MAC, &ciphertext.data[length], hash_size) != 0) {\n\tgnutls_assert();\n\treturn GNUTLS_E_DECRYPTION_FAILED;\n    }\n\n    /* copy the decrypted stuff to compress_data.\n     */\n    if (compress_size < length) {\n\tgnutls_assert();\n\treturn GNUTLS_E_INTERNAL_ERROR;\n    }\n    memcpy(compress_data, ciphertext.data, length);\n\n    return length;\n}", "target": 0, "cwe": [], "project": "gnutls", "commit_id": "7ad6162573ba79a4392c63b453ad0220ca6c5ace", "hash": 158496975013272959571533274715541422662, "size": 156, "message": "added an extra check while checking the padding."}
{"func": "inline static int is_write_comp_null(gnutls_session_t session)\n{\n    if (session->security_parameters.write_compression_algorithm ==\n\tGNUTLS_COMP_NULL)\n\treturn 0;\n\n    return 1;\n}", "target": 0, "cwe": [], "project": "gnutls", "commit_id": "7ad6162573ba79a4392c63b453ad0220ca6c5ace", "hash": 119322514087527166454801906167102433500, "size": 8, "message": "added an extra check while checking the padding."}
{"func": "inline static int is_read_comp_null(gnutls_session_t session)\n{\n    if (session->security_parameters.read_compression_algorithm ==\n\tGNUTLS_COMP_NULL)\n\treturn 0;\n\n    return 1;\n}", "target": 0, "cwe": [], "project": "gnutls", "commit_id": "7ad6162573ba79a4392c63b453ad0220ca6c5ace", "hash": 186331153386239778509824193020346552887, "size": 8, "message": "added an extra check while checking the padding."}
{"func": "int _gnutls_encrypt(gnutls_session_t session, const opaque * headers,\n\t\t    size_t headers_size, const opaque * data,\n\t\t    size_t data_size, opaque * ciphertext,\n\t\t    size_t ciphertext_size, content_type_t type,\n\t\t    int random_pad)\n{\n    gnutls_datum_t plain;\n    gnutls_datum_t comp;\n    int ret;\n    int free_comp = 1;\n\n    plain.data = (opaque *) data;\n    plain.size = data_size;\n\n    if (plain.size == 0 || is_write_comp_null(session) == 0) {\n\tcomp = plain;\n\tfree_comp = 0;\n    } else {\n\t/* Here comp is allocated and must be \n\t * freed.\n\t */\n\tret = _gnutls_m_plaintext2compressed(session, &comp, plain);\n\tif (ret < 0) {\n\t    gnutls_assert();\n\t    return ret;\n\t}\n    }\n\n    ret = _gnutls_compressed2ciphertext(session, &ciphertext[headers_size],\n\t\t\t\t\tciphertext_size - headers_size,\n\t\t\t\t\tcomp, type, random_pad);\n\n    if (free_comp)\n\t_gnutls_free_datum(&comp);\n\n    if (ret < 0) {\n\tgnutls_assert();\n\treturn ret;\n    }\n\n\n    /* copy the headers */\n    memcpy(ciphertext, headers, headers_size);\n    _gnutls_write_uint16(ret, &ciphertext[3]);\n\n    return ret + headers_size;\n}", "target": 0, "cwe": [], "project": "gnutls", "commit_id": "7ad6162573ba79a4392c63b453ad0220ca6c5ace", "hash": 294926889118506914771512745949269390737, "size": 47, "message": "added an extra check while checking the padding."}
{"func": "mac_init(gnutls_mac_algorithm_t mac, opaque * secret, int secret_size,\n\t int ver)\n{\n    mac_hd_t td;\n\n    if (mac == GNUTLS_MAC_NULL)\n\treturn GNUTLS_MAC_FAILED;\n\n    if (ver == GNUTLS_SSL3) {\t/* SSL 3.0 */\n\ttd = _gnutls_mac_init_ssl3(mac, secret, secret_size);\n    } else {\t\t\t/* TLS 1.x */\n\ttd = _gnutls_hmac_init(mac, secret, secret_size);\n    }\n\n    return td;\n}", "target": 0, "cwe": [], "project": "gnutls", "commit_id": "7ad6162573ba79a4392c63b453ad0220ca6c5ace", "hash": 296838753533092808465537781903939082889, "size": 16, "message": "added an extra check while checking the padding."}
{"func": "inline static void mac_deinit(mac_hd_t td, opaque * res, int ver)\n{\n    if (ver == GNUTLS_SSL3) {\t/* SSL 3.0 */\n\t_gnutls_mac_deinit_ssl3(td, res);\n    } else {\n\t_gnutls_hmac_deinit(td, res);\n    }\n}", "target": 0, "cwe": [], "project": "gnutls", "commit_id": "7ad6162573ba79a4392c63b453ad0220ca6c5ace", "hash": 123187747839242397648315345367591237543, "size": 8, "message": "added an extra check while checking the padding."}
{"func": "static inline void cirrus_bitblt_bgcol(CirrusVGAState *s)\n{\n    unsigned int color;\n    switch (s->cirrus_blt_pixelwidth) {\n    case 1:\n        s->cirrus_blt_bgcol = s->cirrus_shadow_gr0;\n        break;\n    case 2:\n        color = s->cirrus_shadow_gr0 | (s->gr[0x10] << 8);\n        s->cirrus_blt_bgcol = le16_to_cpu(color);\n        break;\n    case 3:\n        s->cirrus_blt_bgcol = s->cirrus_shadow_gr0 |\n            (s->gr[0x10] << 8) | (s->gr[0x12] << 16);\n        break;\n    default:\n    case 4:\n        color = s->cirrus_shadow_gr0 | (s->gr[0x10] << 8) |\n            (s->gr[0x12] << 16) | (s->gr[0x14] << 24);\n        s->cirrus_blt_bgcol = le32_to_cpu(color);\n        break;\n    }\n}", "target": 0, "cwe": ["CWE-787"], "project": "qemu", "commit_id": "b2eb849d4b1fdb6f35d5c46958c7f703cf64cfef", "hash": 209924585110214439672843089672755322159, "size": 23, "message": "CVE-2007-1320 - Cirrus LGD-54XX \"bitblt\" heap overflow\n\nI have just noticed that patch for CVE-2007-1320 has never been applied\nto the QEMU CVS. Please find it below.\n\n| Multiple heap-based buffer overflows in the cirrus_invalidate_region\n| function in the Cirrus VGA extension in QEMU 0.8.2, as used in Xen and\n| possibly other products, might allow local users to execute arbitrary\n| code via unspecified vectors related to \"attempting to mark\n| non-existent regions as dirty,\" aka the \"bitblt\" heap overflow.\n\n\ngit-svn-id: svn://svn.savannah.nongnu.org/qemu/trunk@4340 c046a42c-6fe2-441c-8c8c-71466251a162"}
{"func": "static void cirrus_vga_mem_writeb(void *opaque, target_phys_addr_t addr,\n                                  uint32_t mem_value)\n{\n    CirrusVGAState *s = opaque;\n    unsigned bank_index;\n    unsigned bank_offset;\n    unsigned mode;\n\n    if ((s->sr[0x07] & 0x01) == 0) {\n\tvga_mem_writeb(s, addr, mem_value);\n        return;\n    }\n\n    addr &= 0x1ffff;\n\n    if (addr < 0x10000) {\n\tif (s->cirrus_srcptr != s->cirrus_srcptr_end) {\n\t    /* bitblt */\n\t    *s->cirrus_srcptr++ = (uint8_t) mem_value;\n\t    if (s->cirrus_srcptr >= s->cirrus_srcptr_end) {\n\t\tcirrus_bitblt_cputovideo_next(s);\n\t    }\n\t} else {\n\t    /* video memory */\n\t    bank_index = addr >> 15;\n\t    bank_offset = addr & 0x7fff;\n\t    if (bank_offset < s->cirrus_bank_limit[bank_index]) {\n\t\tbank_offset += s->cirrus_bank_base[bank_index];\n\t\tif ((s->gr[0x0B] & 0x14) == 0x14) {\n\t\t    bank_offset <<= 4;\n\t\t} else if (s->gr[0x0B] & 0x02) {\n\t\t    bank_offset <<= 3;\n\t\t}\n\t\tbank_offset &= s->cirrus_addr_mask;\n\t\tmode = s->gr[0x05] & 0x7;\n\t\tif (mode < 4 || mode > 5 || ((s->gr[0x0B] & 0x4) == 0)) {\n\t\t    *(s->vram_ptr + bank_offset) = mem_value;\n\t\t    cpu_physical_memory_set_dirty(s->vram_offset +\n\t\t\t\t\t\t  bank_offset);\n\t\t} else {\n\t\t    if ((s->gr[0x0B] & 0x14) != 0x14) {\n\t\t\tcirrus_mem_writeb_mode4and5_8bpp(s, mode,\n\t\t\t\t\t\t\t bank_offset,\n\t\t\t\t\t\t\t mem_value);\n\t\t    } else {\n\t\t\tcirrus_mem_writeb_mode4and5_16bpp(s, mode,\n\t\t\t\t\t\t\t  bank_offset,\n\t\t\t\t\t\t\t  mem_value);\n\t\t    }\n\t\t}\n\t    }\n\t}\n    } else if (addr >= 0x18000 && addr < 0x18100) {\n\t/* memory-mapped I/O */\n\tif ((s->sr[0x17] & 0x44) == 0x04) {\n\t    cirrus_mmio_blt_write(s, addr & 0xff, mem_value);\n\t}\n    } else {\n#ifdef DEBUG_CIRRUS\n\tprintf(\"cirrus: mem_writeb %06x value %02x\\n\", addr, mem_value);\n#endif\n    }\n}", "target": 0, "cwe": ["CWE-787"], "project": "qemu", "commit_id": "b2eb849d4b1fdb6f35d5c46958c7f703cf64cfef", "hash": 325319156759451925306778559778856459338, "size": 63, "message": "CVE-2007-1320 - Cirrus LGD-54XX \"bitblt\" heap overflow\n\nI have just noticed that patch for CVE-2007-1320 has never been applied\nto the QEMU CVS. Please find it below.\n\n| Multiple heap-based buffer overflows in the cirrus_invalidate_region\n| function in the Cirrus VGA extension in QEMU 0.8.2, as used in Xen and\n| possibly other products, might allow local users to execute arbitrary\n| code via unspecified vectors related to \"attempting to mark\n| non-existent regions as dirty,\" aka the \"bitblt\" heap overflow.\n\n\ngit-svn-id: svn://svn.savannah.nongnu.org/qemu/trunk@4340 c046a42c-6fe2-441c-8c8c-71466251a162"}
{"func": "static void cirrus_bitblt_reset(CirrusVGAState * s)\n{\n    s->gr[0x31] &=\n\t~(CIRRUS_BLT_START | CIRRUS_BLT_BUSY | CIRRUS_BLT_FIFOUSED);\n    s->cirrus_srcptr = &s->cirrus_bltbuf[0];\n    s->cirrus_srcptr_end = &s->cirrus_bltbuf[0];\n    s->cirrus_srccounter = 0;\n    cirrus_update_memory_access(s);\n}", "target": 0, "cwe": ["CWE-787"], "project": "qemu", "commit_id": "b2eb849d4b1fdb6f35d5c46958c7f703cf64cfef", "hash": 109098509340697264536150523824387703197, "size": 9, "message": "CVE-2007-1320 - Cirrus LGD-54XX \"bitblt\" heap overflow\n\nI have just noticed that patch for CVE-2007-1320 has never been applied\nto the QEMU CVS. Please find it below.\n\n| Multiple heap-based buffer overflows in the cirrus_invalidate_region\n| function in the Cirrus VGA extension in QEMU 0.8.2, as used in Xen and\n| possibly other products, might allow local users to execute arbitrary\n| code via unspecified vectors related to \"attempting to mark\n| non-existent regions as dirty,\" aka the \"bitblt\" heap overflow.\n\n\ngit-svn-id: svn://svn.savannah.nongnu.org/qemu/trunk@4340 c046a42c-6fe2-441c-8c8c-71466251a162"}
{"func": "glue(glue(cirrus_bitblt_rop_fwd_transp_, ROP_NAME),_8)(CirrusVGAState *s,\n\t\t\t\t\t\t       uint8_t *dst,const uint8_t *src,\n\t\t\t\t\t\t       int dstpitch,int srcpitch,\n\t\t\t\t\t\t       int bltwidth,int bltheight)\n{\n    int x,y;\n    uint8_t p;\n    dstpitch -= bltwidth;\n    srcpitch -= bltwidth;\n    for (y = 0; y < bltheight; y++) {\n        for (x = 0; x < bltwidth; x++) {\n\t    p = *dst;\n            ROP_OP(p, *src);\n\t    if (p != s->gr[0x34]) *dst = p;\n            dst++;\n            src++;\n        }\n        dst += dstpitch;\n        src += srcpitch;\n    }\n}", "target": 0, "cwe": ["CWE-787"], "project": "qemu", "commit_id": "b2eb849d4b1fdb6f35d5c46958c7f703cf64cfef", "hash": 192867493684831853931006465161860801842, "size": 21, "message": "CVE-2007-1320 - Cirrus LGD-54XX \"bitblt\" heap overflow\n\nI have just noticed that patch for CVE-2007-1320 has never been applied\nto the QEMU CVS. Please find it below.\n\n| Multiple heap-based buffer overflows in the cirrus_invalidate_region\n| function in the Cirrus VGA extension in QEMU 0.8.2, as used in Xen and\n| possibly other products, might allow local users to execute arbitrary\n| code via unspecified vectors related to \"attempting to mark\n| non-existent regions as dirty,\" aka the \"bitblt\" heap overflow.\n\n\ngit-svn-id: svn://svn.savannah.nongnu.org/qemu/trunk@4340 c046a42c-6fe2-441c-8c8c-71466251a162"}
{"func": "static uint32_t cirrus_get_bpp16_depth(CirrusVGAState * s)\n{\n    uint32_t ret = 16;\n\n    switch (s->cirrus_hidden_dac_data & 0xf) {\n    case 0:\n\tret = 15;\n\tbreak;\t\t\t/* Sierra HiColor */\n    case 1:\n\tret = 16;\n\tbreak;\t\t\t/* XGA HiColor */\n    default:\n#ifdef DEBUG_CIRRUS\n\tprintf(\"cirrus: invalid DAC value %x in 16bpp\\n\",\n\t       (s->cirrus_hidden_dac_data & 0xf));\n#endif\n\tret = 15;\t\t/* XXX */\n\tbreak;\n    }\n    return ret;\n}", "target": 0, "cwe": ["CWE-787"], "project": "qemu", "commit_id": "b2eb849d4b1fdb6f35d5c46958c7f703cf64cfef", "hash": 256065668890845458166476274192307072881, "size": 21, "message": "CVE-2007-1320 - Cirrus LGD-54XX \"bitblt\" heap overflow\n\nI have just noticed that patch for CVE-2007-1320 has never been applied\nto the QEMU CVS. Please find it below.\n\n| Multiple heap-based buffer overflows in the cirrus_invalidate_region\n| function in the Cirrus VGA extension in QEMU 0.8.2, as used in Xen and\n| possibly other products, might allow local users to execute arbitrary\n| code via unspecified vectors related to \"attempting to mark\n| non-existent regions as dirty,\" aka the \"bitblt\" heap overflow.\n\n\ngit-svn-id: svn://svn.savannah.nongnu.org/qemu/trunk@4340 c046a42c-6fe2-441c-8c8c-71466251a162"}
{"func": "glue(glue(cirrus_bitblt_rop_bkwd_transp_, ROP_NAME),_16)(CirrusVGAState *s,\n\t\t\t\t\t\t\t uint8_t *dst,const uint8_t *src,\n\t\t\t\t\t\t\t int dstpitch,int srcpitch,\n\t\t\t\t\t\t\t int bltwidth,int bltheight)\n{\n    int x,y;\n    uint8_t p1, p2;\n    dstpitch += bltwidth;\n    srcpitch += bltwidth;\n    for (y = 0; y < bltheight; y++) {\n        for (x = 0; x < bltwidth; x+=2) {\n\t    p1 = *(dst-1);\n\t    p2 = *dst;\n            ROP_OP(p1, *(src-1));\n            ROP_OP(p2, *src);\n\t    if ((p1 != s->gr[0x34]) || (p2 != s->gr[0x35])) {\n\t\t*(dst-1) = p1;\n\t\t*dst = p2;\n\t    }\n            dst-=2;\n            src-=2;\n        }\n        dst += dstpitch;\n        src += srcpitch;\n    }\n}", "target": 0, "cwe": ["CWE-787"], "project": "qemu", "commit_id": "b2eb849d4b1fdb6f35d5c46958c7f703cf64cfef", "hash": 26724004335636406514054021713772771086, "size": 26, "message": "CVE-2007-1320 - Cirrus LGD-54XX \"bitblt\" heap overflow\n\nI have just noticed that patch for CVE-2007-1320 has never been applied\nto the QEMU CVS. Please find it below.\n\n| Multiple heap-based buffer overflows in the cirrus_invalidate_region\n| function in the Cirrus VGA extension in QEMU 0.8.2, as used in Xen and\n| possibly other products, might allow local users to execute arbitrary\n| code via unspecified vectors related to \"attempting to mark\n| non-existent regions as dirty,\" aka the \"bitblt\" heap overflow.\n\n\ngit-svn-id: svn://svn.savannah.nongnu.org/qemu/trunk@4340 c046a42c-6fe2-441c-8c8c-71466251a162"}
{"func": "static void cirrus_bitblt_start(CirrusVGAState * s)\n{\n    uint8_t blt_rop;\n\n    s->gr[0x31] |= CIRRUS_BLT_BUSY;\n\n    s->cirrus_blt_width = (s->gr[0x20] | (s->gr[0x21] << 8)) + 1;\n    s->cirrus_blt_height = (s->gr[0x22] | (s->gr[0x23] << 8)) + 1;\n    s->cirrus_blt_dstpitch = (s->gr[0x24] | (s->gr[0x25] << 8));\n    s->cirrus_blt_srcpitch = (s->gr[0x26] | (s->gr[0x27] << 8));\n    s->cirrus_blt_dstaddr =\n\t(s->gr[0x28] | (s->gr[0x29] << 8) | (s->gr[0x2a] << 16));\n    s->cirrus_blt_srcaddr =\n\t(s->gr[0x2c] | (s->gr[0x2d] << 8) | (s->gr[0x2e] << 16));\n    s->cirrus_blt_mode = s->gr[0x30];\n    s->cirrus_blt_modeext = s->gr[0x33];\n    blt_rop = s->gr[0x32];\n\n#ifdef DEBUG_BITBLT\n    printf(\"rop=0x%02x mode=0x%02x modeext=0x%02x w=%d h=%d dpitch=%d spitch=%d daddr=0x%08x saddr=0x%08x writemask=0x%02x\\n\",\n           blt_rop,\n           s->cirrus_blt_mode,\n           s->cirrus_blt_modeext,\n           s->cirrus_blt_width,\n           s->cirrus_blt_height,\n           s->cirrus_blt_dstpitch,\n           s->cirrus_blt_srcpitch,\n           s->cirrus_blt_dstaddr,\n           s->cirrus_blt_srcaddr,\n           s->gr[0x2f]);\n#endif\n\n    switch (s->cirrus_blt_mode & CIRRUS_BLTMODE_PIXELWIDTHMASK) {\n    case CIRRUS_BLTMODE_PIXELWIDTH8:\n\ts->cirrus_blt_pixelwidth = 1;\n\tbreak;\n    case CIRRUS_BLTMODE_PIXELWIDTH16:\n\ts->cirrus_blt_pixelwidth = 2;\n\tbreak;\n    case CIRRUS_BLTMODE_PIXELWIDTH24:\n\ts->cirrus_blt_pixelwidth = 3;\n\tbreak;\n    case CIRRUS_BLTMODE_PIXELWIDTH32:\n\ts->cirrus_blt_pixelwidth = 4;\n\tbreak;\n    default:\n#ifdef DEBUG_BITBLT\n\tprintf(\"cirrus: bitblt - pixel width is unknown\\n\");\n#endif\n\tgoto bitblt_ignore;\n    }\n    s->cirrus_blt_mode &= ~CIRRUS_BLTMODE_PIXELWIDTHMASK;\n\n    if ((s->\n\t cirrus_blt_mode & (CIRRUS_BLTMODE_MEMSYSSRC |\n\t\t\t    CIRRUS_BLTMODE_MEMSYSDEST))\n\t== (CIRRUS_BLTMODE_MEMSYSSRC | CIRRUS_BLTMODE_MEMSYSDEST)) {\n#ifdef DEBUG_BITBLT\n\tprintf(\"cirrus: bitblt - memory-to-memory copy is requested\\n\");\n#endif\n\tgoto bitblt_ignore;\n    }\n\n    if ((s->cirrus_blt_modeext & CIRRUS_BLTMODEEXT_SOLIDFILL) &&\n        (s->cirrus_blt_mode & (CIRRUS_BLTMODE_MEMSYSDEST |\n                               CIRRUS_BLTMODE_TRANSPARENTCOMP |\n                               CIRRUS_BLTMODE_PATTERNCOPY |\n                               CIRRUS_BLTMODE_COLOREXPAND)) ==\n         (CIRRUS_BLTMODE_PATTERNCOPY | CIRRUS_BLTMODE_COLOREXPAND)) {\n        cirrus_bitblt_fgcol(s);\n        cirrus_bitblt_solidfill(s, blt_rop);\n    } else {\n        if ((s->cirrus_blt_mode & (CIRRUS_BLTMODE_COLOREXPAND |\n                                   CIRRUS_BLTMODE_PATTERNCOPY)) ==\n            CIRRUS_BLTMODE_COLOREXPAND) {\n\n            if (s->cirrus_blt_mode & CIRRUS_BLTMODE_TRANSPARENTCOMP) {\n                if (s->cirrus_blt_modeext & CIRRUS_BLTMODEEXT_COLOREXPINV)\n                    cirrus_bitblt_bgcol(s);\n                else\n                    cirrus_bitblt_fgcol(s);\n                s->cirrus_rop = cirrus_colorexpand_transp[rop_to_index[blt_rop]][s->cirrus_blt_pixelwidth - 1];\n            } else {\n                cirrus_bitblt_fgcol(s);\n                cirrus_bitblt_bgcol(s);\n                s->cirrus_rop = cirrus_colorexpand[rop_to_index[blt_rop]][s->cirrus_blt_pixelwidth - 1];\n            }\n        } else if (s->cirrus_blt_mode & CIRRUS_BLTMODE_PATTERNCOPY) {\n            if (s->cirrus_blt_mode & CIRRUS_BLTMODE_COLOREXPAND) {\n                if (s->cirrus_blt_mode & CIRRUS_BLTMODE_TRANSPARENTCOMP) {\n                    if (s->cirrus_blt_modeext & CIRRUS_BLTMODEEXT_COLOREXPINV)\n                        cirrus_bitblt_bgcol(s);\n                    else\n                        cirrus_bitblt_fgcol(s);\n                    s->cirrus_rop = cirrus_colorexpand_pattern_transp[rop_to_index[blt_rop]][s->cirrus_blt_pixelwidth - 1];\n                } else {\n                    cirrus_bitblt_fgcol(s);\n                    cirrus_bitblt_bgcol(s);\n                    s->cirrus_rop = cirrus_colorexpand_pattern[rop_to_index[blt_rop]][s->cirrus_blt_pixelwidth - 1];\n                }\n            } else {\n                s->cirrus_rop = cirrus_patternfill[rop_to_index[blt_rop]][s->cirrus_blt_pixelwidth - 1];\n            }\n        } else {\n\t    if (s->cirrus_blt_mode & CIRRUS_BLTMODE_TRANSPARENTCOMP) {\n\t\tif (s->cirrus_blt_pixelwidth > 2) {\n\t\t    printf(\"src transparent without colorexpand must be 8bpp or 16bpp\\n\");\n\t\t    goto bitblt_ignore;\n\t\t}\n\t\tif (s->cirrus_blt_mode & CIRRUS_BLTMODE_BACKWARDS) {\n\t\t    s->cirrus_blt_dstpitch = -s->cirrus_blt_dstpitch;\n\t\t    s->cirrus_blt_srcpitch = -s->cirrus_blt_srcpitch;\n\t\t    s->cirrus_rop = cirrus_bkwd_transp_rop[rop_to_index[blt_rop]][s->cirrus_blt_pixelwidth - 1];\n\t\t} else {\n\t\t    s->cirrus_rop = cirrus_fwd_transp_rop[rop_to_index[blt_rop]][s->cirrus_blt_pixelwidth - 1];\n\t\t}\n\t    } else {\n\t\tif (s->cirrus_blt_mode & CIRRUS_BLTMODE_BACKWARDS) {\n\t\t    s->cirrus_blt_dstpitch = -s->cirrus_blt_dstpitch;\n\t\t    s->cirrus_blt_srcpitch = -s->cirrus_blt_srcpitch;\n\t\t    s->cirrus_rop = cirrus_bkwd_rop[rop_to_index[blt_rop]];\n\t\t} else {\n\t\t    s->cirrus_rop = cirrus_fwd_rop[rop_to_index[blt_rop]];\n\t\t}\n\t    }\n\t}\n        // setup bitblt engine.\n        if (s->cirrus_blt_mode & CIRRUS_BLTMODE_MEMSYSSRC) {\n            if (!cirrus_bitblt_cputovideo(s))\n                goto bitblt_ignore;\n        } else if (s->cirrus_blt_mode & CIRRUS_BLTMODE_MEMSYSDEST) {\n            if (!cirrus_bitblt_videotocpu(s))\n                goto bitblt_ignore;\n        } else {\n            if (!cirrus_bitblt_videotovideo(s))\n                goto bitblt_ignore;\n        }\n    }\n    return;\n  bitblt_ignore:;\n    cirrus_bitblt_reset(s);\n}", "target": 0, "cwe": ["CWE-787"], "project": "qemu", "commit_id": "b2eb849d4b1fdb6f35d5c46958c7f703cf64cfef", "hash": 297221541426409817796343005986796669151, "size": 142, "message": "CVE-2007-1320 - Cirrus LGD-54XX \"bitblt\" heap overflow\n\nI have just noticed that patch for CVE-2007-1320 has never been applied\nto the QEMU CVS. Please find it below.\n\n| Multiple heap-based buffer overflows in the cirrus_invalidate_region\n| function in the Cirrus VGA extension in QEMU 0.8.2, as used in Xen and\n| possibly other products, might allow local users to execute arbitrary\n| code via unspecified vectors related to \"attempting to mark\n| non-existent regions as dirty,\" aka the \"bitblt\" heap overflow.\n\n\ngit-svn-id: svn://svn.savannah.nongnu.org/qemu/trunk@4340 c046a42c-6fe2-441c-8c8c-71466251a162"}
{"func": "glue(glue(cirrus_bitblt_rop_bkwd_transp_, ROP_NAME),_8)(CirrusVGAState *s,\n\t\t\t\t\t\t\tuint8_t *dst,const uint8_t *src,\n\t\t\t\t\t\t\tint dstpitch,int srcpitch,\n\t\t\t\t\t\t\tint bltwidth,int bltheight)\n{\n    int x,y;\n    uint8_t p;\n    dstpitch += bltwidth;\n    srcpitch += bltwidth;\n    for (y = 0; y < bltheight; y++) {\n        for (x = 0; x < bltwidth; x++) {\n\t    p = *dst;\n            ROP_OP(p, *src);\n\t    if (p != s->gr[0x34]) *dst = p;\n            dst--;\n            src--;\n        }\n        dst += dstpitch;\n        src += srcpitch;\n    }\n}", "target": 0, "cwe": ["CWE-787"], "project": "qemu", "commit_id": "b2eb849d4b1fdb6f35d5c46958c7f703cf64cfef", "hash": 202656166810501028692110517888269482110, "size": 21, "message": "CVE-2007-1320 - Cirrus LGD-54XX \"bitblt\" heap overflow\n\nI have just noticed that patch for CVE-2007-1320 has never been applied\nto the QEMU CVS. Please find it below.\n\n| Multiple heap-based buffer overflows in the cirrus_invalidate_region\n| function in the Cirrus VGA extension in QEMU 0.8.2, as used in Xen and\n| possibly other products, might allow local users to execute arbitrary\n| code via unspecified vectors related to \"attempting to mark\n| non-existent regions as dirty,\" aka the \"bitblt\" heap overflow.\n\n\ngit-svn-id: svn://svn.savannah.nongnu.org/qemu/trunk@4340 c046a42c-6fe2-441c-8c8c-71466251a162"}
{"func": "static void cirrus_mmio_writel(void *opaque, target_phys_addr_t addr,\n\t\t\t       uint32_t val)\n{\n#ifdef TARGET_WORDS_BIGENDIAN\n    cirrus_mmio_writeb(opaque, addr, (val >> 24) & 0xff);\n    cirrus_mmio_writeb(opaque, addr + 1, (val >> 16) & 0xff);\n    cirrus_mmio_writeb(opaque, addr + 2, (val >> 8) & 0xff);\n    cirrus_mmio_writeb(opaque, addr + 3, val & 0xff);\n#else\n    cirrus_mmio_writeb(opaque, addr, val & 0xff);\n    cirrus_mmio_writeb(opaque, addr + 1, (val >> 8) & 0xff);\n    cirrus_mmio_writeb(opaque, addr + 2, (val >> 16) & 0xff);\n    cirrus_mmio_writeb(opaque, addr + 3, (val >> 24) & 0xff);\n#endif\n}", "target": 0, "cwe": ["CWE-787"], "project": "qemu", "commit_id": "b2eb849d4b1fdb6f35d5c46958c7f703cf64cfef", "hash": 334699662091006313918310302634576482728, "size": 15, "message": "CVE-2007-1320 - Cirrus LGD-54XX \"bitblt\" heap overflow\n\nI have just noticed that patch for CVE-2007-1320 has never been applied\nto the QEMU CVS. Please find it below.\n\n| Multiple heap-based buffer overflows in the cirrus_invalidate_region\n| function in the Cirrus VGA extension in QEMU 0.8.2, as used in Xen and\n| possibly other products, might allow local users to execute arbitrary\n| code via unspecified vectors related to \"attempting to mark\n| non-existent regions as dirty,\" aka the \"bitblt\" heap overflow.\n\n\ngit-svn-id: svn://svn.savannah.nongnu.org/qemu/trunk@4340 c046a42c-6fe2-441c-8c8c-71466251a162"}
{"func": "static uint32_t cirrus_linear_bitblt_readb(void *opaque, target_phys_addr_t addr)\n{\n    uint32_t ret;\n\n    /* XXX handle bitblt */\n    ret = 0xff;\n    return ret;\n}", "target": 0, "cwe": ["CWE-787"], "project": "qemu", "commit_id": "b2eb849d4b1fdb6f35d5c46958c7f703cf64cfef", "hash": 147229127408331101444336786515903305612, "size": 8, "message": "CVE-2007-1320 - Cirrus LGD-54XX \"bitblt\" heap overflow\n\nI have just noticed that patch for CVE-2007-1320 has never been applied\nto the QEMU CVS. Please find it below.\n\n| Multiple heap-based buffer overflows in the cirrus_invalidate_region\n| function in the Cirrus VGA extension in QEMU 0.8.2, as used in Xen and\n| possibly other products, might allow local users to execute arbitrary\n| code via unspecified vectors related to \"attempting to mark\n| non-existent regions as dirty,\" aka the \"bitblt\" heap overflow.\n\n\ngit-svn-id: svn://svn.savannah.nongnu.org/qemu/trunk@4340 c046a42c-6fe2-441c-8c8c-71466251a162"}
{"func": "static inline void cirrus_cursor_compute_yrange(CirrusVGAState *s)\n{\n    const uint8_t *src;\n    uint32_t content;\n    int y, y_min, y_max;\n\n    src = s->vram_ptr + s->real_vram_size - 16 * 1024;\n    if (s->sr[0x12] & CIRRUS_CURSOR_LARGE) {\n        src += (s->sr[0x13] & 0x3c) * 256;\n        y_min = 64;\n        y_max = -1;\n        for(y = 0; y < 64; y++) {\n            content = ((uint32_t *)src)[0] |\n                ((uint32_t *)src)[1] |\n                ((uint32_t *)src)[2] |\n                ((uint32_t *)src)[3];\n            if (content) {\n                if (y < y_min)\n                    y_min = y;\n                if (y > y_max)\n                    y_max = y;\n            }\n            src += 16;\n        }\n    } else {\n        src += (s->sr[0x13] & 0x3f) * 256;\n        y_min = 32;\n        y_max = -1;\n        for(y = 0; y < 32; y++) {\n            content = ((uint32_t *)src)[0] |\n                ((uint32_t *)(src + 128))[0];\n            if (content) {\n                if (y < y_min)\n                    y_min = y;\n                if (y > y_max)\n                    y_max = y;\n            }\n            src += 4;\n        }\n    }\n    if (y_min > y_max) {\n        s->last_hw_cursor_y_start = 0;\n        s->last_hw_cursor_y_end = 0;\n    } else {\n        s->last_hw_cursor_y_start = y_min;\n        s->last_hw_cursor_y_end = y_max + 1;\n    }\n}", "target": 0, "cwe": ["CWE-787"], "project": "qemu", "commit_id": "b2eb849d4b1fdb6f35d5c46958c7f703cf64cfef", "hash": 218282585088483254928439665750673403346, "size": 48, "message": "CVE-2007-1320 - Cirrus LGD-54XX \"bitblt\" heap overflow\n\nI have just noticed that patch for CVE-2007-1320 has never been applied\nto the QEMU CVS. Please find it below.\n\n| Multiple heap-based buffer overflows in the cirrus_invalidate_region\n| function in the Cirrus VGA extension in QEMU 0.8.2, as used in Xen and\n| possibly other products, might allow local users to execute arbitrary\n| code via unspecified vectors related to \"attempting to mark\n| non-existent regions as dirty,\" aka the \"bitblt\" heap overflow.\n\n\ngit-svn-id: svn://svn.savannah.nongnu.org/qemu/trunk@4340 c046a42c-6fe2-441c-8c8c-71466251a162"}
{"func": "static void cirrus_pci_mmio_map(PCIDevice *d, int region_num,\n\t\t\t\tuint32_t addr, uint32_t size, int type)\n{\n    CirrusVGAState *s = &((PCICirrusVGAState *)d)->cirrus_vga;\n\n    cpu_register_physical_memory(addr, CIRRUS_PNPMMIO_SIZE,\n\t\t\t\t s->cirrus_mmio_io_addr);\n}", "target": 0, "cwe": ["CWE-787"], "project": "qemu", "commit_id": "b2eb849d4b1fdb6f35d5c46958c7f703cf64cfef", "hash": 69916388071407800172683104069445751440, "size": 8, "message": "CVE-2007-1320 - Cirrus LGD-54XX \"bitblt\" heap overflow\n\nI have just noticed that patch for CVE-2007-1320 has never been applied\nto the QEMU CVS. Please find it below.\n\n| Multiple heap-based buffer overflows in the cirrus_invalidate_region\n| function in the Cirrus VGA extension in QEMU 0.8.2, as used in Xen and\n| possibly other products, might allow local users to execute arbitrary\n| code via unspecified vectors related to \"attempting to mark\n| non-existent regions as dirty,\" aka the \"bitblt\" heap overflow.\n\n\ngit-svn-id: svn://svn.savannah.nongnu.org/qemu/trunk@4340 c046a42c-6fe2-441c-8c8c-71466251a162"}
{"func": "static void cirrus_mmio_blt_write(CirrusVGAState * s, unsigned address,\n\t\t\t\t  uint8_t value)\n{\n    switch (address) {\n    case (CIRRUS_MMIO_BLTBGCOLOR + 0):\n\tcirrus_hook_write_gr(s, 0x00, value);\n\tbreak;\n    case (CIRRUS_MMIO_BLTBGCOLOR + 1):\n\tcirrus_hook_write_gr(s, 0x10, value);\n\tbreak;\n    case (CIRRUS_MMIO_BLTBGCOLOR + 2):\n\tcirrus_hook_write_gr(s, 0x12, value);\n\tbreak;\n    case (CIRRUS_MMIO_BLTBGCOLOR + 3):\n\tcirrus_hook_write_gr(s, 0x14, value);\n\tbreak;\n    case (CIRRUS_MMIO_BLTFGCOLOR + 0):\n\tcirrus_hook_write_gr(s, 0x01, value);\n\tbreak;\n    case (CIRRUS_MMIO_BLTFGCOLOR + 1):\n\tcirrus_hook_write_gr(s, 0x11, value);\n\tbreak;\n    case (CIRRUS_MMIO_BLTFGCOLOR + 2):\n\tcirrus_hook_write_gr(s, 0x13, value);\n\tbreak;\n    case (CIRRUS_MMIO_BLTFGCOLOR + 3):\n\tcirrus_hook_write_gr(s, 0x15, value);\n\tbreak;\n    case (CIRRUS_MMIO_BLTWIDTH + 0):\n\tcirrus_hook_write_gr(s, 0x20, value);\n\tbreak;\n    case (CIRRUS_MMIO_BLTWIDTH + 1):\n\tcirrus_hook_write_gr(s, 0x21, value);\n\tbreak;\n    case (CIRRUS_MMIO_BLTHEIGHT + 0):\n\tcirrus_hook_write_gr(s, 0x22, value);\n\tbreak;\n    case (CIRRUS_MMIO_BLTHEIGHT + 1):\n\tcirrus_hook_write_gr(s, 0x23, value);\n\tbreak;\n    case (CIRRUS_MMIO_BLTDESTPITCH + 0):\n\tcirrus_hook_write_gr(s, 0x24, value);\n\tbreak;\n    case (CIRRUS_MMIO_BLTDESTPITCH + 1):\n\tcirrus_hook_write_gr(s, 0x25, value);\n\tbreak;\n    case (CIRRUS_MMIO_BLTSRCPITCH + 0):\n\tcirrus_hook_write_gr(s, 0x26, value);\n\tbreak;\n    case (CIRRUS_MMIO_BLTSRCPITCH + 1):\n\tcirrus_hook_write_gr(s, 0x27, value);\n\tbreak;\n    case (CIRRUS_MMIO_BLTDESTADDR + 0):\n\tcirrus_hook_write_gr(s, 0x28, value);\n\tbreak;\n    case (CIRRUS_MMIO_BLTDESTADDR + 1):\n\tcirrus_hook_write_gr(s, 0x29, value);\n\tbreak;\n    case (CIRRUS_MMIO_BLTDESTADDR + 2):\n\tcirrus_hook_write_gr(s, 0x2a, value);\n\tbreak;\n    case (CIRRUS_MMIO_BLTDESTADDR + 3):\n\t/* ignored */\n\tbreak;\n    case (CIRRUS_MMIO_BLTSRCADDR + 0):\n\tcirrus_hook_write_gr(s, 0x2c, value);\n\tbreak;\n    case (CIRRUS_MMIO_BLTSRCADDR + 1):\n\tcirrus_hook_write_gr(s, 0x2d, value);\n\tbreak;\n    case (CIRRUS_MMIO_BLTSRCADDR + 2):\n\tcirrus_hook_write_gr(s, 0x2e, value);\n\tbreak;\n    case CIRRUS_MMIO_BLTWRITEMASK:\n\tcirrus_hook_write_gr(s, 0x2f, value);\n\tbreak;\n    case CIRRUS_MMIO_BLTMODE:\n\tcirrus_hook_write_gr(s, 0x30, value);\n\tbreak;\n    case CIRRUS_MMIO_BLTROP:\n\tcirrus_hook_write_gr(s, 0x32, value);\n\tbreak;\n    case CIRRUS_MMIO_BLTMODEEXT:\n\tcirrus_hook_write_gr(s, 0x33, value);\n\tbreak;\n    case (CIRRUS_MMIO_BLTTRANSPARENTCOLOR + 0):\n\tcirrus_hook_write_gr(s, 0x34, value);\n\tbreak;\n    case (CIRRUS_MMIO_BLTTRANSPARENTCOLOR + 1):\n\tcirrus_hook_write_gr(s, 0x35, value);\n\tbreak;\n    case (CIRRUS_MMIO_BLTTRANSPARENTCOLORMASK + 0):\n\tcirrus_hook_write_gr(s, 0x38, value);\n\tbreak;\n    case (CIRRUS_MMIO_BLTTRANSPARENTCOLORMASK + 1):\n\tcirrus_hook_write_gr(s, 0x39, value);\n\tbreak;\n    case CIRRUS_MMIO_BLTSTATUS:\n\tcirrus_hook_write_gr(s, 0x31, value);\n\tbreak;\n    default:\n#ifdef DEBUG_CIRRUS\n\tprintf(\"cirrus: mmio write - addr 0x%04x val 0x%02x (ignored)\\n\",\n\t       address, value);\n#endif\n\tbreak;\n    }\n}", "target": 0, "cwe": ["CWE-787"], "project": "qemu", "commit_id": "b2eb849d4b1fdb6f35d5c46958c7f703cf64cfef", "hash": 247476223324605392633727640251935904726, "size": 108, "message": "CVE-2007-1320 - Cirrus LGD-54XX \"bitblt\" heap overflow\n\nI have just noticed that patch for CVE-2007-1320 has never been applied\nto the QEMU CVS. Please find it below.\n\n| Multiple heap-based buffer overflows in the cirrus_invalidate_region\n| function in the Cirrus VGA extension in QEMU 0.8.2, as used in Xen and\n| possibly other products, might allow local users to execute arbitrary\n| code via unspecified vectors related to \"attempting to mark\n| non-existent regions as dirty,\" aka the \"bitblt\" heap overflow.\n\n\ngit-svn-id: svn://svn.savannah.nongnu.org/qemu/trunk@4340 c046a42c-6fe2-441c-8c8c-71466251a162"}
{"func": "static void cirrus_read_hidden_dac(CirrusVGAState * s, int *reg_value)\n{\n    *reg_value = 0xff;\n    if (++s->cirrus_hidden_dac_lockindex == 5) {\n        *reg_value = s->cirrus_hidden_dac_data;\n\ts->cirrus_hidden_dac_lockindex = 0;\n    }\n}", "target": 0, "cwe": ["CWE-787"], "project": "qemu", "commit_id": "b2eb849d4b1fdb6f35d5c46958c7f703cf64cfef", "hash": 126250363499282960242779510559333560202, "size": 8, "message": "CVE-2007-1320 - Cirrus LGD-54XX \"bitblt\" heap overflow\n\nI have just noticed that patch for CVE-2007-1320 has never been applied\nto the QEMU CVS. Please find it below.\n\n| Multiple heap-based buffer overflows in the cirrus_invalidate_region\n| function in the Cirrus VGA extension in QEMU 0.8.2, as used in Xen and\n| possibly other products, might allow local users to execute arbitrary\n| code via unspecified vectors related to \"attempting to mark\n| non-existent regions as dirty,\" aka the \"bitblt\" heap overflow.\n\n\ngit-svn-id: svn://svn.savannah.nongnu.org/qemu/trunk@4340 c046a42c-6fe2-441c-8c8c-71466251a162"}
{"func": "static void cirrus_linear_writel(void *opaque, target_phys_addr_t addr,\n\t\t\t\t uint32_t val)\n{\n#ifdef TARGET_WORDS_BIGENDIAN\n    cirrus_linear_writeb(opaque, addr, (val >> 24) & 0xff);\n    cirrus_linear_writeb(opaque, addr + 1, (val >> 16) & 0xff);\n    cirrus_linear_writeb(opaque, addr + 2, (val >> 8) & 0xff);\n    cirrus_linear_writeb(opaque, addr + 3, val & 0xff);\n#else\n    cirrus_linear_writeb(opaque, addr, val & 0xff);\n    cirrus_linear_writeb(opaque, addr + 1, (val >> 8) & 0xff);\n    cirrus_linear_writeb(opaque, addr + 2, (val >> 16) & 0xff);\n    cirrus_linear_writeb(opaque, addr + 3, (val >> 24) & 0xff);\n#endif\n}", "target": 0, "cwe": ["CWE-787"], "project": "qemu", "commit_id": "b2eb849d4b1fdb6f35d5c46958c7f703cf64cfef", "hash": 267317670837418283728227944167906376864, "size": 15, "message": "CVE-2007-1320 - Cirrus LGD-54XX \"bitblt\" heap overflow\n\nI have just noticed that patch for CVE-2007-1320 has never been applied\nto the QEMU CVS. Please find it below.\n\n| Multiple heap-based buffer overflows in the cirrus_invalidate_region\n| function in the Cirrus VGA extension in QEMU 0.8.2, as used in Xen and\n| possibly other products, might allow local users to execute arbitrary\n| code via unspecified vectors related to \"attempting to mark\n| non-existent regions as dirty,\" aka the \"bitblt\" heap overflow.\n\n\ngit-svn-id: svn://svn.savannah.nongnu.org/qemu/trunk@4340 c046a42c-6fe2-441c-8c8c-71466251a162"}
{"func": "static inline void invalidate_cursor1(CirrusVGAState *s)\n{\n    if (s->last_hw_cursor_size) {\n        vga_invalidate_scanlines((VGAState *)s,\n                                 s->last_hw_cursor_y + s->last_hw_cursor_y_start,\n                                 s->last_hw_cursor_y + s->last_hw_cursor_y_end);\n    }\n}", "target": 0, "cwe": ["CWE-787"], "project": "qemu", "commit_id": "b2eb849d4b1fdb6f35d5c46958c7f703cf64cfef", "hash": 65595313429928489956058731213652164801, "size": 8, "message": "CVE-2007-1320 - Cirrus LGD-54XX \"bitblt\" heap overflow\n\nI have just noticed that patch for CVE-2007-1320 has never been applied\nto the QEMU CVS. Please find it below.\n\n| Multiple heap-based buffer overflows in the cirrus_invalidate_region\n| function in the Cirrus VGA extension in QEMU 0.8.2, as used in Xen and\n| possibly other products, might allow local users to execute arbitrary\n| code via unspecified vectors related to \"attempting to mark\n| non-existent regions as dirty,\" aka the \"bitblt\" heap overflow.\n\n\ngit-svn-id: svn://svn.savannah.nongnu.org/qemu/trunk@4340 c046a42c-6fe2-441c-8c8c-71466251a162"}